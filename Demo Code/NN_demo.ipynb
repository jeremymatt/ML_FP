{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries and set the plotting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import Sequential \n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from RPD import RPD\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "#set plotting defaults\n",
    "mpl.rcParams['font.size'] = 12\n",
    "mpl.rcParams['axes.grid'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data samples for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'samples_20k_30min.xlsx'\n",
    "samples_all = pd.read_excel(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mask the samples that were generated using no bad data and keep only those samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = samples_all['sum_t1-n_labels']==0\n",
    "samples = samples_all[mask].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate header variables to use when indexing into the pandas dataframes and generate X, Y, and label variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['solar:','temp:','speed:','dir:','u','v']\n",
    "\n",
    "#Extract the headers associated with the X variables \n",
    "variable_headers = [var for var in samples.keys() if var.split('|')[0] in variables]\n",
    "y_headers = [key for key in variable_headers if int(key.split('|')[1]) == 0]\n",
    "x_headers = ['month','day','hour','minute']\n",
    "x_headers.extend([key for key in variable_headers if int(key.split('|')[1]) > 0])\n",
    "\n",
    "label_headers = ['label|{}'.format(var) for var in variables]\n",
    "\n",
    "X = samples[x_headers].values\n",
    "Y = samples[y_headers].values\n",
    "labels = samples[label_headers].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the data and split into testing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scaler = StandardScaler()\n",
    "y_scaler.fit(Y)\n",
    "Y_scale = y_scaler.transform(Y)\n",
    "Y_scale = Y\n",
    "\n",
    "x_scaler = StandardScaler()\n",
    "x_scaler.fit(X)\n",
    "X_scale = x_scaler.transform(X)\n",
    "X_scale = X\n",
    "\n",
    "xtrain, xval, ytrain, yval,label_train,label_val = train_test_split(X_scale, Y_scale, labels, test_size=0.20, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12688 samples, validate on 3173 samples\n",
      "Epoch 1/20\n",
      "12688/12688 [==============================] - 1s 58us/step - loss: 1070.6028 - val_loss: 321.9341\n",
      "Epoch 2/20\n",
      "12688/12688 [==============================] - 0s 33us/step - loss: 369.9080 - val_loss: 333.2736\n",
      "Epoch 3/20\n",
      "12688/12688 [==============================] - 0s 33us/step - loss: 357.2801 - val_loss: 308.7238\n",
      "Epoch 4/20\n",
      "12688/12688 [==============================] - 0s 33us/step - loss: 346.7893 - val_loss: 296.1304\n",
      "Epoch 5/20\n",
      "12688/12688 [==============================] - 0s 33us/step - loss: 343.8886 - val_loss: 313.3415\n",
      "Epoch 6/20\n",
      "12688/12688 [==============================] - 0s 33us/step - loss: 339.0934 - val_loss: 305.8460\n",
      "Epoch 7/20\n",
      "12688/12688 [==============================] - 0s 33us/step - loss: 351.3769 - val_loss: 291.7359\n",
      "Epoch 8/20\n",
      "12688/12688 [==============================] - 0s 33us/step - loss: 341.0846 - val_loss: 288.9746\n",
      "Epoch 9/20\n",
      "12688/12688 [==============================] - 0s 33us/step - loss: 346.1785 - val_loss: 298.3139\n",
      "Epoch 10/20\n",
      "12688/12688 [==============================] - 0s 35us/step - loss: 347.8342 - val_loss: 288.3521\n",
      "Epoch 11/20\n",
      "12688/12688 [==============================] - 0s 34us/step - loss: 338.1211 - val_loss: 308.9481\n",
      "Epoch 12/20\n",
      "12688/12688 [==============================] - 0s 35us/step - loss: 336.4101 - val_loss: 282.8084\n",
      "Epoch 13/20\n",
      "12688/12688 [==============================] - 0s 35us/step - loss: 339.1750 - val_loss: 299.4527\n",
      "Epoch 14/20\n",
      "12688/12688 [==============================] - 1s 40us/step - loss: 334.9807 - val_loss: 287.1403\n",
      "Epoch 15/20\n",
      "12688/12688 [==============================] - 0s 35us/step - loss: 333.6382 - val_loss: 283.1751\n",
      "Epoch 16/20\n",
      "12688/12688 [==============================] - 1s 42us/step - loss: 332.9985 - val_loss: 287.7059\n",
      "Epoch 17/20\n",
      "12688/12688 [==============================] - 0s 35us/step - loss: 335.2345 - val_loss: 299.9781\n",
      "Epoch 18/20\n",
      "12688/12688 [==============================] - 0s 37us/step - loss: 330.7574 - val_loss: 283.6559\n",
      "Epoch 19/20\n",
      "12688/12688 [==============================] - 0s 36us/step - loss: 334.2851 - val_loss: 283.5912\n",
      "Epoch 20/20\n",
      "12688/12688 [==============================] - 0s 35us/step - loss: 332.4501 - val_loss: 281.6534\n",
      "Train on 12688 samples, validate on 3173 samples\n",
      "Epoch 1/500\n",
      "12688/12688 [==============================] - 0s 30us/step - loss: 23984.9154 - val_loss: 17948.3863\n",
      "Epoch 2/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 13783.0684 - val_loss: 7263.9320\n",
      "Epoch 3/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 5267.2627 - val_loss: 2045.6535\n",
      "Epoch 4/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1860.3930 - val_loss: 1430.0308\n",
      "Epoch 5/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1719.7511 - val_loss: 1183.0354\n",
      "Epoch 6/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1465.4482 - val_loss: 1104.6635\n",
      "Epoch 7/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1319.8214 - val_loss: 967.6037\n",
      "Epoch 8/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1185.2086 - val_loss: 878.6370\n",
      "Epoch 9/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1086.1246 - val_loss: 774.3863\n",
      "Epoch 10/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1005.9522 - val_loss: 704.2820\n",
      "Epoch 11/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 972.0006 - val_loss: 695.2708\n",
      "Epoch 12/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 948.6742 - val_loss: 658.9344\n",
      "Epoch 13/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 912.1660 - val_loss: 681.8390\n",
      "Epoch 14/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 887.2283 - val_loss: 646.9612\n",
      "Epoch 15/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 870.9979 - val_loss: 633.3417\n",
      "Epoch 16/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 866.4788 - val_loss: 628.7210\n",
      "Epoch 17/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 852.5747 - val_loss: 639.5050\n",
      "Epoch 18/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 840.8104 - val_loss: 619.1616\n",
      "Epoch 19/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 830.7086 - val_loss: 618.5623\n",
      "Epoch 20/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 822.3891 - val_loss: 616.6656\n",
      "Epoch 21/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 821.6916 - val_loss: 609.3654\n",
      "Epoch 22/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 814.0959 - val_loss: 610.1288\n",
      "Epoch 23/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 815.0905 - val_loss: 615.8266\n",
      "Epoch 24/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 810.6014 - val_loss: 604.9388\n",
      "Epoch 25/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 804.5998 - val_loss: 607.2093\n",
      "Epoch 26/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 802.1473 - val_loss: 599.1357\n",
      "Epoch 27/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 800.4449 - val_loss: 598.6558\n",
      "Epoch 28/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 794.6251 - val_loss: 628.0889\n",
      "Epoch 29/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 810.5479 - val_loss: 598.2916\n",
      "Epoch 30/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 800.2974 - val_loss: 595.0375\n",
      "Epoch 31/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 797.2121 - val_loss: 602.9536\n",
      "Epoch 32/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 793.7067 - val_loss: 609.7674\n",
      "Epoch 33/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 787.8396 - val_loss: 593.8739\n",
      "Epoch 34/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 783.8672 - val_loss: 595.0824\n",
      "Epoch 35/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 782.8858 - val_loss: 592.8720\n",
      "Epoch 36/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 784.5289 - val_loss: 596.0640\n",
      "Epoch 37/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 792.6625 - val_loss: 615.4164\n",
      "Epoch 38/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 802.6724 - val_loss: 641.6305\n",
      "Epoch 39/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 844.1581 - val_loss: 671.9986\n",
      "Epoch 40/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 798.7921 - val_loss: 589.5576\n",
      "Epoch 41/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 785.5678 - val_loss: 597.8963\n",
      "Epoch 42/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 790.1973 - val_loss: 593.1219\n",
      "Epoch 43/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 777.1717 - val_loss: 589.8243\n",
      "Epoch 44/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 777.6003 - val_loss: 607.3534\n",
      "Epoch 45/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 783.1323 - val_loss: 589.0216\n",
      "Epoch 46/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 778.5673 - val_loss: 598.9637\n",
      "Epoch 47/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 777.5522 - val_loss: 604.4676\n",
      "Epoch 48/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 781.6552 - val_loss: 602.7971\n",
      "Epoch 49/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 785.2805 - val_loss: 599.8534\n",
      "Epoch 50/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 785.4105 - val_loss: 598.0449\n",
      "Epoch 51/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 783.6473 - val_loss: 597.2515\n",
      "Epoch 52/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 774.4359 - val_loss: 588.3989\n",
      "Epoch 53/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 769.9169 - val_loss: 592.0230\n",
      "Epoch 54/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 775.9799 - val_loss: 587.2473\n",
      "Epoch 55/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 781.0239 - val_loss: 586.5011\n",
      "Epoch 56/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 782.5237 - val_loss: 608.7102\n",
      "Epoch 57/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 782.3294 - val_loss: 585.5988\n",
      "Epoch 58/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 780.8902 - val_loss: 589.0915\n",
      "Epoch 59/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 773.3913 - val_loss: 614.5106\n",
      "Epoch 60/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 775.4714 - val_loss: 591.2247\n",
      "Epoch 61/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 773.5421 - val_loss: 590.0807\n",
      "Epoch 62/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 767.5084 - val_loss: 593.8803\n",
      "Epoch 63/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 772.5514 - val_loss: 598.1725\n",
      "Epoch 64/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 765.3483 - val_loss: 587.9587\n",
      "Epoch 65/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 763.9291 - val_loss: 589.6950\n",
      "Epoch 66/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 762.3650 - val_loss: 608.4893\n",
      "Epoch 67/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 762.9717 - val_loss: 585.5029\n",
      "Epoch 68/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 789.5975 - val_loss: 699.6766\n",
      "Epoch 69/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 820.8980 - val_loss: 608.3168\n",
      "Epoch 70/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 768.4776 - val_loss: 585.7052\n",
      "Epoch 71/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 761.5901 - val_loss: 596.4713\n",
      "Epoch 72/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 772.3110 - val_loss: 602.7541\n",
      "Epoch 73/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 765.3795 - val_loss: 585.6075\n",
      "Epoch 74/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 763.9690 - val_loss: 589.7624\n",
      "Epoch 75/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 776.3797 - val_loss: 587.1144\n",
      "Epoch 76/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 760.1355 - val_loss: 587.5046\n",
      "Epoch 77/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 758.3354 - val_loss: 692.7063\n",
      "Epoch 78/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 786.2472 - val_loss: 589.9369\n",
      "Epoch 79/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 758.7230 - val_loss: 611.6885\n",
      "Epoch 80/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 761.2573 - val_loss: 588.3707\n",
      "Epoch 81/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 765.7882 - val_loss: 583.4604\n",
      "Epoch 82/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 755.9950 - val_loss: 586.1816\n",
      "Epoch 83/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 755.7141 - val_loss: 589.2921\n",
      "Epoch 84/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 760.2795 - val_loss: 594.1829\n",
      "Epoch 85/500\n",
      "12688/12688 [==============================] - 0s 7us/step - loss: 761.3926 - val_loss: 595.6609\n",
      "Epoch 86/500\n",
      "12688/12688 [==============================] - 0s 7us/step - loss: 754.7981 - val_loss: 625.8938\n",
      "Epoch 87/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 776.7899 - val_loss: 598.9730\n",
      "Epoch 88/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 786.0851 - val_loss: 597.9807\n",
      "Epoch 89/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 768.5739 - val_loss: 616.4329\n",
      "Epoch 90/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 759.0551 - val_loss: 643.1698\n",
      "Epoch 91/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 770.5346 - val_loss: 589.5017\n",
      "Epoch 92/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 750.3227 - val_loss: 584.0233\n",
      "Epoch 93/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 749.0057 - val_loss: 583.1865\n",
      "Epoch 94/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 748.5562 - val_loss: 606.0615\n",
      "Epoch 95/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 753.1422 - val_loss: 583.1201\n",
      "Epoch 96/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 751.0547 - val_loss: 616.7361\n",
      "Epoch 97/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 758.1208 - val_loss: 605.4621\n",
      "Epoch 98/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 750.2956 - val_loss: 613.2430\n",
      "Epoch 99/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 785.0845 - val_loss: 600.7760\n",
      "Epoch 100/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 810.8429 - val_loss: 686.9681\n",
      "Epoch 101/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 849.5629 - val_loss: 700.0532\n",
      "Epoch 102/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 762.8406 - val_loss: 603.8953\n",
      "Epoch 103/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 749.9115 - val_loss: 634.0851\n",
      "Epoch 104/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 755.4799 - val_loss: 598.3318\n",
      "Epoch 105/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 758.9996 - val_loss: 604.9924\n",
      "Epoch 106/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 750.1898 - val_loss: 585.6600\n",
      "Epoch 107/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 746.1722 - val_loss: 605.6467\n",
      "Epoch 108/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 754.5077 - val_loss: 590.4138\n",
      "Epoch 109/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 746.3416 - val_loss: 583.7655\n",
      "Epoch 110/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 742.0372 - val_loss: 592.2958\n",
      "Epoch 111/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 739.4138 - val_loss: 589.6340\n",
      "Epoch 112/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 742.7437 - val_loss: 584.8850\n",
      "Epoch 113/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 736.8285 - val_loss: 591.3499\n",
      "Epoch 114/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 740.1027 - val_loss: 597.5405\n",
      "Epoch 115/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 740.1524 - val_loss: 587.4280\n",
      "Epoch 116/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 747.6528 - val_loss: 605.7244\n",
      "Epoch 117/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 740.6881 - val_loss: 592.2077\n",
      "Epoch 118/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 738.3100 - val_loss: 594.4317\n",
      "Epoch 119/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 736.3548 - val_loss: 588.4804\n",
      "Epoch 120/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 746.0121 - val_loss: 588.4563\n",
      "Epoch 121/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 737.0569 - val_loss: 584.0860\n",
      "Epoch 122/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 736.6221 - val_loss: 583.1595\n",
      "Epoch 123/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 735.8670 - val_loss: 585.1080\n",
      "Epoch 124/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 740.4569 - val_loss: 587.5444\n",
      "Epoch 125/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 731.3963 - val_loss: 586.4202\n",
      "Epoch 126/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 724.5944 - val_loss: 587.0738\n",
      "Epoch 127/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 745.8270 - val_loss: 603.9153\n",
      "Epoch 128/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12688/12688 [==============================] - 0s 3us/step - loss: 738.9119 - val_loss: 586.2767\n",
      "Epoch 129/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 730.1070 - val_loss: 586.7375\n",
      "Epoch 130/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 737.0148 - val_loss: 588.3191\n",
      "Epoch 131/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 730.1208 - val_loss: 585.4340\n",
      "Epoch 132/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 723.5489 - val_loss: 585.0955\n",
      "Epoch 133/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 725.2145 - val_loss: 584.7499\n",
      "Epoch 134/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 727.3650 - val_loss: 595.0667\n",
      "Epoch 135/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 727.6598 - val_loss: 598.5773\n",
      "Epoch 136/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 726.5689 - val_loss: 605.7227\n",
      "Epoch 137/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 744.2702 - val_loss: 589.3575\n",
      "Epoch 138/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 729.7774 - val_loss: 595.7430\n",
      "Epoch 139/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 716.4040 - val_loss: 586.0494\n",
      "Epoch 140/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 723.0388 - val_loss: 594.6907\n",
      "Epoch 141/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 726.3086 - val_loss: 601.4232\n",
      "Epoch 142/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 722.2151 - val_loss: 584.9084\n",
      "Epoch 143/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 720.4392 - val_loss: 591.0370\n",
      "Epoch 144/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 718.6310 - val_loss: 587.3485\n",
      "Epoch 145/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 723.4400 - val_loss: 595.2634\n",
      "Epoch 146/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 748.0495 - val_loss: 666.3329\n",
      "Epoch 147/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 740.8180 - val_loss: 586.7913\n",
      "Epoch 148/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 716.0245 - val_loss: 601.1293\n",
      "Epoch 149/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 714.4411 - val_loss: 607.9537\n",
      "Epoch 150/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 724.4337 - val_loss: 612.6362\n",
      "Epoch 151/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 710.7823 - val_loss: 597.9491\n",
      "Epoch 152/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 718.1273 - val_loss: 591.3861\n",
      "Epoch 153/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 708.8494 - val_loss: 585.8729\n",
      "Epoch 154/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 718.5219 - val_loss: 608.3253\n",
      "Epoch 155/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 711.9541 - val_loss: 600.4124\n",
      "Epoch 156/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 707.3414 - val_loss: 589.5451\n",
      "Epoch 157/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 718.4044 - val_loss: 588.9004\n",
      "Epoch 158/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 709.1969 - val_loss: 660.5647\n",
      "Epoch 159/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 724.1936 - val_loss: 586.3802\n",
      "Epoch 160/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 727.9086 - val_loss: 651.2625\n",
      "Epoch 161/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 734.5757 - val_loss: 593.1756\n",
      "Epoch 162/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 738.4345 - val_loss: 617.7784\n",
      "Epoch 163/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 713.6612 - val_loss: 598.1976\n",
      "Epoch 164/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 718.2265 - val_loss: 593.4998\n",
      "Epoch 165/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 701.2338 - val_loss: 594.0224\n",
      "Epoch 166/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 704.0912 - val_loss: 594.1342\n",
      "Epoch 167/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 717.4287 - val_loss: 614.4854\n",
      "Epoch 168/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 701.4999 - val_loss: 586.1839\n",
      "Epoch 169/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 702.7832 - val_loss: 593.4834\n",
      "Epoch 170/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 711.2677 - val_loss: 588.9230\n",
      "Epoch 171/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 696.4035 - val_loss: 598.2722\n",
      "Epoch 172/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 703.1859 - val_loss: 626.6182\n",
      "Epoch 173/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 710.3233 - val_loss: 594.4087\n",
      "Epoch 174/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 700.1232 - val_loss: 639.1442\n",
      "Epoch 175/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 721.3111 - val_loss: 599.9362\n",
      "Epoch 176/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 711.2119 - val_loss: 615.0835\n",
      "Epoch 177/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 703.7674 - val_loss: 591.3993\n",
      "Epoch 178/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 690.5126 - val_loss: 590.7747\n",
      "Epoch 179/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 694.0730 - val_loss: 608.0791\n",
      "Epoch 180/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 726.1788 - val_loss: 588.5262\n",
      "Epoch 181/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 717.1156 - val_loss: 587.8601\n",
      "Epoch 182/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 693.4651 - val_loss: 597.9652\n",
      "Epoch 183/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 689.0429 - val_loss: 593.2150\n",
      "Epoch 184/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 693.7337 - val_loss: 613.3400\n",
      "Epoch 185/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 693.4344 - val_loss: 605.1008\n",
      "Epoch 186/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 692.1005 - val_loss: 590.5415\n",
      "Epoch 187/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 703.0503 - val_loss: 588.2178\n",
      "Epoch 188/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 687.3771 - val_loss: 589.5280\n",
      "Epoch 189/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 685.4639 - val_loss: 593.6865\n",
      "Epoch 190/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 691.0829 - val_loss: 588.6977\n",
      "Epoch 191/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 702.2788 - val_loss: 634.9122\n",
      "Epoch 192/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 706.3565 - val_loss: 588.3902\n",
      "Epoch 193/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 687.8857 - val_loss: 592.5718\n",
      "Epoch 194/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 695.0933 - val_loss: 591.8490\n",
      "Epoch 195/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 685.7487 - val_loss: 591.3823\n",
      "Epoch 196/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 686.6440 - val_loss: 590.5707\n",
      "Epoch 197/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 683.9885 - val_loss: 611.7381\n",
      "Epoch 198/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 686.8759 - val_loss: 588.5444\n",
      "Epoch 199/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 687.1521 - val_loss: 592.2610\n",
      "Epoch 200/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 701.1274 - val_loss: 611.6355\n",
      "Epoch 201/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 684.2556 - val_loss: 592.9214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 202/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 677.6044 - val_loss: 589.4260\n",
      "Epoch 203/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 684.5104 - val_loss: 589.2326\n",
      "Epoch 204/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 686.4176 - val_loss: 599.3856\n",
      "Epoch 205/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 692.1079 - val_loss: 592.5465\n",
      "Epoch 206/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 713.0607 - val_loss: 652.9184\n",
      "Epoch 207/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 710.6271 - val_loss: 592.6475\n",
      "Epoch 208/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 689.0083 - val_loss: 599.6522\n",
      "Epoch 209/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 679.2766 - val_loss: 592.6633\n",
      "Epoch 210/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 679.3048 - val_loss: 592.2468\n",
      "Epoch 211/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 688.5372 - val_loss: 592.5785\n",
      "Epoch 212/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 674.4061 - val_loss: 589.9827\n",
      "Epoch 213/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 674.4858 - val_loss: 594.0401\n",
      "Epoch 214/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 682.4589 - val_loss: 597.1940\n",
      "Epoch 215/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 678.7336 - val_loss: 600.3521\n",
      "Epoch 216/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 677.1344 - val_loss: 592.9113\n",
      "Epoch 217/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 673.6990 - val_loss: 602.4348\n",
      "Epoch 218/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 671.3040 - val_loss: 590.3449\n",
      "Epoch 219/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 677.7507 - val_loss: 591.1868\n",
      "Epoch 220/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 682.2660 - val_loss: 603.9644\n",
      "Epoch 221/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 677.5345 - val_loss: 597.9019\n",
      "Epoch 222/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 675.4885 - val_loss: 619.0035\n",
      "Epoch 223/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 676.2056 - val_loss: 605.2810\n",
      "Epoch 224/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 675.1292 - val_loss: 625.1891\n",
      "Epoch 225/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 694.7109 - val_loss: 616.0451\n",
      "Epoch 226/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 686.2217 - val_loss: 642.5144\n",
      "Epoch 227/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 676.8574 - val_loss: 597.4160\n",
      "Epoch 228/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 679.3279 - val_loss: 596.8636\n",
      "Epoch 229/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 669.8685 - val_loss: 595.3126\n",
      "Epoch 230/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 665.1429 - val_loss: 633.0731\n",
      "Epoch 231/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 677.0366 - val_loss: 596.2671\n",
      "Epoch 232/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 663.9181 - val_loss: 601.9856\n",
      "Epoch 233/500\n",
      "12688/12688 [==============================] - ETA: 0s - loss: 608.891 - 0s 4us/step - loss: 670.9723 - val_loss: 602.0215\n",
      "Epoch 234/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 667.2842 - val_loss: 599.6041\n",
      "Epoch 235/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 669.6612 - val_loss: 600.7046\n",
      "Epoch 236/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 663.0863 - val_loss: 597.1708\n",
      "Epoch 237/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 665.6172 - val_loss: 610.4320\n",
      "Epoch 238/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 662.6946 - val_loss: 597.0786\n",
      "Epoch 239/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 664.6226 - val_loss: 605.6812\n",
      "Epoch 240/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 666.2806 - val_loss: 618.6674\n",
      "Epoch 241/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 668.9828 - val_loss: 594.3146\n",
      "Epoch 242/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 663.7622 - val_loss: 610.0066\n",
      "Epoch 243/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 676.2983 - val_loss: 599.5498\n",
      "Epoch 244/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 659.9097 - val_loss: 620.8786\n",
      "Epoch 245/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 678.6010 - val_loss: 628.8256\n",
      "Epoch 246/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 676.6155 - val_loss: 605.9085\n",
      "Epoch 247/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 673.8246 - val_loss: 605.0735\n",
      "Epoch 248/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 667.6675 - val_loss: 599.4587\n",
      "Epoch 249/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 665.0860 - val_loss: 600.8309\n",
      "Epoch 250/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 662.9458 - val_loss: 597.4094\n",
      "Epoch 251/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 681.6155 - val_loss: 662.8074\n",
      "Epoch 252/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 702.5766 - val_loss: 635.5342\n",
      "Epoch 253/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 662.0962 - val_loss: 604.3397\n",
      "Epoch 254/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 657.5354 - val_loss: 609.9785\n",
      "Epoch 255/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 662.1875 - val_loss: 599.3182\n",
      "Epoch 256/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 672.7039 - val_loss: 620.4782\n",
      "Epoch 257/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 662.9141 - val_loss: 596.2914\n",
      "Epoch 258/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 656.9749 - val_loss: 615.1133\n",
      "Epoch 259/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 662.2792 - val_loss: 597.7558\n",
      "Epoch 260/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 652.9384 - val_loss: 604.8818\n",
      "Epoch 261/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 678.4223 - val_loss: 597.2523\n",
      "Epoch 262/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 669.8510 - val_loss: 606.2687\n",
      "Epoch 263/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 667.6750 - val_loss: 599.2609\n",
      "Epoch 264/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 657.7080 - val_loss: 596.0689\n",
      "Epoch 265/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 674.0823 - val_loss: 598.9706\n",
      "Epoch 266/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 660.9224 - val_loss: 645.9231\n",
      "Epoch 267/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 664.4912 - val_loss: 597.7027\n",
      "Epoch 268/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 663.8026 - val_loss: 597.6234\n",
      "Epoch 269/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 648.4667 - val_loss: 628.0432\n",
      "Epoch 270/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 660.1541 - val_loss: 640.5315\n",
      "Epoch 271/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 651.4855 - val_loss: 617.2535\n",
      "Epoch 272/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 655.6181 - val_loss: 600.3392\n",
      "Epoch 273/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 653.1775 - val_loss: 618.3138\n",
      "Epoch 274/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 649.9668 - val_loss: 625.4424\n",
      "Epoch 275/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 653.3413 - val_loss: 598.0899\n",
      "Epoch 276/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 655.9004 - val_loss: 599.5685\n",
      "Epoch 277/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 646.3763 - val_loss: 611.4049\n",
      "Epoch 278/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 671.3971 - val_loss: 633.8889\n",
      "Epoch 279/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 644.1716 - val_loss: 606.2827\n",
      "Epoch 280/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 642.3739 - val_loss: 626.0211\n",
      "Epoch 281/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 649.7869 - val_loss: 612.6807\n",
      "Epoch 282/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 647.8648 - val_loss: 633.1669\n",
      "Epoch 283/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 675.6509 - val_loss: 605.5680\n",
      "Epoch 284/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 661.2842 - val_loss: 707.0901\n",
      "Epoch 285/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 690.8024 - val_loss: 638.0207\n",
      "Epoch 286/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 678.6420 - val_loss: 675.4482\n",
      "Epoch 287/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 650.4912 - val_loss: 610.4265\n",
      "Epoch 288/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 632.6841 - val_loss: 607.5711\n",
      "Epoch 289/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 638.3896 - val_loss: 605.0732\n",
      "Epoch 290/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 638.1450 - val_loss: 609.1637\n",
      "Epoch 291/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 645.2680 - val_loss: 650.0079\n",
      "Epoch 292/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 668.1941 - val_loss: 651.8438\n",
      "Epoch 293/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 643.6170 - val_loss: 662.7119\n",
      "Epoch 294/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 665.0441 - val_loss: 615.5565\n",
      "Epoch 295/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 650.0464 - val_loss: 634.3205\n",
      "Epoch 296/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 644.3896 - val_loss: 602.4455\n",
      "Epoch 297/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 646.0092 - val_loss: 616.5778\n",
      "Epoch 298/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 641.0379 - val_loss: 598.7961\n",
      "Epoch 299/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 640.8572 - val_loss: 617.0429\n",
      "Epoch 300/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 627.1312 - val_loss: 610.2126\n",
      "Epoch 301/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 628.7976 - val_loss: 605.4436\n",
      "Epoch 302/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 628.2285 - val_loss: 611.3767\n",
      "Epoch 303/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 624.7914 - val_loss: 599.5946\n",
      "Epoch 304/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 633.7744 - val_loss: 602.1957\n",
      "Epoch 305/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 628.3398 - val_loss: 607.8278\n",
      "Epoch 306/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 632.3537 - val_loss: 610.4715\n",
      "Epoch 307/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 647.0788 - val_loss: 599.6453\n",
      "Epoch 308/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 643.5667 - val_loss: 618.3878\n",
      "Epoch 309/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 621.8957 - val_loss: 606.8497\n",
      "Epoch 310/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 624.3720 - val_loss: 602.2895\n",
      "Epoch 311/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 626.0839 - val_loss: 610.4049\n",
      "Epoch 312/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 626.5517 - val_loss: 599.8287\n",
      "Epoch 313/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 629.0924 - val_loss: 602.9720\n",
      "Epoch 314/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 622.6795 - val_loss: 605.9938\n",
      "Epoch 315/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 631.6882 - val_loss: 608.3079\n",
      "Epoch 316/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 622.5186 - val_loss: 611.4190\n",
      "Epoch 317/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 619.7629 - val_loss: 603.0771\n",
      "Epoch 318/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 624.8254 - val_loss: 620.3804\n",
      "Epoch 319/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 625.4463 - val_loss: 612.6050\n",
      "Epoch 320/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 644.1676 - val_loss: 603.5786\n",
      "Epoch 321/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 635.1781 - val_loss: 610.7812\n",
      "Epoch 322/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 620.8754 - val_loss: 610.0240\n",
      "Epoch 323/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 617.2719 - val_loss: 611.3455\n",
      "Epoch 324/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 622.9618 - val_loss: 619.2113\n",
      "Epoch 325/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 629.9653 - val_loss: 608.8494\n",
      "Epoch 326/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 633.4722 - val_loss: 613.1881\n",
      "Epoch 327/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 647.9640 - val_loss: 623.9043\n",
      "Epoch 328/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 622.9855 - val_loss: 605.2177\n",
      "Epoch 329/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 622.7180 - val_loss: 623.8167\n",
      "Epoch 330/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 618.9436 - val_loss: 611.5942\n",
      "Epoch 331/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 617.1796 - val_loss: 612.5217\n",
      "Epoch 332/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 616.0417 - val_loss: 610.0150\n",
      "Epoch 333/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 613.3789 - val_loss: 610.7840\n",
      "Epoch 334/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 626.0249 - val_loss: 629.4585\n",
      "Epoch 335/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 630.8096 - val_loss: 613.5505\n",
      "Epoch 336/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 617.6870 - val_loss: 609.7029\n",
      "Epoch 337/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 623.7566 - val_loss: 631.6304\n",
      "Epoch 338/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 606.2065 - val_loss: 623.9249\n",
      "Epoch 339/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 620.5707 - val_loss: 630.7635\n",
      "Epoch 340/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 612.3586 - val_loss: 606.9358\n",
      "Epoch 341/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 626.6105 - val_loss: 623.4798\n",
      "Epoch 342/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 608.3057 - val_loss: 621.8112\n",
      "Epoch 343/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 614.5212 - val_loss: 610.3542\n",
      "Epoch 344/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 622.5432 - val_loss: 634.5243\n",
      "Epoch 345/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 619.8193 - val_loss: 605.9976\n",
      "Epoch 346/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 623.6216 - val_loss: 631.3805\n",
      "Epoch 347/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 624.6485 - val_loss: 607.9346\n",
      "Epoch 348/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 611.8480 - val_loss: 644.7053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 629.6077 - val_loss: 612.0215\n",
      "Epoch 350/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 601.9004 - val_loss: 621.1436\n",
      "Epoch 351/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 611.5211 - val_loss: 638.8037\n",
      "Epoch 352/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 612.4449 - val_loss: 610.3613\n",
      "Epoch 353/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 604.2927 - val_loss: 640.9713\n",
      "Epoch 354/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 620.4107 - val_loss: 630.7383\n",
      "Epoch 355/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 626.8792 - val_loss: 611.5679\n",
      "Epoch 356/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 615.7890 - val_loss: 623.3068\n",
      "Epoch 357/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 603.8439 - val_loss: 613.6750\n",
      "Epoch 358/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 608.9266 - val_loss: 612.1389\n",
      "Epoch 359/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 605.6568 - val_loss: 618.6760\n",
      "Epoch 360/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 602.8270 - val_loss: 612.0795\n",
      "Epoch 361/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 597.0303 - val_loss: 626.4349\n",
      "Epoch 362/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 610.0092 - val_loss: 608.8869\n",
      "Epoch 363/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 609.2807 - val_loss: 691.8464\n",
      "Epoch 364/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 628.4533 - val_loss: 638.2691\n",
      "Epoch 365/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 605.7474 - val_loss: 610.2517\n",
      "Epoch 366/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 596.8282 - val_loss: 632.6116\n",
      "Epoch 367/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 608.2277 - val_loss: 608.7793\n",
      "Epoch 368/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 609.0455 - val_loss: 635.5225\n",
      "Epoch 369/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 597.3355 - val_loss: 608.3937\n",
      "Epoch 370/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 600.7681 - val_loss: 681.3162\n",
      "Epoch 371/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 612.8880 - val_loss: 619.6133\n",
      "Epoch 372/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 597.2486 - val_loss: 629.1828\n",
      "Epoch 373/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 592.0575 - val_loss: 610.8383\n",
      "Epoch 374/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 589.0340 - val_loss: 610.6129\n",
      "Epoch 375/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 592.0414 - val_loss: 620.6772\n",
      "Epoch 376/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 598.1057 - val_loss: 647.0633\n",
      "Epoch 377/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 603.6624 - val_loss: 613.7415\n",
      "Epoch 378/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 585.4885 - val_loss: 614.4565\n",
      "Epoch 379/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 590.3036 - val_loss: 622.8133\n",
      "Epoch 380/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 600.1681 - val_loss: 614.7861\n",
      "Epoch 381/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 599.7387 - val_loss: 617.2017\n",
      "Epoch 382/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 598.6745 - val_loss: 630.0914\n",
      "Epoch 383/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 590.3853 - val_loss: 620.1469\n",
      "Epoch 384/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 583.1048 - val_loss: 617.2825\n",
      "Epoch 385/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 588.0017 - val_loss: 657.0950\n",
      "Epoch 386/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 604.6252 - val_loss: 619.2939\n",
      "Epoch 387/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 592.9160 - val_loss: 624.8026\n",
      "Epoch 388/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 590.3490 - val_loss: 612.1318\n",
      "Epoch 389/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 587.8319 - val_loss: 615.0086\n",
      "Epoch 390/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 587.4418 - val_loss: 650.6093\n",
      "Epoch 391/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 602.5375 - val_loss: 617.7386\n",
      "Epoch 392/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 583.9470 - val_loss: 610.3928\n",
      "Epoch 393/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 609.8275 - val_loss: 639.9603\n",
      "Epoch 394/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 608.5053 - val_loss: 648.4767\n",
      "Epoch 395/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 605.9388 - val_loss: 642.2681\n",
      "Epoch 396/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 585.3167 - val_loss: 625.7688\n",
      "Epoch 397/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 590.8966 - val_loss: 621.4353\n",
      "Epoch 398/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 583.7077 - val_loss: 626.5112\n",
      "Epoch 399/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 588.1238 - val_loss: 635.4973\n",
      "Epoch 400/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 593.3772 - val_loss: 643.6152\n",
      "Epoch 401/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 589.7863 - val_loss: 611.6045\n",
      "Epoch 402/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 589.2371 - val_loss: 620.4524\n",
      "Epoch 403/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 591.7233 - val_loss: 623.5405\n",
      "Epoch 404/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 612.7344 - val_loss: 641.1045\n",
      "Epoch 405/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 596.1588 - val_loss: 619.8086\n",
      "Epoch 406/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 590.0874 - val_loss: 607.2102\n",
      "Epoch 407/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 599.9149 - val_loss: 688.9351\n",
      "Epoch 408/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 601.2796 - val_loss: 630.6620\n",
      "Epoch 409/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 577.3614 - val_loss: 615.2695\n",
      "Epoch 410/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 565.7906 - val_loss: 615.6095\n",
      "Epoch 411/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 574.6201 - val_loss: 671.6641\n",
      "Epoch 412/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 599.5386 - val_loss: 619.2904\n",
      "Epoch 413/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 586.8396 - val_loss: 612.5667\n",
      "Epoch 414/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 562.7560 - val_loss: 628.4979\n",
      "Epoch 415/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 572.1453 - val_loss: 610.5464\n",
      "Epoch 416/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 614.2897 - val_loss: 617.3695\n",
      "Epoch 417/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 638.2938 - val_loss: 726.6209\n",
      "Epoch 418/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 601.5184 - val_loss: 612.2427\n",
      "Epoch 419/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 578.8621 - val_loss: 671.6559\n",
      "Epoch 420/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 604.5036 - val_loss: 635.3023\n",
      "Epoch 421/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 571.1472 - val_loss: 610.5046\n",
      "Epoch 422/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 567.5231 - val_loss: 632.0672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 423/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 580.7854 - val_loss: 611.5559\n",
      "Epoch 424/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 572.2690 - val_loss: 610.7581\n",
      "Epoch 425/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 573.6111 - val_loss: 665.6639\n",
      "Epoch 426/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 588.6897 - val_loss: 613.6253\n",
      "Epoch 427/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 575.5593 - val_loss: 611.6832\n",
      "Epoch 428/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 567.5492 - val_loss: 631.5783\n",
      "Epoch 429/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 570.1036 - val_loss: 614.3994\n",
      "Epoch 430/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 563.3758 - val_loss: 621.7917\n",
      "Epoch 431/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 565.7299 - val_loss: 611.2204\n",
      "Epoch 432/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 557.7734 - val_loss: 623.9483\n",
      "Epoch 433/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 566.9291 - val_loss: 648.6801\n",
      "Epoch 434/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 601.7119 - val_loss: 621.9507\n",
      "Epoch 435/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 571.1914 - val_loss: 625.0387\n",
      "Epoch 436/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 572.8438 - val_loss: 628.0458\n",
      "Epoch 437/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 570.0626 - val_loss: 622.6908\n",
      "Epoch 438/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 564.3931 - val_loss: 613.8349\n",
      "Epoch 439/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 553.4276 - val_loss: 612.5914\n",
      "Epoch 440/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 553.4374 - val_loss: 635.3806\n",
      "Epoch 441/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 560.7963 - val_loss: 615.6370\n",
      "Epoch 442/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 556.0456 - val_loss: 613.3976\n",
      "Epoch 443/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 546.5294 - val_loss: 615.5303\n",
      "Epoch 444/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 560.9430 - val_loss: 623.5166\n",
      "Epoch 445/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 579.0902 - val_loss: 618.0867\n",
      "Epoch 446/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 559.4088 - val_loss: 618.2850\n",
      "Epoch 447/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 558.7876 - val_loss: 605.1853\n",
      "Epoch 448/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 558.0202 - val_loss: 611.8044\n",
      "Epoch 449/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 546.5425 - val_loss: 621.1702\n",
      "Epoch 450/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 555.8492 - val_loss: 650.1546\n",
      "Epoch 451/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 550.7924 - val_loss: 614.0556\n",
      "Epoch 452/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 556.8235 - val_loss: 667.4782\n",
      "Epoch 453/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 562.9337 - val_loss: 615.7687\n",
      "Epoch 454/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 545.9247 - val_loss: 611.0055\n",
      "Epoch 455/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 542.6975 - val_loss: 609.9579\n",
      "Epoch 456/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 548.5258 - val_loss: 616.7852\n",
      "Epoch 457/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 545.9128 - val_loss: 627.5699\n",
      "Epoch 458/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 542.0124 - val_loss: 632.4945\n",
      "Epoch 459/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 542.8421 - val_loss: 609.8994\n",
      "Epoch 460/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 547.5802 - val_loss: 610.4462\n",
      "Epoch 461/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 540.0439 - val_loss: 615.1900\n",
      "Epoch 462/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 541.4316 - val_loss: 618.3995\n",
      "Epoch 463/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 536.7672 - val_loss: 613.6063\n",
      "Epoch 464/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 538.7076 - val_loss: 617.7878\n",
      "Epoch 465/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 559.5295 - val_loss: 608.8719\n",
      "Epoch 466/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 554.2854 - val_loss: 631.7422\n",
      "Epoch 467/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 546.5742 - val_loss: 603.1297\n",
      "Epoch 468/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 542.4170 - val_loss: 649.1878\n",
      "Epoch 469/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 538.3331 - val_loss: 622.8387\n",
      "Epoch 470/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 532.8739 - val_loss: 610.4013\n",
      "Epoch 471/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 525.4737 - val_loss: 612.7976\n",
      "Epoch 472/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 535.5089 - val_loss: 622.1770\n",
      "Epoch 473/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 537.2050 - val_loss: 610.5483\n",
      "Epoch 474/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 525.4569 - val_loss: 625.3223\n",
      "Epoch 475/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 547.4650 - val_loss: 622.8093\n",
      "Epoch 476/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 553.5078 - val_loss: 608.9373\n",
      "Epoch 477/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 529.6831 - val_loss: 624.1632\n",
      "Epoch 478/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 525.4273 - val_loss: 612.9202\n",
      "Epoch 479/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 523.9379 - val_loss: 615.1941\n",
      "Epoch 480/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 519.2762 - val_loss: 611.6604\n",
      "Epoch 481/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 528.2123 - val_loss: 610.2758\n",
      "Epoch 482/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 535.3855 - val_loss: 643.0990\n",
      "Epoch 483/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 519.8410 - val_loss: 612.0516\n",
      "Epoch 484/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 532.3459 - val_loss: 615.2251\n",
      "Epoch 485/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 548.4155 - val_loss: 621.9007\n",
      "Epoch 486/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 517.7810 - val_loss: 618.0831\n",
      "Epoch 487/500\n",
      "12688/12688 [==============================] - 0s 9us/step - loss: 553.3570 - val_loss: 647.2276\n",
      "Epoch 488/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 559.5787 - val_loss: 608.0116\n",
      "Epoch 489/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 518.3484 - val_loss: 611.6308\n",
      "Epoch 490/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 522.3948 - val_loss: 632.8563\n",
      "Epoch 491/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 525.7769 - val_loss: 617.2808\n",
      "Epoch 492/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 514.6762 - val_loss: 639.5203\n",
      "Epoch 493/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 538.4541 - val_loss: 620.4111\n",
      "Epoch 494/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 512.0690 - val_loss: 616.0284\n",
      "Epoch 495/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 512.1888 - val_loss: 611.8745\n",
      "Epoch 496/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 522.7402 - val_loss: 615.8876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 518.3320 - val_loss: 614.6551\n",
      "Epoch 498/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 513.8227 - val_loss: 620.3810\n",
      "Epoch 499/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 515.4150 - val_loss: 615.9436\n",
      "Epoch 500/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 515.6097 - val_loss: 613.1085\n",
      "Train on 12688 samples, validate on 3173 samples\n",
      "Epoch 1/500\n",
      "12688/12688 [==============================] - 0s 30us/step - loss: 666.2410 - val_loss: 331.6450\n",
      "Epoch 2/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 295.4511 - val_loss: 215.2786\n",
      "Epoch 3/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 164.6454 - val_loss: 100.8889\n",
      "Epoch 4/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 55.1747 - val_loss: 25.9923\n",
      "Epoch 5/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 23.9446 - val_loss: 19.4800\n",
      "Epoch 6/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 14.5006 - val_loss: 11.4269\n",
      "Epoch 7/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 8.7153 - val_loss: 6.4477\n",
      "Epoch 8/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 4.7559 - val_loss: 3.4169\n",
      "Epoch 9/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 2.7061 - val_loss: 2.1200\n",
      "Epoch 10/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 2.0014 - val_loss: 1.7688\n",
      "Epoch 11/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.7260 - val_loss: 1.5199\n",
      "Epoch 12/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5545 - val_loss: 1.4363\n",
      "Epoch 13/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4702 - val_loss: 1.3383\n",
      "Epoch 14/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4438 - val_loss: 1.3121\n",
      "Epoch 15/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4606 - val_loss: 1.3958\n",
      "Epoch 16/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3332 - val_loss: 1.1864\n",
      "Epoch 17/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.2499 - val_loss: 1.1606\n",
      "Epoch 18/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.2261 - val_loss: 1.1714\n",
      "Epoch 19/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.2207 - val_loss: 1.1288\n",
      "Epoch 20/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.1965 - val_loss: 1.0946\n",
      "Epoch 21/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.1439 - val_loss: 1.0879\n",
      "Epoch 22/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.1297 - val_loss: 1.0787\n",
      "Epoch 23/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.1157 - val_loss: 1.0682\n",
      "Epoch 24/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.1031 - val_loss: 1.0453\n",
      "Epoch 25/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.0831 - val_loss: 1.0480\n",
      "Epoch 26/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 1.0591 - val_loss: 1.0462\n",
      "Epoch 27/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.1176 - val_loss: 1.0129\n",
      "Epoch 28/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.0840 - val_loss: 1.0001\n",
      "Epoch 29/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.0320 - val_loss: 1.0194\n",
      "Epoch 30/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.0450 - val_loss: 1.0045\n",
      "Epoch 31/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.0234 - val_loss: 0.9662\n",
      "Epoch 32/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.9975 - val_loss: 0.9593\n",
      "Epoch 33/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.0098 - val_loss: 1.0503\n",
      "Epoch 34/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.0265 - val_loss: 0.9528\n",
      "Epoch 35/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.0103 - val_loss: 1.0306\n",
      "Epoch 36/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.0311 - val_loss: 0.9306\n",
      "Epoch 37/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.9698 - val_loss: 0.9521\n",
      "Epoch 38/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.9563 - val_loss: 0.9572\n",
      "Epoch 39/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.9741 - val_loss: 0.9107\n",
      "Epoch 40/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.9395 - val_loss: 0.9083\n",
      "Epoch 41/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.9346 - val_loss: 0.9253\n",
      "Epoch 42/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.9281 - val_loss: 0.9160\n",
      "Epoch 43/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.9406 - val_loss: 0.9903\n",
      "Epoch 44/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.9741 - val_loss: 1.0326\n",
      "Epoch 45/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.0114 - val_loss: 1.0208\n",
      "Epoch 46/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.0269 - val_loss: 1.0010\n",
      "Epoch 47/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.9469 - val_loss: 0.9712\n",
      "Epoch 48/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.9102 - val_loss: 0.8625\n",
      "Epoch 49/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.8921 - val_loss: 0.8781\n",
      "Epoch 50/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.8814 - val_loss: 0.8548\n",
      "Epoch 51/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.9402 - val_loss: 0.8644\n",
      "Epoch 52/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.8946 - val_loss: 0.8565\n",
      "Epoch 53/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.8586 - val_loss: 0.8907\n",
      "Epoch 54/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.8881 - val_loss: 0.8916\n",
      "Epoch 55/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.9150 - val_loss: 0.8784\n",
      "Epoch 56/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.8674 - val_loss: 0.8297\n",
      "Epoch 57/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.8645 - val_loss: 0.8711\n",
      "Epoch 58/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.9035 - val_loss: 0.8312\n",
      "Epoch 59/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.8562 - val_loss: 0.8695\n",
      "Epoch 60/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.8401 - val_loss: 0.8313\n",
      "Epoch 61/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.8244 - val_loss: 0.8612\n",
      "Epoch 62/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.8361 - val_loss: 0.8142\n",
      "Epoch 63/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.8171 - val_loss: 0.8117\n",
      "Epoch 64/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.8328 - val_loss: 1.1175\n",
      "Epoch 65/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.9802 - val_loss: 0.7964\n",
      "Epoch 66/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.9122 - val_loss: 0.8090\n",
      "Epoch 67/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.8049 - val_loss: 0.7934\n",
      "Epoch 68/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.8180 - val_loss: 0.9485\n",
      "Epoch 69/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.8979 - val_loss: 0.8107\n",
      "Epoch 70/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.8113 - val_loss: 0.7868\n",
      "Epoch 71/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.9114 - val_loss: 0.9559\n",
      "Epoch 72/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.8727 - val_loss: 0.8872\n",
      "Epoch 73/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.8150 - val_loss: 0.7844\n",
      "Epoch 74/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7882 - val_loss: 0.8200\n",
      "Epoch 75/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.8158 - val_loss: 0.7738\n",
      "Epoch 76/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7873 - val_loss: 0.7728\n",
      "Epoch 77/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.8000 - val_loss: 0.8573\n",
      "Epoch 78/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.8282 - val_loss: 0.8904\n",
      "Epoch 79/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.8515 - val_loss: 0.7691\n",
      "Epoch 80/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.8246 - val_loss: 0.7710\n",
      "Epoch 81/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7835 - val_loss: 0.7670\n",
      "Epoch 82/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.8015 - val_loss: 0.7737\n",
      "Epoch 83/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.8213 - val_loss: 0.8392\n",
      "Epoch 84/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7797 - val_loss: 0.7968\n",
      "Epoch 85/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7516 - val_loss: 0.7373\n",
      "Epoch 86/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7329 - val_loss: 0.7970\n",
      "Epoch 87/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7975 - val_loss: 0.8787\n",
      "Epoch 88/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.7727 - val_loss: 0.7561\n",
      "Epoch 89/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7562 - val_loss: 0.7428\n",
      "Epoch 90/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7226 - val_loss: 0.7492\n",
      "Epoch 91/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7325 - val_loss: 0.7295\n",
      "Epoch 92/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7389 - val_loss: 0.7454\n",
      "Epoch 93/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7253 - val_loss: 0.7261\n",
      "Epoch 94/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7791 - val_loss: 0.7337\n",
      "Epoch 95/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7703 - val_loss: 0.7248\n",
      "Epoch 96/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7223 - val_loss: 0.7969\n",
      "Epoch 97/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7472 - val_loss: 0.8057\n",
      "Epoch 98/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7135 - val_loss: 0.7057\n",
      "Epoch 99/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7150 - val_loss: 0.7373\n",
      "Epoch 100/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.8679 - val_loss: 0.6985\n",
      "Epoch 101/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.8218 - val_loss: 1.1259\n",
      "Epoch 102/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.8065 - val_loss: 0.7437\n",
      "Epoch 103/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7797 - val_loss: 1.0714\n",
      "Epoch 104/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.8081 - val_loss: 0.7653\n",
      "Epoch 105/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6839 - val_loss: 0.7068\n",
      "Epoch 106/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6974 - val_loss: 0.8227\n",
      "Epoch 107/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6826 - val_loss: 0.6869\n",
      "Epoch 108/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6781 - val_loss: 0.6858\n",
      "Epoch 109/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6999 - val_loss: 0.7588\n",
      "Epoch 110/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6732 - val_loss: 0.6957\n",
      "Epoch 111/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6901 - val_loss: 0.6834\n",
      "Epoch 112/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6881 - val_loss: 0.7026\n",
      "Epoch 113/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7339 - val_loss: 0.7730\n",
      "Epoch 114/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6962 - val_loss: 0.7380\n",
      "Epoch 115/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7094 - val_loss: 0.7151\n",
      "Epoch 116/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.0515 - val_loss: 0.6963\n",
      "Epoch 117/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7826 - val_loss: 0.6894\n",
      "Epoch 118/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6767 - val_loss: 0.6621\n",
      "Epoch 119/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6639 - val_loss: 0.6682\n",
      "Epoch 120/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6535 - val_loss: 0.6550\n",
      "Epoch 121/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6973 - val_loss: 0.6563\n",
      "Epoch 122/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7319 - val_loss: 0.7683\n",
      "Epoch 123/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7251 - val_loss: 0.6672\n",
      "Epoch 124/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6928 - val_loss: 0.7510\n",
      "Epoch 125/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.7105 - val_loss: 0.7259\n",
      "Epoch 126/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.6903 - val_loss: 0.7120\n",
      "Epoch 127/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6606 - val_loss: 0.6758\n",
      "Epoch 128/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6615 - val_loss: 0.7262\n",
      "Epoch 129/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7216 - val_loss: 0.7845\n",
      "Epoch 130/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6680 - val_loss: 0.7412\n",
      "Epoch 131/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6498 - val_loss: 0.6563\n",
      "Epoch 132/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6220 - val_loss: 0.6426\n",
      "Epoch 133/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6517 - val_loss: 0.6399\n",
      "Epoch 134/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6504 - val_loss: 0.6328\n",
      "Epoch 135/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6500 - val_loss: 0.6334\n",
      "Epoch 136/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6419 - val_loss: 0.6338\n",
      "Epoch 137/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6673 - val_loss: 0.8048\n",
      "Epoch 138/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6453 - val_loss: 0.6695\n",
      "Epoch 139/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5992 - val_loss: 0.6316\n",
      "Epoch 140/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6045 - val_loss: 0.6281\n",
      "Epoch 141/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6275 - val_loss: 0.6620\n",
      "Epoch 142/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6790 - val_loss: 0.6529\n",
      "Epoch 143/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6607 - val_loss: 0.8602\n",
      "Epoch 144/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6523 - val_loss: 0.6187\n",
      "Epoch 145/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6138 - val_loss: 0.8946\n",
      "Epoch 146/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7292 - val_loss: 0.6245\n",
      "Epoch 147/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6033 - val_loss: 0.6770\n",
      "Epoch 148/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6175 - val_loss: 0.6494\n",
      "Epoch 149/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5986 - val_loss: 0.6832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6064 - val_loss: 0.6296\n",
      "Epoch 151/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6055 - val_loss: 0.6665\n",
      "Epoch 152/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5894 - val_loss: 0.6543\n",
      "Epoch 153/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6556 - val_loss: 0.6149\n",
      "Epoch 154/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5791 - val_loss: 0.6316\n",
      "Epoch 155/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6282 - val_loss: 0.6103\n",
      "Epoch 156/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6318 - val_loss: 0.5955\n",
      "Epoch 157/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6308 - val_loss: 0.7901\n",
      "Epoch 158/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6437 - val_loss: 0.5994\n",
      "Epoch 159/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.6118 - val_loss: 0.7401\n",
      "Epoch 160/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7053 - val_loss: 0.8941\n",
      "Epoch 161/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6915 - val_loss: 0.6478\n",
      "Epoch 162/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6171 - val_loss: 0.6703\n",
      "Epoch 163/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7175 - val_loss: 1.2084\n",
      "Epoch 164/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7135 - val_loss: 0.5995\n",
      "Epoch 165/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.6301 - val_loss: 0.5984\n",
      "Epoch 166/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5885 - val_loss: 0.6236\n",
      "Epoch 167/500\n",
      "12688/12688 [==============================] - 0s 7us/step - loss: 0.5930 - val_loss: 0.6201\n",
      "Epoch 168/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 0.5595 - val_loss: 0.5954\n",
      "Epoch 169/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5473 - val_loss: 0.5958\n",
      "Epoch 170/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.6126 - val_loss: 0.5886\n",
      "Epoch 171/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6418 - val_loss: 0.5862\n",
      "Epoch 172/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5863 - val_loss: 0.6855\n",
      "Epoch 173/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5926 - val_loss: 0.6883\n",
      "Epoch 174/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6986 - val_loss: 0.8462\n",
      "Epoch 175/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6047 - val_loss: 0.5872\n",
      "Epoch 176/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5455 - val_loss: 0.5833\n",
      "Epoch 177/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6666 - val_loss: 0.6442\n",
      "Epoch 178/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7823 - val_loss: 0.8332\n",
      "Epoch 179/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7133 - val_loss: 0.5933\n",
      "Epoch 180/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5688 - val_loss: 0.6359\n",
      "Epoch 181/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6924 - val_loss: 0.8391\n",
      "Epoch 182/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6251 - val_loss: 0.5945\n",
      "Epoch 183/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5624 - val_loss: 0.5653\n",
      "Epoch 184/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5467 - val_loss: 0.5629\n",
      "Epoch 185/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5478 - val_loss: 0.5935\n",
      "Epoch 186/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5994 - val_loss: 0.6938\n",
      "Epoch 187/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5892 - val_loss: 0.5915\n",
      "Epoch 188/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5706 - val_loss: 0.6252\n",
      "Epoch 189/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5572 - val_loss: 0.7638\n",
      "Epoch 190/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5507 - val_loss: 0.5834\n",
      "Epoch 191/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5258 - val_loss: 0.6060\n",
      "Epoch 192/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5257 - val_loss: 0.5925\n",
      "Epoch 193/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5508 - val_loss: 0.6057\n",
      "Epoch 194/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6363 - val_loss: 0.7068\n",
      "Epoch 195/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6673 - val_loss: 0.6885\n",
      "Epoch 196/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6255 - val_loss: 0.5563\n",
      "Epoch 197/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5257 - val_loss: 0.5741\n",
      "Epoch 198/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5195 - val_loss: 0.5472\n",
      "Epoch 199/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5457 - val_loss: 0.7060\n",
      "Epoch 200/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6679 - val_loss: 0.6595\n",
      "Epoch 201/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6443 - val_loss: 0.7351\n",
      "Epoch 202/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6491 - val_loss: 0.5454\n",
      "Epoch 203/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5060 - val_loss: 0.5825\n",
      "Epoch 204/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5128 - val_loss: 0.5953\n",
      "Epoch 205/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5105 - val_loss: 0.5591\n",
      "Epoch 206/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5256 - val_loss: 0.5716\n",
      "Epoch 207/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5572 - val_loss: 0.6036\n",
      "Epoch 208/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5767 - val_loss: 0.5909\n",
      "Epoch 209/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5282 - val_loss: 0.5632\n",
      "Epoch 210/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6027 - val_loss: 0.5364\n",
      "Epoch 211/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5753 - val_loss: 0.5680\n",
      "Epoch 212/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6290 - val_loss: 0.5463\n",
      "Epoch 213/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5418 - val_loss: 0.5924\n",
      "Epoch 214/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6290 - val_loss: 0.7117\n",
      "Epoch 215/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.5515 - val_loss: 0.5524\n",
      "Epoch 216/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5234 - val_loss: 0.5474\n",
      "Epoch 217/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5508 - val_loss: 0.6844\n",
      "Epoch 218/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5255 - val_loss: 0.5489\n",
      "Epoch 219/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5288 - val_loss: 0.6546\n",
      "Epoch 220/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.5299 - val_loss: 0.5402\n",
      "Epoch 221/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5754 - val_loss: 0.6647\n",
      "Epoch 222/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5614 - val_loss: 0.5364\n",
      "Epoch 223/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5047 - val_loss: 0.5472\n",
      "Epoch 224/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5520 - val_loss: 0.5304\n",
      "Epoch 225/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5687 - val_loss: 0.5298\n",
      "Epoch 226/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 0.4786 - val_loss: 0.6751\n",
      "Epoch 227/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5288 - val_loss: 0.5353\n",
      "Epoch 228/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4799 - val_loss: 0.5559\n",
      "Epoch 229/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5015 - val_loss: 0.6254\n",
      "Epoch 230/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5282 - val_loss: 0.5286\n",
      "Epoch 231/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5901 - val_loss: 0.6860\n",
      "Epoch 232/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5347 - val_loss: 0.5398\n",
      "Epoch 233/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5735 - val_loss: 0.6056\n",
      "Epoch 234/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4986 - val_loss: 0.5341\n",
      "Epoch 235/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4873 - val_loss: 0.6044\n",
      "Epoch 236/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.5018 - val_loss: 0.5664\n",
      "Epoch 237/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5161 - val_loss: 0.5854\n",
      "Epoch 238/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4894 - val_loss: 0.5541\n",
      "Epoch 239/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6597 - val_loss: 0.5300\n",
      "Epoch 240/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5454 - val_loss: 0.6786\n",
      "Epoch 241/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6220 - val_loss: 1.0329\n",
      "Epoch 242/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6085 - val_loss: 0.5295\n",
      "Epoch 243/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.4715 - val_loss: 0.5217\n",
      "Epoch 244/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5599 - val_loss: 0.6523\n",
      "Epoch 245/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5056 - val_loss: 0.5195\n",
      "Epoch 246/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4709 - val_loss: 0.5285\n",
      "Epoch 247/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4853 - val_loss: 0.5462\n",
      "Epoch 248/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5154 - val_loss: 0.6283\n",
      "Epoch 249/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5871 - val_loss: 0.6381\n",
      "Epoch 250/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5811 - val_loss: 0.5263\n",
      "Epoch 251/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5428 - val_loss: 0.6014\n",
      "Epoch 252/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4789 - val_loss: 0.5261\n",
      "Epoch 253/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5040 - val_loss: 0.6865\n",
      "Epoch 254/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5775 - val_loss: 0.5144\n",
      "Epoch 255/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5011 - val_loss: 0.6049\n",
      "Epoch 256/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6473 - val_loss: 0.5449\n",
      "Epoch 257/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4649 - val_loss: 0.5672\n",
      "Epoch 258/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4632 - val_loss: 0.5366\n",
      "Epoch 259/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5027 - val_loss: 0.5503\n",
      "Epoch 260/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.4829 - val_loss: 0.6233\n",
      "Epoch 261/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4864 - val_loss: 0.5276\n",
      "Epoch 262/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4753 - val_loss: 0.5104\n",
      "Epoch 263/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4607 - val_loss: 0.5835\n",
      "Epoch 264/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5543 - val_loss: 0.5373\n",
      "Epoch 265/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4610 - val_loss: 0.5066\n",
      "Epoch 266/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4922 - val_loss: 0.7269\n",
      "Epoch 267/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5394 - val_loss: 0.8463\n",
      "Epoch 268/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6578 - val_loss: 0.5257\n",
      "Epoch 269/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5197 - val_loss: 0.5328\n",
      "Epoch 270/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5464 - val_loss: 0.8650\n",
      "Epoch 271/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5662 - val_loss: 0.5618\n",
      "Epoch 272/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4622 - val_loss: 0.5700\n",
      "Epoch 273/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4824 - val_loss: 0.5316\n",
      "Epoch 274/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.4542 - val_loss: 0.5062\n",
      "Epoch 275/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4553 - val_loss: 0.5046\n",
      "Epoch 276/500\n",
      "12688/12688 [==============================] - ETA: 0s - loss: 0.442 - 0s 3us/step - loss: 0.5112 - val_loss: 0.5166\n",
      "Epoch 277/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4958 - val_loss: 0.6729\n",
      "Epoch 278/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.8880 - val_loss: 0.4984\n",
      "Epoch 279/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7729 - val_loss: 0.5136\n",
      "Epoch 280/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.6915 - val_loss: 0.7796\n",
      "Epoch 281/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5837 - val_loss: 0.5263\n",
      "Epoch 282/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.4610 - val_loss: 0.5014\n",
      "Epoch 283/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.4622 - val_loss: 0.4998\n",
      "Epoch 284/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.4547 - val_loss: 0.5859\n",
      "Epoch 285/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4530 - val_loss: 0.5535\n",
      "Epoch 286/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4800 - val_loss: 0.4969\n",
      "Epoch 287/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4639 - val_loss: 0.7437\n",
      "Epoch 288/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6211 - val_loss: 0.6723\n",
      "Epoch 289/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5223 - val_loss: 0.5475\n",
      "Epoch 290/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4685 - val_loss: 0.5032\n",
      "Epoch 291/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4904 - val_loss: 0.5091\n",
      "Epoch 292/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4773 - val_loss: 0.5239\n",
      "Epoch 293/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5644 - val_loss: 0.5137\n",
      "Epoch 294/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5307 - val_loss: 0.8600\n",
      "Epoch 295/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5834 - val_loss: 0.5626\n",
      "Epoch 296/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4859 - val_loss: 0.5509\n",
      "Epoch 297/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4902 - val_loss: 0.6303\n",
      "Epoch 298/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4972 - val_loss: 0.4971\n",
      "Epoch 299/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4495 - val_loss: 0.5508\n",
      "Epoch 300/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4774 - val_loss: 0.5212\n",
      "Epoch 301/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6263 - val_loss: 0.9478\n",
      "Epoch 302/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5881 - val_loss: 0.5259\n",
      "Epoch 303/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.6175 - val_loss: 0.8720\n",
      "Epoch 304/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5766 - val_loss: 0.5014\n",
      "Epoch 305/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4397 - val_loss: 0.5005\n",
      "Epoch 306/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5202 - val_loss: 0.5846\n",
      "Epoch 307/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5541 - val_loss: 0.5488\n",
      "Epoch 308/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6164 - val_loss: 0.5262\n",
      "Epoch 309/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5341 - val_loss: 0.6317\n",
      "Epoch 310/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4402 - val_loss: 0.4890\n",
      "Epoch 311/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4271 - val_loss: 0.4984\n",
      "Epoch 312/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4450 - val_loss: 0.4976\n",
      "Epoch 313/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4454 - val_loss: 0.5542\n",
      "Epoch 314/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4795 - val_loss: 0.5066\n",
      "Epoch 315/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4494 - val_loss: 0.5162\n",
      "Epoch 316/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4380 - val_loss: 0.4987\n",
      "Epoch 317/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4243 - val_loss: 0.5740\n",
      "Epoch 318/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4393 - val_loss: 0.5006\n",
      "Epoch 319/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4217 - val_loss: 0.5746\n",
      "Epoch 320/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4520 - val_loss: 0.5000\n",
      "Epoch 321/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4357 - val_loss: 0.5054\n",
      "Epoch 322/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6196 - val_loss: 0.9054\n",
      "Epoch 323/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6629 - val_loss: 0.5471\n",
      "Epoch 324/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4658 - val_loss: 0.4847\n",
      "Epoch 325/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4227 - val_loss: 0.4887\n",
      "Epoch 326/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4678 - val_loss: 0.4829\n",
      "Epoch 327/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4810 - val_loss: 0.5541\n",
      "Epoch 328/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4746 - val_loss: 0.4933\n",
      "Epoch 329/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4468 - val_loss: 0.5743\n",
      "Epoch 330/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5501 - val_loss: 0.5754\n",
      "Epoch 331/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.4855 - val_loss: 0.5065\n",
      "Epoch 332/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4223 - val_loss: 0.4851\n",
      "Epoch 333/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4724 - val_loss: 0.5262\n",
      "Epoch 334/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4868 - val_loss: 0.4868\n",
      "Epoch 335/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4274 - val_loss: 0.6296\n",
      "Epoch 336/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4633 - val_loss: 0.4995\n",
      "Epoch 337/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4428 - val_loss: 0.6093\n",
      "Epoch 338/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5739 - val_loss: 0.6932\n",
      "Epoch 339/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5401 - val_loss: 0.5622\n",
      "Epoch 340/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5810 - val_loss: 0.5100\n",
      "Epoch 341/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4371 - val_loss: 0.4941\n",
      "Epoch 342/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4816 - val_loss: 0.6246\n",
      "Epoch 343/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7044 - val_loss: 0.7185\n",
      "Epoch 344/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5075 - val_loss: 0.5183\n",
      "Epoch 345/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4397 - val_loss: 0.5141\n",
      "Epoch 346/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4214 - val_loss: 0.4816\n",
      "Epoch 347/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4197 - val_loss: 0.5019\n",
      "Epoch 348/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4480 - val_loss: 0.4754\n",
      "Epoch 349/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4259 - val_loss: 0.4835\n",
      "Epoch 350/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4658 - val_loss: 0.4904\n",
      "Epoch 351/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4523 - val_loss: 0.6676\n",
      "Epoch 352/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4553 - val_loss: 0.4868\n",
      "Epoch 353/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4464 - val_loss: 0.4902\n",
      "Epoch 354/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.4216 - val_loss: 0.4854\n",
      "Epoch 355/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.4226 - val_loss: 0.4844\n",
      "Epoch 356/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.4197 - val_loss: 0.4778\n",
      "Epoch 357/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.4233 - val_loss: 0.6868\n",
      "Epoch 358/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.4894 - val_loss: 0.5618\n",
      "Epoch 359/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.5479 - val_loss: 0.5918\n",
      "Epoch 360/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.7028 - val_loss: 0.4880\n",
      "Epoch 361/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4966 - val_loss: 0.4930\n",
      "Epoch 362/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4580 - val_loss: 0.5050\n",
      "Epoch 363/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5102 - val_loss: 0.5164\n",
      "Epoch 364/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4355 - val_loss: 0.5048\n",
      "Epoch 365/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4724 - val_loss: 0.5522\n",
      "Epoch 366/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4526 - val_loss: 0.4751\n",
      "Epoch 367/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5432 - val_loss: 0.4809\n",
      "Epoch 368/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5996 - val_loss: 0.7807\n",
      "Epoch 369/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4852 - val_loss: 0.4801\n",
      "Epoch 370/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4359 - val_loss: 0.5154\n",
      "Epoch 371/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4090 - val_loss: 0.4862\n",
      "Epoch 372/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4305 - val_loss: 0.5094\n",
      "Epoch 373/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4389 - val_loss: 0.5095\n",
      "Epoch 374/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4104 - val_loss: 0.4788\n",
      "Epoch 375/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4113 - val_loss: 0.4956\n",
      "Epoch 376/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4249 - val_loss: 0.5313\n",
      "Epoch 377/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.4606 - val_loss: 0.4972\n",
      "Epoch 378/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4662 - val_loss: 0.5362\n",
      "Epoch 379/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4582 - val_loss: 0.5710\n",
      "Epoch 380/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4670 - val_loss: 0.6339\n",
      "Epoch 381/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6350 - val_loss: 0.5340\n",
      "Epoch 382/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5140 - val_loss: 0.6239\n",
      "Epoch 383/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4826 - val_loss: 0.5799\n",
      "Epoch 384/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4917 - val_loss: 0.6979\n",
      "Epoch 385/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4984 - val_loss: 0.4875\n",
      "Epoch 386/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4801 - val_loss: 0.4971\n",
      "Epoch 387/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4784 - val_loss: 0.5279\n",
      "Epoch 388/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 0.4845 - val_loss: 0.4700\n",
      "Epoch 389/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.4030 - val_loss: 0.4935\n",
      "Epoch 390/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4142 - val_loss: 0.4918\n",
      "Epoch 391/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4036 - val_loss: 0.5041\n",
      "Epoch 392/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4342 - val_loss: 0.4752\n",
      "Epoch 393/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5761 - val_loss: 0.5559\n",
      "Epoch 394/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5663 - val_loss: 0.9546\n",
      "Epoch 395/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4758 - val_loss: 0.4711\n",
      "Epoch 396/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.3963 - val_loss: 0.4707\n",
      "Epoch 397/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4314 - val_loss: 0.6102\n",
      "Epoch 398/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4378 - val_loss: 0.5747\n",
      "Epoch 399/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4145 - val_loss: 0.4894\n",
      "Epoch 400/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4377 - val_loss: 0.5184\n",
      "Epoch 401/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4266 - val_loss: 0.4961\n",
      "Epoch 402/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4279 - val_loss: 0.5391\n",
      "Epoch 403/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4799 - val_loss: 0.4765\n",
      "Epoch 404/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4085 - val_loss: 0.4997\n",
      "Epoch 405/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4237 - val_loss: 0.5401\n",
      "Epoch 406/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4481 - val_loss: 0.7162\n",
      "Epoch 407/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5434 - val_loss: 0.4890\n",
      "Epoch 408/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5460 - val_loss: 0.5657\n",
      "Epoch 409/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4237 - val_loss: 0.4804\n",
      "Epoch 410/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.3995 - val_loss: 0.4928\n",
      "Epoch 411/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4115 - val_loss: 0.4954\n",
      "Epoch 412/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4312 - val_loss: 0.4739\n",
      "Epoch 413/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4173 - val_loss: 0.4702\n",
      "Epoch 414/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4679 - val_loss: 0.5805\n",
      "Epoch 415/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5653 - val_loss: 0.4761\n",
      "Epoch 416/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4835 - val_loss: 0.5602\n",
      "Epoch 417/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5317 - val_loss: 0.4948\n",
      "Epoch 418/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5326 - val_loss: 0.4729\n",
      "Epoch 419/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4265 - val_loss: 0.5597\n",
      "Epoch 420/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4174 - val_loss: 0.5718\n",
      "Epoch 421/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4709 - val_loss: 0.6653\n",
      "Epoch 422/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4428 - val_loss: 0.4794\n",
      "Epoch 423/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.3947 - val_loss: 0.5627\n",
      "Epoch 424/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4652 - val_loss: 0.6095\n",
      "Epoch 425/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4353 - val_loss: 0.5001\n",
      "Epoch 426/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.3924 - val_loss: 0.4933\n",
      "Epoch 427/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4093 - val_loss: 0.5753\n",
      "Epoch 428/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4742 - val_loss: 0.5110\n",
      "Epoch 429/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.3868 - val_loss: 0.4703\n",
      "Epoch 430/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.3853 - val_loss: 0.6695\n",
      "Epoch 431/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6335 - val_loss: 0.5139\n",
      "Epoch 432/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.3994 - val_loss: 0.4953\n",
      "Epoch 433/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4109 - val_loss: 0.5025\n",
      "Epoch 434/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4133 - val_loss: 0.4799\n",
      "Epoch 435/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4184 - val_loss: 0.5205\n",
      "Epoch 436/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4656 - val_loss: 0.5357\n",
      "Epoch 437/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5786 - val_loss: 0.5768\n",
      "Epoch 438/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7296 - val_loss: 0.7137\n",
      "Epoch 439/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4646 - val_loss: 0.4898\n",
      "Epoch 440/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4099 - val_loss: 0.4775\n",
      "Epoch 441/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4079 - val_loss: 0.5250\n",
      "Epoch 442/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.3924 - val_loss: 0.4707\n",
      "Epoch 443/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4205 - val_loss: 0.6133\n",
      "Epoch 444/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4972 - val_loss: 0.7292\n",
      "Epoch 445/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4999 - val_loss: 0.4969\n",
      "Epoch 446/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4031 - val_loss: 0.5227\n",
      "Epoch 447/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.3840 - val_loss: 0.4773\n",
      "Epoch 448/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4017 - val_loss: 0.5155\n",
      "Epoch 449/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4066 - val_loss: 0.5815\n",
      "Epoch 450/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.3874 - val_loss: 0.4918\n",
      "Epoch 451/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.3951 - val_loss: 0.5328\n",
      "Epoch 452/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5042 - val_loss: 0.4778\n",
      "Epoch 453/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4409 - val_loss: 0.4653\n",
      "Epoch 454/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.3986 - val_loss: 0.4693\n",
      "Epoch 455/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4743 - val_loss: 0.4830\n",
      "Epoch 456/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4393 - val_loss: 0.6412\n",
      "Epoch 457/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4963 - val_loss: 0.4674\n",
      "Epoch 458/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4281 - val_loss: 0.4892\n",
      "Epoch 459/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4630 - val_loss: 0.5725\n",
      "Epoch 460/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4961 - val_loss: 0.7692\n",
      "Epoch 461/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.4858 - val_loss: 0.5238\n",
      "Epoch 462/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.3796 - val_loss: 0.4794\n",
      "Epoch 463/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.3940 - val_loss: 0.4606\n",
      "Epoch 464/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.3879 - val_loss: 0.4696\n",
      "Epoch 465/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.4736 - val_loss: 0.4957\n",
      "Epoch 466/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4520 - val_loss: 0.4664\n",
      "Epoch 467/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4113 - val_loss: 0.4847\n",
      "Epoch 468/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4400 - val_loss: 0.4642\n",
      "Epoch 469/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.7196 - val_loss: 0.4762\n",
      "Epoch 470/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 0.4533 - val_loss: 0.4856\n",
      "Epoch 471/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.4415 - val_loss: 0.5323\n",
      "Epoch 472/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.3994 - val_loss: 0.4978\n",
      "Epoch 473/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.3847 - val_loss: 0.4781\n",
      "Epoch 474/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4422 - val_loss: 0.5118\n",
      "Epoch 475/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.3957 - val_loss: 0.4679\n",
      "Epoch 476/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4027 - val_loss: 0.5808\n",
      "Epoch 477/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4314 - val_loss: 0.6540\n",
      "Epoch 478/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4801 - val_loss: 0.5863\n",
      "Epoch 479/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.4670 - val_loss: 0.8967\n",
      "Epoch 480/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5625 - val_loss: 0.4704\n",
      "Epoch 481/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4003 - val_loss: 0.4650\n",
      "Epoch 482/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4036 - val_loss: 0.4651\n",
      "Epoch 483/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.3985 - val_loss: 0.4622\n",
      "Epoch 484/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4213 - val_loss: 0.4843\n",
      "Epoch 485/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5203 - val_loss: 0.5357\n",
      "Epoch 486/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.3897 - val_loss: 0.4653\n",
      "Epoch 487/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4167 - val_loss: 0.4608\n",
      "Epoch 488/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4086 - val_loss: 0.8603\n",
      "Epoch 489/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4918 - val_loss: 0.4664\n",
      "Epoch 490/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.3791 - val_loss: 0.4708\n",
      "Epoch 491/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.3942 - val_loss: 0.5004\n",
      "Epoch 492/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.3914 - val_loss: 0.5533\n",
      "Epoch 493/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4853 - val_loss: 0.4665\n",
      "Epoch 494/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4030 - val_loss: 0.5498\n",
      "Epoch 495/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4060 - val_loss: 0.5535\n",
      "Epoch 496/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.3930 - val_loss: 0.4689\n",
      "Epoch 497/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.3722 - val_loss: 0.4698\n",
      "Epoch 498/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4247 - val_loss: 0.4709\n",
      "Epoch 499/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.5029 - val_loss: 0.4847\n",
      "Epoch 500/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.4037 - val_loss: 0.4800\n",
      "Train on 12688 samples, validate on 3173 samples\n",
      "Epoch 1/500\n",
      "12688/12688 [==============================] - 0s 24us/step - loss: 51.7561 - val_loss: 36.7935\n",
      "Epoch 2/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 27.6194 - val_loss: 21.1537\n",
      "Epoch 3/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 17.5590 - val_loss: 13.2686\n",
      "Epoch 4/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 9.6383 - val_loss: 6.0763\n",
      "Epoch 5/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 4.3978 - val_loss: 3.9257\n",
      "Epoch 6/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 3.6575 - val_loss: 3.6160\n",
      "Epoch 7/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 3.2609 - val_loss: 3.2818\n",
      "Epoch 8/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 3.1310 - val_loss: 3.3234\n",
      "Epoch 9/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 3.2281 - val_loss: 3.4836\n",
      "Epoch 10/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 3.0353 - val_loss: 2.9834\n",
      "Epoch 11/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 2.8631 - val_loss: 2.9442\n",
      "Epoch 12/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 2.8403 - val_loss: 2.8954\n",
      "Epoch 13/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 2.7484 - val_loss: 2.7615\n",
      "Epoch 14/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 2.7539 - val_loss: 2.7616\n",
      "Epoch 15/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 2.6494 - val_loss: 2.6349\n",
      "Epoch 16/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 2.5885 - val_loss: 2.6455\n",
      "Epoch 17/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 2.5712 - val_loss: 2.6878\n",
      "Epoch 18/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 2.5675 - val_loss: 2.6281\n",
      "Epoch 19/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 2.5931 - val_loss: 3.1252\n",
      "Epoch 20/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 2.4575 - val_loss: 2.5099\n",
      "Epoch 21/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 2.2877 - val_loss: 2.3519\n",
      "Epoch 22/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 2.2296 - val_loss: 2.3457\n",
      "Epoch 23/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 2.2148 - val_loss: 2.3001\n",
      "Epoch 24/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 2.3941 - val_loss: 2.4960\n",
      "Epoch 25/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 2.3172 - val_loss: 2.3752\n",
      "Epoch 26/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 2.2132 - val_loss: 2.2092\n",
      "Epoch 27/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 2.1835 - val_loss: 2.3159\n",
      "Epoch 28/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 2.2018 - val_loss: 2.2549\n",
      "Epoch 29/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 2.0439 - val_loss: 2.1742\n",
      "Epoch 30/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 2.0133 - val_loss: 2.0930\n",
      "Epoch 31/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 2.0422 - val_loss: 2.1439\n",
      "Epoch 32/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.9756 - val_loss: 2.0540\n",
      "Epoch 33/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.9607 - val_loss: 2.0869\n",
      "Epoch 34/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 1.9279 - val_loss: 2.1428\n",
      "Epoch 35/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 2.0885 - val_loss: 2.0122\n",
      "Epoch 36/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 2.0154 - val_loss: 1.9896\n",
      "Epoch 37/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.9265 - val_loss: 1.9814\n",
      "Epoch 38/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.8506 - val_loss: 2.0926\n",
      "Epoch 39/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.8261 - val_loss: 2.1445\n",
      "Epoch 40/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.8741 - val_loss: 2.0953\n",
      "Epoch 41/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.9110 - val_loss: 2.0252\n",
      "Epoch 42/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.8233 - val_loss: 2.0618\n",
      "Epoch 43/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.8819 - val_loss: 2.0503\n",
      "Epoch 44/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.8864 - val_loss: 2.2362\n",
      "Epoch 45/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.8954 - val_loss: 1.9781\n",
      "Epoch 46/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.8607 - val_loss: 1.9107\n",
      "Epoch 47/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.7884 - val_loss: 2.0241\n",
      "Epoch 48/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.8164 - val_loss: 1.9022\n",
      "Epoch 49/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.7204 - val_loss: 1.8608\n",
      "Epoch 50/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.7711 - val_loss: 2.2152\n",
      "Epoch 51/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 2.3903 - val_loss: 1.9160\n",
      "Epoch 52/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 2.0232 - val_loss: 1.9132\n",
      "Epoch 53/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.7109 - val_loss: 1.8738\n",
      "Epoch 54/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.7028 - val_loss: 1.8397\n",
      "Epoch 55/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6790 - val_loss: 1.8691\n",
      "Epoch 56/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6782 - val_loss: 1.9213\n",
      "Epoch 57/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6973 - val_loss: 1.8246\n",
      "Epoch 58/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.6847 - val_loss: 1.9471\n",
      "Epoch 59/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6944 - val_loss: 1.8284\n",
      "Epoch 60/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.6636 - val_loss: 1.8086\n",
      "Epoch 61/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6595 - val_loss: 1.9316\n",
      "Epoch 62/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6825 - val_loss: 1.9346\n",
      "Epoch 63/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.7833 - val_loss: 1.9099\n",
      "Epoch 64/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6694 - val_loss: 1.8930\n",
      "Epoch 65/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6465 - val_loss: 1.7880\n",
      "Epoch 66/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6366 - val_loss: 2.1698\n",
      "Epoch 67/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.7837 - val_loss: 1.8020\n",
      "Epoch 68/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6391 - val_loss: 1.8524\n",
      "Epoch 69/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6873 - val_loss: 1.8818\n",
      "Epoch 70/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6892 - val_loss: 1.8225\n",
      "Epoch 71/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6505 - val_loss: 1.7606\n",
      "Epoch 72/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5904 - val_loss: 1.7805\n",
      "Epoch 73/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6074 - val_loss: 1.7633\n",
      "Epoch 74/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6968 - val_loss: 2.0626\n",
      "Epoch 75/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.7544 - val_loss: 1.8956\n",
      "Epoch 76/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6286 - val_loss: 1.9052\n",
      "Epoch 77/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6270 - val_loss: 1.8992\n",
      "Epoch 78/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6024 - val_loss: 1.8803\n",
      "Epoch 79/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6452 - val_loss: 1.7778\n",
      "Epoch 80/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.7367 - val_loss: 1.7938\n",
      "Epoch 81/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.7382 - val_loss: 1.7574\n",
      "Epoch 82/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 1.7364 - val_loss: 1.7928\n",
      "Epoch 83/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 1.5805 - val_loss: 1.7745\n",
      "Epoch 84/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6642 - val_loss: 2.0535\n",
      "Epoch 85/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6398 - val_loss: 2.0718\n",
      "Epoch 86/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6579 - val_loss: 1.8113\n",
      "Epoch 87/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.7305 - val_loss: 1.7394\n",
      "Epoch 88/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5560 - val_loss: 1.7402\n",
      "Epoch 89/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.5602 - val_loss: 1.7711\n",
      "Epoch 90/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5979 - val_loss: 1.7435\n",
      "Epoch 91/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5975 - val_loss: 1.8654\n",
      "Epoch 92/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5686 - val_loss: 1.7252\n",
      "Epoch 93/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5756 - val_loss: 1.9459\n",
      "Epoch 94/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.8121 - val_loss: 2.4210\n",
      "Epoch 95/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.9241 - val_loss: 1.7455\n",
      "Epoch 96/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 1.7526 - val_loss: 1.9430\n",
      "Epoch 97/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6333 - val_loss: 1.7203\n",
      "Epoch 98/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5646 - val_loss: 1.7313\n",
      "Epoch 99/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5310 - val_loss: 1.7494\n",
      "Epoch 100/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 1.5288 - val_loss: 1.7506\n",
      "Epoch 101/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5148 - val_loss: 1.7326\n",
      "Epoch 102/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5552 - val_loss: 1.7384\n",
      "Epoch 103/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5762 - val_loss: 1.8253\n",
      "Epoch 104/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6337 - val_loss: 1.9855\n",
      "Epoch 105/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6827 - val_loss: 1.7235\n",
      "Epoch 106/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.8323 - val_loss: 1.7616\n",
      "Epoch 107/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.7707 - val_loss: 2.0372\n",
      "Epoch 108/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6243 - val_loss: 1.7441\n",
      "Epoch 109/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6834 - val_loss: 1.8806\n",
      "Epoch 110/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6895 - val_loss: 1.8352\n",
      "Epoch 111/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5309 - val_loss: 1.7399\n",
      "Epoch 112/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6091 - val_loss: 1.7259\n",
      "Epoch 113/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5473 - val_loss: 1.7769\n",
      "Epoch 114/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5233 - val_loss: 1.7088\n",
      "Epoch 115/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5465 - val_loss: 1.7923\n",
      "Epoch 116/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5394 - val_loss: 1.7226\n",
      "Epoch 117/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5836 - val_loss: 1.7040\n",
      "Epoch 118/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6098 - val_loss: 1.8292\n",
      "Epoch 119/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6793 - val_loss: 1.7225\n",
      "Epoch 120/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5581 - val_loss: 1.7310\n",
      "Epoch 121/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5366 - val_loss: 1.7002\n",
      "Epoch 122/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4904 - val_loss: 1.7135\n",
      "Epoch 123/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5383 - val_loss: 1.8280\n",
      "Epoch 124/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5944 - val_loss: 1.8717\n",
      "Epoch 125/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5757 - val_loss: 1.8185\n",
      "Epoch 126/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5487 - val_loss: 1.8434\n",
      "Epoch 127/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6930 - val_loss: 1.7820\n",
      "Epoch 128/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6685 - val_loss: 1.8316\n",
      "Epoch 129/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6045 - val_loss: 1.7603\n",
      "Epoch 130/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5955 - val_loss: 1.9183\n",
      "Epoch 131/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6591 - val_loss: 1.8147\n",
      "Epoch 132/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6372 - val_loss: 1.7134\n",
      "Epoch 133/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6547 - val_loss: 1.7356\n",
      "Epoch 134/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5100 - val_loss: 1.7258\n",
      "Epoch 135/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5462 - val_loss: 1.7502\n",
      "Epoch 136/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4892 - val_loss: 1.7974\n",
      "Epoch 137/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5430 - val_loss: 1.8519\n",
      "Epoch 138/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5498 - val_loss: 1.6960\n",
      "Epoch 139/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.7323 - val_loss: 1.6904\n",
      "Epoch 140/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.7354 - val_loss: 1.8737\n",
      "Epoch 141/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6119 - val_loss: 1.8156\n",
      "Epoch 142/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5570 - val_loss: 1.9797\n",
      "Epoch 143/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6244 - val_loss: 1.7503\n",
      "Epoch 144/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5098 - val_loss: 1.7001\n",
      "Epoch 145/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4775 - val_loss: 1.7194\n",
      "Epoch 146/500\n",
      "12688/12688 [==============================] - 0s 8us/step - loss: 1.5077 - val_loss: 1.6822\n",
      "Epoch 147/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4968 - val_loss: 1.6814\n",
      "Epoch 148/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4751 - val_loss: 1.7236\n",
      "Epoch 149/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4889 - val_loss: 1.7066\n",
      "Epoch 150/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4700 - val_loss: 1.6744\n",
      "Epoch 151/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4841 - val_loss: 1.8563\n",
      "Epoch 152/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5809 - val_loss: 1.7441\n",
      "Epoch 153/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5312 - val_loss: 1.7667\n",
      "Epoch 154/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5684 - val_loss: 1.7483\n",
      "Epoch 155/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4831 - val_loss: 1.7011\n",
      "Epoch 156/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4546 - val_loss: 1.6778\n",
      "Epoch 157/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4941 - val_loss: 1.7429\n",
      "Epoch 158/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5453 - val_loss: 1.9560\n",
      "Epoch 159/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5458 - val_loss: 1.8078\n",
      "Epoch 160/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6083 - val_loss: 1.8425\n",
      "Epoch 161/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4994 - val_loss: 1.7083\n",
      "Epoch 162/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4572 - val_loss: 1.6695\n",
      "Epoch 163/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4687 - val_loss: 1.7759\n",
      "Epoch 164/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5108 - val_loss: 1.7339\n",
      "Epoch 165/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4813 - val_loss: 1.7553\n",
      "Epoch 166/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4842 - val_loss: 1.7079\n",
      "Epoch 167/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5288 - val_loss: 1.7217\n",
      "Epoch 168/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4959 - val_loss: 1.6879\n",
      "Epoch 169/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4862 - val_loss: 1.8396\n",
      "Epoch 170/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5527 - val_loss: 1.7009\n",
      "Epoch 171/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5146 - val_loss: 1.7686\n",
      "Epoch 172/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5024 - val_loss: 1.7049\n",
      "Epoch 173/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5442 - val_loss: 1.7654\n",
      "Epoch 174/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5427 - val_loss: 1.9285\n",
      "Epoch 175/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5181 - val_loss: 1.7083\n",
      "Epoch 176/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5680 - val_loss: 1.8086\n",
      "Epoch 177/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.5209 - val_loss: 1.6818\n",
      "Epoch 178/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4395 - val_loss: 1.7248\n",
      "Epoch 179/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4656 - val_loss: 1.7233\n",
      "Epoch 180/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6057 - val_loss: 2.3181\n",
      "Epoch 181/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6343 - val_loss: 2.0306\n",
      "Epoch 182/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5551 - val_loss: 1.6980\n",
      "Epoch 183/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4486 - val_loss: 1.7019\n",
      "Epoch 184/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.5078 - val_loss: 1.7786\n",
      "Epoch 185/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4798 - val_loss: 1.7131\n",
      "Epoch 186/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5283 - val_loss: 1.7346\n",
      "Epoch 187/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5883 - val_loss: 1.8010\n",
      "Epoch 188/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5059 - val_loss: 1.6776\n",
      "Epoch 189/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4834 - val_loss: 1.7246\n",
      "Epoch 190/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4802 - val_loss: 1.7007\n",
      "Epoch 191/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4757 - val_loss: 1.7162\n",
      "Epoch 192/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5372 - val_loss: 1.6655\n",
      "Epoch 193/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 1.4540 - val_loss: 1.8231\n",
      "Epoch 194/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4722 - val_loss: 1.6663\n",
      "Epoch 195/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5473 - val_loss: 2.2084\n",
      "Epoch 196/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6357 - val_loss: 1.6666\n",
      "Epoch 197/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5275 - val_loss: 1.6959\n",
      "Epoch 198/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6777 - val_loss: 1.6857\n",
      "Epoch 199/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5282 - val_loss: 1.6951\n",
      "Epoch 200/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4790 - val_loss: 1.7055\n",
      "Epoch 201/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4821 - val_loss: 1.7697\n",
      "Epoch 202/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4787 - val_loss: 1.7933\n",
      "Epoch 203/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4860 - val_loss: 1.7190\n",
      "Epoch 204/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5786 - val_loss: 1.8047\n",
      "Epoch 205/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5632 - val_loss: 1.8070\n",
      "Epoch 206/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5060 - val_loss: 1.7597\n",
      "Epoch 207/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4442 - val_loss: 1.7425\n",
      "Epoch 208/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4467 - val_loss: 1.6847\n",
      "Epoch 209/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4555 - val_loss: 1.6758\n",
      "Epoch 210/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5067 - val_loss: 1.8193\n",
      "Epoch 211/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4750 - val_loss: 1.8119\n",
      "Epoch 212/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4673 - val_loss: 1.6793\n",
      "Epoch 213/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5174 - val_loss: 1.7376\n",
      "Epoch 214/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5147 - val_loss: 1.6852\n",
      "Epoch 215/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4750 - val_loss: 1.7073\n",
      "Epoch 216/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4607 - val_loss: 1.7053\n",
      "Epoch 217/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4472 - val_loss: 1.6844\n",
      "Epoch 218/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4360 - val_loss: 1.6984\n",
      "Epoch 219/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4527 - val_loss: 1.7003\n",
      "Epoch 220/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4534 - val_loss: 1.6945\n",
      "Epoch 221/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4796 - val_loss: 1.8027\n",
      "Epoch 222/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6298 - val_loss: 1.8627\n",
      "Epoch 223/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4811 - val_loss: 1.7530\n",
      "Epoch 224/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4917 - val_loss: 1.7591\n",
      "Epoch 225/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5150 - val_loss: 1.8166\n",
      "Epoch 226/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5572 - val_loss: 1.8519\n",
      "Epoch 227/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5112 - val_loss: 1.7080\n",
      "Epoch 228/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4507 - val_loss: 1.7470\n",
      "Epoch 229/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5115 - val_loss: 1.7754\n",
      "Epoch 230/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4314 - val_loss: 1.7167\n",
      "Epoch 231/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4385 - val_loss: 1.6902\n",
      "Epoch 232/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4954 - val_loss: 2.0119\n",
      "Epoch 233/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6921 - val_loss: 2.0231\n",
      "Epoch 234/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5808 - val_loss: 2.0087\n",
      "Epoch 235/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5842 - val_loss: 1.8076\n",
      "Epoch 236/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5417 - val_loss: 1.8137\n",
      "Epoch 237/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5374 - val_loss: 1.9476\n",
      "Epoch 238/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4962 - val_loss: 1.6790\n",
      "Epoch 239/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4572 - val_loss: 1.6883\n",
      "Epoch 240/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4280 - val_loss: 1.7251\n",
      "Epoch 241/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5264 - val_loss: 1.7247\n",
      "Epoch 242/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4262 - val_loss: 1.6729\n",
      "Epoch 243/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4498 - val_loss: 1.7264\n",
      "Epoch 244/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4296 - val_loss: 1.6920\n",
      "Epoch 245/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5121 - val_loss: 1.7786\n",
      "Epoch 246/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4733 - val_loss: 1.7064\n",
      "Epoch 247/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5005 - val_loss: 1.7657\n",
      "Epoch 248/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4839 - val_loss: 1.7218\n",
      "Epoch 249/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4481 - val_loss: 1.7056\n",
      "Epoch 250/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.5183 - val_loss: 1.7744\n",
      "Epoch 251/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4979 - val_loss: 1.7459\n",
      "Epoch 252/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 1.4699 - val_loss: 1.7393\n",
      "Epoch 253/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.4703 - val_loss: 2.2022\n",
      "Epoch 254/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.7668 - val_loss: 2.0099\n",
      "Epoch 255/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5585 - val_loss: 1.8285\n",
      "Epoch 256/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4581 - val_loss: 1.6986\n",
      "Epoch 257/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4786 - val_loss: 1.7753\n",
      "Epoch 258/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.4891 - val_loss: 1.8795\n",
      "Epoch 259/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.4727 - val_loss: 1.7162\n",
      "Epoch 260/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.4423 - val_loss: 1.8559\n",
      "Epoch 261/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4289 - val_loss: 1.6948\n",
      "Epoch 262/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4373 - val_loss: 1.6749\n",
      "Epoch 263/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4627 - val_loss: 1.6763\n",
      "Epoch 264/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4679 - val_loss: 1.6944\n",
      "Epoch 265/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4594 - val_loss: 1.6851\n",
      "Epoch 266/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5886 - val_loss: 1.7531\n",
      "Epoch 267/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4403 - val_loss: 1.6711\n",
      "Epoch 268/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3985 - val_loss: 1.7066\n",
      "Epoch 269/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.4261 - val_loss: 1.6940\n",
      "Epoch 270/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4051 - val_loss: 1.7063\n",
      "Epoch 271/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4231 - val_loss: 1.6776\n",
      "Epoch 272/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4530 - val_loss: 2.1413\n",
      "Epoch 273/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5381 - val_loss: 1.9283\n",
      "Epoch 274/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4605 - val_loss: 1.7309\n",
      "Epoch 275/500\n",
      "12688/12688 [==============================] - 0s 11us/step - loss: 1.5456 - val_loss: 1.7774\n",
      "Epoch 276/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.4780 - val_loss: 1.7099\n",
      "Epoch 277/500\n",
      "12688/12688 [==============================] - 0s 7us/step - loss: 1.4071 - val_loss: 1.6873\n",
      "Epoch 278/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4089 - val_loss: 1.7038\n",
      "Epoch 279/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4426 - val_loss: 1.7202\n",
      "Epoch 280/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4285 - val_loss: 1.6807\n",
      "Epoch 281/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 1.4092 - val_loss: 1.6957\n",
      "Epoch 282/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 1.4499 - val_loss: 1.7128\n",
      "Epoch 283/500\n",
      "12688/12688 [==============================] - 0s 7us/step - loss: 1.4507 - val_loss: 1.8388\n",
      "Epoch 284/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4624 - val_loss: 1.7390\n",
      "Epoch 285/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4810 - val_loss: 1.6759\n",
      "Epoch 286/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4281 - val_loss: 1.6794\n",
      "Epoch 287/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4079 - val_loss: 1.7737\n",
      "Epoch 288/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4383 - val_loss: 1.7514\n",
      "Epoch 289/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4476 - val_loss: 1.6816\n",
      "Epoch 290/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4206 - val_loss: 1.7238\n",
      "Epoch 291/500\n",
      "12688/12688 [==============================] - 0s 8us/step - loss: 1.3991 - val_loss: 1.6925\n",
      "Epoch 292/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 1.4369 - val_loss: 1.7888\n",
      "Epoch 293/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4638 - val_loss: 1.8883\n",
      "Epoch 294/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4309 - val_loss: 1.6944\n",
      "Epoch 295/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4423 - val_loss: 1.6790\n",
      "Epoch 296/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.4936 - val_loss: 1.7740\n",
      "Epoch 297/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4627 - val_loss: 1.7113\n",
      "Epoch 298/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3956 - val_loss: 1.7512\n",
      "Epoch 299/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.5550 - val_loss: 2.5369\n",
      "Epoch 300/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.6473 - val_loss: 1.8213\n",
      "Epoch 301/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 1.5292 - val_loss: 1.6964\n",
      "Epoch 302/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.4910 - val_loss: 1.6857\n",
      "Epoch 303/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.3897 - val_loss: 1.6955\n",
      "Epoch 304/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.4389 - val_loss: 1.8898\n",
      "Epoch 305/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.4980 - val_loss: 1.8796\n",
      "Epoch 306/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4281 - val_loss: 1.7242\n",
      "Epoch 307/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.3887 - val_loss: 1.6882\n",
      "Epoch 308/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3921 - val_loss: 1.6810\n",
      "Epoch 309/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3911 - val_loss: 1.7760\n",
      "Epoch 310/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.3972 - val_loss: 1.8467\n",
      "Epoch 311/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.4311 - val_loss: 1.7026\n",
      "Epoch 312/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4609 - val_loss: 1.8091\n",
      "Epoch 313/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.4166 - val_loss: 1.6784\n",
      "Epoch 314/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3835 - val_loss: 1.7010\n",
      "Epoch 315/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4323 - val_loss: 1.7079\n",
      "Epoch 316/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.4568 - val_loss: 1.6925\n",
      "Epoch 317/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3814 - val_loss: 1.7914\n",
      "Epoch 318/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.4236 - val_loss: 1.7305\n",
      "Epoch 319/500\n",
      "12688/12688 [==============================] - ETA: 0s - loss: 1.364 - 0s 3us/step - loss: 1.4695 - val_loss: 2.1469\n",
      "Epoch 320/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.5354 - val_loss: 1.7704\n",
      "Epoch 321/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.4147 - val_loss: 1.8478\n",
      "Epoch 322/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4930 - val_loss: 2.3209\n",
      "Epoch 323/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5700 - val_loss: 1.7378\n",
      "Epoch 324/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4508 - val_loss: 1.7234\n",
      "Epoch 325/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4836 - val_loss: 1.7132\n",
      "Epoch 326/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4940 - val_loss: 1.8043\n",
      "Epoch 327/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3931 - val_loss: 1.6752\n",
      "Epoch 328/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.3783 - val_loss: 1.7124\n",
      "Epoch 329/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3911 - val_loss: 1.7407\n",
      "Epoch 330/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4413 - val_loss: 1.7522\n",
      "Epoch 331/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4141 - val_loss: 1.7371\n",
      "Epoch 332/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4217 - val_loss: 1.8080\n",
      "Epoch 333/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4573 - val_loss: 1.9431\n",
      "Epoch 334/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4309 - val_loss: 1.7891\n",
      "Epoch 335/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.3953 - val_loss: 1.6881\n",
      "Epoch 336/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4347 - val_loss: 1.7564\n",
      "Epoch 337/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4093 - val_loss: 1.7801\n",
      "Epoch 338/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4042 - val_loss: 1.8210\n",
      "Epoch 339/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4692 - val_loss: 1.7816\n",
      "Epoch 340/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4039 - val_loss: 1.6918\n",
      "Epoch 341/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3868 - val_loss: 1.8841\n",
      "Epoch 342/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3949 - val_loss: 1.6960\n",
      "Epoch 343/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4746 - val_loss: 1.7557\n",
      "Epoch 344/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4926 - val_loss: 1.8654\n",
      "Epoch 345/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4878 - val_loss: 1.8171\n",
      "Epoch 346/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3995 - val_loss: 1.7019\n",
      "Epoch 347/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3759 - val_loss: 1.8847\n",
      "Epoch 348/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4413 - val_loss: 1.8812\n",
      "Epoch 349/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4102 - val_loss: 1.7431\n",
      "Epoch 350/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3838 - val_loss: 1.7226\n",
      "Epoch 351/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3787 - val_loss: 1.6978\n",
      "Epoch 352/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3604 - val_loss: 1.7195\n",
      "Epoch 353/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4196 - val_loss: 1.7442\n",
      "Epoch 354/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3689 - val_loss: 1.7082\n",
      "Epoch 355/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3692 - val_loss: 1.7160\n",
      "Epoch 356/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4330 - val_loss: 1.7227\n",
      "Epoch 357/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4544 - val_loss: 1.7079\n",
      "Epoch 358/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4213 - val_loss: 1.7067\n",
      "Epoch 359/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3803 - val_loss: 1.7478\n",
      "Epoch 360/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4127 - val_loss: 1.8536\n",
      "Epoch 361/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5659 - val_loss: 2.0986\n",
      "Epoch 362/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4348 - val_loss: 1.7361\n",
      "Epoch 363/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3816 - val_loss: 1.7847\n",
      "Epoch 364/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4142 - val_loss: 1.8251\n",
      "Epoch 365/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3974 - val_loss: 1.7099\n",
      "Epoch 366/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3651 - val_loss: 1.7213\n",
      "Epoch 367/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3616 - val_loss: 1.7066\n",
      "Epoch 368/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3611 - val_loss: 1.7168\n",
      "Epoch 369/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3649 - val_loss: 1.7258\n",
      "Epoch 370/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3725 - val_loss: 1.7279\n",
      "Epoch 371/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3613 - val_loss: 1.8026\n",
      "Epoch 372/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3662 - val_loss: 1.7436\n",
      "Epoch 373/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3820 - val_loss: 1.7076\n",
      "Epoch 374/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3740 - val_loss: 1.7322\n",
      "Epoch 375/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4017 - val_loss: 1.7621\n",
      "Epoch 376/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4188 - val_loss: 1.8181\n",
      "Epoch 377/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5397 - val_loss: 1.7177\n",
      "Epoch 378/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4860 - val_loss: 1.6871\n",
      "Epoch 379/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.5098 - val_loss: 1.7442\n",
      "Epoch 380/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.4084 - val_loss: 1.8316\n",
      "Epoch 381/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.5701 - val_loss: 2.1574\n",
      "Epoch 382/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4982 - val_loss: 1.8068\n",
      "Epoch 383/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4659 - val_loss: 1.7338\n",
      "Epoch 384/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.3613 - val_loss: 1.7222\n",
      "Epoch 385/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3556 - val_loss: 1.6870\n",
      "Epoch 386/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3689 - val_loss: 1.7060\n",
      "Epoch 387/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3552 - val_loss: 1.7779\n",
      "Epoch 388/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3683 - val_loss: 1.7815\n",
      "Epoch 389/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4552 - val_loss: 1.9364\n",
      "Epoch 390/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4632 - val_loss: 1.7188\n",
      "Epoch 391/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3528 - val_loss: 1.7187\n",
      "Epoch 392/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3707 - val_loss: 1.7273\n",
      "Epoch 393/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.3803 - val_loss: 1.8231\n",
      "Epoch 394/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 1.4578 - val_loss: 1.8547\n",
      "Epoch 395/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.4410 - val_loss: 1.7327\n",
      "Epoch 396/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4326 - val_loss: 1.7252\n",
      "Epoch 397/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3511 - val_loss: 1.7103\n",
      "Epoch 398/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3702 - val_loss: 1.7901\n",
      "Epoch 399/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3505 - val_loss: 1.7195\n",
      "Epoch 400/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3953 - val_loss: 1.8757\n",
      "Epoch 401/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.4324 - val_loss: 1.7804\n",
      "Epoch 402/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3923 - val_loss: 1.8843\n",
      "Epoch 403/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4224 - val_loss: 1.7545\n",
      "Epoch 404/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3774 - val_loss: 1.7171\n",
      "Epoch 405/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3347 - val_loss: 1.7613\n",
      "Epoch 406/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3906 - val_loss: 1.7800\n",
      "Epoch 407/500\n",
      "12688/12688 [==============================] - ETA: 0s - loss: 1.416 - 0s 3us/step - loss: 1.4455 - val_loss: 1.7116\n",
      "Epoch 408/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3840 - val_loss: 1.7335\n",
      "Epoch 409/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3604 - val_loss: 1.8912\n",
      "Epoch 410/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3818 - val_loss: 1.7118\n",
      "Epoch 411/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3818 - val_loss: 1.9130\n",
      "Epoch 412/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.4936 - val_loss: 1.7693\n",
      "Epoch 413/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5172 - val_loss: 1.7570\n",
      "Epoch 414/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4205 - val_loss: 1.7077\n",
      "Epoch 415/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3693 - val_loss: 1.7346\n",
      "Epoch 416/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.4402 - val_loss: 1.8132\n",
      "Epoch 417/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.4287 - val_loss: 1.8213\n",
      "Epoch 418/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3795 - val_loss: 1.7055\n",
      "Epoch 419/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3576 - val_loss: 1.7150\n",
      "Epoch 420/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3535 - val_loss: 1.7075\n",
      "Epoch 421/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4673 - val_loss: 1.8198\n",
      "Epoch 422/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4931 - val_loss: 1.7918\n",
      "Epoch 423/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5124 - val_loss: 1.7175\n",
      "Epoch 424/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4605 - val_loss: 1.7255\n",
      "Epoch 425/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3355 - val_loss: 1.7615\n",
      "Epoch 426/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3369 - val_loss: 1.7135\n",
      "Epoch 427/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3455 - val_loss: 1.8297\n",
      "Epoch 428/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4256 - val_loss: 1.8107\n",
      "Epoch 429/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4142 - val_loss: 1.7120\n",
      "Epoch 430/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3504 - val_loss: 1.7273\n",
      "Epoch 431/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3437 - val_loss: 1.7642\n",
      "Epoch 432/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3685 - val_loss: 1.7538\n",
      "Epoch 433/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4005 - val_loss: 1.7953\n",
      "Epoch 434/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4032 - val_loss: 1.7373\n",
      "Epoch 435/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3374 - val_loss: 1.7300\n",
      "Epoch 436/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3551 - val_loss: 1.7491\n",
      "Epoch 437/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3406 - val_loss: 1.7180\n",
      "Epoch 438/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3373 - val_loss: 1.7357\n",
      "Epoch 439/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3467 - val_loss: 1.7362\n",
      "Epoch 440/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3948 - val_loss: 2.1251\n",
      "Epoch 441/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4348 - val_loss: 1.7107\n",
      "Epoch 442/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3283 - val_loss: 1.8016\n",
      "Epoch 443/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3396 - val_loss: 1.8347\n",
      "Epoch 444/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3941 - val_loss: 1.8221\n",
      "Epoch 445/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3859 - val_loss: 1.7360\n",
      "Epoch 446/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1.3634 - val_loss: 1.7247\n",
      "Epoch 447/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3295 - val_loss: 1.7384\n",
      "Epoch 448/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3906 - val_loss: 1.7174\n",
      "Epoch 449/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3323 - val_loss: 1.7451\n",
      "Epoch 450/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3362 - val_loss: 1.7814\n",
      "Epoch 451/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3646 - val_loss: 1.8180\n",
      "Epoch 452/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3501 - val_loss: 1.7321\n",
      "Epoch 453/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3739 - val_loss: 1.7717\n",
      "Epoch 454/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3362 - val_loss: 1.7352\n",
      "Epoch 455/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3536 - val_loss: 2.0107\n",
      "Epoch 456/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4019 - val_loss: 1.7350\n",
      "Epoch 457/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3568 - val_loss: 1.7519\n",
      "Epoch 458/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3503 - val_loss: 1.7463\n",
      "Epoch 459/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3355 - val_loss: 1.7675\n",
      "Epoch 460/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3626 - val_loss: 1.7980\n",
      "Epoch 461/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4665 - val_loss: 1.7752\n",
      "Epoch 462/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4190 - val_loss: 1.7618\n",
      "Epoch 463/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3505 - val_loss: 1.7318\n",
      "Epoch 464/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 1.3472 - val_loss: 1.7624\n",
      "Epoch 465/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4201 - val_loss: 1.7640\n",
      "Epoch 466/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3449 - val_loss: 1.7617\n",
      "Epoch 467/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3355 - val_loss: 1.7589\n",
      "Epoch 468/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3505 - val_loss: 1.8551\n",
      "Epoch 469/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3417 - val_loss: 1.7636\n",
      "Epoch 470/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3511 - val_loss: 1.8925\n",
      "Epoch 471/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3653 - val_loss: 1.7649\n",
      "Epoch 472/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3501 - val_loss: 1.7323\n",
      "Epoch 473/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4233 - val_loss: 2.0124\n",
      "Epoch 474/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.5607 - val_loss: 2.0832\n",
      "Epoch 475/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4928 - val_loss: 1.7444\n",
      "Epoch 476/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4138 - val_loss: 1.7645\n",
      "Epoch 477/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4167 - val_loss: 1.7599\n",
      "Epoch 478/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3262 - val_loss: 1.7514\n",
      "Epoch 479/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3320 - val_loss: 1.7438\n",
      "Epoch 480/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3337 - val_loss: 1.7542\n",
      "Epoch 481/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3478 - val_loss: 1.7764\n",
      "Epoch 482/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3270 - val_loss: 1.8164\n",
      "Epoch 483/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3480 - val_loss: 2.0279\n",
      "Epoch 484/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3498 - val_loss: 1.7260\n",
      "Epoch 485/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3315 - val_loss: 1.8661\n",
      "Epoch 486/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3664 - val_loss: 1.7736\n",
      "Epoch 487/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3302 - val_loss: 1.8413\n",
      "Epoch 488/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4937 - val_loss: 1.8280\n",
      "Epoch 489/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3649 - val_loss: 1.8028\n",
      "Epoch 490/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3676 - val_loss: 1.7429\n",
      "Epoch 491/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3354 - val_loss: 1.8357\n",
      "Epoch 492/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3263 - val_loss: 1.8037\n",
      "Epoch 493/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3418 - val_loss: 1.7562\n",
      "Epoch 494/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3870 - val_loss: 1.7815\n",
      "Epoch 495/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.4823 - val_loss: 1.7622\n",
      "Epoch 496/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3933 - val_loss: 1.7914\n",
      "Epoch 497/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3402 - val_loss: 1.7330\n",
      "Epoch 498/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3062 - val_loss: 1.7723\n",
      "Epoch 499/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3442 - val_loss: 1.8740\n",
      "Epoch 500/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1.3361 - val_loss: 1.7634\n",
      "Train on 12688 samples, validate on 3173 samples\n",
      "Epoch 1/500\n",
      "12688/12688 [==============================] - 0s 24us/step - loss: 27919.6823 - val_loss: 19440.1301\n",
      "Epoch 2/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 12704.5972 - val_loss: 5787.7200\n",
      "Epoch 3/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 5245.5857 - val_loss: 2975.0710\n",
      "Epoch 4/500\n",
      "12688/12688 [==============================] - 0s 11us/step - loss: 2449.9549 - val_loss: 2083.3712\n",
      "Epoch 5/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 2086.5213 - val_loss: 1977.6130\n",
      "Epoch 6/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1912.0604 - val_loss: 1832.9626\n",
      "Epoch 7/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1798.6814 - val_loss: 1718.2424\n",
      "Epoch 8/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1695.6168 - val_loss: 1611.7932\n",
      "Epoch 9/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1590.8749 - val_loss: 1502.7713\n",
      "Epoch 10/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1490.4910 - val_loss: 1393.3789\n",
      "Epoch 11/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1409.5633 - val_loss: 1311.6661\n",
      "Epoch 12/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1345.9621 - val_loss: 1266.8965\n",
      "Epoch 13/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1301.9465 - val_loss: 1222.1166\n",
      "Epoch 14/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1273.4039 - val_loss: 1193.5146\n",
      "Epoch 15/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1250.4161 - val_loss: 1168.4315\n",
      "Epoch 16/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1229.4773 - val_loss: 1152.5548\n",
      "Epoch 17/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1211.3289 - val_loss: 1145.3868\n",
      "Epoch 18/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1201.6154 - val_loss: 1131.2336\n",
      "Epoch 19/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1191.9715 - val_loss: 1123.1167\n",
      "Epoch 20/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1184.5228 - val_loss: 1116.6062\n",
      "Epoch 21/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1175.7873 - val_loss: 1116.3588\n",
      "Epoch 22/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1171.6909 - val_loss: 1110.1624\n",
      "Epoch 23/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1167.0333 - val_loss: 1106.6255\n",
      "Epoch 24/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1164.9472 - val_loss: 1106.9342\n",
      "Epoch 25/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1160.8551 - val_loss: 1100.6322\n",
      "Epoch 26/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1157.0121 - val_loss: 1099.2730\n",
      "Epoch 27/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1154.1223 - val_loss: 1097.9786\n",
      "Epoch 28/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1150.0155 - val_loss: 1100.8843\n",
      "Epoch 29/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1151.8055 - val_loss: 1096.8706\n",
      "Epoch 30/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1146.7526 - val_loss: 1100.4176\n",
      "Epoch 31/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1145.3170 - val_loss: 1096.0805\n",
      "Epoch 32/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1145.8698 - val_loss: 1104.9891\n",
      "Epoch 33/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1140.4071 - val_loss: 1098.1518\n",
      "Epoch 34/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1140.7208 - val_loss: 1092.8043\n",
      "Epoch 35/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1137.2080 - val_loss: 1091.3312\n",
      "Epoch 36/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1136.1735 - val_loss: 1095.1166\n",
      "Epoch 37/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1137.8575 - val_loss: 1095.5847\n",
      "Epoch 38/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1137.0220 - val_loss: 1094.1686\n",
      "Epoch 39/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1131.2702 - val_loss: 1095.6419\n",
      "Epoch 40/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1134.1220 - val_loss: 1091.1830\n",
      "Epoch 41/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1134.1021 - val_loss: 1096.8345\n",
      "Epoch 42/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1133.1333 - val_loss: 1099.0710\n",
      "Epoch 43/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1130.1628 - val_loss: 1098.5878\n",
      "Epoch 44/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1134.6740 - val_loss: 1090.0155\n",
      "Epoch 45/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1133.0058 - val_loss: 1098.4132\n",
      "Epoch 46/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1136.6566 - val_loss: 1108.4287\n",
      "Epoch 47/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1124.1860 - val_loss: 1090.0039\n",
      "Epoch 48/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1122.2737 - val_loss: 1094.8553\n",
      "Epoch 49/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1122.1426 - val_loss: 1101.7588\n",
      "Epoch 50/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1129.2761 - val_loss: 1089.8926\n",
      "Epoch 51/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1119.7710 - val_loss: 1085.8515\n",
      "Epoch 52/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1122.1163 - val_loss: 1085.8746\n",
      "Epoch 53/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1119.5665 - val_loss: 1097.7243\n",
      "Epoch 54/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1120.2479 - val_loss: 1092.7118\n",
      "Epoch 55/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1119.8532 - val_loss: 1093.1313\n",
      "Epoch 56/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1116.7589 - val_loss: 1085.3839\n",
      "Epoch 57/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1114.5406 - val_loss: 1085.7184\n",
      "Epoch 58/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1112.7188 - val_loss: 1087.4277\n",
      "Epoch 59/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1114.8838 - val_loss: 1099.5221\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12688/12688 [==============================] - 0s 3us/step - loss: 1114.0921 - val_loss: 1084.0239\n",
      "Epoch 61/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1111.7799 - val_loss: 1097.4570\n",
      "Epoch 62/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1112.6978 - val_loss: 1086.5391\n",
      "Epoch 63/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1111.4248 - val_loss: 1083.2479\n",
      "Epoch 64/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1114.7064 - val_loss: 1086.8454\n",
      "Epoch 65/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1112.3830 - val_loss: 1090.9806\n",
      "Epoch 66/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1110.8414 - val_loss: 1088.1771\n",
      "Epoch 67/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1105.5860 - val_loss: 1089.1200\n",
      "Epoch 68/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1107.4764 - val_loss: 1086.7123\n",
      "Epoch 69/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1112.5670 - val_loss: 1091.1685\n",
      "Epoch 70/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1108.9242 - val_loss: 1090.9148\n",
      "Epoch 71/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1102.1994 - val_loss: 1082.7891\n",
      "Epoch 72/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1107.3952 - val_loss: 1088.7790\n",
      "Epoch 73/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1123.2515 - val_loss: 1113.5466\n",
      "Epoch 74/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1119.6112 - val_loss: 1127.5898\n",
      "Epoch 75/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1114.4515 - val_loss: 1088.0807\n",
      "Epoch 76/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1102.3772 - val_loss: 1081.9019\n",
      "Epoch 77/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1095.6900 - val_loss: 1087.1980\n",
      "Epoch 78/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1098.8466 - val_loss: 1081.7709\n",
      "Epoch 79/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1097.8396 - val_loss: 1087.3956\n",
      "Epoch 80/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1096.5608 - val_loss: 1088.5673\n",
      "Epoch 81/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1095.1456 - val_loss: 1083.8102\n",
      "Epoch 82/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1102.3466 - val_loss: 1087.1876\n",
      "Epoch 83/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1097.7084 - val_loss: 1092.7745\n",
      "Epoch 84/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1095.1578 - val_loss: 1086.7753\n",
      "Epoch 85/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1092.9419 - val_loss: 1093.6630\n",
      "Epoch 86/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1092.2218 - val_loss: 1083.3922\n",
      "Epoch 87/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1091.1394 - val_loss: 1089.4433\n",
      "Epoch 88/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1093.2383 - val_loss: 1094.6604\n",
      "Epoch 89/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1094.5253 - val_loss: 1090.5404\n",
      "Epoch 90/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1088.2251 - val_loss: 1081.8260\n",
      "Epoch 91/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1090.4169 - val_loss: 1086.6976\n",
      "Epoch 92/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1086.1989 - val_loss: 1082.9016\n",
      "Epoch 93/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1084.0684 - val_loss: 1081.2768\n",
      "Epoch 94/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1082.6060 - val_loss: 1081.9456\n",
      "Epoch 95/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1081.6311 - val_loss: 1082.4478\n",
      "Epoch 96/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1082.8646 - val_loss: 1084.2978\n",
      "Epoch 97/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1082.0640 - val_loss: 1086.9209\n",
      "Epoch 98/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1084.9344 - val_loss: 1081.4554\n",
      "Epoch 99/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1082.8637 - val_loss: 1089.6722\n",
      "Epoch 100/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 1084.7418 - val_loss: 1081.9035\n",
      "Epoch 101/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1079.9028 - val_loss: 1088.6958\n",
      "Epoch 102/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1079.9684 - val_loss: 1083.5559\n",
      "Epoch 103/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1078.3028 - val_loss: 1088.3365\n",
      "Epoch 104/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1079.5992 - val_loss: 1079.9371\n",
      "Epoch 105/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1093.0493 - val_loss: 1093.8881\n",
      "Epoch 106/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1082.5328 - val_loss: 1084.8175\n",
      "Epoch 107/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1076.3456 - val_loss: 1087.5117\n",
      "Epoch 108/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1074.6583 - val_loss: 1079.8559\n",
      "Epoch 109/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1076.5179 - val_loss: 1077.6380\n",
      "Epoch 110/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1072.4479 - val_loss: 1078.8711\n",
      "Epoch 111/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 1071.4573 - val_loss: 1078.7982\n",
      "Epoch 112/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1072.9340 - val_loss: 1080.4690\n",
      "Epoch 113/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1071.0908 - val_loss: 1078.4050\n",
      "Epoch 114/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1077.4127 - val_loss: 1086.6513\n",
      "Epoch 115/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1072.7051 - val_loss: 1099.0656\n",
      "Epoch 116/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1068.5537 - val_loss: 1079.0441\n",
      "Epoch 117/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1063.4353 - val_loss: 1082.4434\n",
      "Epoch 118/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 1066.1407 - val_loss: 1083.3411\n",
      "Epoch 119/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1064.0590 - val_loss: 1085.5068\n",
      "Epoch 120/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1061.7334 - val_loss: 1080.2842\n",
      "Epoch 121/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1062.6722 - val_loss: 1089.2373\n",
      "Epoch 122/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1077.7207 - val_loss: 1080.4230\n",
      "Epoch 123/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1065.3250 - val_loss: 1076.2678\n",
      "Epoch 124/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1068.6258 - val_loss: 1072.5758\n",
      "Epoch 125/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1059.8828 - val_loss: 1094.6116\n",
      "Epoch 126/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1059.6303 - val_loss: 1080.6818\n",
      "Epoch 127/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 1054.9035 - val_loss: 1074.4682\n",
      "Epoch 128/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1055.9199 - val_loss: 1078.3525\n",
      "Epoch 129/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1055.6932 - val_loss: 1072.4837\n",
      "Epoch 130/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1052.3468 - val_loss: 1073.4418\n",
      "Epoch 131/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1056.6688 - val_loss: 1079.8012\n",
      "Epoch 132/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1059.2925 - val_loss: 1079.5773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1050.6756 - val_loss: 1073.2731\n",
      "Epoch 134/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1053.1154 - val_loss: 1077.9613\n",
      "Epoch 135/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1050.7850 - val_loss: 1095.6422\n",
      "Epoch 136/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1054.0440 - val_loss: 1083.7727\n",
      "Epoch 137/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1060.2887 - val_loss: 1089.6636\n",
      "Epoch 138/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 1053.0976 - val_loss: 1079.4498\n",
      "Epoch 139/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1052.5129 - val_loss: 1069.5997\n",
      "Epoch 140/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1045.6669 - val_loss: 1074.6423\n",
      "Epoch 141/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1047.3460 - val_loss: 1074.7580\n",
      "Epoch 142/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1046.0272 - val_loss: 1070.7618\n",
      "Epoch 143/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 1040.6854 - val_loss: 1073.8488\n",
      "Epoch 144/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1040.7367 - val_loss: 1072.3736\n",
      "Epoch 145/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1040.6633 - val_loss: 1078.3343\n",
      "Epoch 146/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1043.9192 - val_loss: 1077.0316\n",
      "Epoch 147/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1047.2912 - val_loss: 1075.5077\n",
      "Epoch 148/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1043.4799 - val_loss: 1070.3581\n",
      "Epoch 149/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1036.4497 - val_loss: 1071.6900\n",
      "Epoch 150/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1041.6924 - val_loss: 1073.4740\n",
      "Epoch 151/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 1045.8518 - val_loss: 1074.6789\n",
      "Epoch 152/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1039.8531 - val_loss: 1081.3143\n",
      "Epoch 153/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1057.0003 - val_loss: 1068.9522\n",
      "Epoch 154/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1042.7721 - val_loss: 1073.5639\n",
      "Epoch 155/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1039.3309 - val_loss: 1080.4089\n",
      "Epoch 156/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1033.0648 - val_loss: 1080.8662\n",
      "Epoch 157/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1042.2643 - val_loss: 1085.7520\n",
      "Epoch 158/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 1041.8171 - val_loss: 1085.3218\n",
      "Epoch 159/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1037.6892 - val_loss: 1093.7907\n",
      "Epoch 160/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 1060.2320 - val_loss: 1073.6703\n",
      "Epoch 161/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1034.6348 - val_loss: 1071.8182\n",
      "Epoch 162/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1032.8080 - val_loss: 1071.0353\n",
      "Epoch 163/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1026.7731 - val_loss: 1076.6003\n",
      "Epoch 164/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1029.2151 - val_loss: 1077.0726\n",
      "Epoch 165/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1029.2936 - val_loss: 1078.2019\n",
      "Epoch 166/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1032.5766 - val_loss: 1072.7413\n",
      "Epoch 167/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1036.4329 - val_loss: 1074.1516\n",
      "Epoch 168/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1025.5295 - val_loss: 1073.8532\n",
      "Epoch 169/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1023.3716 - val_loss: 1072.2315\n",
      "Epoch 170/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1020.0351 - val_loss: 1074.5317\n",
      "Epoch 171/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1021.0259 - val_loss: 1077.0214\n",
      "Epoch 172/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1019.5314 - val_loss: 1082.6660\n",
      "Epoch 173/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1017.5206 - val_loss: 1075.2288\n",
      "Epoch 174/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1016.2834 - val_loss: 1074.7763\n",
      "Epoch 175/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1015.5061 - val_loss: 1077.4846\n",
      "Epoch 176/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1017.1780 - val_loss: 1081.0505\n",
      "Epoch 177/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1014.3043 - val_loss: 1074.5251\n",
      "Epoch 178/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1016.6681 - val_loss: 1081.4822\n",
      "Epoch 179/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1015.5603 - val_loss: 1072.5748\n",
      "Epoch 180/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1011.0238 - val_loss: 1071.0642\n",
      "Epoch 181/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1014.1583 - val_loss: 1069.4147\n",
      "Epoch 182/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1024.5890 - val_loss: 1101.8425\n",
      "Epoch 183/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1021.8179 - val_loss: 1075.7443\n",
      "Epoch 184/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1007.4742 - val_loss: 1070.6452\n",
      "Epoch 185/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1010.2004 - val_loss: 1074.6242\n",
      "Epoch 186/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1005.9002 - val_loss: 1074.7880\n",
      "Epoch 187/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1006.5215 - val_loss: 1074.1235\n",
      "Epoch 188/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1017.9522 - val_loss: 1077.3094\n",
      "Epoch 189/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1010.0865 - val_loss: 1096.7545\n",
      "Epoch 190/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1006.5384 - val_loss: 1073.7182\n",
      "Epoch 191/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1006.7311 - val_loss: 1078.1476\n",
      "Epoch 192/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1003.9044 - val_loss: 1071.4561\n",
      "Epoch 193/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1001.8622 - val_loss: 1074.5709\n",
      "Epoch 194/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 997.4616 - val_loss: 1083.3281\n",
      "Epoch 195/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1000.4629 - val_loss: 1090.9123\n",
      "Epoch 196/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1009.2551 - val_loss: 1082.2931\n",
      "Epoch 197/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1016.0016 - val_loss: 1074.1055\n",
      "Epoch 198/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 994.7899 - val_loss: 1081.3411\n",
      "Epoch 199/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1012.1801 - val_loss: 1124.0093\n",
      "Epoch 200/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1010.1813 - val_loss: 1082.7981\n",
      "Epoch 201/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 1002.3899 - val_loss: 1078.1649\n",
      "Epoch 202/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 989.2699 - val_loss: 1078.9659\n",
      "Epoch 203/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 993.7819 - val_loss: 1074.8627\n",
      "Epoch 204/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 992.4149 - val_loss: 1080.7454\n",
      "Epoch 205/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 997.8837 - val_loss: 1083.6141\n",
      "Epoch 206/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 992.4319 - val_loss: 1076.0286\n",
      "Epoch 207/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 987.4505 - val_loss: 1080.5654\n",
      "Epoch 208/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 984.1223 - val_loss: 1074.5068\n",
      "Epoch 209/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 989.7655 - val_loss: 1080.5102\n",
      "Epoch 210/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 992.9587 - val_loss: 1087.0971\n",
      "Epoch 211/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 989.9958 - val_loss: 1079.9741\n",
      "Epoch 212/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 985.1551 - val_loss: 1084.1856\n",
      "Epoch 213/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 985.1762 - val_loss: 1081.9346\n",
      "Epoch 214/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 983.1347 - val_loss: 1083.9664\n",
      "Epoch 215/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 981.6393 - val_loss: 1092.7306\n",
      "Epoch 216/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 986.1246 - val_loss: 1090.9111\n",
      "Epoch 217/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 993.2009 - val_loss: 1089.6745\n",
      "Epoch 218/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 995.4698 - val_loss: 1094.2828\n",
      "Epoch 219/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 983.8370 - val_loss: 1087.0025\n",
      "Epoch 220/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 979.7871 - val_loss: 1081.3049\n",
      "Epoch 221/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 973.4775 - val_loss: 1083.1038\n",
      "Epoch 222/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 972.0323 - val_loss: 1082.6459\n",
      "Epoch 223/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 974.1085 - val_loss: 1097.5599\n",
      "Epoch 224/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 976.3030 - val_loss: 1078.5549\n",
      "Epoch 225/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 975.6577 - val_loss: 1084.8696\n",
      "Epoch 226/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 971.5125 - val_loss: 1084.4841\n",
      "Epoch 227/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 972.4660 - val_loss: 1081.8103\n",
      "Epoch 228/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 970.2376 - val_loss: 1081.8882\n",
      "Epoch 229/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 972.7951 - val_loss: 1086.7468\n",
      "Epoch 230/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 969.4820 - val_loss: 1085.0952\n",
      "Epoch 231/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 963.7655 - val_loss: 1086.4980\n",
      "Epoch 232/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 963.3127 - val_loss: 1084.6461\n",
      "Epoch 233/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 965.7557 - val_loss: 1096.1584\n",
      "Epoch 234/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 967.3800 - val_loss: 1106.9867\n",
      "Epoch 235/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 967.3325 - val_loss: 1091.1287\n",
      "Epoch 236/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 964.4338 - val_loss: 1083.9181\n",
      "Epoch 237/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 962.3781 - val_loss: 1090.8460\n",
      "Epoch 238/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 964.5942 - val_loss: 1089.0463\n",
      "Epoch 239/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 958.8705 - val_loss: 1086.5202\n",
      "Epoch 240/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 969.1159 - val_loss: 1113.6218\n",
      "Epoch 241/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 966.0580 - val_loss: 1108.2005\n",
      "Epoch 242/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 975.8130 - val_loss: 1090.4509\n",
      "Epoch 243/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 963.2752 - val_loss: 1084.7494\n",
      "Epoch 244/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 963.1578 - val_loss: 1088.4711\n",
      "Epoch 245/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 964.8139 - val_loss: 1093.3073\n",
      "Epoch 246/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 966.4551 - val_loss: 1088.2258\n",
      "Epoch 247/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 962.0712 - val_loss: 1095.2639\n",
      "Epoch 248/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 965.1472 - val_loss: 1087.0124\n",
      "Epoch 249/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 955.2473 - val_loss: 1099.0254\n",
      "Epoch 250/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 954.2306 - val_loss: 1138.3818\n",
      "Epoch 251/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 981.7194 - val_loss: 1094.0343\n",
      "Epoch 252/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 952.2290 - val_loss: 1087.2890\n",
      "Epoch 253/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 947.9362 - val_loss: 1102.5135\n",
      "Epoch 254/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 955.0115 - val_loss: 1086.2930\n",
      "Epoch 255/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 949.1273 - val_loss: 1105.3118\n",
      "Epoch 256/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 964.0709 - val_loss: 1095.9527\n",
      "Epoch 257/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 959.4194 - val_loss: 1096.4401\n",
      "Epoch 258/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 959.5204 - val_loss: 1091.4306\n",
      "Epoch 259/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 952.9699 - val_loss: 1088.2334\n",
      "Epoch 260/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 949.7308 - val_loss: 1115.0139\n",
      "Epoch 261/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 961.2341 - val_loss: 1102.7337\n",
      "Epoch 262/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 957.2441 - val_loss: 1091.0657\n",
      "Epoch 263/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 943.7668 - val_loss: 1094.6720\n",
      "Epoch 264/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 947.3924 - val_loss: 1092.4304\n",
      "Epoch 265/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 945.0398 - val_loss: 1092.3153\n",
      "Epoch 266/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 938.4343 - val_loss: 1095.4720\n",
      "Epoch 267/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 944.9750 - val_loss: 1093.4122\n",
      "Epoch 268/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 945.9551 - val_loss: 1116.1422\n",
      "Epoch 269/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 948.4702 - val_loss: 1106.6461\n",
      "Epoch 270/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 959.4843 - val_loss: 1090.0408\n",
      "Epoch 271/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 937.1672 - val_loss: 1092.6378\n",
      "Epoch 272/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 938.9331 - val_loss: 1105.4434\n",
      "Epoch 273/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 942.3855 - val_loss: 1103.5777\n",
      "Epoch 274/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 941.8503 - val_loss: 1090.6027\n",
      "Epoch 275/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 950.1825 - val_loss: 1126.1827\n",
      "Epoch 276/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 949.7136 - val_loss: 1106.2871\n",
      "Epoch 277/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 948.5595 - val_loss: 1093.4444\n",
      "Epoch 278/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12688/12688 [==============================] - 0s 3us/step - loss: 940.2209 - val_loss: 1092.0088\n",
      "Epoch 279/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 933.0208 - val_loss: 1103.7857\n",
      "Epoch 280/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 938.9992 - val_loss: 1097.8279\n",
      "Epoch 281/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 934.8766 - val_loss: 1103.2300\n",
      "Epoch 282/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 940.2127 - val_loss: 1129.2422\n",
      "Epoch 283/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 935.5350 - val_loss: 1092.3670\n",
      "Epoch 284/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 930.2720 - val_loss: 1102.0153\n",
      "Epoch 285/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 925.4168 - val_loss: 1101.4960\n",
      "Epoch 286/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 934.6186 - val_loss: 1113.3936\n",
      "Epoch 287/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 931.8493 - val_loss: 1100.6779\n",
      "Epoch 288/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 944.4157 - val_loss: 1112.6375\n",
      "Epoch 289/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 935.7963 - val_loss: 1105.8976\n",
      "Epoch 290/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 944.4799 - val_loss: 1098.5197\n",
      "Epoch 291/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 941.2550 - val_loss: 1102.3767\n",
      "Epoch 292/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 936.6373 - val_loss: 1092.5296\n",
      "Epoch 293/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 919.8282 - val_loss: 1112.7534\n",
      "Epoch 294/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 927.5031 - val_loss: 1097.2427\n",
      "Epoch 295/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 924.1382 - val_loss: 1106.8698\n",
      "Epoch 296/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 920.1472 - val_loss: 1094.5255\n",
      "Epoch 297/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 923.6597 - val_loss: 1109.4309\n",
      "Epoch 298/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 926.0498 - val_loss: 1088.7721\n",
      "Epoch 299/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 918.6525 - val_loss: 1106.4996\n",
      "Epoch 300/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 924.8625 - val_loss: 1102.3917\n",
      "Epoch 301/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 918.3309 - val_loss: 1094.9877\n",
      "Epoch 302/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 917.1808 - val_loss: 1100.5414\n",
      "Epoch 303/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 928.4913 - val_loss: 1100.6160\n",
      "Epoch 304/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 920.8584 - val_loss: 1110.9185\n",
      "Epoch 305/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 913.4893 - val_loss: 1099.6369\n",
      "Epoch 306/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 913.3076 - val_loss: 1102.0632\n",
      "Epoch 307/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 922.3366 - val_loss: 1096.0583\n",
      "Epoch 308/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 912.2118 - val_loss: 1108.0470\n",
      "Epoch 309/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 911.8846 - val_loss: 1095.6543\n",
      "Epoch 310/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 911.6712 - val_loss: 1106.2380\n",
      "Epoch 311/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 910.1915 - val_loss: 1107.2628\n",
      "Epoch 312/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 916.6471 - val_loss: 1111.5705\n",
      "Epoch 313/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 917.6573 - val_loss: 1096.3967\n",
      "Epoch 314/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 922.4542 - val_loss: 1112.0447\n",
      "Epoch 315/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 923.5671 - val_loss: 1127.3199\n",
      "Epoch 316/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 913.1884 - val_loss: 1098.4230\n",
      "Epoch 317/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 903.8000 - val_loss: 1107.2009\n",
      "Epoch 318/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 903.0454 - val_loss: 1101.6736\n",
      "Epoch 319/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 906.0524 - val_loss: 1105.0383\n",
      "Epoch 320/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 905.1945 - val_loss: 1103.9341\n",
      "Epoch 321/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 901.2621 - val_loss: 1104.4966\n",
      "Epoch 322/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 912.6908 - val_loss: 1152.3029\n",
      "Epoch 323/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 915.9985 - val_loss: 1114.5580\n",
      "Epoch 324/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 900.8957 - val_loss: 1099.6524\n",
      "Epoch 325/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 899.9063 - val_loss: 1098.6691\n",
      "Epoch 326/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 895.6407 - val_loss: 1103.6990\n",
      "Epoch 327/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 899.6091 - val_loss: 1111.5721\n",
      "Epoch 328/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 892.6180 - val_loss: 1108.5225\n",
      "Epoch 329/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 902.7182 - val_loss: 1117.4644\n",
      "Epoch 330/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 899.9394 - val_loss: 1100.9666\n",
      "Epoch 331/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 909.7840 - val_loss: 1104.4537\n",
      "Epoch 332/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 898.1142 - val_loss: 1108.9841\n",
      "Epoch 333/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 897.9107 - val_loss: 1109.5681\n",
      "Epoch 334/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 894.7998 - val_loss: 1104.8309\n",
      "Epoch 335/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 889.3754 - val_loss: 1111.5125\n",
      "Epoch 336/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 902.4216 - val_loss: 1107.5976\n",
      "Epoch 337/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 893.3696 - val_loss: 1107.9575\n",
      "Epoch 338/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 889.0651 - val_loss: 1105.2756\n",
      "Epoch 339/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 894.6481 - val_loss: 1123.7936\n",
      "Epoch 340/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 889.8980 - val_loss: 1122.7788\n",
      "Epoch 341/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 895.4008 - val_loss: 1108.9024\n",
      "Epoch 342/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 889.2314 - val_loss: 1110.4146\n",
      "Epoch 343/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 888.4843 - val_loss: 1113.7678\n",
      "Epoch 344/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 887.4774 - val_loss: 1113.0172\n",
      "Epoch 345/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 890.1891 - val_loss: 1148.9902\n",
      "Epoch 346/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 910.4889 - val_loss: 1107.3430\n",
      "Epoch 347/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 887.4098 - val_loss: 1121.4753\n",
      "Epoch 348/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 883.1183 - val_loss: 1110.0552\n",
      "Epoch 349/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 885.9001 - val_loss: 1116.0783\n",
      "Epoch 350/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 889.8013 - val_loss: 1123.6785\n",
      "Epoch 351/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 889.8404 - val_loss: 1119.4951\n",
      "Epoch 352/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 883.4656 - val_loss: 1118.6725\n",
      "Epoch 353/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 883.2362 - val_loss: 1117.9038\n",
      "Epoch 354/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 883.6586 - val_loss: 1129.4876\n",
      "Epoch 355/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 898.4934 - val_loss: 1126.0291\n",
      "Epoch 356/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 890.3801 - val_loss: 1123.2816\n",
      "Epoch 357/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 880.3510 - val_loss: 1130.5908\n",
      "Epoch 358/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 880.9163 - val_loss: 1129.7378\n",
      "Epoch 359/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 886.1359 - val_loss: 1120.6609\n",
      "Epoch 360/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 876.9617 - val_loss: 1121.6565\n",
      "Epoch 361/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 882.8219 - val_loss: 1112.7067\n",
      "Epoch 362/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 879.9950 - val_loss: 1108.2140\n",
      "Epoch 363/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 880.8208 - val_loss: 1124.9443\n",
      "Epoch 364/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 882.0376 - val_loss: 1118.2885\n",
      "Epoch 365/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 872.0618 - val_loss: 1165.5857\n",
      "Epoch 366/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 901.3346 - val_loss: 1125.0977\n",
      "Epoch 367/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 880.1029 - val_loss: 1117.7829\n",
      "Epoch 368/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 878.7222 - val_loss: 1134.4023\n",
      "Epoch 369/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 869.3538 - val_loss: 1122.8849\n",
      "Epoch 370/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 878.0670 - val_loss: 1137.7716\n",
      "Epoch 371/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 884.7744 - val_loss: 1121.9681\n",
      "Epoch 372/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 868.5452 - val_loss: 1122.5781\n",
      "Epoch 373/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 868.1421 - val_loss: 1128.7155\n",
      "Epoch 374/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 868.3900 - val_loss: 1146.2364\n",
      "Epoch 375/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 880.4251 - val_loss: 1124.8984\n",
      "Epoch 376/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 870.1302 - val_loss: 1128.9775\n",
      "Epoch 377/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 881.2478 - val_loss: 1128.1283\n",
      "Epoch 378/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 870.0696 - val_loss: 1147.5064\n",
      "Epoch 379/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 873.4429 - val_loss: 1124.4484\n",
      "Epoch 380/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 869.7522 - val_loss: 1123.6264\n",
      "Epoch 381/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 870.6041 - val_loss: 1134.0556\n",
      "Epoch 382/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 868.0314 - val_loss: 1112.4701\n",
      "Epoch 383/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 863.2521 - val_loss: 1133.8280\n",
      "Epoch 384/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 860.4079 - val_loss: 1118.1007\n",
      "Epoch 385/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 861.5934 - val_loss: 1132.0644\n",
      "Epoch 386/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 861.7937 - val_loss: 1126.6175\n",
      "Epoch 387/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 865.3541 - val_loss: 1122.4928\n",
      "Epoch 388/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 858.6601 - val_loss: 1140.3102\n",
      "Epoch 389/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 865.9861 - val_loss: 1124.8692\n",
      "Epoch 390/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 862.1863 - val_loss: 1129.6294\n",
      "Epoch 391/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 859.5263 - val_loss: 1129.9375\n",
      "Epoch 392/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 860.4255 - val_loss: 1126.8200\n",
      "Epoch 393/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 865.1036 - val_loss: 1154.2729\n",
      "Epoch 394/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 883.2750 - val_loss: 1138.3708\n",
      "Epoch 395/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 877.1469 - val_loss: 1139.9416\n",
      "Epoch 396/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 865.3687 - val_loss: 1131.7386\n",
      "Epoch 397/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 864.5900 - val_loss: 1142.0008\n",
      "Epoch 398/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 855.6330 - val_loss: 1133.1015\n",
      "Epoch 399/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 853.1452 - val_loss: 1159.7451\n",
      "Epoch 400/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 873.4659 - val_loss: 1133.3529\n",
      "Epoch 401/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 862.3034 - val_loss: 1139.3375\n",
      "Epoch 402/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 849.5291 - val_loss: 1134.0419\n",
      "Epoch 403/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 854.6185 - val_loss: 1134.1685\n",
      "Epoch 404/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 848.6526 - val_loss: 1133.4245\n",
      "Epoch 405/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 853.6791 - val_loss: 1134.1079\n",
      "Epoch 406/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 852.3272 - val_loss: 1138.0731\n",
      "Epoch 407/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 852.1634 - val_loss: 1144.2247\n",
      "Epoch 408/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 852.4028 - val_loss: 1134.4879\n",
      "Epoch 409/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 844.3225 - val_loss: 1133.1097\n",
      "Epoch 410/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 844.0142 - val_loss: 1130.0103\n",
      "Epoch 411/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 841.6410 - val_loss: 1141.5837\n",
      "Epoch 412/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 849.3609 - val_loss: 1148.0132\n",
      "Epoch 413/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 865.1384 - val_loss: 1158.7482\n",
      "Epoch 414/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 854.4338 - val_loss: 1137.0712\n",
      "Epoch 415/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 839.5562 - val_loss: 1132.8858\n",
      "Epoch 416/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 843.2157 - val_loss: 1136.4818\n",
      "Epoch 417/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 842.2202 - val_loss: 1142.5509\n",
      "Epoch 418/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 847.5787 - val_loss: 1138.8027\n",
      "Epoch 419/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 854.5477 - val_loss: 1130.4040\n",
      "Epoch 420/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 843.0574 - val_loss: 1147.7689\n",
      "Epoch 421/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 839.6824 - val_loss: 1141.4902\n",
      "Epoch 422/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 845.6895 - val_loss: 1151.8362\n",
      "Epoch 423/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 851.4567 - val_loss: 1146.6000\n",
      "Epoch 424/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12688/12688 [==============================] - 0s 3us/step - loss: 841.3678 - val_loss: 1141.7568\n",
      "Epoch 425/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 856.9908 - val_loss: 1150.2780\n",
      "Epoch 426/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 838.7850 - val_loss: 1146.0745\n",
      "Epoch 427/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 842.8497 - val_loss: 1165.4183\n",
      "Epoch 428/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 845.5555 - val_loss: 1138.6216\n",
      "Epoch 429/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 844.3212 - val_loss: 1153.4652\n",
      "Epoch 430/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 839.2344 - val_loss: 1148.4406\n",
      "Epoch 431/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 841.1125 - val_loss: 1146.1742\n",
      "Epoch 432/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 840.9185 - val_loss: 1151.0465\n",
      "Epoch 433/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 847.2226 - val_loss: 1144.5638\n",
      "Epoch 434/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 844.2048 - val_loss: 1156.4389\n",
      "Epoch 435/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 846.7093 - val_loss: 1175.9384\n",
      "Epoch 436/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 836.8260 - val_loss: 1147.4360\n",
      "Epoch 437/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 834.2852 - val_loss: 1159.9850\n",
      "Epoch 438/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 835.5135 - val_loss: 1147.8014\n",
      "Epoch 439/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 835.9379 - val_loss: 1154.9148\n",
      "Epoch 440/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 828.2611 - val_loss: 1148.9141\n",
      "Epoch 441/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 832.5240 - val_loss: 1164.9603\n",
      "Epoch 442/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 841.6648 - val_loss: 1144.3634\n",
      "Epoch 443/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 837.0678 - val_loss: 1153.3594\n",
      "Epoch 444/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 838.0513 - val_loss: 1150.2547\n",
      "Epoch 445/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 833.5790 - val_loss: 1146.4781\n",
      "Epoch 446/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 823.6511 - val_loss: 1153.6653\n",
      "Epoch 447/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 827.4513 - val_loss: 1150.5176\n",
      "Epoch 448/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 822.9030 - val_loss: 1147.4572\n",
      "Epoch 449/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 829.0217 - val_loss: 1155.4430\n",
      "Epoch 450/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 830.3292 - val_loss: 1151.8991\n",
      "Epoch 451/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 822.0828 - val_loss: 1153.2373\n",
      "Epoch 452/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 827.3681 - val_loss: 1166.2207\n",
      "Epoch 453/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 831.2111 - val_loss: 1172.0646\n",
      "Epoch 454/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 835.3515 - val_loss: 1166.8029\n",
      "Epoch 455/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 827.3760 - val_loss: 1161.7821\n",
      "Epoch 456/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 818.8369 - val_loss: 1168.4990\n",
      "Epoch 457/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 828.3324 - val_loss: 1169.9770\n",
      "Epoch 458/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 820.3712 - val_loss: 1175.3962\n",
      "Epoch 459/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 838.0617 - val_loss: 1150.5052\n",
      "Epoch 460/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 828.7365 - val_loss: 1175.2062\n",
      "Epoch 461/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 821.9490 - val_loss: 1160.8180\n",
      "Epoch 462/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 819.1231 - val_loss: 1162.5943\n",
      "Epoch 463/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 831.1908 - val_loss: 1164.8392\n",
      "Epoch 464/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 822.9489 - val_loss: 1197.0176\n",
      "Epoch 465/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 840.2792 - val_loss: 1187.1270\n",
      "Epoch 466/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 839.4167 - val_loss: 1170.1929\n",
      "Epoch 467/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 823.6921 - val_loss: 1155.0831\n",
      "Epoch 468/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 811.3241 - val_loss: 1170.5234\n",
      "Epoch 469/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 816.9789 - val_loss: 1176.8378\n",
      "Epoch 470/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 824.6430 - val_loss: 1172.8439\n",
      "Epoch 471/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 812.9981 - val_loss: 1172.8219\n",
      "Epoch 472/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 827.2801 - val_loss: 1204.7795\n",
      "Epoch 473/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 825.6580 - val_loss: 1182.6819\n",
      "Epoch 474/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 825.9157 - val_loss: 1164.4355\n",
      "Epoch 475/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 817.1783 - val_loss: 1190.4159\n",
      "Epoch 476/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 810.7927 - val_loss: 1157.8688\n",
      "Epoch 477/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 808.0645 - val_loss: 1158.4443\n",
      "Epoch 478/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 808.6352 - val_loss: 1177.2291\n",
      "Epoch 479/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 813.6125 - val_loss: 1171.5248\n",
      "Epoch 480/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 811.5623 - val_loss: 1171.2962\n",
      "Epoch 481/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 813.5024 - val_loss: 1166.7405\n",
      "Epoch 482/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 808.9827 - val_loss: 1181.7255\n",
      "Epoch 483/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 804.7008 - val_loss: 1174.0991\n",
      "Epoch 484/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 805.3773 - val_loss: 1173.5763\n",
      "Epoch 485/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 805.8714 - val_loss: 1175.3648\n",
      "Epoch 486/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 801.7934 - val_loss: 1165.0779\n",
      "Epoch 487/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 802.4898 - val_loss: 1199.3311\n",
      "Epoch 488/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 807.1331 - val_loss: 1171.3168\n",
      "Epoch 489/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 806.9743 - val_loss: 1214.0852\n",
      "Epoch 490/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 812.2228 - val_loss: 1182.3505\n",
      "Epoch 491/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 822.5124 - val_loss: 1211.3643\n",
      "Epoch 492/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 824.1882 - val_loss: 1215.5954\n",
      "Epoch 493/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 818.4861 - val_loss: 1186.3823\n",
      "Epoch 494/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 806.0594 - val_loss: 1177.7074\n",
      "Epoch 495/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 803.9016 - val_loss: 1172.4567\n",
      "Epoch 496/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 809.5250 - val_loss: 1170.7428\n",
      "Epoch 497/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 804.2256 - val_loss: 1175.1583\n",
      "Epoch 498/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 800.8091 - val_loss: 1175.2270\n",
      "Epoch 499/500\n",
      "12688/12688 [==============================] - 0s 11us/step - loss: 799.4543 - val_loss: 1182.4293\n",
      "Epoch 500/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 798.6659 - val_loss: 1179.7011\n",
      "Train on 12688 samples, validate on 3173 samples\n",
      "Epoch 1/500\n",
      "12688/12688 [==============================] - 1s 43us/step - loss: 2.0126 - val_loss: 0.4557\n",
      "Epoch 2/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.5055 - val_loss: 0.3644\n",
      "Epoch 3/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.3185 - val_loss: 0.2543\n",
      "Epoch 4/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.2485 - val_loss: 0.2373\n",
      "Epoch 5/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.2151 - val_loss: 0.2020\n",
      "Epoch 6/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.1930 - val_loss: 0.1879\n",
      "Epoch 7/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.1763 - val_loss: 0.1712\n",
      "Epoch 8/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.1622 - val_loss: 0.1583\n",
      "Epoch 9/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.1507 - val_loss: 0.1510\n",
      "Epoch 10/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.1415 - val_loss: 0.1393\n",
      "Epoch 11/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 0.1299 - val_loss: 0.1304\n",
      "Epoch 12/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.1215 - val_loss: 0.1249\n",
      "Epoch 13/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.1149 - val_loss: 0.1153\n",
      "Epoch 14/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.1056 - val_loss: 0.1089\n",
      "Epoch 15/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.1021 - val_loss: 0.1007\n",
      "Epoch 16/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0980 - val_loss: 0.0970\n",
      "Epoch 17/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0880 - val_loss: 0.0976\n",
      "Epoch 18/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0843 - val_loss: 0.0876\n",
      "Epoch 19/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0829 - val_loss: 0.0961\n",
      "Epoch 20/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0811 - val_loss: 0.0817\n",
      "Epoch 21/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0736 - val_loss: 0.0843\n",
      "Epoch 22/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0714 - val_loss: 0.0772\n",
      "Epoch 23/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0696 - val_loss: 0.0862\n",
      "Epoch 24/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0705 - val_loss: 0.0749\n",
      "Epoch 25/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0664 - val_loss: 0.0743\n",
      "Epoch 26/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0661 - val_loss: 0.0766\n",
      "Epoch 27/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0657 - val_loss: 0.0728\n",
      "Epoch 28/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 0.0632 - val_loss: 0.0717\n",
      "Epoch 29/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0616 - val_loss: 0.0707\n",
      "Epoch 30/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0613 - val_loss: 0.0697\n",
      "Epoch 31/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0597 - val_loss: 0.0701\n",
      "Epoch 32/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0588 - val_loss: 0.0689\n",
      "Epoch 33/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0600 - val_loss: 0.0692\n",
      "Epoch 34/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0580 - val_loss: 0.0673\n",
      "Epoch 35/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0587 - val_loss: 0.0713\n",
      "Epoch 36/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0617 - val_loss: 0.0695\n",
      "Epoch 37/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0621 - val_loss: 0.0788\n",
      "Epoch 38/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0582 - val_loss: 0.0694\n",
      "Epoch 39/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0586 - val_loss: 0.0655\n",
      "Epoch 40/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0553 - val_loss: 0.0660\n",
      "Epoch 41/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0544 - val_loss: 0.0674\n",
      "Epoch 42/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0551 - val_loss: 0.0712\n",
      "Epoch 43/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0546 - val_loss: 0.0661\n",
      "Epoch 44/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0539 - val_loss: 0.0689\n",
      "Epoch 45/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0532 - val_loss: 0.0654\n",
      "Epoch 46/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0538 - val_loss: 0.0639\n",
      "Epoch 47/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0538 - val_loss: 0.0655\n",
      "Epoch 48/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0526 - val_loss: 0.0666\n",
      "Epoch 49/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0520 - val_loss: 0.0677\n",
      "Epoch 50/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0521 - val_loss: 0.0679\n",
      "Epoch 51/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0508 - val_loss: 0.0633\n",
      "Epoch 52/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0503 - val_loss: 0.0665\n",
      "Epoch 53/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0534 - val_loss: 0.0661\n",
      "Epoch 54/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0572 - val_loss: 0.0793\n",
      "Epoch 55/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0559 - val_loss: 0.0668\n",
      "Epoch 56/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0502 - val_loss: 0.0627\n",
      "Epoch 57/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0490 - val_loss: 0.0627\n",
      "Epoch 58/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0518 - val_loss: 0.0628\n",
      "Epoch 59/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0486 - val_loss: 0.0625\n",
      "Epoch 60/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0481 - val_loss: 0.0624\n",
      "Epoch 61/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0486 - val_loss: 0.0615\n",
      "Epoch 62/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0488 - val_loss: 0.0642\n",
      "Epoch 63/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0489 - val_loss: 0.0623\n",
      "Epoch 64/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0479 - val_loss: 0.0644\n",
      "Epoch 65/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0472 - val_loss: 0.0622\n",
      "Epoch 66/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0475 - val_loss: 0.0629\n",
      "Epoch 67/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0486 - val_loss: 0.0613\n",
      "Epoch 68/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0482 - val_loss: 0.0616\n",
      "Epoch 69/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0469 - val_loss: 0.0617\n",
      "Epoch 70/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0466 - val_loss: 0.0644\n",
      "Epoch 71/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0462 - val_loss: 0.0610\n",
      "Epoch 72/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0457 - val_loss: 0.0626\n",
      "Epoch 73/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0462 - val_loss: 0.0626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0463 - val_loss: 0.0631\n",
      "Epoch 75/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0458 - val_loss: 0.0614\n",
      "Epoch 76/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0464 - val_loss: 0.0634\n",
      "Epoch 77/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0454 - val_loss: 0.0611\n",
      "Epoch 78/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0464 - val_loss: 0.0615\n",
      "Epoch 79/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0457 - val_loss: 0.0617\n",
      "Epoch 80/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0476 - val_loss: 0.0636\n",
      "Epoch 81/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0479 - val_loss: 0.0621\n",
      "Epoch 82/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0459 - val_loss: 0.0632\n",
      "Epoch 83/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0445 - val_loss: 0.0625\n",
      "Epoch 84/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0444 - val_loss: 0.0599\n",
      "Epoch 85/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0469 - val_loss: 0.0610\n",
      "Epoch 86/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0474 - val_loss: 0.0627\n",
      "Epoch 87/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0476 - val_loss: 0.0621\n",
      "Epoch 88/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0453 - val_loss: 0.0616\n",
      "Epoch 89/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0440 - val_loss: 0.0599\n",
      "Epoch 90/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0464 - val_loss: 0.0686\n",
      "Epoch 91/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0458 - val_loss: 0.0613\n",
      "Epoch 92/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0434 - val_loss: 0.0602\n",
      "Epoch 93/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0423 - val_loss: 0.0602\n",
      "Epoch 94/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0443 - val_loss: 0.0639\n",
      "Epoch 95/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0443 - val_loss: 0.0610\n",
      "Epoch 96/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0465 - val_loss: 0.0619\n",
      "Epoch 97/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0448 - val_loss: 0.0692\n",
      "Epoch 98/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0473 - val_loss: 0.0624\n",
      "Epoch 99/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0452 - val_loss: 0.0599\n",
      "Epoch 100/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0484 - val_loss: 0.0675\n",
      "Epoch 101/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0448 - val_loss: 0.0642\n",
      "Epoch 102/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0443 - val_loss: 0.0618\n",
      "Epoch 103/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0423 - val_loss: 0.0587\n",
      "Epoch 104/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0422 - val_loss: 0.0598\n",
      "Epoch 105/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0441 - val_loss: 0.0597\n",
      "Epoch 106/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0408 - val_loss: 0.0685\n",
      "Epoch 107/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0458 - val_loss: 0.0587\n",
      "Epoch 108/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0494 - val_loss: 0.0741\n",
      "Epoch 109/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0489 - val_loss: 0.0608\n",
      "Epoch 110/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0425 - val_loss: 0.0611\n",
      "Epoch 111/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0406 - val_loss: 0.0592\n",
      "Epoch 112/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0423 - val_loss: 0.0649\n",
      "Epoch 113/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0456 - val_loss: 0.0666\n",
      "Epoch 114/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0418 - val_loss: 0.0589\n",
      "Epoch 115/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0414 - val_loss: 0.0588\n",
      "Epoch 116/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0407 - val_loss: 0.0602\n",
      "Epoch 117/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0432 - val_loss: 0.0605\n",
      "Epoch 118/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0427 - val_loss: 0.0605\n",
      "Epoch 119/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0401 - val_loss: 0.0603\n",
      "Epoch 120/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0401 - val_loss: 0.0587\n",
      "Epoch 121/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0408 - val_loss: 0.0622\n",
      "Epoch 122/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0418 - val_loss: 0.0604\n",
      "Epoch 123/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0416 - val_loss: 0.0663\n",
      "Epoch 124/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0412 - val_loss: 0.0624\n",
      "Epoch 125/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0423 - val_loss: 0.0616\n",
      "Epoch 126/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0414 - val_loss: 0.0601\n",
      "Epoch 127/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0393 - val_loss: 0.0588\n",
      "Epoch 128/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0387 - val_loss: 0.0587\n",
      "Epoch 129/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0399 - val_loss: 0.0592\n",
      "Epoch 130/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0405 - val_loss: 0.0624\n",
      "Epoch 131/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0407 - val_loss: 0.0585\n",
      "Epoch 132/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0409 - val_loss: 0.0697\n",
      "Epoch 133/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0459 - val_loss: 0.0620\n",
      "Epoch 134/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0538 - val_loss: 0.0760\n",
      "Epoch 135/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0468 - val_loss: 0.0600\n",
      "Epoch 136/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0417 - val_loss: 0.0594\n",
      "Epoch 137/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0404 - val_loss: 0.0620\n",
      "Epoch 138/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0415 - val_loss: 0.0596\n",
      "Epoch 139/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0396 - val_loss: 0.0600\n",
      "Epoch 140/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0384 - val_loss: 0.0626\n",
      "Epoch 141/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0403 - val_loss: 0.0601\n",
      "Epoch 142/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0388 - val_loss: 0.0658\n",
      "Epoch 143/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0416 - val_loss: 0.0594\n",
      "Epoch 144/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0401 - val_loss: 0.0610\n",
      "Epoch 145/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0391 - val_loss: 0.0606\n",
      "Epoch 146/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0378 - val_loss: 0.0587\n",
      "Epoch 147/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0437 - val_loss: 0.0596\n",
      "Epoch 148/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0434 - val_loss: 0.0639\n",
      "Epoch 149/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0393 - val_loss: 0.0586\n",
      "Epoch 150/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0385 - val_loss: 0.0631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0383 - val_loss: 0.0601\n",
      "Epoch 152/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0390 - val_loss: 0.0625\n",
      "Epoch 153/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0410 - val_loss: 0.0621\n",
      "Epoch 154/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0385 - val_loss: 0.0589\n",
      "Epoch 155/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0375 - val_loss: 0.0623\n",
      "Epoch 156/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0417 - val_loss: 0.0643\n",
      "Epoch 157/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0389 - val_loss: 0.0615\n",
      "Epoch 158/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0382 - val_loss: 0.0583\n",
      "Epoch 159/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0383 - val_loss: 0.0603\n",
      "Epoch 160/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0372 - val_loss: 0.0594\n",
      "Epoch 161/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0394 - val_loss: 0.0724\n",
      "Epoch 162/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0435 - val_loss: 0.0624\n",
      "Epoch 163/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0382 - val_loss: 0.0592\n",
      "Epoch 164/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0380 - val_loss: 0.0612\n",
      "Epoch 165/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0365 - val_loss: 0.0602\n",
      "Epoch 166/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0367 - val_loss: 0.0591\n",
      "Epoch 167/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0368 - val_loss: 0.0597\n",
      "Epoch 168/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0368 - val_loss: 0.0590\n",
      "Epoch 169/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0364 - val_loss: 0.0631\n",
      "Epoch 170/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0395 - val_loss: 0.0625\n",
      "Epoch 171/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0430 - val_loss: 0.0596\n",
      "Epoch 172/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0363 - val_loss: 0.0627\n",
      "Epoch 173/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0383 - val_loss: 0.0621\n",
      "Epoch 174/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0375 - val_loss: 0.0598\n",
      "Epoch 175/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0357 - val_loss: 0.0606\n",
      "Epoch 176/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0411 - val_loss: 0.0672\n",
      "Epoch 177/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0441 - val_loss: 0.0702\n",
      "Epoch 178/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0408 - val_loss: 0.0708\n",
      "Epoch 179/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0423 - val_loss: 0.0616\n",
      "Epoch 180/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0364 - val_loss: 0.0621\n",
      "Epoch 181/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0380 - val_loss: 0.0604\n",
      "Epoch 182/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0362 - val_loss: 0.0640\n",
      "Epoch 183/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0367 - val_loss: 0.0611\n",
      "Epoch 184/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0360 - val_loss: 0.0625\n",
      "Epoch 185/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0357 - val_loss: 0.0610\n",
      "Epoch 186/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0354 - val_loss: 0.0629\n",
      "Epoch 187/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0374 - val_loss: 0.0637\n",
      "Epoch 188/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0380 - val_loss: 0.0601\n",
      "Epoch 189/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0358 - val_loss: 0.0629\n",
      "Epoch 190/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0365 - val_loss: 0.0612\n",
      "Epoch 191/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0368 - val_loss: 0.0610\n",
      "Epoch 192/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0367 - val_loss: 0.0673\n",
      "Epoch 193/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0367 - val_loss: 0.0610\n",
      "Epoch 194/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0384 - val_loss: 0.0633\n",
      "Epoch 195/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0350 - val_loss: 0.0599\n",
      "Epoch 196/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0377 - val_loss: 0.0624\n",
      "Epoch 197/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0414 - val_loss: 0.0630\n",
      "Epoch 198/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 0.0440 - val_loss: 0.0724\n",
      "Epoch 199/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0401 - val_loss: 0.0619\n",
      "Epoch 200/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0353 - val_loss: 0.0609\n",
      "Epoch 201/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0390 - val_loss: 0.0604\n",
      "Epoch 202/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0354 - val_loss: 0.0623\n",
      "Epoch 203/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0349 - val_loss: 0.0608\n",
      "Epoch 204/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 0.0348 - val_loss: 0.0600\n",
      "Epoch 205/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0381 - val_loss: 0.0651\n",
      "Epoch 206/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0354 - val_loss: 0.0625\n",
      "Epoch 207/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0355 - val_loss: 0.0600\n",
      "Epoch 208/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0363 - val_loss: 0.0606\n",
      "Epoch 209/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0352 - val_loss: 0.0615\n",
      "Epoch 210/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0368 - val_loss: 0.0668\n",
      "Epoch 211/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0375 - val_loss: 0.0616\n",
      "Epoch 212/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 0.0349 - val_loss: 0.0659\n",
      "Epoch 213/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0417 - val_loss: 0.0659\n",
      "Epoch 214/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0405 - val_loss: 0.0634\n",
      "Epoch 215/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0393 - val_loss: 0.0645\n",
      "Epoch 216/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0391 - val_loss: 0.0699\n",
      "Epoch 217/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0383 - val_loss: 0.0599\n",
      "Epoch 218/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0353 - val_loss: 0.0655\n",
      "Epoch 219/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0364 - val_loss: 0.0621\n",
      "Epoch 220/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0342 - val_loss: 0.0649\n",
      "Epoch 221/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0363 - val_loss: 0.0616\n",
      "Epoch 222/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0332 - val_loss: 0.0605\n",
      "Epoch 223/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0332 - val_loss: 0.0625\n",
      "Epoch 224/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0348 - val_loss: 0.0622\n",
      "Epoch 225/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0346 - val_loss: 0.0617\n",
      "Epoch 226/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0337 - val_loss: 0.0634\n",
      "Epoch 227/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0356 - val_loss: 0.0633\n",
      "Epoch 228/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0337 - val_loss: 0.0604\n",
      "Epoch 229/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0351 - val_loss: 0.0629\n",
      "Epoch 230/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0342 - val_loss: 0.0615\n",
      "Epoch 231/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0340 - val_loss: 0.0647\n",
      "Epoch 232/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0341 - val_loss: 0.0643\n",
      "Epoch 233/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0353 - val_loss: 0.0647\n",
      "Epoch 234/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0348 - val_loss: 0.0626\n",
      "Epoch 235/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0366 - val_loss: 0.0665\n",
      "Epoch 236/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0369 - val_loss: 0.0751\n",
      "Epoch 237/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0455 - val_loss: 0.0638\n",
      "Epoch 238/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0507 - val_loss: 0.0674\n",
      "Epoch 239/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0363 - val_loss: 0.0610\n",
      "Epoch 240/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0337 - val_loss: 0.0637\n",
      "Epoch 241/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0349 - val_loss: 0.0631\n",
      "Epoch 242/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0365 - val_loss: 0.0640\n",
      "Epoch 243/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0355 - val_loss: 0.0674\n",
      "Epoch 244/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0363 - val_loss: 0.0614\n",
      "Epoch 245/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0335 - val_loss: 0.0693\n",
      "Epoch 246/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0387 - val_loss: 0.0618\n",
      "Epoch 247/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0343 - val_loss: 0.0614\n",
      "Epoch 248/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0328 - val_loss: 0.0610\n",
      "Epoch 249/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0335 - val_loss: 0.0616\n",
      "Epoch 250/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0334 - val_loss: 0.0623\n",
      "Epoch 251/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0338 - val_loss: 0.0606\n",
      "Epoch 252/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0332 - val_loss: 0.0632\n",
      "Epoch 253/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0379 - val_loss: 0.0644\n",
      "Epoch 254/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0345 - val_loss: 0.0732\n",
      "Epoch 255/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0392 - val_loss: 0.0690\n",
      "Epoch 256/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0347 - val_loss: 0.0657\n",
      "Epoch 257/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0339 - val_loss: 0.0690\n",
      "Epoch 258/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0352 - val_loss: 0.0619\n",
      "Epoch 259/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0330 - val_loss: 0.0614\n",
      "Epoch 260/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0328 - val_loss: 0.0624\n",
      "Epoch 261/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0328 - val_loss: 0.0618\n",
      "Epoch 262/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0328 - val_loss: 0.0681\n",
      "Epoch 263/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0346 - val_loss: 0.0623\n",
      "Epoch 264/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0338 - val_loss: 0.0626\n",
      "Epoch 265/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0325 - val_loss: 0.0643\n",
      "Epoch 266/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0350 - val_loss: 0.0627\n",
      "Epoch 267/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0362 - val_loss: 0.0636\n",
      "Epoch 268/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0335 - val_loss: 0.0645\n",
      "Epoch 269/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0329 - val_loss: 0.0618\n",
      "Epoch 270/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 0.0312 - val_loss: 0.0628\n",
      "Epoch 271/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0321 - val_loss: 0.0668\n",
      "Epoch 272/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0358 - val_loss: 0.0635\n",
      "Epoch 273/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0336 - val_loss: 0.0647\n",
      "Epoch 274/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0328 - val_loss: 0.0637\n",
      "Epoch 275/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0319 - val_loss: 0.0624\n",
      "Epoch 276/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0341 - val_loss: 0.0697\n",
      "Epoch 277/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0330 - val_loss: 0.0625\n",
      "Epoch 278/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0333 - val_loss: 0.0690\n",
      "Epoch 279/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0339 - val_loss: 0.0670\n",
      "Epoch 280/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0328 - val_loss: 0.0632\n",
      "Epoch 281/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0340 - val_loss: 0.0649\n",
      "Epoch 282/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0318 - val_loss: 0.0646\n",
      "Epoch 283/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0323 - val_loss: 0.0636\n",
      "Epoch 284/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0314 - val_loss: 0.0677\n",
      "Epoch 285/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0340 - val_loss: 0.0626\n",
      "Epoch 286/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0345 - val_loss: 0.0659\n",
      "Epoch 287/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0323 - val_loss: 0.0637\n",
      "Epoch 288/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0330 - val_loss: 0.0628\n",
      "Epoch 289/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0304 - val_loss: 0.0638\n",
      "Epoch 290/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0316 - val_loss: 0.0646\n",
      "Epoch 291/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0352 - val_loss: 0.0669\n",
      "Epoch 292/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0337 - val_loss: 0.0639\n",
      "Epoch 293/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0325 - val_loss: 0.0649\n",
      "Epoch 294/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0314 - val_loss: 0.0657\n",
      "Epoch 295/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0338 - val_loss: 0.0647\n",
      "Epoch 296/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0356 - val_loss: 0.0642\n",
      "Epoch 297/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0326 - val_loss: 0.0662\n",
      "Epoch 298/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0315 - val_loss: 0.0660\n",
      "Epoch 299/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0321 - val_loss: 0.0633\n",
      "Epoch 300/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0391 - val_loss: 0.0870\n",
      "Epoch 301/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0382 - val_loss: 0.0635\n",
      "Epoch 302/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0351 - val_loss: 0.0674\n",
      "Epoch 303/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0340 - val_loss: 0.0683\n",
      "Epoch 304/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0316 - val_loss: 0.0637\n",
      "Epoch 305/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0313 - val_loss: 0.0703\n",
      "Epoch 306/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0333 - val_loss: 0.0658\n",
      "Epoch 307/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0308 - val_loss: 0.0647\n",
      "Epoch 308/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0335 - val_loss: 0.0747\n",
      "Epoch 309/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0343 - val_loss: 0.0640\n",
      "Epoch 310/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0306 - val_loss: 0.0643\n",
      "Epoch 311/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0322 - val_loss: 0.0641\n",
      "Epoch 312/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0306 - val_loss: 0.0657\n",
      "Epoch 313/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0334 - val_loss: 0.0662\n",
      "Epoch 314/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0355 - val_loss: 0.0696\n",
      "Epoch 315/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0318 - val_loss: 0.0664\n",
      "Epoch 316/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0329 - val_loss: 0.0655\n",
      "Epoch 317/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0331 - val_loss: 0.0656\n",
      "Epoch 318/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0305 - val_loss: 0.0644\n",
      "Epoch 319/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0307 - val_loss: 0.0687\n",
      "Epoch 320/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0326 - val_loss: 0.0693\n",
      "Epoch 321/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0351 - val_loss: 0.0797\n",
      "Epoch 322/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0369 - val_loss: 0.0661\n",
      "Epoch 323/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0326 - val_loss: 0.0647\n",
      "Epoch 324/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 0.0317 - val_loss: 0.0643\n",
      "Epoch 325/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0316 - val_loss: 0.0678\n",
      "Epoch 326/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0320 - val_loss: 0.0726\n",
      "Epoch 327/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0329 - val_loss: 0.0662\n",
      "Epoch 328/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0305 - val_loss: 0.0662\n",
      "Epoch 329/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0301 - val_loss: 0.0668\n",
      "Epoch 330/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0313 - val_loss: 0.0747\n",
      "Epoch 331/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0339 - val_loss: 0.0660\n",
      "Epoch 332/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0322 - val_loss: 0.0685\n",
      "Epoch 333/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0311 - val_loss: 0.0655\n",
      "Epoch 334/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0306 - val_loss: 0.0661\n",
      "Epoch 335/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0297 - val_loss: 0.0667\n",
      "Epoch 336/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0319 - val_loss: 0.0700\n",
      "Epoch 337/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0313 - val_loss: 0.0686\n",
      "Epoch 338/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0327 - val_loss: 0.0682\n",
      "Epoch 339/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0318 - val_loss: 0.0659\n",
      "Epoch 340/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0299 - val_loss: 0.0658\n",
      "Epoch 341/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0296 - val_loss: 0.0661\n",
      "Epoch 342/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0306 - val_loss: 0.0677\n",
      "Epoch 343/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0307 - val_loss: 0.0652\n",
      "Epoch 344/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0318 - val_loss: 0.0696\n",
      "Epoch 345/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0301 - val_loss: 0.0675\n",
      "Epoch 346/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0305 - val_loss: 0.0663\n",
      "Epoch 347/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0332 - val_loss: 0.0781\n",
      "Epoch 348/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0330 - val_loss: 0.0660\n",
      "Epoch 349/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0322 - val_loss: 0.0765\n",
      "Epoch 350/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0317 - val_loss: 0.0688\n",
      "Epoch 351/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0328 - val_loss: 0.0667\n",
      "Epoch 352/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0298 - val_loss: 0.0673\n",
      "Epoch 353/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0298 - val_loss: 0.0683\n",
      "Epoch 354/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0305 - val_loss: 0.0668\n",
      "Epoch 355/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0297 - val_loss: 0.0657\n",
      "Epoch 356/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0289 - val_loss: 0.0647\n",
      "Epoch 357/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0295 - val_loss: 0.0669\n",
      "Epoch 358/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0321 - val_loss: 0.0710\n",
      "Epoch 359/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0322 - val_loss: 0.0672\n",
      "Epoch 360/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0321 - val_loss: 0.0732\n",
      "Epoch 361/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0341 - val_loss: 0.0677\n",
      "Epoch 362/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0294 - val_loss: 0.0669\n",
      "Epoch 363/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0295 - val_loss: 0.0679\n",
      "Epoch 364/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0311 - val_loss: 0.0676\n",
      "Epoch 365/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0333 - val_loss: 0.0761\n",
      "Epoch 366/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0322 - val_loss: 0.0704\n",
      "Epoch 367/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0297 - val_loss: 0.0678\n",
      "Epoch 368/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0294 - val_loss: 0.0670\n",
      "Epoch 369/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0294 - val_loss: 0.0668\n",
      "Epoch 370/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0310 - val_loss: 0.0724\n",
      "Epoch 371/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0312 - val_loss: 0.0735\n",
      "Epoch 372/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0308 - val_loss: 0.0758\n",
      "Epoch 373/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0306 - val_loss: 0.0708\n",
      "Epoch 374/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0301 - val_loss: 0.0670\n",
      "Epoch 375/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0292 - val_loss: 0.0708\n",
      "Epoch 376/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0311 - val_loss: 0.0683\n",
      "Epoch 377/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0283 - val_loss: 0.0694\n",
      "Epoch 378/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0288 - val_loss: 0.0673\n",
      "Epoch 379/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0318 - val_loss: 0.0684\n",
      "Epoch 380/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0309 - val_loss: 0.0676\n",
      "Epoch 381/500\n",
      "12688/12688 [==============================] - 0s 8us/step - loss: 0.0315 - val_loss: 0.0683\n",
      "Epoch 382/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0322 - val_loss: 0.0698\n",
      "Epoch 383/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0301 - val_loss: 0.0674\n",
      "Epoch 384/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0310 - val_loss: 0.0713\n",
      "Epoch 385/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0329 - val_loss: 0.0731\n",
      "Epoch 386/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0313 - val_loss: 0.0676\n",
      "Epoch 387/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0288 - val_loss: 0.0686\n",
      "Epoch 388/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0285 - val_loss: 0.0733\n",
      "Epoch 389/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0296 - val_loss: 0.0690\n",
      "Epoch 390/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0317 - val_loss: 0.0803\n",
      "Epoch 391/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0301 - val_loss: 0.0679\n",
      "Epoch 392/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0289 - val_loss: 0.0731\n",
      "Epoch 393/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0294 - val_loss: 0.0696\n",
      "Epoch 394/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0281 - val_loss: 0.0709\n",
      "Epoch 395/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0291 - val_loss: 0.0717\n",
      "Epoch 396/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0347 - val_loss: 0.0743\n",
      "Epoch 397/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0335 - val_loss: 0.0727\n",
      "Epoch 398/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0343 - val_loss: 0.0725\n",
      "Epoch 399/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0356 - val_loss: 0.0708\n",
      "Epoch 400/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0306 - val_loss: 0.0704\n",
      "Epoch 401/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0307 - val_loss: 0.0728\n",
      "Epoch 402/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0304 - val_loss: 0.0689\n",
      "Epoch 403/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0301 - val_loss: 0.0702\n",
      "Epoch 404/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0291 - val_loss: 0.0695\n",
      "Epoch 405/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0286 - val_loss: 0.0714\n",
      "Epoch 406/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0282 - val_loss: 0.0694\n",
      "Epoch 407/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0282 - val_loss: 0.0728\n",
      "Epoch 408/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0293 - val_loss: 0.0684\n",
      "Epoch 409/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0306 - val_loss: 0.0726\n",
      "Epoch 410/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0302 - val_loss: 0.0788\n",
      "Epoch 411/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0327 - val_loss: 0.0746\n",
      "Epoch 412/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0294 - val_loss: 0.0714\n",
      "Epoch 413/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0278 - val_loss: 0.0705\n",
      "Epoch 414/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0277 - val_loss: 0.0690\n",
      "Epoch 415/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0291 - val_loss: 0.0738\n",
      "Epoch 416/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0291 - val_loss: 0.0706\n",
      "Epoch 417/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0277 - val_loss: 0.0704\n",
      "Epoch 418/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0276 - val_loss: 0.0715\n",
      "Epoch 419/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0281 - val_loss: 0.0701\n",
      "Epoch 420/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0281 - val_loss: 0.0700\n",
      "Epoch 421/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0274 - val_loss: 0.0713\n",
      "Epoch 422/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0288 - val_loss: 0.0766\n",
      "Epoch 423/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0300 - val_loss: 0.0703\n",
      "Epoch 424/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0283 - val_loss: 0.0706\n",
      "Epoch 425/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0286 - val_loss: 0.0758\n",
      "Epoch 426/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0307 - val_loss: 0.0708\n",
      "Epoch 427/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0313 - val_loss: 0.0685\n",
      "Epoch 428/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0311 - val_loss: 0.0777\n",
      "Epoch 429/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0299 - val_loss: 0.0745\n",
      "Epoch 430/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0286 - val_loss: 0.0732\n",
      "Epoch 431/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0289 - val_loss: 0.0785\n",
      "Epoch 432/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0313 - val_loss: 0.0716\n",
      "Epoch 433/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 0.0287 - val_loss: 0.0717\n",
      "Epoch 434/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0280 - val_loss: 0.0734\n",
      "Epoch 435/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0283 - val_loss: 0.0704\n",
      "Epoch 436/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0278 - val_loss: 0.0721\n",
      "Epoch 437/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0294 - val_loss: 0.0751\n",
      "Epoch 438/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0305 - val_loss: 0.0722\n",
      "Epoch 439/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0288 - val_loss: 0.0741\n",
      "Epoch 440/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0286 - val_loss: 0.0755\n",
      "Epoch 441/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0307 - val_loss: 0.0709\n",
      "Epoch 442/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0276 - val_loss: 0.0770\n",
      "Epoch 443/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0315 - val_loss: 0.0686\n",
      "Epoch 444/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0276 - val_loss: 0.0725\n",
      "Epoch 445/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0296 - val_loss: 0.0743\n",
      "Epoch 446/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0296 - val_loss: 0.0720\n",
      "Epoch 447/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0289 - val_loss: 0.0707\n",
      "Epoch 448/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0280 - val_loss: 0.0705\n",
      "Epoch 449/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0287 - val_loss: 0.0707\n",
      "Epoch 450/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0295 - val_loss: 0.0733\n",
      "Epoch 451/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0287 - val_loss: 0.0726\n",
      "Epoch 452/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0284 - val_loss: 0.0729\n",
      "Epoch 453/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0279 - val_loss: 0.0716\n",
      "Epoch 454/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0274 - val_loss: 0.0725\n",
      "Epoch 455/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0287 - val_loss: 0.0729\n",
      "Epoch 456/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0312 - val_loss: 0.0719\n",
      "Epoch 457/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0278 - val_loss: 0.0729\n",
      "Epoch 458/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0273 - val_loss: 0.0720\n",
      "Epoch 459/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0267 - val_loss: 0.0718\n",
      "Epoch 460/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0276 - val_loss: 0.0730\n",
      "Epoch 461/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0286 - val_loss: 0.0751\n",
      "Epoch 462/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0277 - val_loss: 0.0719\n",
      "Epoch 463/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0288 - val_loss: 0.0775\n",
      "Epoch 464/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0307 - val_loss: 0.0807\n",
      "Epoch 465/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0281 - val_loss: 0.0727\n",
      "Epoch 466/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0263 - val_loss: 0.0731\n",
      "Epoch 467/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0273 - val_loss: 0.0717\n",
      "Epoch 468/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0278 - val_loss: 0.0744\n",
      "Epoch 469/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0282 - val_loss: 0.0754\n",
      "Epoch 470/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0274 - val_loss: 0.0726\n",
      "Epoch 471/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0273 - val_loss: 0.0703\n",
      "Epoch 472/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0297 - val_loss: 0.0709\n",
      "Epoch 473/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0278 - val_loss: 0.0741\n",
      "Epoch 474/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0280 - val_loss: 0.0746\n",
      "Epoch 475/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0277 - val_loss: 0.0745\n",
      "Epoch 476/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0275 - val_loss: 0.0731\n",
      "Epoch 477/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0270 - val_loss: 0.0733\n",
      "Epoch 478/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0280 - val_loss: 0.0752\n",
      "Epoch 479/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0274 - val_loss: 0.0756\n",
      "Epoch 480/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0267 - val_loss: 0.0710\n",
      "Epoch 481/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0274 - val_loss: 0.0801\n",
      "Epoch 482/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0283 - val_loss: 0.0746\n",
      "Epoch 483/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0280 - val_loss: 0.0732\n",
      "Epoch 484/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0273 - val_loss: 0.0725\n",
      "Epoch 485/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0264 - val_loss: 0.0728\n",
      "Epoch 486/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0266 - val_loss: 0.0746\n",
      "Epoch 487/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0275 - val_loss: 0.0764\n",
      "Epoch 488/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0276 - val_loss: 0.0759\n",
      "Epoch 489/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0277 - val_loss: 0.0789\n",
      "Epoch 490/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0281 - val_loss: 0.0761\n",
      "Epoch 491/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0275 - val_loss: 0.0792\n",
      "Epoch 492/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0281 - val_loss: 0.0735\n",
      "Epoch 493/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0262 - val_loss: 0.0751\n",
      "Epoch 494/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0273 - val_loss: 0.0746\n",
      "Epoch 495/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0265 - val_loss: 0.0749\n",
      "Epoch 496/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0273 - val_loss: 0.0803\n",
      "Epoch 497/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0302 - val_loss: 0.0762\n",
      "Epoch 498/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0311 - val_loss: 0.0862\n",
      "Epoch 499/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0308 - val_loss: 0.0759\n",
      "Epoch 500/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0266 - val_loss: 0.0740\n",
      "Train on 12688 samples, validate on 3173 samples\n",
      "Epoch 1/500\n",
      "12688/12688 [==============================] - 0s 24us/step - loss: 3.2349 - val_loss: 0.4509\n",
      "Epoch 2/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.6180 - val_loss: 0.3965\n",
      "Epoch 3/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.3525 - val_loss: 0.2859\n",
      "Epoch 4/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.2681 - val_loss: 0.2360\n",
      "Epoch 5/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.2278 - val_loss: 0.2072\n",
      "Epoch 6/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.1995 - val_loss: 0.1822\n",
      "Epoch 7/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.1773 - val_loss: 0.1687\n",
      "Epoch 8/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.1611 - val_loss: 0.1523\n",
      "Epoch 9/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.1507 - val_loss: 0.1426\n",
      "Epoch 10/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.1409 - val_loss: 0.1392\n",
      "Epoch 11/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.1358 - val_loss: 0.1350\n",
      "Epoch 12/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.1307 - val_loss: 0.1248\n",
      "Epoch 13/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.1234 - val_loss: 0.1186\n",
      "Epoch 14/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.1192 - val_loss: 0.1194\n",
      "Epoch 15/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.1147 - val_loss: 0.1132\n",
      "Epoch 16/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.1094 - val_loss: 0.1098\n",
      "Epoch 17/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.1108 - val_loss: 0.1085\n",
      "Epoch 18/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.1040 - val_loss: 0.1012\n",
      "Epoch 19/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.1003 - val_loss: 0.1005\n",
      "Epoch 20/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0996 - val_loss: 0.0980\n",
      "Epoch 21/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0965 - val_loss: 0.0977\n",
      "Epoch 22/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0952 - val_loss: 0.0961\n",
      "Epoch 23/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0938 - val_loss: 0.0926\n",
      "Epoch 24/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0919 - val_loss: 0.0930\n",
      "Epoch 25/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0911 - val_loss: 0.0921\n",
      "Epoch 26/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0896 - val_loss: 0.0920\n",
      "Epoch 27/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0889 - val_loss: 0.0961\n",
      "Epoch 28/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0906 - val_loss: 0.0897\n",
      "Epoch 29/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0911 - val_loss: 0.0912\n",
      "Epoch 30/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0877 - val_loss: 0.0882\n",
      "Epoch 31/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0843 - val_loss: 0.0869\n",
      "Epoch 32/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0826 - val_loss: 0.0869\n",
      "Epoch 33/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0834 - val_loss: 0.0864\n",
      "Epoch 34/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0813 - val_loss: 0.0849\n",
      "Epoch 35/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0808 - val_loss: 0.0860\n",
      "Epoch 36/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0819 - val_loss: 0.0871\n",
      "Epoch 37/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0829 - val_loss: 0.0851\n",
      "Epoch 38/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0811 - val_loss: 0.0836\n",
      "Epoch 39/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0798 - val_loss: 0.0835\n",
      "Epoch 40/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0783 - val_loss: 0.0823\n",
      "Epoch 41/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0777 - val_loss: 0.0809\n",
      "Epoch 42/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0763 - val_loss: 0.0825\n",
      "Epoch 43/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0773 - val_loss: 0.0825\n",
      "Epoch 44/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0767 - val_loss: 0.0809\n",
      "Epoch 45/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0750 - val_loss: 0.0814\n",
      "Epoch 46/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0746 - val_loss: 0.0839\n",
      "Epoch 47/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0752 - val_loss: 0.0866\n",
      "Epoch 48/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0748 - val_loss: 0.0795\n",
      "Epoch 49/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0731 - val_loss: 0.0816\n",
      "Epoch 50/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0730 - val_loss: 0.0801\n",
      "Epoch 51/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0725 - val_loss: 0.0822\n",
      "Epoch 52/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0727 - val_loss: 0.0794\n",
      "Epoch 53/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0711 - val_loss: 0.0811\n",
      "Epoch 54/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0721 - val_loss: 0.0824\n",
      "Epoch 55/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0723 - val_loss: 0.0811\n",
      "Epoch 56/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0718 - val_loss: 0.0789\n",
      "Epoch 57/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0716 - val_loss: 0.0818\n",
      "Epoch 58/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0710 - val_loss: 0.0806\n",
      "Epoch 59/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 0.0717 - val_loss: 0.0814\n",
      "Epoch 60/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0776 - val_loss: 0.0825\n",
      "Epoch 61/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0761 - val_loss: 0.0889\n",
      "Epoch 62/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0799 - val_loss: 0.0889\n",
      "Epoch 63/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0737 - val_loss: 0.0890\n",
      "Epoch 64/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0733 - val_loss: 0.0790\n",
      "Epoch 65/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0707 - val_loss: 0.0789\n",
      "Epoch 66/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0691 - val_loss: 0.0826\n",
      "Epoch 67/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0708 - val_loss: 0.0806\n",
      "Epoch 68/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0688 - val_loss: 0.0816\n",
      "Epoch 69/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0683 - val_loss: 0.0822\n",
      "Epoch 70/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0686 - val_loss: 0.0831\n",
      "Epoch 71/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0704 - val_loss: 0.0835\n",
      "Epoch 72/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0690 - val_loss: 0.0794\n",
      "Epoch 73/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0708 - val_loss: 0.0958\n",
      "Epoch 74/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0739 - val_loss: 0.0854\n",
      "Epoch 75/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0731 - val_loss: 0.0784\n",
      "Epoch 76/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0678 - val_loss: 0.0803\n",
      "Epoch 77/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0669 - val_loss: 0.0790\n",
      "Epoch 78/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0681 - val_loss: 0.0791\n",
      "Epoch 79/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0679 - val_loss: 0.0778\n",
      "Epoch 80/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0673 - val_loss: 0.0800\n",
      "Epoch 81/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0651 - val_loss: 0.0788\n",
      "Epoch 82/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0654 - val_loss: 0.0768\n",
      "Epoch 83/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0638 - val_loss: 0.0799\n",
      "Epoch 84/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0663 - val_loss: 0.0826\n",
      "Epoch 85/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0646 - val_loss: 0.0793\n",
      "Epoch 86/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 0.0642 - val_loss: 0.0790\n",
      "Epoch 87/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0660 - val_loss: 0.0788\n",
      "Epoch 88/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0654 - val_loss: 0.0813\n",
      "Epoch 89/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0649 - val_loss: 0.0803\n",
      "Epoch 90/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0674 - val_loss: 0.0784\n",
      "Epoch 91/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0699 - val_loss: 0.0786\n",
      "Epoch 92/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0643 - val_loss: 0.0802\n",
      "Epoch 93/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0681 - val_loss: 0.0793\n",
      "Epoch 94/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0631 - val_loss: 0.0790\n",
      "Epoch 95/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0644 - val_loss: 0.0785\n",
      "Epoch 96/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 0.0624 - val_loss: 0.0783\n",
      "Epoch 97/500\n",
      "12688/12688 [==============================] - 0s 7us/step - loss: 0.0633 - val_loss: 0.0823\n",
      "Epoch 98/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 0.0623 - val_loss: 0.0799\n",
      "Epoch 99/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0623 - val_loss: 0.0784\n",
      "Epoch 100/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0646 - val_loss: 0.0851\n",
      "Epoch 101/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0633 - val_loss: 0.0814\n",
      "Epoch 102/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0628 - val_loss: 0.0797\n",
      "Epoch 103/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0629 - val_loss: 0.0799\n",
      "Epoch 104/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0620 - val_loss: 0.0806\n",
      "Epoch 105/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0622 - val_loss: 0.0811\n",
      "Epoch 106/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0669 - val_loss: 0.0970\n",
      "Epoch 107/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0656 - val_loss: 0.0802\n",
      "Epoch 108/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0632 - val_loss: 0.0949\n",
      "Epoch 109/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0661 - val_loss: 0.0854\n",
      "Epoch 110/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0640 - val_loss: 0.0807\n",
      "Epoch 111/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0611 - val_loss: 0.0880\n",
      "Epoch 112/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0611 - val_loss: 0.0798\n",
      "Epoch 113/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0607 - val_loss: 0.0822\n",
      "Epoch 114/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0602 - val_loss: 0.0796\n",
      "Epoch 115/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0624 - val_loss: 0.0808\n",
      "Epoch 116/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0643 - val_loss: 0.0833\n",
      "Epoch 117/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0607 - val_loss: 0.0864\n",
      "Epoch 118/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0681 - val_loss: 0.0804\n",
      "Epoch 119/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0611 - val_loss: 0.0817\n",
      "Epoch 120/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0593 - val_loss: 0.0844\n",
      "Epoch 121/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0597 - val_loss: 0.0809\n",
      "Epoch 122/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0588 - val_loss: 0.0806\n",
      "Epoch 123/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0597 - val_loss: 0.0845\n",
      "Epoch 124/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0607 - val_loss: 0.0862\n",
      "Epoch 125/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0620 - val_loss: 0.0837\n",
      "Epoch 126/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0596 - val_loss: 0.0824\n",
      "Epoch 127/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0592 - val_loss: 0.0851\n",
      "Epoch 128/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0594 - val_loss: 0.0845\n",
      "Epoch 129/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0589 - val_loss: 0.0846\n",
      "Epoch 130/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0594 - val_loss: 0.0810\n",
      "Epoch 131/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0571 - val_loss: 0.0826\n",
      "Epoch 132/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0589 - val_loss: 0.0801\n",
      "Epoch 133/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0594 - val_loss: 0.0868\n",
      "Epoch 134/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0600 - val_loss: 0.0846\n",
      "Epoch 135/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0569 - val_loss: 0.0818\n",
      "Epoch 136/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0563 - val_loss: 0.0829\n",
      "Epoch 137/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0573 - val_loss: 0.0867\n",
      "Epoch 138/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0609 - val_loss: 0.0933\n",
      "Epoch 139/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0609 - val_loss: 0.0850\n",
      "Epoch 140/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0571 - val_loss: 0.0828\n",
      "Epoch 141/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0567 - val_loss: 0.0859\n",
      "Epoch 142/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0593 - val_loss: 0.0861\n",
      "Epoch 143/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0619 - val_loss: 0.0875\n",
      "Epoch 144/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0606 - val_loss: 0.0834\n",
      "Epoch 145/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 0.0635 - val_loss: 0.0966\n",
      "Epoch 146/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0649 - val_loss: 0.0918\n",
      "Epoch 147/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0629 - val_loss: 0.0896\n",
      "Epoch 148/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0647 - val_loss: 0.0870\n",
      "Epoch 149/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0611 - val_loss: 0.0901\n",
      "Epoch 150/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0607 - val_loss: 0.0886\n",
      "Epoch 151/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0644 - val_loss: 0.0890\n",
      "Epoch 152/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0583 - val_loss: 0.0853\n",
      "Epoch 153/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0561 - val_loss: 0.0871\n",
      "Epoch 154/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0590 - val_loss: 0.0896\n",
      "Epoch 155/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0598 - val_loss: 0.0838\n",
      "Epoch 156/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0575 - val_loss: 0.0850\n",
      "Epoch 157/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0564 - val_loss: 0.0862\n",
      "Epoch 158/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0567 - val_loss: 0.0862\n",
      "Epoch 159/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0550 - val_loss: 0.0846\n",
      "Epoch 160/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0551 - val_loss: 0.0913\n",
      "Epoch 161/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0554 - val_loss: 0.0831\n",
      "Epoch 162/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0554 - val_loss: 0.0860\n",
      "Epoch 163/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0550 - val_loss: 0.0869\n",
      "Epoch 164/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0537 - val_loss: 0.0888\n",
      "Epoch 165/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0560 - val_loss: 0.0856\n",
      "Epoch 166/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0559 - val_loss: 0.0899\n",
      "Epoch 167/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0553 - val_loss: 0.0873\n",
      "Epoch 168/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0584 - val_loss: 0.0857\n",
      "Epoch 169/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0563 - val_loss: 0.0852\n",
      "Epoch 170/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 0.0580 - val_loss: 0.0841\n",
      "Epoch 171/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0598 - val_loss: 0.0879\n",
      "Epoch 172/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0569 - val_loss: 0.0885\n",
      "Epoch 173/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0555 - val_loss: 0.0846\n",
      "Epoch 174/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0543 - val_loss: 0.0836\n",
      "Epoch 175/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0547 - val_loss: 0.0887\n",
      "Epoch 176/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0588 - val_loss: 0.0868\n",
      "Epoch 177/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0552 - val_loss: 0.0853\n",
      "Epoch 178/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0569 - val_loss: 0.0895\n",
      "Epoch 179/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0556 - val_loss: 0.0842\n",
      "Epoch 180/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0552 - val_loss: 0.0994\n",
      "Epoch 181/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0558 - val_loss: 0.0847\n",
      "Epoch 182/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0520 - val_loss: 0.0865\n",
      "Epoch 183/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0540 - val_loss: 0.0975\n",
      "Epoch 184/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0587 - val_loss: 0.0874\n",
      "Epoch 185/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0555 - val_loss: 0.0922\n",
      "Epoch 186/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0567 - val_loss: 0.0910\n",
      "Epoch 187/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0526 - val_loss: 0.0867\n",
      "Epoch 188/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0531 - val_loss: 0.0899\n",
      "Epoch 189/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0528 - val_loss: 0.0869\n",
      "Epoch 190/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0515 - val_loss: 0.0893\n",
      "Epoch 191/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0522 - val_loss: 0.0867\n",
      "Epoch 192/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0546 - val_loss: 0.0948\n",
      "Epoch 193/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0595 - val_loss: 0.0888\n",
      "Epoch 194/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0538 - val_loss: 0.0866\n",
      "Epoch 195/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0521 - val_loss: 0.0915\n",
      "Epoch 196/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 0.0554 - val_loss: 0.0873\n",
      "Epoch 197/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0526 - val_loss: 0.0876\n",
      "Epoch 198/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0541 - val_loss: 0.1014\n",
      "Epoch 199/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0551 - val_loss: 0.0986\n",
      "Epoch 200/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0551 - val_loss: 0.0963\n",
      "Epoch 201/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0559 - val_loss: 0.0921\n",
      "Epoch 202/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 0.0577 - val_loss: 0.0908\n",
      "Epoch 203/500\n",
      "12688/12688 [==============================] - 0s 7us/step - loss: 0.0565 - val_loss: 0.0952\n",
      "Epoch 204/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0557 - val_loss: 0.0891\n",
      "Epoch 205/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0546 - val_loss: 0.0899\n",
      "Epoch 206/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0596 - val_loss: 0.0959\n",
      "Epoch 207/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0563 - val_loss: 0.0952\n",
      "Epoch 208/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0564 - val_loss: 0.0896\n",
      "Epoch 209/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0516 - val_loss: 0.0922\n",
      "Epoch 210/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0504 - val_loss: 0.0866\n",
      "Epoch 211/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0532 - val_loss: 0.0916\n",
      "Epoch 212/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0584 - val_loss: 0.0922\n",
      "Epoch 213/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0528 - val_loss: 0.0932\n",
      "Epoch 214/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0513 - val_loss: 0.0917\n",
      "Epoch 215/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0516 - val_loss: 0.0942\n",
      "Epoch 216/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0512 - val_loss: 0.0919\n",
      "Epoch 217/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0562 - val_loss: 0.1011\n",
      "Epoch 218/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0583 - val_loss: 0.0960\n",
      "Epoch 219/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0539 - val_loss: 0.0919\n",
      "Epoch 220/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0525 - val_loss: 0.0996\n",
      "Epoch 221/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0527 - val_loss: 0.0933\n",
      "Epoch 222/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0518 - val_loss: 0.0891\n",
      "Epoch 223/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0520 - val_loss: 0.0896\n",
      "Epoch 224/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0496 - val_loss: 0.0973\n",
      "Epoch 225/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0513 - val_loss: 0.0931\n",
      "Epoch 226/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0509 - val_loss: 0.0886\n",
      "Epoch 227/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0497 - val_loss: 0.0911\n",
      "Epoch 228/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0500 - val_loss: 0.0925\n",
      "Epoch 229/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0523 - val_loss: 0.0920\n",
      "Epoch 230/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0493 - val_loss: 0.0924\n",
      "Epoch 231/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0493 - val_loss: 0.0934\n",
      "Epoch 232/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0487 - val_loss: 0.0926\n",
      "Epoch 233/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0491 - val_loss: 0.0907\n",
      "Epoch 234/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0487 - val_loss: 0.0924\n",
      "Epoch 235/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0488 - val_loss: 0.0956\n",
      "Epoch 236/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0513 - val_loss: 0.0917\n",
      "Epoch 237/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0501 - val_loss: 0.1001\n",
      "Epoch 238/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0541 - val_loss: 0.0957\n",
      "Epoch 239/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0492 - val_loss: 0.0912\n",
      "Epoch 240/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 0.0496 - val_loss: 0.0970\n",
      "Epoch 241/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0512 - val_loss: 0.0893\n",
      "Epoch 242/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0487 - val_loss: 0.0937\n",
      "Epoch 243/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0485 - val_loss: 0.0938\n",
      "Epoch 244/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0469 - val_loss: 0.0948\n",
      "Epoch 245/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0486 - val_loss: 0.0934\n",
      "Epoch 246/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0496 - val_loss: 0.1110\n",
      "Epoch 247/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0544 - val_loss: 0.1130\n",
      "Epoch 248/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0531 - val_loss: 0.0983\n",
      "Epoch 249/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0486 - val_loss: 0.0943\n",
      "Epoch 250/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0488 - val_loss: 0.0954\n",
      "Epoch 251/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0495 - val_loss: 0.0921\n",
      "Epoch 252/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0557 - val_loss: 0.1021\n",
      "Epoch 253/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0505 - val_loss: 0.1022\n",
      "Epoch 254/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0517 - val_loss: 0.0971\n",
      "Epoch 255/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0506 - val_loss: 0.0985\n",
      "Epoch 256/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0471 - val_loss: 0.0954\n",
      "Epoch 257/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0471 - val_loss: 0.0954\n",
      "Epoch 258/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0502 - val_loss: 0.1035\n",
      "Epoch 259/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0506 - val_loss: 0.0974\n",
      "Epoch 260/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0483 - val_loss: 0.0940\n",
      "Epoch 261/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0481 - val_loss: 0.0926\n",
      "Epoch 262/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0488 - val_loss: 0.0985\n",
      "Epoch 263/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0475 - val_loss: 0.0985\n",
      "Epoch 264/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0498 - val_loss: 0.0978\n",
      "Epoch 265/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0482 - val_loss: 0.1054\n",
      "Epoch 266/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0548 - val_loss: 0.1043\n",
      "Epoch 267/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0569 - val_loss: 0.1014\n",
      "Epoch 268/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0488 - val_loss: 0.0962\n",
      "Epoch 269/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0474 - val_loss: 0.0984\n",
      "Epoch 270/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0467 - val_loss: 0.0935\n",
      "Epoch 271/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0471 - val_loss: 0.0927\n",
      "Epoch 272/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0474 - val_loss: 0.0940\n",
      "Epoch 273/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0480 - val_loss: 0.1008\n",
      "Epoch 274/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0469 - val_loss: 0.0960\n",
      "Epoch 275/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0474 - val_loss: 0.0973\n",
      "Epoch 276/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0537 - val_loss: 0.1052\n",
      "Epoch 277/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0503 - val_loss: 0.0973\n",
      "Epoch 278/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0472 - val_loss: 0.0992\n",
      "Epoch 279/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0483 - val_loss: 0.0985\n",
      "Epoch 280/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0480 - val_loss: 0.0998\n",
      "Epoch 281/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0500 - val_loss: 0.0936\n",
      "Epoch 282/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0500 - val_loss: 0.0919\n",
      "Epoch 283/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0499 - val_loss: 0.0973\n",
      "Epoch 284/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0471 - val_loss: 0.0926\n",
      "Epoch 285/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0471 - val_loss: 0.0972\n",
      "Epoch 286/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0458 - val_loss: 0.0939\n",
      "Epoch 287/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0465 - val_loss: 0.0973\n",
      "Epoch 288/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0456 - val_loss: 0.0976\n",
      "Epoch 289/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0456 - val_loss: 0.1017\n",
      "Epoch 290/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0471 - val_loss: 0.0947\n",
      "Epoch 291/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0458 - val_loss: 0.0987\n",
      "Epoch 292/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0459 - val_loss: 0.0984\n",
      "Epoch 293/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0496 - val_loss: 0.1074\n",
      "Epoch 294/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0501 - val_loss: 0.0962\n",
      "Epoch 295/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0482 - val_loss: 0.0965\n",
      "Epoch 296/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0465 - val_loss: 0.0990\n",
      "Epoch 297/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0456 - val_loss: 0.1021\n",
      "Epoch 298/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0472 - val_loss: 0.0945\n",
      "Epoch 299/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0501 - val_loss: 0.0965\n",
      "Epoch 300/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0467 - val_loss: 0.0968\n",
      "Epoch 301/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0457 - val_loss: 0.0965\n",
      "Epoch 302/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0455 - val_loss: 0.1002\n",
      "Epoch 303/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0460 - val_loss: 0.1001\n",
      "Epoch 304/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0463 - val_loss: 0.0997\n",
      "Epoch 305/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0471 - val_loss: 0.0966\n",
      "Epoch 306/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0455 - val_loss: 0.0993\n",
      "Epoch 307/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0469 - val_loss: 0.0999\n",
      "Epoch 308/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0461 - val_loss: 0.1006\n",
      "Epoch 309/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0466 - val_loss: 0.1004\n",
      "Epoch 310/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0470 - val_loss: 0.1077\n",
      "Epoch 311/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0505 - val_loss: 0.0980\n",
      "Epoch 312/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0480 - val_loss: 0.1117\n",
      "Epoch 313/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0518 - val_loss: 0.0964\n",
      "Epoch 314/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0483 - val_loss: 0.0977\n",
      "Epoch 315/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0464 - val_loss: 0.0996\n",
      "Epoch 316/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0449 - val_loss: 0.1023\n",
      "Epoch 317/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0471 - val_loss: 0.0989\n",
      "Epoch 318/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0452 - val_loss: 0.1014\n",
      "Epoch 319/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0450 - val_loss: 0.0964\n",
      "Epoch 320/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0445 - val_loss: 0.0953\n",
      "Epoch 321/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0436 - val_loss: 0.0951\n",
      "Epoch 322/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 0.0443 - val_loss: 0.1004\n",
      "Epoch 323/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0487 - val_loss: 0.1034\n",
      "Epoch 324/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0473 - val_loss: 0.1005\n",
      "Epoch 325/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0506 - val_loss: 0.1035\n",
      "Epoch 326/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0469 - val_loss: 0.0997\n",
      "Epoch 327/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0459 - val_loss: 0.0988\n",
      "Epoch 328/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0447 - val_loss: 0.0984\n",
      "Epoch 329/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0452 - val_loss: 0.0962\n",
      "Epoch 330/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0445 - val_loss: 0.0955\n",
      "Epoch 331/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0436 - val_loss: 0.1003\n",
      "Epoch 332/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0434 - val_loss: 0.0967\n",
      "Epoch 333/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0444 - val_loss: 0.0996\n",
      "Epoch 334/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0438 - val_loss: 0.1035\n",
      "Epoch 335/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0444 - val_loss: 0.1022\n",
      "Epoch 336/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0440 - val_loss: 0.0976\n",
      "Epoch 337/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0451 - val_loss: 0.1010\n",
      "Epoch 338/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 0.0439 - val_loss: 0.0953\n",
      "Epoch 339/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 0.0438 - val_loss: 0.1024\n",
      "Epoch 340/500\n",
      "12688/12688 [==============================] - 0s 9us/step - loss: 0.0469 - val_loss: 0.0977\n",
      "Epoch 341/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 0.0447 - val_loss: 0.1022\n",
      "Epoch 342/500\n",
      "12688/12688 [==============================] - 0s 8us/step - loss: 0.0449 - val_loss: 0.1003\n",
      "Epoch 343/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0455 - val_loss: 0.0987\n",
      "Epoch 344/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 0.0445 - val_loss: 0.1020\n",
      "Epoch 345/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0459 - val_loss: 0.1029\n",
      "Epoch 346/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0446 - val_loss: 0.1027\n",
      "Epoch 347/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0479 - val_loss: 0.0959\n",
      "Epoch 348/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0434 - val_loss: 0.0984\n",
      "Epoch 349/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0431 - val_loss: 0.0977\n",
      "Epoch 350/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0432 - val_loss: 0.0987\n",
      "Epoch 351/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0433 - val_loss: 0.0988\n",
      "Epoch 352/500\n",
      "12688/12688 [==============================] - ETA: 0s - loss: 0.034 - 0s 3us/step - loss: 0.0444 - val_loss: 0.0980\n",
      "Epoch 353/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0451 - val_loss: 0.0996\n",
      "Epoch 354/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0456 - val_loss: 0.1002\n",
      "Epoch 355/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0438 - val_loss: 0.1000\n",
      "Epoch 356/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0435 - val_loss: 0.1002\n",
      "Epoch 357/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0451 - val_loss: 0.0990\n",
      "Epoch 358/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0431 - val_loss: 0.0997\n",
      "Epoch 359/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0435 - val_loss: 0.1041\n",
      "Epoch 360/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0438 - val_loss: 0.1077\n",
      "Epoch 361/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0463 - val_loss: 0.1153\n",
      "Epoch 362/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0499 - val_loss: 0.1051\n",
      "Epoch 363/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0445 - val_loss: 0.1046\n",
      "Epoch 364/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0478 - val_loss: 0.1045\n",
      "Epoch 365/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0446 - val_loss: 0.0964\n",
      "Epoch 366/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 0.0419 - val_loss: 0.1048\n",
      "Epoch 367/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0461 - val_loss: 0.1067\n",
      "Epoch 368/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0460 - val_loss: 0.1090\n",
      "Epoch 369/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0468 - val_loss: 0.1004\n",
      "Epoch 370/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0444 - val_loss: 0.0971\n",
      "Epoch 371/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0436 - val_loss: 0.1026\n",
      "Epoch 372/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0439 - val_loss: 0.0984\n",
      "Epoch 373/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0454 - val_loss: 0.0966\n",
      "Epoch 374/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0420 - val_loss: 0.0999\n",
      "Epoch 375/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0430 - val_loss: 0.1007\n",
      "Epoch 376/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0418 - val_loss: 0.1021\n",
      "Epoch 377/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0437 - val_loss: 0.1006\n",
      "Epoch 378/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0472 - val_loss: 0.1004\n",
      "Epoch 379/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0470 - val_loss: 0.1017\n",
      "Epoch 380/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0432 - val_loss: 0.0978\n",
      "Epoch 381/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0430 - val_loss: 0.1020\n",
      "Epoch 382/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0431 - val_loss: 0.0997\n",
      "Epoch 383/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0440 - val_loss: 0.0979\n",
      "Epoch 384/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0418 - val_loss: 0.0994\n",
      "Epoch 385/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0417 - val_loss: 0.0997\n",
      "Epoch 386/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0439 - val_loss: 0.1013\n",
      "Epoch 387/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0458 - val_loss: 0.1161\n",
      "Epoch 388/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0463 - val_loss: 0.0988\n",
      "Epoch 389/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0415 - val_loss: 0.0990\n",
      "Epoch 390/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0448 - val_loss: 0.1009\n",
      "Epoch 391/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0451 - val_loss: 0.1056\n",
      "Epoch 392/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0476 - val_loss: 0.1038\n",
      "Epoch 393/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0450 - val_loss: 0.1037\n",
      "Epoch 394/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0420 - val_loss: 0.1071\n",
      "Epoch 395/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0429 - val_loss: 0.1029\n",
      "Epoch 396/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0457 - val_loss: 0.0968\n",
      "Epoch 397/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0415 - val_loss: 0.1026\n",
      "Epoch 398/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0419 - val_loss: 0.1008\n",
      "Epoch 399/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0416 - val_loss: 0.0982\n",
      "Epoch 400/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0429 - val_loss: 0.1036\n",
      "Epoch 401/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0421 - val_loss: 0.1025\n",
      "Epoch 402/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0412 - val_loss: 0.0989\n",
      "Epoch 403/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0418 - val_loss: 0.1006\n",
      "Epoch 404/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0432 - val_loss: 0.1026\n",
      "Epoch 405/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0415 - val_loss: 0.0996\n",
      "Epoch 406/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0401 - val_loss: 0.1017\n",
      "Epoch 407/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0419 - val_loss: 0.1014\n",
      "Epoch 408/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0414 - val_loss: 0.1086\n",
      "Epoch 409/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0412 - val_loss: 0.1040\n",
      "Epoch 410/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0420 - val_loss: 0.1037\n",
      "Epoch 411/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0411 - val_loss: 0.1025\n",
      "Epoch 412/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0411 - val_loss: 0.1059\n",
      "Epoch 413/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0420 - val_loss: 0.1022\n",
      "Epoch 414/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0423 - val_loss: 0.1121\n",
      "Epoch 415/500\n",
      "12688/12688 [==============================] - 0s 13us/step - loss: 0.0481 - val_loss: 0.1085\n",
      "Epoch 416/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0429 - val_loss: 0.1000\n",
      "Epoch 417/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0417 - val_loss: 0.1007\n",
      "Epoch 418/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0438 - val_loss: 0.1042\n",
      "Epoch 419/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0462 - val_loss: 0.1026\n",
      "Epoch 420/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0439 - val_loss: 0.1081\n",
      "Epoch 421/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0424 - val_loss: 0.1024\n",
      "Epoch 422/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0408 - val_loss: 0.1050\n",
      "Epoch 423/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0408 - val_loss: 0.1038\n",
      "Epoch 424/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0434 - val_loss: 0.1129\n",
      "Epoch 425/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0431 - val_loss: 0.1026\n",
      "Epoch 426/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0417 - val_loss: 0.1101\n",
      "Epoch 427/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0406 - val_loss: 0.1048\n",
      "Epoch 428/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0450 - val_loss: 0.1073\n",
      "Epoch 429/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0403 - val_loss: 0.0986\n",
      "Epoch 430/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0418 - val_loss: 0.0999\n",
      "Epoch 431/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0480 - val_loss: 0.1072\n",
      "Epoch 432/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0446 - val_loss: 0.1151\n",
      "Epoch 433/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0439 - val_loss: 0.0973\n",
      "Epoch 434/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0413 - val_loss: 0.1016\n",
      "Epoch 435/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0400 - val_loss: 0.1064\n",
      "Epoch 436/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0420 - val_loss: 0.1022\n",
      "Epoch 437/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0399 - val_loss: 0.1043\n",
      "Epoch 438/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0398 - val_loss: 0.0999\n",
      "Epoch 439/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0400 - val_loss: 0.1037\n",
      "Epoch 440/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0437 - val_loss: 0.1008\n",
      "Epoch 441/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0454 - val_loss: 0.1086\n",
      "Epoch 442/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0424 - val_loss: 0.1085\n",
      "Epoch 443/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0407 - val_loss: 0.1080\n",
      "Epoch 444/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0408 - val_loss: 0.1002\n",
      "Epoch 445/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0399 - val_loss: 0.1030\n",
      "Epoch 446/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0410 - val_loss: 0.1047\n",
      "Epoch 447/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0419 - val_loss: 0.1020\n",
      "Epoch 448/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0406 - val_loss: 0.0996\n",
      "Epoch 449/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0389 - val_loss: 0.1030\n",
      "Epoch 450/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0396 - val_loss: 0.1050\n",
      "Epoch 451/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0410 - val_loss: 0.1060\n",
      "Epoch 452/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0409 - val_loss: 0.1017\n",
      "Epoch 453/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0388 - val_loss: 0.1011\n",
      "Epoch 454/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0395 - val_loss: 0.1005\n",
      "Epoch 455/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0400 - val_loss: 0.1048\n",
      "Epoch 456/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0408 - val_loss: 0.1028\n",
      "Epoch 457/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0429 - val_loss: 0.1034\n",
      "Epoch 458/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0407 - val_loss: 0.1035\n",
      "Epoch 459/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0416 - val_loss: 0.1046\n",
      "Epoch 460/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0410 - val_loss: 0.1025\n",
      "Epoch 461/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0415 - val_loss: 0.1048\n",
      "Epoch 462/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0397 - val_loss: 0.1035\n",
      "Epoch 463/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0396 - val_loss: 0.1023\n",
      "Epoch 464/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0409 - val_loss: 0.1104\n",
      "Epoch 465/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0397 - val_loss: 0.1026\n",
      "Epoch 466/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0384 - val_loss: 0.1089\n",
      "Epoch 467/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0395 - val_loss: 0.1010\n",
      "Epoch 468/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0410 - val_loss: 0.1060\n",
      "Epoch 469/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0427 - val_loss: 0.1061\n",
      "Epoch 470/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0427 - val_loss: 0.1058\n",
      "Epoch 471/500\n",
      "12688/12688 [==============================] - ETA: 0s - loss: 0.039 - 0s 4us/step - loss: 0.0428 - val_loss: 0.1225\n",
      "Epoch 472/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0443 - val_loss: 0.1033\n",
      "Epoch 473/500\n",
      "12688/12688 [==============================] - 0s 6us/step - loss: 0.0411 - val_loss: 0.1032\n",
      "Epoch 474/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0388 - val_loss: 0.1063\n",
      "Epoch 475/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0390 - val_loss: 0.1042\n",
      "Epoch 476/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0398 - val_loss: 0.1007\n",
      "Epoch 477/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0482 - val_loss: 0.1102\n",
      "Epoch 478/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0478 - val_loss: 0.1045\n",
      "Epoch 479/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0463 - val_loss: 0.1112\n",
      "Epoch 480/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0407 - val_loss: 0.1065\n",
      "Epoch 481/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0395 - val_loss: 0.1055\n",
      "Epoch 482/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0389 - val_loss: 0.1040\n",
      "Epoch 483/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0403 - val_loss: 0.1058\n",
      "Epoch 484/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0405 - val_loss: 0.1094\n",
      "Epoch 485/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0409 - val_loss: 0.1065\n",
      "Epoch 486/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0419 - val_loss: 0.1100\n",
      "Epoch 487/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0435 - val_loss: 0.1068\n",
      "Epoch 488/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0405 - val_loss: 0.1064\n",
      "Epoch 489/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0418 - val_loss: 0.1047\n",
      "Epoch 490/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0428 - val_loss: 0.1081\n",
      "Epoch 491/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0404 - val_loss: 0.1035\n",
      "Epoch 492/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0383 - val_loss: 0.1069\n",
      "Epoch 493/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0411 - val_loss: 0.1080\n",
      "Epoch 494/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0419 - val_loss: 0.1077\n",
      "Epoch 495/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0388 - val_loss: 0.1108\n",
      "Epoch 496/500\n",
      "12688/12688 [==============================] - 0s 3us/step - loss: 0.0382 - val_loss: 0.1108\n",
      "Epoch 497/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0408 - val_loss: 0.1081\n",
      "Epoch 498/500\n",
      "12688/12688 [==============================] - 0s 5us/step - loss: 0.0392 - val_loss: 0.1116\n",
      "Epoch 499/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0396 - val_loss: 0.1038\n",
      "Epoch 500/500\n",
      "12688/12688 [==============================] - 0s 4us/step - loss: 0.0390 - val_loss: 0.1046\n"
     ]
    }
   ],
   "source": [
    "num_inputs = xtrain.shape[1]\n",
    "num_outputs = ytrain.shape[1]\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(100, input_dim=num_inputs, kernel_initializer='normal', activation='relu'))\n",
    "model.add(layers.Dense(50, kernel_initializer='normal', activation='relu'))\n",
    "model.add(layers.Dense(num_outputs, kernel_initializer='normal'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "model.fit(xtrain,ytrain,epochs=20,batch_size=32,\n",
    "          validation_data=(xval, yval))\n",
    "\n",
    "\n",
    "regressions = {}\n",
    "for ind,var in enumerate(variables):\n",
    "    num_inputs = xtrain.shape[1]\n",
    "    num_outputs = ytrain.shape[1]\n",
    "    regressions[var] = Sequential()\n",
    "    regressions[var].add(layers.Dense(100, input_dim=num_inputs, kernel_initializer='normal', activation='relu'))\n",
    "    regressions[var].add(layers.Dense(50, kernel_initializer='normal', activation='relu'))\n",
    "    regressions[var].add(layers.Dense(1, kernel_initializer='normal'))\n",
    "    \n",
    "    regressions[var].compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    regressions[var].fit(xtrain,ytrain[:,ind],epochs=500,batch_size=1000,\n",
    "              validation_data=(xval, yval[:,ind]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reload the data (including the bad points) for training the classifier.  Also Inspect the output of the regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = samples_all[x_headers].values\n",
    "Y = samples_all[y_headers].values\n",
    "labels = samples_all[label_headers].values\n",
    "\n",
    "Y_scale = y_scaler.transform(Y)\n",
    "X_scale = x_scaler.transform(X)\n",
    "\n",
    "Y_scale = Y\n",
    "X_scale = X\n",
    "\n",
    "xtrain, xval, ytrain, yval,label_train,label_val = train_test_split(X_scale, Y_scale, labels, test_size=0.20, random_state=42)\n",
    "\n",
    "pred = {}\n",
    "rpd = {}\n",
    "plt.figure(figsize=(6, 8))\n",
    "for ind,var in enumerate(variables):\n",
    "    pred[var] = regressions[var].predict(X_scale)\n",
    "    rpd[var] = RPD(pred[var],np.array([Y_scale[:,ind]]).T)\n",
    "    ax = plt.subplot(3, 2, ind+1)\n",
    "    plt.subplots_adjust(hspace=0.45,wspace=0.3)\n",
    "    plt.ylabel('Actual Reading')\n",
    "    plt.xlabel('Predicted Reading')\n",
    "    plt.scatter(pred[var],Y_scale[:,ind],label=var)\n",
    "    plt.title(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate plots of RPD vs class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 8))\n",
    "for ind,var in enumerate(variables):\n",
    "    ax = plt.subplot(3, 2, ind+1)\n",
    "    plt.subplots_adjust(hspace=0.55,wspace=0.4)\n",
    "    plt.ylabel('Class')\n",
    "    plt.xlabel('Normalized RPD')\n",
    "    plt.scatter(rpd[var]/max(rpd[var]),labels[:,ind])\n",
    "    plt.title(var)\n",
    "    plt.title(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the classifier network \n",
    "<font color=blue>\n",
    "    \n",
    "NOTE: This is the code I used originally with the output of the regression model.  However, because the RPD results are non-separable based on RPD, it was never updated to work with changes to the regression network.  It is included here just for completeness to demonstrate what was tried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rpd_unnorm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-583a44d88fa9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mclassifiers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mclassifiers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrpd_unnorm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'normal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mclassifiers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'normal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mclassifiers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'normal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rpd_unnorm' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "class_weight = {0:1,\n",
    "                1:labels.shape[0]*labels.shape[1]/labels.sum()} \n",
    "    \n",
    "classifiers = {}\n",
    "for ind,var in enumerate(variables):\n",
    "    \n",
    "    classifiers[var] = Sequential()\n",
    "    classifiers[var].add(layers.Dense(50, input_dim=rpd_unnorm.shape[1], kernel_initializer='normal', activation='relu'))\n",
    "    classifiers[var].add(layers.Dense(50, kernel_initializer='normal', activation='relu'))\n",
    "    classifiers[var].add(layers.Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    \n",
    "    sgd = optimizers.Adam(learning_rate=0.005, decay=0.95)\n",
    "    \n",
    "    classifiers[var].compile(loss='binary_crossentropy', \n",
    "                        optimizer=sgd,\n",
    "                        metrics = ['accuracy'])\n",
    "    \n",
    "    classifiers[var].fit(rpd_unnorm,label_train[:,ind],epochs=20,batch_size=32,\n",
    "               class_weight = class_weight,\n",
    "              validation_data=(rpd_val, label_val[:,ind]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change directions and try to directly classify the data using a MLP network.  The settings given here represent the best operation I was able to obtain.\n",
    "\n",
    "First step: reload and rescale the data to make sure we're working with the correct subsets of the data.  \n",
    "\n",
    "<font color=blue>\n",
    "\n",
    "NOTE: For the regression model, the time0 samples were left out and used to generate the y values.  For the direct classifier, the data from all timesteps was used to predict the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = samples_all[variable_headers].values\n",
    "labels = samples_all[label_headers].values\n",
    "\n",
    "\n",
    "x_scaler = StandardScaler()\n",
    "x_scaler.fit(X)\n",
    "X_scale = x_scaler.transform(X)\n",
    "X_scale = X\n",
    "\n",
    "xtrain, xval, ytrain, yval,label_train,label_val = train_test_split(X_scale, Y_scale, labels, test_size=0.20, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a class weight array for use during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_fraction = labels.shape[0]/sum(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the direct classifier and generate a plot of training and testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/1000\n",
      "16000/16000 [==============================] - 0s 26us/step - loss: 1.5594 - accuracy: 0.6162 - val_loss: 0.5234 - val_accuracy: 0.7945\n",
      "Epoch 2/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2987 - accuracy: 0.6752 - val_loss: 0.2973 - val_accuracy: 0.9095\n",
      "Epoch 3/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2041 - accuracy: 0.8104 - val_loss: 0.8168 - val_accuracy: 0.5982\n",
      "Epoch 4/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0833 - accuracy: 0.8154 - val_loss: 0.4654 - val_accuracy: 0.8322\n",
      "Epoch 5/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0532 - accuracy: 0.7996 - val_loss: 0.3283 - val_accuracy: 0.8928\n",
      "Epoch 6/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0523 - accuracy: 0.7977 - val_loss: 0.4835 - val_accuracy: 0.7878\n",
      "Epoch 7/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9771 - accuracy: 0.8291 - val_loss: 0.5326 - val_accuracy: 0.7853\n",
      "Epoch 8/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9359 - accuracy: 0.8069 - val_loss: 0.4636 - val_accuracy: 0.8080\n",
      "Epoch 9/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9082 - accuracy: 0.8202 - val_loss: 0.4142 - val_accuracy: 0.7950\n",
      "Epoch 10/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8787 - accuracy: 0.8112 - val_loss: 0.6324 - val_accuracy: 0.6930\n",
      "Epoch 11/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9199 - accuracy: 0.7921 - val_loss: 0.3618 - val_accuracy: 0.8242\n",
      "Epoch 12/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9040 - accuracy: 0.7722 - val_loss: 0.2081 - val_accuracy: 0.9185\n",
      "Epoch 13/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8678 - accuracy: 0.8121 - val_loss: 0.3258 - val_accuracy: 0.8407\n",
      "Epoch 14/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8043 - accuracy: 0.8049 - val_loss: 0.4265 - val_accuracy: 0.7965\n",
      "Epoch 15/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7905 - accuracy: 0.8453 - val_loss: 0.4097 - val_accuracy: 0.7900\n",
      "Epoch 16/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7366 - accuracy: 0.8238 - val_loss: 0.4101 - val_accuracy: 0.8062\n",
      "Epoch 17/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7627 - accuracy: 0.8029 - val_loss: 0.3184 - val_accuracy: 0.7987\n",
      "Epoch 18/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.7670 - accuracy: 0.8208 - val_loss: 0.3072 - val_accuracy: 0.8535\n",
      "Epoch 19/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7282 - accuracy: 0.8298 - val_loss: 0.5221 - val_accuracy: 0.7437\n",
      "Epoch 20/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7723 - accuracy: 0.8179 - val_loss: 0.5595 - val_accuracy: 0.7362\n",
      "Epoch 21/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7634 - accuracy: 0.8311 - val_loss: 0.3618 - val_accuracy: 0.8393\n",
      "Epoch 22/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7507 - accuracy: 0.8256 - val_loss: 0.2729 - val_accuracy: 0.8767\n",
      "Epoch 23/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6680 - accuracy: 0.8157 - val_loss: 0.2050 - val_accuracy: 0.9010\n",
      "Epoch 24/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7211 - accuracy: 0.8091 - val_loss: 0.2713 - val_accuracy: 0.8985\n",
      "Epoch 25/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6727 - accuracy: 0.8705 - val_loss: 0.3659 - val_accuracy: 0.8158\n",
      "Epoch 26/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6337 - accuracy: 0.8613 - val_loss: 0.3713 - val_accuracy: 0.8215\n",
      "Epoch 27/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6212 - accuracy: 0.8547 - val_loss: 0.3391 - val_accuracy: 0.8225\n",
      "Epoch 28/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6066 - accuracy: 0.8547 - val_loss: 0.1706 - val_accuracy: 0.9295\n",
      "Epoch 29/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6374 - accuracy: 0.8399 - val_loss: 0.2107 - val_accuracy: 0.9120\n",
      "Epoch 30/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6165 - accuracy: 0.8501 - val_loss: 0.2812 - val_accuracy: 0.8788\n",
      "Epoch 31/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6088 - accuracy: 0.8744 - val_loss: 0.4632 - val_accuracy: 0.7768\n",
      "Epoch 32/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6421 - accuracy: 0.8580 - val_loss: 0.6017 - val_accuracy: 0.7247\n",
      "Epoch 33/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7110 - accuracy: 0.8585 - val_loss: 0.5550 - val_accuracy: 0.7467\n",
      "Epoch 34/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6677 - accuracy: 0.8294 - val_loss: 0.1618 - val_accuracy: 0.9330\n",
      "Epoch 35/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6461 - accuracy: 0.8270 - val_loss: 0.2243 - val_accuracy: 0.9007\n",
      "Epoch 36/1000\n",
      "16000/16000 [==============================] - ETA: 0s - loss: 0.7314 - accuracy: 0.89 - 0s 3us/step - loss: 0.5864 - accuracy: 0.8857 - val_loss: 0.3032 - val_accuracy: 0.8630\n",
      "Epoch 37/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5588 - accuracy: 0.8786 - val_loss: 0.2716 - val_accuracy: 0.8712\n",
      "Epoch 38/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5447 - accuracy: 0.8729 - val_loss: 0.2056 - val_accuracy: 0.9032\n",
      "Epoch 39/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5410 - accuracy: 0.8795 - val_loss: 0.3437 - val_accuracy: 0.8522\n",
      "Epoch 40/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5526 - accuracy: 0.8760 - val_loss: 0.2553 - val_accuracy: 0.8790\n",
      "Epoch 41/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5118 - accuracy: 0.8790 - val_loss: 0.2790 - val_accuracy: 0.8708\n",
      "Epoch 42/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5251 - accuracy: 0.8841 - val_loss: 0.2256 - val_accuracy: 0.9013\n",
      "Epoch 43/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5062 - accuracy: 0.8855 - val_loss: 0.1949 - val_accuracy: 0.9103\n",
      "Epoch 44/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4985 - accuracy: 0.8699 - val_loss: 0.1978 - val_accuracy: 0.9197\n",
      "Epoch 45/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4950 - accuracy: 0.8767 - val_loss: 0.1090 - val_accuracy: 0.9515\n",
      "Epoch 46/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5897 - accuracy: 0.8661 - val_loss: 0.1837 - val_accuracy: 0.9168\n",
      "Epoch 47/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6399 - accuracy: 0.8447 - val_loss: 0.3230 - val_accuracy: 0.8562\n",
      "Epoch 48/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.6205 - accuracy: 0.8763 - val_loss: 0.3973 - val_accuracy: 0.8220\n",
      "Epoch 49/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5790 - accuracy: 0.8888 - val_loss: 0.5154 - val_accuracy: 0.7828\n",
      "Epoch 50/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6549 - accuracy: 0.8621 - val_loss: 0.3691 - val_accuracy: 0.8413\n",
      "Epoch 51/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5771 - accuracy: 0.8627 - val_loss: 0.2151 - val_accuracy: 0.8928\n",
      "Epoch 52/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.5182 - accuracy: 0.8617 - val_loss: 0.2000 - val_accuracy: 0.9158\n",
      "Epoch 53/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5413 - accuracy: 0.8824 - val_loss: 0.2595 - val_accuracy: 0.8838\n",
      "Epoch 54/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5065 - accuracy: 0.8848 - val_loss: 0.3523 - val_accuracy: 0.8350\n",
      "Epoch 55/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4660 - accuracy: 0.8967 - val_loss: 0.2545 - val_accuracy: 0.8950\n",
      "Epoch 56/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5052 - accuracy: 0.8889 - val_loss: 0.2952 - val_accuracy: 0.8670\n",
      "Epoch 57/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4569 - accuracy: 0.8857 - val_loss: 0.1566 - val_accuracy: 0.9283\n",
      "Epoch 58/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5216 - accuracy: 0.8658 - val_loss: 0.2058 - val_accuracy: 0.9120\n",
      "Epoch 59/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4867 - accuracy: 0.8904 - val_loss: 0.2413 - val_accuracy: 0.8932\n",
      "Epoch 60/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4644 - accuracy: 0.8955 - val_loss: 0.2821 - val_accuracy: 0.8725\n",
      "Epoch 61/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4523 - accuracy: 0.8996 - val_loss: 0.3096 - val_accuracy: 0.8633\n",
      "Epoch 62/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4414 - accuracy: 0.8904 - val_loss: 0.2073 - val_accuracy: 0.9080\n",
      "Epoch 63/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4218 - accuracy: 0.9028 - val_loss: 0.2801 - val_accuracy: 0.8795\n",
      "Epoch 64/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4142 - accuracy: 0.9084 - val_loss: 0.2079 - val_accuracy: 0.9072\n",
      "Epoch 65/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4357 - accuracy: 0.8924 - val_loss: 0.1711 - val_accuracy: 0.9233\n",
      "Epoch 66/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4268 - accuracy: 0.8959 - val_loss: 0.2123 - val_accuracy: 0.9090\n",
      "Epoch 67/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3961 - accuracy: 0.9071 - val_loss: 0.1787 - val_accuracy: 0.9197\n",
      "Epoch 68/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4058 - accuracy: 0.9040 - val_loss: 0.2621 - val_accuracy: 0.8928\n",
      "Epoch 69/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3978 - accuracy: 0.9064 - val_loss: 0.1868 - val_accuracy: 0.9205\n",
      "Epoch 70/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3791 - accuracy: 0.8992 - val_loss: 0.1585 - val_accuracy: 0.9273\n",
      "Epoch 71/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4051 - accuracy: 0.9111 - val_loss: 0.2989 - val_accuracy: 0.8800\n",
      "Epoch 72/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4010 - accuracy: 0.9072 - val_loss: 0.2315 - val_accuracy: 0.9005\n",
      "Epoch 73/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3935 - accuracy: 0.9061 - val_loss: 0.2101 - val_accuracy: 0.9075\n",
      "Epoch 74/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3986 - accuracy: 0.9078 - val_loss: 0.2229 - val_accuracy: 0.9035\n",
      "Epoch 75/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4583 - accuracy: 0.8917 - val_loss: 0.2666 - val_accuracy: 0.8950\n",
      "Epoch 76/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4472 - accuracy: 0.9013 - val_loss: 0.2015 - val_accuracy: 0.9107\n",
      "Epoch 77/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3843 - accuracy: 0.8996 - val_loss: 0.1670 - val_accuracy: 0.9258\n",
      "Epoch 78/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3968 - accuracy: 0.9101 - val_loss: 0.1737 - val_accuracy: 0.9243\n",
      "Epoch 79/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3818 - accuracy: 0.9134 - val_loss: 0.2316 - val_accuracy: 0.9010\n",
      "Epoch 80/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3638 - accuracy: 0.9176 - val_loss: 0.2173 - val_accuracy: 0.9055\n",
      "Epoch 81/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3683 - accuracy: 0.9117 - val_loss: 0.1981 - val_accuracy: 0.9158\n",
      "Epoch 82/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3372 - accuracy: 0.9156 - val_loss: 0.1686 - val_accuracy: 0.9260\n",
      "Epoch 83/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3633 - accuracy: 0.9087 - val_loss: 0.1800 - val_accuracy: 0.9252\n",
      "Epoch 84/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3590 - accuracy: 0.9217 - val_loss: 0.2293 - val_accuracy: 0.9055\n",
      "Epoch 85/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3697 - accuracy: 0.9114 - val_loss: 0.2562 - val_accuracy: 0.8972\n",
      "Epoch 86/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3399 - accuracy: 0.9226 - val_loss: 0.2921 - val_accuracy: 0.8823\n",
      "Epoch 87/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3514 - accuracy: 0.9102 - val_loss: 0.2829 - val_accuracy: 0.8863\n",
      "Epoch 88/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3402 - accuracy: 0.9217 - val_loss: 0.2904 - val_accuracy: 0.8898\n",
      "Epoch 89/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3706 - accuracy: 0.9039 - val_loss: 0.3254 - val_accuracy: 0.8705\n",
      "Epoch 90/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3909 - accuracy: 0.9133 - val_loss: 0.4334 - val_accuracy: 0.8335\n",
      "Epoch 91/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4131 - accuracy: 0.9072 - val_loss: 0.2761 - val_accuracy: 0.8907\n",
      "Epoch 92/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3563 - accuracy: 0.9136 - val_loss: 0.1860 - val_accuracy: 0.9200\n",
      "Epoch 93/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3415 - accuracy: 0.9256 - val_loss: 0.2272 - val_accuracy: 0.9060\n",
      "Epoch 94/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3420 - accuracy: 0.9133 - val_loss: 0.2310 - val_accuracy: 0.9078\n",
      "Epoch 95/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3279 - accuracy: 0.9246 - val_loss: 0.2228 - val_accuracy: 0.9112\n",
      "Epoch 96/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3278 - accuracy: 0.9201 - val_loss: 0.1522 - val_accuracy: 0.9348\n",
      "Epoch 97/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3404 - accuracy: 0.9189 - val_loss: 0.2281 - val_accuracy: 0.9047\n",
      "Epoch 98/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3809 - accuracy: 0.9044 - val_loss: 0.1789 - val_accuracy: 0.9312\n",
      "Epoch 99/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3608 - accuracy: 0.9244 - val_loss: 0.2861 - val_accuracy: 0.8878\n",
      "Epoch 100/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3653 - accuracy: 0.9073 - val_loss: 0.3516 - val_accuracy: 0.8708\n",
      "Epoch 101/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3892 - accuracy: 0.9144 - val_loss: 0.2551 - val_accuracy: 0.9000\n",
      "Epoch 102/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3319 - accuracy: 0.9251 - val_loss: 0.1889 - val_accuracy: 0.9227\n",
      "Epoch 103/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3436 - accuracy: 0.9164 - val_loss: 0.2422 - val_accuracy: 0.9030\n",
      "Epoch 104/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3480 - accuracy: 0.9193 - val_loss: 0.2555 - val_accuracy: 0.8990\n",
      "Epoch 105/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3474 - accuracy: 0.9195 - val_loss: 0.1949 - val_accuracy: 0.9202\n",
      "Epoch 106/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3309 - accuracy: 0.9181 - val_loss: 0.1824 - val_accuracy: 0.9252\n",
      "Epoch 107/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3631 - accuracy: 0.9159 - val_loss: 0.3597 - val_accuracy: 0.8493\n",
      "Epoch 108/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3498 - accuracy: 0.9162 - val_loss: 0.3074 - val_accuracy: 0.8845\n",
      "Epoch 109/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3248 - accuracy: 0.9259 - val_loss: 0.2256 - val_accuracy: 0.9118\n",
      "Epoch 110/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2781 - accuracy: 0.9308 - val_loss: 0.1300 - val_accuracy: 0.9470\n",
      "Epoch 111/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2791 - accuracy: 0.9366 - val_loss: 0.1593 - val_accuracy: 0.9375\n",
      "Epoch 112/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2863 - accuracy: 0.9366 - val_loss: 0.2726 - val_accuracy: 0.9015\n",
      "Epoch 113/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3197 - accuracy: 0.9273 - val_loss: 0.2649 - val_accuracy: 0.8965\n",
      "Epoch 114/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3487 - accuracy: 0.9174 - val_loss: 0.3040 - val_accuracy: 0.8932\n",
      "Epoch 115/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3649 - accuracy: 0.9187 - val_loss: 0.2189 - val_accuracy: 0.9172\n",
      "Epoch 116/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3302 - accuracy: 0.9165 - val_loss: 0.1593 - val_accuracy: 0.9335\n",
      "Epoch 117/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3258 - accuracy: 0.9255 - val_loss: 0.1542 - val_accuracy: 0.9400\n",
      "Epoch 118/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3282 - accuracy: 0.9201 - val_loss: 0.1719 - val_accuracy: 0.9340\n",
      "Epoch 119/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3059 - accuracy: 0.9254 - val_loss: 0.1340 - val_accuracy: 0.9427\n",
      "Epoch 120/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3152 - accuracy: 0.9323 - val_loss: 0.1398 - val_accuracy: 0.9420\n",
      "Epoch 121/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3592 - accuracy: 0.9204 - val_loss: 0.1814 - val_accuracy: 0.9310\n",
      "Epoch 122/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3788 - accuracy: 0.9070 - val_loss: 0.1243 - val_accuracy: 0.9485\n",
      "Epoch 123/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3292 - accuracy: 0.9291 - val_loss: 0.1647 - val_accuracy: 0.9340\n",
      "Epoch 124/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2905 - accuracy: 0.9302 - val_loss: 0.1859 - val_accuracy: 0.9277\n",
      "Epoch 125/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3352 - accuracy: 0.9187 - val_loss: 0.2029 - val_accuracy: 0.9202\n",
      "Epoch 126/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2901 - accuracy: 0.9375 - val_loss: 0.1735 - val_accuracy: 0.9285\n",
      "Epoch 127/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2667 - accuracy: 0.9317 - val_loss: 0.1444 - val_accuracy: 0.9442\n",
      "Epoch 128/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2540 - accuracy: 0.9387 - val_loss: 0.1081 - val_accuracy: 0.9592\n",
      "Epoch 129/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2795 - accuracy: 0.9435 - val_loss: 0.1846 - val_accuracy: 0.9325\n",
      "Epoch 130/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2913 - accuracy: 0.9214 - val_loss: 0.1801 - val_accuracy: 0.9295\n",
      "Epoch 131/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3986 - accuracy: 0.9042 - val_loss: 0.1424 - val_accuracy: 0.9450\n",
      "Epoch 132/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3472 - accuracy: 0.9362 - val_loss: 0.1831 - val_accuracy: 0.9293\n",
      "Epoch 133/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3526 - accuracy: 0.9061 - val_loss: 0.2138 - val_accuracy: 0.9205\n",
      "Epoch 134/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4948 - accuracy: 0.8934 - val_loss: 0.3159 - val_accuracy: 0.8817\n",
      "Epoch 135/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4400 - accuracy: 0.9109 - val_loss: 0.3133 - val_accuracy: 0.8852\n",
      "Epoch 136/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3672 - accuracy: 0.9230 - val_loss: 0.2496 - val_accuracy: 0.9047\n",
      "Epoch 137/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3315 - accuracy: 0.9299 - val_loss: 0.2337 - val_accuracy: 0.9087\n",
      "Epoch 138/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3188 - accuracy: 0.9238 - val_loss: 0.1458 - val_accuracy: 0.9398\n",
      "Epoch 139/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3012 - accuracy: 0.9252 - val_loss: 0.1312 - val_accuracy: 0.9492\n",
      "Epoch 140/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2882 - accuracy: 0.9351 - val_loss: 0.1661 - val_accuracy: 0.9333\n",
      "Epoch 141/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2521 - accuracy: 0.9378 - val_loss: 0.1579 - val_accuracy: 0.9385\n",
      "Epoch 142/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2402 - accuracy: 0.9412 - val_loss: 0.1167 - val_accuracy: 0.9532\n",
      "Epoch 143/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2373 - accuracy: 0.9448 - val_loss: 0.2053 - val_accuracy: 0.9252\n",
      "Epoch 144/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2630 - accuracy: 0.9458 - val_loss: 0.2057 - val_accuracy: 0.9218\n",
      "Epoch 145/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2503 - accuracy: 0.9352 - val_loss: 0.1514 - val_accuracy: 0.9423\n",
      "Epoch 146/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2271 - accuracy: 0.9431 - val_loss: 0.1657 - val_accuracy: 0.9383\n",
      "Epoch 147/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2215 - accuracy: 0.9482 - val_loss: 0.1337 - val_accuracy: 0.9498\n",
      "Epoch 148/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2064 - accuracy: 0.9516 - val_loss: 0.0891 - val_accuracy: 0.9680\n",
      "Epoch 149/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2298 - accuracy: 0.9444 - val_loss: 0.1053 - val_accuracy: 0.9610\n",
      "Epoch 150/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2330 - accuracy: 0.9437 - val_loss: 0.1308 - val_accuracy: 0.9515\n",
      "Epoch 151/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2602 - accuracy: 0.9342 - val_loss: 0.1451 - val_accuracy: 0.9477\n",
      "Epoch 152/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2665 - accuracy: 0.9433 - val_loss: 0.2070 - val_accuracy: 0.9273\n",
      "Epoch 153/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.2472 - accuracy: 0.9474 - val_loss: 0.1672 - val_accuracy: 0.9348\n",
      "Epoch 154/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.2466 - accuracy: 0.9426 - val_loss: 0.1660 - val_accuracy: 0.9433\n",
      "Epoch 155/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2464 - accuracy: 0.9457 - val_loss: 0.1921 - val_accuracy: 0.9302\n",
      "Epoch 156/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2340 - accuracy: 0.9393 - val_loss: 0.1102 - val_accuracy: 0.9582\n",
      "Epoch 157/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2446 - accuracy: 0.9398 - val_loss: 0.1305 - val_accuracy: 0.9542\n",
      "Epoch 158/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2246 - accuracy: 0.9485 - val_loss: 0.1419 - val_accuracy: 0.9465\n",
      "Epoch 159/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2519 - accuracy: 0.9445 - val_loss: 0.2455 - val_accuracy: 0.9115\n",
      "Epoch 160/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2179 - accuracy: 0.9499 - val_loss: 0.1044 - val_accuracy: 0.9615\n",
      "Epoch 161/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2475 - accuracy: 0.9343 - val_loss: 0.0809 - val_accuracy: 0.9685\n",
      "Epoch 162/1000\n",
      "16000/16000 [==============================] - ETA: 0s - loss: 0.2181 - accuracy: 0.97 - 0s 3us/step - loss: 0.2551 - accuracy: 0.9398 - val_loss: 0.1358 - val_accuracy: 0.9475\n",
      "Epoch 163/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2258 - accuracy: 0.9498 - val_loss: 0.1245 - val_accuracy: 0.9495\n",
      "Epoch 164/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2362 - accuracy: 0.9429 - val_loss: 0.1513 - val_accuracy: 0.9440\n",
      "Epoch 165/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2252 - accuracy: 0.9484 - val_loss: 0.1666 - val_accuracy: 0.9395\n",
      "Epoch 166/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2123 - accuracy: 0.9553 - val_loss: 0.1998 - val_accuracy: 0.9268\n",
      "Epoch 167/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2169 - accuracy: 0.9459 - val_loss: 0.1197 - val_accuracy: 0.9555\n",
      "Epoch 168/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2166 - accuracy: 0.9388 - val_loss: 0.0837 - val_accuracy: 0.9700\n",
      "Epoch 169/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2717 - accuracy: 0.9404 - val_loss: 0.1626 - val_accuracy: 0.9440\n",
      "Epoch 170/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2908 - accuracy: 0.9401 - val_loss: 0.1870 - val_accuracy: 0.9310\n",
      "Epoch 171/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2734 - accuracy: 0.9293 - val_loss: 0.1179 - val_accuracy: 0.9555\n",
      "Epoch 172/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2746 - accuracy: 0.9355 - val_loss: 0.1632 - val_accuracy: 0.9360\n",
      "Epoch 173/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.2971 - accuracy: 0.9376 - val_loss: 0.1533 - val_accuracy: 0.9408\n",
      "Epoch 174/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.2278 - accuracy: 0.9386 - val_loss: 0.1104 - val_accuracy: 0.9567\n",
      "Epoch 175/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2150 - accuracy: 0.9486 - val_loss: 0.1157 - val_accuracy: 0.9550\n",
      "Epoch 176/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2050 - accuracy: 0.9540 - val_loss: 0.1202 - val_accuracy: 0.9528\n",
      "Epoch 177/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2110 - accuracy: 0.9510 - val_loss: 0.1570 - val_accuracy: 0.9438\n",
      "Epoch 178/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2426 - accuracy: 0.9513 - val_loss: 0.2854 - val_accuracy: 0.8888\n",
      "Epoch 179/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3043 - accuracy: 0.9390 - val_loss: 0.1707 - val_accuracy: 0.9315\n",
      "Epoch 180/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2645 - accuracy: 0.9362 - val_loss: 0.1299 - val_accuracy: 0.9530\n",
      "Epoch 181/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2539 - accuracy: 0.9323 - val_loss: 0.1265 - val_accuracy: 0.9548\n",
      "Epoch 182/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2960 - accuracy: 0.9436 - val_loss: 0.1806 - val_accuracy: 0.9310\n",
      "Epoch 183/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3238 - accuracy: 0.9195 - val_loss: 0.1301 - val_accuracy: 0.9525\n",
      "Epoch 184/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2954 - accuracy: 0.9286 - val_loss: 0.1097 - val_accuracy: 0.9592\n",
      "Epoch 185/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2680 - accuracy: 0.9381 - val_loss: 0.1460 - val_accuracy: 0.9572\n",
      "Epoch 186/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2335 - accuracy: 0.9458 - val_loss: 0.1790 - val_accuracy: 0.9402\n",
      "Epoch 187/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2193 - accuracy: 0.9554 - val_loss: 0.1730 - val_accuracy: 0.9402\n",
      "Epoch 188/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2075 - accuracy: 0.9552 - val_loss: 0.1379 - val_accuracy: 0.9520\n",
      "Epoch 189/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2013 - accuracy: 0.9538 - val_loss: 0.1008 - val_accuracy: 0.9647\n",
      "Epoch 190/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1929 - accuracy: 0.9457 - val_loss: 0.0925 - val_accuracy: 0.9668\n",
      "Epoch 191/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1954 - accuracy: 0.9576 - val_loss: 0.1819 - val_accuracy: 0.9293\n",
      "Epoch 192/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2080 - accuracy: 0.9508 - val_loss: 0.1663 - val_accuracy: 0.9402\n",
      "Epoch 193/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2216 - accuracy: 0.9497 - val_loss: 0.2312 - val_accuracy: 0.9140\n",
      "Epoch 194/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2173 - accuracy: 0.9459 - val_loss: 0.1360 - val_accuracy: 0.9503\n",
      "Epoch 195/1000\n",
      "16000/16000 [==============================] - 0s 7us/step - loss: 0.2151 - accuracy: 0.9569 - val_loss: 0.1496 - val_accuracy: 0.9477\n",
      "Epoch 196/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1821 - accuracy: 0.9575 - val_loss: 0.0945 - val_accuracy: 0.9670\n",
      "Epoch 197/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1740 - accuracy: 0.9613 - val_loss: 0.1190 - val_accuracy: 0.9603\n",
      "Epoch 198/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1734 - accuracy: 0.9637 - val_loss: 0.1504 - val_accuracy: 0.9490\n",
      "Epoch 199/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1713 - accuracy: 0.9630 - val_loss: 0.1208 - val_accuracy: 0.9600\n",
      "Epoch 200/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1678 - accuracy: 0.9582 - val_loss: 0.1024 - val_accuracy: 0.9643\n",
      "Epoch 201/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.1563 - accuracy: 0.9617 - val_loss: 0.0939 - val_accuracy: 0.9693\n",
      "Epoch 202/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1521 - accuracy: 0.9599 - val_loss: 0.0820 - val_accuracy: 0.9715\n",
      "Epoch 203/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1648 - accuracy: 0.9612 - val_loss: 0.1365 - val_accuracy: 0.9542\n",
      "Epoch 204/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1536 - accuracy: 0.9683 - val_loss: 0.0965 - val_accuracy: 0.9665\n",
      "Epoch 205/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1424 - accuracy: 0.9615 - val_loss: 0.0751 - val_accuracy: 0.9750\n",
      "Epoch 206/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1540 - accuracy: 0.9651 - val_loss: 0.1029 - val_accuracy: 0.9647\n",
      "Epoch 207/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1497 - accuracy: 0.9692 - val_loss: 0.1098 - val_accuracy: 0.9632\n",
      "Epoch 208/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1398 - accuracy: 0.9687 - val_loss: 0.1137 - val_accuracy: 0.9632\n",
      "Epoch 209/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1386 - accuracy: 0.9674 - val_loss: 0.1055 - val_accuracy: 0.9655\n",
      "Epoch 210/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1583 - accuracy: 0.9628 - val_loss: 0.0943 - val_accuracy: 0.9690\n",
      "Epoch 211/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1630 - accuracy: 0.9599 - val_loss: 0.1063 - val_accuracy: 0.9622\n",
      "Epoch 212/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1585 - accuracy: 0.9631 - val_loss: 0.0893 - val_accuracy: 0.9690\n",
      "Epoch 213/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1484 - accuracy: 0.9606 - val_loss: 0.0860 - val_accuracy: 0.9720\n",
      "Epoch 214/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1508 - accuracy: 0.9657 - val_loss: 0.1032 - val_accuracy: 0.9668\n",
      "Epoch 215/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1416 - accuracy: 0.9661 - val_loss: 0.1338 - val_accuracy: 0.9540\n",
      "Epoch 216/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1319 - accuracy: 0.9676 - val_loss: 0.0796 - val_accuracy: 0.9745\n",
      "Epoch 217/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1322 - accuracy: 0.9674 - val_loss: 0.1064 - val_accuracy: 0.9632\n",
      "Epoch 218/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1253 - accuracy: 0.9688 - val_loss: 0.0758 - val_accuracy: 0.9730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 219/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1536 - accuracy: 0.9614 - val_loss: 0.1022 - val_accuracy: 0.9665\n",
      "Epoch 220/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1416 - accuracy: 0.9675 - val_loss: 0.0984 - val_accuracy: 0.9663\n",
      "Epoch 221/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1431 - accuracy: 0.9688 - val_loss: 0.0978 - val_accuracy: 0.9695\n",
      "Epoch 222/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1325 - accuracy: 0.9668 - val_loss: 0.0937 - val_accuracy: 0.9685\n",
      "Epoch 223/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1282 - accuracy: 0.9681 - val_loss: 0.0811 - val_accuracy: 0.9730\n",
      "Epoch 224/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1510 - accuracy: 0.9628 - val_loss: 0.1231 - val_accuracy: 0.9578\n",
      "Epoch 225/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1445 - accuracy: 0.9654 - val_loss: 0.1139 - val_accuracy: 0.9613\n",
      "Epoch 226/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1715 - accuracy: 0.9554 - val_loss: 0.1463 - val_accuracy: 0.9507\n",
      "Epoch 227/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1950 - accuracy: 0.9553 - val_loss: 0.1163 - val_accuracy: 0.9605\n",
      "Epoch 228/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1721 - accuracy: 0.9588 - val_loss: 0.1246 - val_accuracy: 0.9575\n",
      "Epoch 229/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2037 - accuracy: 0.9544 - val_loss: 0.1865 - val_accuracy: 0.9315\n",
      "Epoch 230/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1840 - accuracy: 0.9632 - val_loss: 0.1707 - val_accuracy: 0.9423\n",
      "Epoch 231/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1880 - accuracy: 0.9531 - val_loss: 0.1307 - val_accuracy: 0.9550\n",
      "Epoch 232/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2293 - accuracy: 0.9634 - val_loss: 0.2700 - val_accuracy: 0.9045\n",
      "Epoch 233/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4384 - accuracy: 0.9104 - val_loss: 0.4067 - val_accuracy: 0.8637\n",
      "Epoch 234/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3688 - accuracy: 0.9173 - val_loss: 0.2882 - val_accuracy: 0.9038\n",
      "Epoch 235/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3300 - accuracy: 0.9390 - val_loss: 0.2556 - val_accuracy: 0.9093\n",
      "Epoch 236/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3027 - accuracy: 0.9216 - val_loss: 0.0999 - val_accuracy: 0.9657\n",
      "Epoch 237/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2359 - accuracy: 0.9396 - val_loss: 0.0910 - val_accuracy: 0.9660\n",
      "Epoch 238/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2225 - accuracy: 0.9571 - val_loss: 0.1843 - val_accuracy: 0.9390\n",
      "Epoch 239/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2186 - accuracy: 0.9578 - val_loss: 0.1369 - val_accuracy: 0.9515\n",
      "Epoch 240/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2132 - accuracy: 0.9500 - val_loss: 0.1053 - val_accuracy: 0.9638\n",
      "Epoch 241/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2308 - accuracy: 0.9477 - val_loss: 0.1933 - val_accuracy: 0.9360\n",
      "Epoch 242/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2407 - accuracy: 0.9528 - val_loss: 0.1833 - val_accuracy: 0.9345\n",
      "Epoch 243/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2048 - accuracy: 0.9472 - val_loss: 0.1074 - val_accuracy: 0.9635\n",
      "Epoch 244/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1830 - accuracy: 0.9591 - val_loss: 0.1039 - val_accuracy: 0.9665\n",
      "Epoch 245/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1831 - accuracy: 0.9589 - val_loss: 0.1429 - val_accuracy: 0.9535\n",
      "Epoch 246/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1934 - accuracy: 0.9635 - val_loss: 0.1795 - val_accuracy: 0.9377\n",
      "Epoch 247/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1801 - accuracy: 0.9553 - val_loss: 0.0919 - val_accuracy: 0.9693\n",
      "Epoch 248/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1591 - accuracy: 0.9583 - val_loss: 0.0902 - val_accuracy: 0.9720\n",
      "Epoch 249/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1560 - accuracy: 0.9621 - val_loss: 0.1219 - val_accuracy: 0.9615\n",
      "Epoch 250/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1621 - accuracy: 0.9642 - val_loss: 0.1594 - val_accuracy: 0.9367\n",
      "Epoch 251/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1511 - accuracy: 0.9638 - val_loss: 0.1187 - val_accuracy: 0.9607\n",
      "Epoch 252/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1377 - accuracy: 0.9663 - val_loss: 0.0917 - val_accuracy: 0.9703\n",
      "Epoch 253/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1248 - accuracy: 0.9732 - val_loss: 0.1063 - val_accuracy: 0.9628\n",
      "Epoch 254/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1263 - accuracy: 0.9743 - val_loss: 0.0978 - val_accuracy: 0.9657\n",
      "Epoch 255/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1216 - accuracy: 0.9674 - val_loss: 0.0919 - val_accuracy: 0.9710\n",
      "Epoch 256/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1248 - accuracy: 0.9745 - val_loss: 0.1158 - val_accuracy: 0.9620\n",
      "Epoch 257/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1286 - accuracy: 0.9686 - val_loss: 0.0918 - val_accuracy: 0.9697\n",
      "Epoch 258/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1116 - accuracy: 0.9704 - val_loss: 0.0764 - val_accuracy: 0.9762\n",
      "Epoch 259/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1110 - accuracy: 0.9746 - val_loss: 0.0901 - val_accuracy: 0.9718\n",
      "Epoch 260/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1061 - accuracy: 0.9719 - val_loss: 0.0676 - val_accuracy: 0.9790\n",
      "Epoch 261/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1157 - accuracy: 0.9719 - val_loss: 0.0890 - val_accuracy: 0.9710\n",
      "Epoch 262/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1049 - accuracy: 0.9777 - val_loss: 0.0955 - val_accuracy: 0.9685\n",
      "Epoch 263/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1012 - accuracy: 0.9759 - val_loss: 0.0827 - val_accuracy: 0.9737\n",
      "Epoch 264/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1161 - accuracy: 0.9711 - val_loss: 0.1056 - val_accuracy: 0.9668\n",
      "Epoch 265/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1370 - accuracy: 0.9678 - val_loss: 0.1534 - val_accuracy: 0.9420\n",
      "Epoch 266/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1416 - accuracy: 0.9650 - val_loss: 0.1418 - val_accuracy: 0.9550\n",
      "Epoch 267/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1503 - accuracy: 0.9671 - val_loss: 0.1573 - val_accuracy: 0.9503\n",
      "Epoch 268/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1627 - accuracy: 0.9611 - val_loss: 0.1256 - val_accuracy: 0.9590\n",
      "Epoch 269/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1487 - accuracy: 0.9624 - val_loss: 0.0815 - val_accuracy: 0.9725\n",
      "Epoch 270/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1258 - accuracy: 0.9679 - val_loss: 0.0899 - val_accuracy: 0.9707\n",
      "Epoch 271/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1207 - accuracy: 0.9735 - val_loss: 0.1052 - val_accuracy: 0.9630\n",
      "Epoch 272/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1129 - accuracy: 0.9704 - val_loss: 0.0865 - val_accuracy: 0.9722\n",
      "Epoch 273/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1248 - accuracy: 0.9725 - val_loss: 0.1010 - val_accuracy: 0.9672\n",
      "Epoch 274/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1294 - accuracy: 0.9695 - val_loss: 0.1325 - val_accuracy: 0.9542\n",
      "Epoch 275/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1464 - accuracy: 0.9616 - val_loss: 0.0893 - val_accuracy: 0.9685\n",
      "Epoch 276/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1240 - accuracy: 0.9731 - val_loss: 0.1056 - val_accuracy: 0.9657\n",
      "Epoch 277/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1179 - accuracy: 0.9688 - val_loss: 0.0865 - val_accuracy: 0.9735\n",
      "Epoch 278/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1064 - accuracy: 0.9737 - val_loss: 0.0771 - val_accuracy: 0.9753\n",
      "Epoch 279/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1061 - accuracy: 0.9749 - val_loss: 0.0909 - val_accuracy: 0.9695\n",
      "Epoch 280/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1008 - accuracy: 0.9753 - val_loss: 0.0777 - val_accuracy: 0.9780\n",
      "Epoch 281/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1139 - accuracy: 0.9716 - val_loss: 0.1138 - val_accuracy: 0.9605\n",
      "Epoch 282/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1371 - accuracy: 0.9677 - val_loss: 0.1810 - val_accuracy: 0.9433\n",
      "Epoch 283/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1464 - accuracy: 0.9674 - val_loss: 0.1029 - val_accuracy: 0.9665\n",
      "Epoch 284/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1359 - accuracy: 0.9643 - val_loss: 0.1009 - val_accuracy: 0.9657\n",
      "Epoch 285/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1326 - accuracy: 0.9698 - val_loss: 0.1061 - val_accuracy: 0.9655\n",
      "Epoch 286/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1326 - accuracy: 0.9721 - val_loss: 0.1007 - val_accuracy: 0.9655\n",
      "Epoch 287/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1359 - accuracy: 0.9617 - val_loss: 0.0949 - val_accuracy: 0.9700\n",
      "Epoch 288/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1602 - accuracy: 0.9565 - val_loss: 0.0997 - val_accuracy: 0.9640\n",
      "Epoch 289/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1540 - accuracy: 0.9665 - val_loss: 0.0849 - val_accuracy: 0.9728\n",
      "Epoch 290/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1778 - accuracy: 0.9553 - val_loss: 0.0802 - val_accuracy: 0.9762\n",
      "Epoch 291/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2478 - accuracy: 0.9490 - val_loss: 0.1823 - val_accuracy: 0.9465\n",
      "Epoch 292/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2216 - accuracy: 0.9571 - val_loss: 0.1932 - val_accuracy: 0.9365\n",
      "Epoch 293/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1764 - accuracy: 0.9598 - val_loss: 0.1293 - val_accuracy: 0.9555\n",
      "Epoch 294/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1533 - accuracy: 0.9586 - val_loss: 0.0822 - val_accuracy: 0.9700\n",
      "Epoch 295/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1513 - accuracy: 0.9666 - val_loss: 0.1162 - val_accuracy: 0.9613\n",
      "Epoch 296/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1407 - accuracy: 0.9712 - val_loss: 0.1425 - val_accuracy: 0.9500\n",
      "Epoch 297/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1802 - accuracy: 0.9566 - val_loss: 0.1619 - val_accuracy: 0.9410\n",
      "Epoch 298/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1912 - accuracy: 0.9528 - val_loss: 0.1610 - val_accuracy: 0.9450\n",
      "Epoch 299/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1914 - accuracy: 0.9487 - val_loss: 0.0811 - val_accuracy: 0.9728\n",
      "Epoch 300/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1611 - accuracy: 0.9596 - val_loss: 0.0881 - val_accuracy: 0.9690\n",
      "Epoch 301/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1387 - accuracy: 0.9729 - val_loss: 0.1510 - val_accuracy: 0.9435\n",
      "Epoch 302/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1440 - accuracy: 0.9652 - val_loss: 0.0759 - val_accuracy: 0.9745\n",
      "Epoch 303/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1342 - accuracy: 0.9653 - val_loss: 0.0656 - val_accuracy: 0.9793\n",
      "Epoch 304/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1399 - accuracy: 0.9690 - val_loss: 0.1318 - val_accuracy: 0.9560\n",
      "Epoch 305/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1356 - accuracy: 0.9722 - val_loss: 0.1181 - val_accuracy: 0.9615\n",
      "Epoch 306/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1701 - accuracy: 0.9621 - val_loss: 0.0929 - val_accuracy: 0.9693\n",
      "Epoch 307/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1604 - accuracy: 0.9538 - val_loss: 0.0750 - val_accuracy: 0.9760\n",
      "Epoch 308/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1444 - accuracy: 0.9663 - val_loss: 0.0904 - val_accuracy: 0.9703\n",
      "Epoch 309/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1396 - accuracy: 0.9761 - val_loss: 0.1636 - val_accuracy: 0.9430\n",
      "Epoch 310/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1470 - accuracy: 0.9638 - val_loss: 0.0863 - val_accuracy: 0.9740\n",
      "Epoch 311/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1137 - accuracy: 0.9708 - val_loss: 0.0978 - val_accuracy: 0.9690\n",
      "Epoch 312/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1089 - accuracy: 0.9748 - val_loss: 0.0953 - val_accuracy: 0.9693\n",
      "Epoch 313/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0993 - accuracy: 0.9741 - val_loss: 0.0733 - val_accuracy: 0.9780\n",
      "Epoch 314/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1152 - accuracy: 0.9707 - val_loss: 0.0806 - val_accuracy: 0.9737\n",
      "Epoch 315/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0979 - accuracy: 0.9789 - val_loss: 0.0831 - val_accuracy: 0.9770\n",
      "Epoch 316/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0901 - accuracy: 0.9777 - val_loss: 0.0782 - val_accuracy: 0.9772\n",
      "Epoch 317/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0937 - accuracy: 0.9754 - val_loss: 0.0894 - val_accuracy: 0.9705\n",
      "Epoch 318/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0982 - accuracy: 0.9826 - val_loss: 0.1032 - val_accuracy: 0.9647\n",
      "Epoch 319/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1574 - accuracy: 0.9644 - val_loss: 0.0997 - val_accuracy: 0.9665\n",
      "Epoch 320/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1920 - accuracy: 0.9502 - val_loss: 0.0900 - val_accuracy: 0.9703\n",
      "Epoch 321/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1674 - accuracy: 0.9651 - val_loss: 0.0887 - val_accuracy: 0.9720\n",
      "Epoch 322/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1263 - accuracy: 0.9762 - val_loss: 0.1300 - val_accuracy: 0.9610\n",
      "Epoch 323/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1291 - accuracy: 0.9707 - val_loss: 0.0876 - val_accuracy: 0.9722\n",
      "Epoch 324/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1496 - accuracy: 0.9626 - val_loss: 0.0869 - val_accuracy: 0.9750\n",
      "Epoch 325/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1115 - accuracy: 0.9772 - val_loss: 0.0962 - val_accuracy: 0.9688\n",
      "Epoch 326/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0994 - accuracy: 0.9747 - val_loss: 0.0833 - val_accuracy: 0.9740\n",
      "Epoch 327/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1004 - accuracy: 0.9739 - val_loss: 0.1180 - val_accuracy: 0.9582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 328/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1198 - accuracy: 0.9713 - val_loss: 0.1102 - val_accuracy: 0.9638\n",
      "Epoch 329/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1123 - accuracy: 0.9698 - val_loss: 0.0884 - val_accuracy: 0.9693\n",
      "Epoch 330/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0913 - accuracy: 0.9762 - val_loss: 0.0701 - val_accuracy: 0.9780\n",
      "Epoch 331/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0962 - accuracy: 0.9761 - val_loss: 0.0720 - val_accuracy: 0.9780\n",
      "Epoch 332/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0873 - accuracy: 0.9812 - val_loss: 0.0890 - val_accuracy: 0.9705\n",
      "Epoch 333/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0894 - accuracy: 0.9745 - val_loss: 0.0641 - val_accuracy: 0.9827\n",
      "Epoch 334/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0789 - accuracy: 0.9794 - val_loss: 0.0722 - val_accuracy: 0.9793\n",
      "Epoch 335/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0879 - accuracy: 0.9823 - val_loss: 0.0854 - val_accuracy: 0.9720\n",
      "Epoch 336/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1210 - accuracy: 0.9709 - val_loss: 0.1376 - val_accuracy: 0.9523\n",
      "Epoch 337/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1600 - accuracy: 0.9643 - val_loss: 0.1166 - val_accuracy: 0.9643\n",
      "Epoch 338/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1323 - accuracy: 0.9630 - val_loss: 0.0779 - val_accuracy: 0.9780\n",
      "Epoch 339/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1357 - accuracy: 0.9732 - val_loss: 0.1754 - val_accuracy: 0.9470\n",
      "Epoch 340/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1506 - accuracy: 0.9656 - val_loss: 0.0973 - val_accuracy: 0.9688\n",
      "Epoch 341/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1161 - accuracy: 0.9741 - val_loss: 0.0963 - val_accuracy: 0.9695\n",
      "Epoch 342/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1192 - accuracy: 0.9665 - val_loss: 0.0707 - val_accuracy: 0.9795\n",
      "Epoch 343/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1437 - accuracy: 0.9627 - val_loss: 0.0690 - val_accuracy: 0.9827\n",
      "Epoch 344/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1049 - accuracy: 0.9808 - val_loss: 0.1060 - val_accuracy: 0.9663\n",
      "Epoch 345/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0897 - accuracy: 0.9784 - val_loss: 0.0751 - val_accuracy: 0.9778\n",
      "Epoch 346/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1100 - accuracy: 0.9728 - val_loss: 0.0758 - val_accuracy: 0.9775\n",
      "Epoch 347/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1070 - accuracy: 0.9737 - val_loss: 0.0887 - val_accuracy: 0.9722\n",
      "Epoch 348/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1096 - accuracy: 0.9756 - val_loss: 0.1146 - val_accuracy: 0.9635\n",
      "Epoch 349/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1035 - accuracy: 0.9745 - val_loss: 0.0983 - val_accuracy: 0.9653\n",
      "Epoch 350/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1158 - accuracy: 0.9722 - val_loss: 0.1359 - val_accuracy: 0.9495\n",
      "Epoch 351/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1225 - accuracy: 0.9708 - val_loss: 0.1172 - val_accuracy: 0.9607\n",
      "Epoch 352/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1545 - accuracy: 0.9600 - val_loss: 0.1563 - val_accuracy: 0.9498\n",
      "Epoch 353/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1559 - accuracy: 0.9661 - val_loss: 0.1154 - val_accuracy: 0.9657\n",
      "Epoch 354/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1491 - accuracy: 0.9664 - val_loss: 0.1054 - val_accuracy: 0.9660\n",
      "Epoch 355/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1121 - accuracy: 0.9745 - val_loss: 0.1325 - val_accuracy: 0.9567\n",
      "Epoch 356/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1132 - accuracy: 0.9728 - val_loss: 0.0879 - val_accuracy: 0.9758\n",
      "Epoch 357/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0949 - accuracy: 0.9760 - val_loss: 0.0721 - val_accuracy: 0.9787\n",
      "Epoch 358/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0852 - accuracy: 0.9796 - val_loss: 0.0752 - val_accuracy: 0.9790\n",
      "Epoch 359/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0816 - accuracy: 0.9808 - val_loss: 0.0722 - val_accuracy: 0.9808\n",
      "Epoch 360/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0794 - accuracy: 0.9803 - val_loss: 0.0702 - val_accuracy: 0.9793\n",
      "Epoch 361/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0876 - accuracy: 0.9767 - val_loss: 0.1022 - val_accuracy: 0.9665\n",
      "Epoch 362/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0882 - accuracy: 0.9811 - val_loss: 0.1085 - val_accuracy: 0.9653\n",
      "Epoch 363/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0909 - accuracy: 0.9763 - val_loss: 0.0867 - val_accuracy: 0.9722\n",
      "Epoch 364/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1027 - accuracy: 0.9795 - val_loss: 0.0965 - val_accuracy: 0.9712\n",
      "Epoch 365/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1078 - accuracy: 0.9679 - val_loss: 0.0652 - val_accuracy: 0.9843\n",
      "Epoch 366/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0969 - accuracy: 0.9783 - val_loss: 0.1027 - val_accuracy: 0.9672\n",
      "Epoch 367/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.0953 - accuracy: 0.9803 - val_loss: 0.0945 - val_accuracy: 0.9740\n",
      "Epoch 368/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.0868 - accuracy: 0.9773 - val_loss: 0.0839 - val_accuracy: 0.9765\n",
      "Epoch 369/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0724 - accuracy: 0.9812 - val_loss: 0.0702 - val_accuracy: 0.9818\n",
      "Epoch 370/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0733 - accuracy: 0.9808 - val_loss: 0.0829 - val_accuracy: 0.9753\n",
      "Epoch 371/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0675 - accuracy: 0.9836 - val_loss: 0.0717 - val_accuracy: 0.9803\n",
      "Epoch 372/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0679 - accuracy: 0.9841 - val_loss: 0.0761 - val_accuracy: 0.9775\n",
      "Epoch 373/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0753 - accuracy: 0.9820 - val_loss: 0.0980 - val_accuracy: 0.9685\n",
      "Epoch 374/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.1275 - accuracy: 0.9678 - val_loss: 0.1872 - val_accuracy: 0.9420\n",
      "Epoch 375/1000\n",
      "16000/16000 [==============================] - 0s 9us/step - loss: 0.2981 - accuracy: 0.9449 - val_loss: 0.2351 - val_accuracy: 0.9377\n",
      "Epoch 376/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3372 - accuracy: 0.9419 - val_loss: 0.1632 - val_accuracy: 0.9505\n",
      "Epoch 377/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2146 - accuracy: 0.9596 - val_loss: 0.1745 - val_accuracy: 0.9505\n",
      "Epoch 378/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3649 - accuracy: 0.9226 - val_loss: 0.1713 - val_accuracy: 0.9532\n",
      "Epoch 379/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3057 - accuracy: 0.9506 - val_loss: 0.1780 - val_accuracy: 0.9398\n",
      "Epoch 380/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1956 - accuracy: 0.9601 - val_loss: 0.1280 - val_accuracy: 0.9590\n",
      "Epoch 381/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1856 - accuracy: 0.9541 - val_loss: 0.0992 - val_accuracy: 0.9705\n",
      "Epoch 382/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2052 - accuracy: 0.9498 - val_loss: 0.1454 - val_accuracy: 0.9435\n",
      "Epoch 383/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1809 - accuracy: 0.9682 - val_loss: 0.2146 - val_accuracy: 0.9317\n",
      "Epoch 384/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1920 - accuracy: 0.9516 - val_loss: 0.0868 - val_accuracy: 0.9728\n",
      "Epoch 385/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1506 - accuracy: 0.9676 - val_loss: 0.1119 - val_accuracy: 0.9632\n",
      "Epoch 386/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1536 - accuracy: 0.9655 - val_loss: 0.2818 - val_accuracy: 0.9273\n",
      "Epoch 387/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2196 - accuracy: 0.9591 - val_loss: 0.0694 - val_accuracy: 0.9780\n",
      "Epoch 388/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2467 - accuracy: 0.9417 - val_loss: 0.1124 - val_accuracy: 0.9653\n",
      "Epoch 389/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2571 - accuracy: 0.9524 - val_loss: 0.3189 - val_accuracy: 0.9035\n",
      "Epoch 390/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2215 - accuracy: 0.9489 - val_loss: 0.1419 - val_accuracy: 0.9570\n",
      "Epoch 391/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2546 - accuracy: 0.9466 - val_loss: 0.1556 - val_accuracy: 0.9427\n",
      "Epoch 392/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1873 - accuracy: 0.9647 - val_loss: 0.1221 - val_accuracy: 0.9607\n",
      "Epoch 393/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1329 - accuracy: 0.9701 - val_loss: 0.0673 - val_accuracy: 0.9797\n",
      "Epoch 394/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1275 - accuracy: 0.9739 - val_loss: 0.1010 - val_accuracy: 0.9665\n",
      "Epoch 395/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1040 - accuracy: 0.9766 - val_loss: 0.0699 - val_accuracy: 0.9780\n",
      "Epoch 396/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0993 - accuracy: 0.9776 - val_loss: 0.0799 - val_accuracy: 0.9737\n",
      "Epoch 397/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1002 - accuracy: 0.9730 - val_loss: 0.0939 - val_accuracy: 0.9670\n",
      "Epoch 398/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0961 - accuracy: 0.9779 - val_loss: 0.0720 - val_accuracy: 0.9768\n",
      "Epoch 399/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0914 - accuracy: 0.9809 - val_loss: 0.0760 - val_accuracy: 0.9765\n",
      "Epoch 400/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0860 - accuracy: 0.9785 - val_loss: 0.0730 - val_accuracy: 0.9780\n",
      "Epoch 401/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0862 - accuracy: 0.9824 - val_loss: 0.0969 - val_accuracy: 0.9690\n",
      "Epoch 402/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0870 - accuracy: 0.9759 - val_loss: 0.0616 - val_accuracy: 0.9830\n",
      "Epoch 403/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0775 - accuracy: 0.9817 - val_loss: 0.0780 - val_accuracy: 0.9745\n",
      "Epoch 404/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0757 - accuracy: 0.9826 - val_loss: 0.0665 - val_accuracy: 0.9810\n",
      "Epoch 405/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0844 - accuracy: 0.9774 - val_loss: 0.0811 - val_accuracy: 0.9718\n",
      "Epoch 406/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0781 - accuracy: 0.9823 - val_loss: 0.0808 - val_accuracy: 0.9743\n",
      "Epoch 407/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0764 - accuracy: 0.9783 - val_loss: 0.0630 - val_accuracy: 0.9812\n",
      "Epoch 408/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0737 - accuracy: 0.9830 - val_loss: 0.0882 - val_accuracy: 0.9718\n",
      "Epoch 409/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0781 - accuracy: 0.9820 - val_loss: 0.0638 - val_accuracy: 0.9827\n",
      "Epoch 410/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0814 - accuracy: 0.9748 - val_loss: 0.0640 - val_accuracy: 0.9820\n",
      "Epoch 411/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0873 - accuracy: 0.9790 - val_loss: 0.0733 - val_accuracy: 0.9795\n",
      "Epoch 412/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0825 - accuracy: 0.9826 - val_loss: 0.0797 - val_accuracy: 0.9745\n",
      "Epoch 413/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0821 - accuracy: 0.9806 - val_loss: 0.0779 - val_accuracy: 0.9762\n",
      "Epoch 414/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0705 - accuracy: 0.9831 - val_loss: 0.0632 - val_accuracy: 0.9835\n",
      "Epoch 415/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0762 - accuracy: 0.9847 - val_loss: 0.0943 - val_accuracy: 0.9663\n",
      "Epoch 416/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0963 - accuracy: 0.9746 - val_loss: 0.0813 - val_accuracy: 0.9740\n",
      "Epoch 417/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0946 - accuracy: 0.9737 - val_loss: 0.0728 - val_accuracy: 0.9803\n",
      "Epoch 418/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1013 - accuracy: 0.9728 - val_loss: 0.0768 - val_accuracy: 0.9755\n",
      "Epoch 419/1000\n",
      "16000/16000 [==============================] - 0s 6us/step - loss: 0.0807 - accuracy: 0.9814 - val_loss: 0.0703 - val_accuracy: 0.9797\n",
      "Epoch 420/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.0792 - accuracy: 0.9835 - val_loss: 0.0902 - val_accuracy: 0.9712\n",
      "Epoch 421/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0792 - accuracy: 0.9764 - val_loss: 0.0585 - val_accuracy: 0.9850\n",
      "Epoch 422/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0779 - accuracy: 0.9835 - val_loss: 0.0873 - val_accuracy: 0.9722\n",
      "Epoch 423/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0747 - accuracy: 0.9808 - val_loss: 0.0687 - val_accuracy: 0.9803\n",
      "Epoch 424/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0991 - accuracy: 0.9796 - val_loss: 0.0719 - val_accuracy: 0.9758\n",
      "Epoch 425/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0895 - accuracy: 0.9773 - val_loss: 0.0734 - val_accuracy: 0.9795\n",
      "Epoch 426/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0714 - accuracy: 0.9809 - val_loss: 0.0687 - val_accuracy: 0.9803\n",
      "Epoch 427/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0695 - accuracy: 0.9823 - val_loss: 0.0828 - val_accuracy: 0.9753\n",
      "Epoch 428/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0663 - accuracy: 0.9839 - val_loss: 0.0706 - val_accuracy: 0.9803\n",
      "Epoch 429/1000\n",
      "16000/16000 [==============================] - 0s 7us/step - loss: 0.0632 - accuracy: 0.9824 - val_loss: 0.0639 - val_accuracy: 0.9840\n",
      "Epoch 430/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.0614 - accuracy: 0.9852 - val_loss: 0.0632 - val_accuracy: 0.9837\n",
      "Epoch 431/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0589 - accuracy: 0.9868 - val_loss: 0.0683 - val_accuracy: 0.9815\n",
      "Epoch 432/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0643 - accuracy: 0.9836 - val_loss: 0.0830 - val_accuracy: 0.9735\n",
      "Epoch 433/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0653 - accuracy: 0.9824 - val_loss: 0.0647 - val_accuracy: 0.9825\n",
      "Epoch 434/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0627 - accuracy: 0.9847 - val_loss: 0.0709 - val_accuracy: 0.9800\n",
      "Epoch 435/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0585 - accuracy: 0.9851 - val_loss: 0.0674 - val_accuracy: 0.9820\n",
      "Epoch 436/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0626 - accuracy: 0.9862 - val_loss: 0.0902 - val_accuracy: 0.9703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 437/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0923 - accuracy: 0.9754 - val_loss: 0.0866 - val_accuracy: 0.9722\n",
      "Epoch 438/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0898 - accuracy: 0.9818 - val_loss: 0.1047 - val_accuracy: 0.9655\n",
      "Epoch 439/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1037 - accuracy: 0.9730 - val_loss: 0.0792 - val_accuracy: 0.9778\n",
      "Epoch 440/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1137 - accuracy: 0.9750 - val_loss: 0.1562 - val_accuracy: 0.9550\n",
      "Epoch 441/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1311 - accuracy: 0.9693 - val_loss: 0.1295 - val_accuracy: 0.9600\n",
      "Epoch 442/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1072 - accuracy: 0.9736 - val_loss: 0.0832 - val_accuracy: 0.9762\n",
      "Epoch 443/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1788 - accuracy: 0.9626 - val_loss: 0.3263 - val_accuracy: 0.9230\n",
      "Epoch 444/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2070 - accuracy: 0.9589 - val_loss: 0.2230 - val_accuracy: 0.9630\n",
      "Epoch 445/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2258 - accuracy: 0.9657 - val_loss: 0.1177 - val_accuracy: 0.9655\n",
      "Epoch 446/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1744 - accuracy: 0.9569 - val_loss: 0.4184 - val_accuracy: 0.9212\n",
      "Epoch 447/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4333 - accuracy: 0.9211 - val_loss: 0.4914 - val_accuracy: 0.8680\n",
      "Epoch 448/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5461 - accuracy: 0.9202 - val_loss: 0.2368 - val_accuracy: 0.9323\n",
      "Epoch 449/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3110 - accuracy: 0.9364 - val_loss: 0.2254 - val_accuracy: 0.9355\n",
      "Epoch 450/1000\n",
      "16000/16000 [==============================] - 0s 5us/step - loss: 0.2594 - accuracy: 0.9479 - val_loss: 0.1096 - val_accuracy: 0.9638\n",
      "Epoch 451/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1639 - accuracy: 0.9621 - val_loss: 0.1075 - val_accuracy: 0.9645\n",
      "Epoch 452/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1385 - accuracy: 0.9703 - val_loss: 0.1470 - val_accuracy: 0.9530\n",
      "Epoch 453/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2084 - accuracy: 0.9554 - val_loss: 0.3412 - val_accuracy: 0.9230\n",
      "Epoch 454/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2509 - accuracy: 0.9579 - val_loss: 0.0733 - val_accuracy: 0.9755\n",
      "Epoch 455/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1633 - accuracy: 0.9613 - val_loss: 0.1069 - val_accuracy: 0.9640\n",
      "Epoch 456/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1237 - accuracy: 0.9675 - val_loss: 0.0892 - val_accuracy: 0.9665\n",
      "Epoch 457/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1075 - accuracy: 0.9721 - val_loss: 0.0848 - val_accuracy: 0.9718\n",
      "Epoch 458/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0899 - accuracy: 0.9788 - val_loss: 0.0709 - val_accuracy: 0.9758\n",
      "Epoch 459/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0971 - accuracy: 0.9759 - val_loss: 0.1039 - val_accuracy: 0.9670\n",
      "Epoch 460/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0882 - accuracy: 0.9795 - val_loss: 0.0688 - val_accuracy: 0.9780\n",
      "Epoch 461/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0835 - accuracy: 0.9801 - val_loss: 0.0739 - val_accuracy: 0.9768\n",
      "Epoch 462/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0874 - accuracy: 0.9821 - val_loss: 0.0781 - val_accuracy: 0.9750\n",
      "Epoch 463/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1026 - accuracy: 0.9667 - val_loss: 0.0705 - val_accuracy: 0.9780\n",
      "Epoch 464/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0966 - accuracy: 0.9778 - val_loss: 0.0877 - val_accuracy: 0.9720\n",
      "Epoch 465/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0894 - accuracy: 0.9809 - val_loss: 0.0782 - val_accuracy: 0.9740\n",
      "Epoch 466/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.0879 - accuracy: 0.9774 - val_loss: 0.0901 - val_accuracy: 0.9718\n",
      "Epoch 467/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0806 - accuracy: 0.9794 - val_loss: 0.0611 - val_accuracy: 0.9840\n",
      "Epoch 468/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.0747 - accuracy: 0.9825 - val_loss: 0.0775 - val_accuracy: 0.9762\n",
      "Epoch 469/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.0696 - accuracy: 0.9831 - val_loss: 0.0700 - val_accuracy: 0.9803\n",
      "Epoch 470/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0696 - accuracy: 0.9819 - val_loss: 0.0720 - val_accuracy: 0.9797\n",
      "Epoch 471/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0796 - accuracy: 0.9792 - val_loss: 0.0649 - val_accuracy: 0.9818\n",
      "Epoch 472/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0986 - accuracy: 0.9741 - val_loss: 0.1103 - val_accuracy: 0.9632\n",
      "Epoch 473/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.1122 - accuracy: 0.9770 - val_loss: 0.1100 - val_accuracy: 0.9645\n",
      "Epoch 474/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0942 - accuracy: 0.9784 - val_loss: 0.0927 - val_accuracy: 0.9722\n",
      "Epoch 475/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0864 - accuracy: 0.9799 - val_loss: 0.0702 - val_accuracy: 0.9825\n",
      "Epoch 476/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.0847 - accuracy: 0.9786 - val_loss: 0.0911 - val_accuracy: 0.9707\n",
      "Epoch 477/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0999 - accuracy: 0.9771 - val_loss: 0.1445 - val_accuracy: 0.9565\n",
      "Epoch 478/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1004 - accuracy: 0.9742 - val_loss: 0.0588 - val_accuracy: 0.9843\n",
      "Epoch 479/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0888 - accuracy: 0.9821 - val_loss: 0.0906 - val_accuracy: 0.9747\n",
      "Epoch 480/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0782 - accuracy: 0.9816 - val_loss: 0.0674 - val_accuracy: 0.9833\n",
      "Epoch 481/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0679 - accuracy: 0.9862 - val_loss: 0.0756 - val_accuracy: 0.9800\n",
      "Epoch 482/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0661 - accuracy: 0.9835 - val_loss: 0.0628 - val_accuracy: 0.9843\n",
      "Epoch 483/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0654 - accuracy: 0.9847 - val_loss: 0.0776 - val_accuracy: 0.9775\n",
      "Epoch 484/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0637 - accuracy: 0.9864 - val_loss: 0.0634 - val_accuracy: 0.9840\n",
      "Epoch 485/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0601 - accuracy: 0.9832 - val_loss: 0.0696 - val_accuracy: 0.9805\n",
      "Epoch 486/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0570 - accuracy: 0.9874 - val_loss: 0.0724 - val_accuracy: 0.9810\n",
      "Epoch 487/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0567 - accuracy: 0.9844 - val_loss: 0.0624 - val_accuracy: 0.9852\n",
      "Epoch 488/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0564 - accuracy: 0.9851 - val_loss: 0.0680 - val_accuracy: 0.9825\n",
      "Epoch 489/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0578 - accuracy: 0.9877 - val_loss: 0.0637 - val_accuracy: 0.9847\n",
      "Epoch 490/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0677 - accuracy: 0.9821 - val_loss: 0.0692 - val_accuracy: 0.9830\n",
      "Epoch 491/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0583 - accuracy: 0.9856 - val_loss: 0.0737 - val_accuracy: 0.9800\n",
      "Epoch 492/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0556 - accuracy: 0.9878 - val_loss: 0.0648 - val_accuracy: 0.9837\n",
      "Epoch 493/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0525 - accuracy: 0.9852 - val_loss: 0.0636 - val_accuracy: 0.9852\n",
      "Epoch 494/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0625 - accuracy: 0.9851 - val_loss: 0.0826 - val_accuracy: 0.9770\n",
      "Epoch 495/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0569 - accuracy: 0.9869 - val_loss: 0.0660 - val_accuracy: 0.9835\n",
      "Epoch 496/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0526 - accuracy: 0.9861 - val_loss: 0.0649 - val_accuracy: 0.9847\n",
      "Epoch 497/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0568 - accuracy: 0.9858 - val_loss: 0.0789 - val_accuracy: 0.9775\n",
      "Epoch 498/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0560 - accuracy: 0.9871 - val_loss: 0.0665 - val_accuracy: 0.9843\n",
      "Epoch 499/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0519 - accuracy: 0.9847 - val_loss: 0.0595 - val_accuracy: 0.9860\n",
      "Epoch 500/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0987 - accuracy: 0.9774 - val_loss: 0.1502 - val_accuracy: 0.9553\n",
      "Epoch 501/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1242 - accuracy: 0.9764 - val_loss: 0.1532 - val_accuracy: 0.9448\n",
      "Epoch 502/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1059 - accuracy: 0.9709 - val_loss: 0.0661 - val_accuracy: 0.9833\n",
      "Epoch 503/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1147 - accuracy: 0.9717 - val_loss: 0.0772 - val_accuracy: 0.9797\n",
      "Epoch 504/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0714 - accuracy: 0.9837 - val_loss: 0.0733 - val_accuracy: 0.9820\n",
      "Epoch 505/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0832 - accuracy: 0.9834 - val_loss: 0.1032 - val_accuracy: 0.9705\n",
      "Epoch 506/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0744 - accuracy: 0.9827 - val_loss: 0.0617 - val_accuracy: 0.9860\n",
      "Epoch 507/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0735 - accuracy: 0.9816 - val_loss: 0.0829 - val_accuracy: 0.9760\n",
      "Epoch 508/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0752 - accuracy: 0.9829 - val_loss: 0.0891 - val_accuracy: 0.9743\n",
      "Epoch 509/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0777 - accuracy: 0.9792 - val_loss: 0.0789 - val_accuracy: 0.9787\n",
      "Epoch 510/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0741 - accuracy: 0.9818 - val_loss: 0.0808 - val_accuracy: 0.9770\n",
      "Epoch 511/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0636 - accuracy: 0.9864 - val_loss: 0.0692 - val_accuracy: 0.9822\n",
      "Epoch 512/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0619 - accuracy: 0.9842 - val_loss: 0.0619 - val_accuracy: 0.9845\n",
      "Epoch 513/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0590 - accuracy: 0.9852 - val_loss: 0.0727 - val_accuracy: 0.9812\n",
      "Epoch 514/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0603 - accuracy: 0.9893 - val_loss: 0.0785 - val_accuracy: 0.9778\n",
      "Epoch 515/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0794 - accuracy: 0.9759 - val_loss: 0.0618 - val_accuracy: 0.9860\n",
      "Epoch 516/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0688 - accuracy: 0.9866 - val_loss: 0.0764 - val_accuracy: 0.9805\n",
      "Epoch 517/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0630 - accuracy: 0.9852 - val_loss: 0.0746 - val_accuracy: 0.9800\n",
      "Epoch 518/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0564 - accuracy: 0.9866 - val_loss: 0.0748 - val_accuracy: 0.9815\n",
      "Epoch 519/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0541 - accuracy: 0.9861 - val_loss: 0.0686 - val_accuracy: 0.9843\n",
      "Epoch 520/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0518 - accuracy: 0.9883 - val_loss: 0.0714 - val_accuracy: 0.9833\n",
      "Epoch 521/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0464 - accuracy: 0.9881 - val_loss: 0.0649 - val_accuracy: 0.9855\n",
      "Epoch 522/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0502 - accuracy: 0.9868 - val_loss: 0.0674 - val_accuracy: 0.9855\n",
      "Epoch 523/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0550 - accuracy: 0.9869 - val_loss: 0.0838 - val_accuracy: 0.9753\n",
      "Epoch 524/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0568 - accuracy: 0.9872 - val_loss: 0.0705 - val_accuracy: 0.9808\n",
      "Epoch 525/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0514 - accuracy: 0.9855 - val_loss: 0.0614 - val_accuracy: 0.9858\n",
      "Epoch 526/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0481 - accuracy: 0.9892 - val_loss: 0.0721 - val_accuracy: 0.9822\n",
      "Epoch 527/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0482 - accuracy: 0.9879 - val_loss: 0.0694 - val_accuracy: 0.9835\n",
      "Epoch 528/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0497 - accuracy: 0.9862 - val_loss: 0.0640 - val_accuracy: 0.9862\n",
      "Epoch 529/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0520 - accuracy: 0.9864 - val_loss: 0.0806 - val_accuracy: 0.9775\n",
      "Epoch 530/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0581 - accuracy: 0.9883 - val_loss: 0.0745 - val_accuracy: 0.9803\n",
      "Epoch 531/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0763 - accuracy: 0.9803 - val_loss: 0.0680 - val_accuracy: 0.9847\n",
      "Epoch 532/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0521 - accuracy: 0.9865 - val_loss: 0.0703 - val_accuracy: 0.9837\n",
      "Epoch 533/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0574 - accuracy: 0.9858 - val_loss: 0.0720 - val_accuracy: 0.9820\n",
      "Epoch 534/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0511 - accuracy: 0.9863 - val_loss: 0.0692 - val_accuracy: 0.9833\n",
      "Epoch 535/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0502 - accuracy: 0.9874 - val_loss: 0.0744 - val_accuracy: 0.9822\n",
      "Epoch 536/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0497 - accuracy: 0.9888 - val_loss: 0.0677 - val_accuracy: 0.9840\n",
      "Epoch 537/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0470 - accuracy: 0.9883 - val_loss: 0.0778 - val_accuracy: 0.9783\n",
      "Epoch 538/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0471 - accuracy: 0.9878 - val_loss: 0.0638 - val_accuracy: 0.9858\n",
      "Epoch 539/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0437 - accuracy: 0.9899 - val_loss: 0.0668 - val_accuracy: 0.9855\n",
      "Epoch 540/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0452 - accuracy: 0.9901 - val_loss: 0.0739 - val_accuracy: 0.9818\n",
      "Epoch 541/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0473 - accuracy: 0.9881 - val_loss: 0.0683 - val_accuracy: 0.9852\n",
      "Epoch 542/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0452 - accuracy: 0.9899 - val_loss: 0.0682 - val_accuracy: 0.9845\n",
      "Epoch 543/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0458 - accuracy: 0.9882 - val_loss: 0.0666 - val_accuracy: 0.9855\n",
      "Epoch 544/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0438 - accuracy: 0.9886 - val_loss: 0.0691 - val_accuracy: 0.9843\n",
      "Epoch 545/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0421 - accuracy: 0.9906 - val_loss: 0.0715 - val_accuracy: 0.9835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 546/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0434 - accuracy: 0.9896 - val_loss: 0.0648 - val_accuracy: 0.9865\n",
      "Epoch 547/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0409 - accuracy: 0.9905 - val_loss: 0.0705 - val_accuracy: 0.9835\n",
      "Epoch 548/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0393 - accuracy: 0.9899 - val_loss: 0.0626 - val_accuracy: 0.9872\n",
      "Epoch 549/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0466 - accuracy: 0.9890 - val_loss: 0.0782 - val_accuracy: 0.9800\n",
      "Epoch 550/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0494 - accuracy: 0.9889 - val_loss: 0.0796 - val_accuracy: 0.9790\n",
      "Epoch 551/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0466 - accuracy: 0.9889 - val_loss: 0.0698 - val_accuracy: 0.9847\n",
      "Epoch 552/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0473 - accuracy: 0.9876 - val_loss: 0.0673 - val_accuracy: 0.9850\n",
      "Epoch 553/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0407 - accuracy: 0.9889 - val_loss: 0.0646 - val_accuracy: 0.9845\n",
      "Epoch 554/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0590 - accuracy: 0.9851 - val_loss: 0.0750 - val_accuracy: 0.9808\n",
      "Epoch 555/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0866 - accuracy: 0.9801 - val_loss: 0.1065 - val_accuracy: 0.9682\n",
      "Epoch 556/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1817 - accuracy: 0.9657 - val_loss: 0.3878 - val_accuracy: 0.9128\n",
      "Epoch 557/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3225 - accuracy: 0.9490 - val_loss: 0.1724 - val_accuracy: 0.9488\n",
      "Epoch 558/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2060 - accuracy: 0.9575 - val_loss: 0.2019 - val_accuracy: 0.9477\n",
      "Epoch 559/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2726 - accuracy: 0.9431 - val_loss: 0.1292 - val_accuracy: 0.9688\n",
      "Epoch 560/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.5236 - accuracy: 0.9224 - val_loss: 0.1440 - val_accuracy: 0.9542\n",
      "Epoch 561/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3284 - accuracy: 0.9334 - val_loss: 0.1883 - val_accuracy: 0.9348\n",
      "Epoch 562/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1902 - accuracy: 0.9604 - val_loss: 0.1457 - val_accuracy: 0.9530\n",
      "Epoch 563/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1619 - accuracy: 0.9601 - val_loss: 0.0760 - val_accuracy: 0.9755\n",
      "Epoch 564/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1302 - accuracy: 0.9644 - val_loss: 0.0848 - val_accuracy: 0.9725\n",
      "Epoch 565/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1042 - accuracy: 0.9784 - val_loss: 0.0977 - val_accuracy: 0.9670\n",
      "Epoch 566/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1134 - accuracy: 0.9741 - val_loss: 0.0739 - val_accuracy: 0.9768\n",
      "Epoch 567/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1160 - accuracy: 0.9698 - val_loss: 0.0725 - val_accuracy: 0.9790\n",
      "Epoch 568/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1279 - accuracy: 0.9696 - val_loss: 0.1433 - val_accuracy: 0.9592\n",
      "Epoch 569/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1696 - accuracy: 0.9603 - val_loss: 0.1892 - val_accuracy: 0.9400\n",
      "Epoch 570/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1759 - accuracy: 0.9659 - val_loss: 0.1312 - val_accuracy: 0.9603\n",
      "Epoch 571/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1362 - accuracy: 0.9669 - val_loss: 0.0938 - val_accuracy: 0.9740\n",
      "Epoch 572/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1179 - accuracy: 0.9746 - val_loss: 0.0970 - val_accuracy: 0.9697\n",
      "Epoch 573/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1193 - accuracy: 0.9732 - val_loss: 0.1107 - val_accuracy: 0.9657\n",
      "Epoch 574/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0992 - accuracy: 0.9760 - val_loss: 0.0913 - val_accuracy: 0.9768\n",
      "Epoch 575/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0971 - accuracy: 0.9761 - val_loss: 0.1029 - val_accuracy: 0.9732\n",
      "Epoch 576/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1067 - accuracy: 0.9787 - val_loss: 0.0939 - val_accuracy: 0.9720\n",
      "Epoch 577/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1401 - accuracy: 0.9681 - val_loss: 0.0989 - val_accuracy: 0.9720\n",
      "Epoch 578/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1229 - accuracy: 0.9720 - val_loss: 0.0840 - val_accuracy: 0.9783\n",
      "Epoch 579/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1023 - accuracy: 0.9743 - val_loss: 0.0812 - val_accuracy: 0.9768\n",
      "Epoch 580/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0858 - accuracy: 0.9803 - val_loss: 0.0801 - val_accuracy: 0.9765\n",
      "Epoch 581/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0892 - accuracy: 0.9801 - val_loss: 0.0899 - val_accuracy: 0.9747\n",
      "Epoch 582/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0780 - accuracy: 0.9814 - val_loss: 0.0702 - val_accuracy: 0.9847\n",
      "Epoch 583/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0692 - accuracy: 0.9831 - val_loss: 0.0835 - val_accuracy: 0.9760\n",
      "Epoch 584/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0668 - accuracy: 0.9851 - val_loss: 0.0739 - val_accuracy: 0.9808\n",
      "Epoch 585/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0635 - accuracy: 0.9814 - val_loss: 0.0649 - val_accuracy: 0.9837\n",
      "Epoch 586/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0639 - accuracy: 0.9860 - val_loss: 0.0923 - val_accuracy: 0.9725\n",
      "Epoch 587/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0672 - accuracy: 0.9839 - val_loss: 0.0713 - val_accuracy: 0.9827\n",
      "Epoch 588/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.0587 - accuracy: 0.9856 - val_loss: 0.0713 - val_accuracy: 0.9830\n",
      "Epoch 589/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0555 - accuracy: 0.9879 - val_loss: 0.0771 - val_accuracy: 0.9793\n",
      "Epoch 590/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0566 - accuracy: 0.9851 - val_loss: 0.0688 - val_accuracy: 0.9822\n",
      "Epoch 591/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0524 - accuracy: 0.9882 - val_loss: 0.0739 - val_accuracy: 0.9822\n",
      "Epoch 592/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0546 - accuracy: 0.9865 - val_loss: 0.0697 - val_accuracy: 0.9843\n",
      "Epoch 593/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0502 - accuracy: 0.9873 - val_loss: 0.0721 - val_accuracy: 0.9815\n",
      "Epoch 594/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0533 - accuracy: 0.9874 - val_loss: 0.0838 - val_accuracy: 0.9770\n",
      "Epoch 595/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0586 - accuracy: 0.9862 - val_loss: 0.0740 - val_accuracy: 0.9822\n",
      "Epoch 596/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0470 - accuracy: 0.9877 - val_loss: 0.0652 - val_accuracy: 0.9868\n",
      "Epoch 597/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0811 - accuracy: 0.9807 - val_loss: 0.1004 - val_accuracy: 0.9740\n",
      "Epoch 598/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1031 - accuracy: 0.9821 - val_loss: 0.1519 - val_accuracy: 0.9588\n",
      "Epoch 599/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1491 - accuracy: 0.9668 - val_loss: 0.0976 - val_accuracy: 0.9735\n",
      "Epoch 600/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1160 - accuracy: 0.9739 - val_loss: 0.0751 - val_accuracy: 0.9805\n",
      "Epoch 601/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1558 - accuracy: 0.9640 - val_loss: 0.1233 - val_accuracy: 0.9630\n",
      "Epoch 602/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1003 - accuracy: 0.9749 - val_loss: 0.0932 - val_accuracy: 0.9730\n",
      "Epoch 603/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1170 - accuracy: 0.9779 - val_loss: 0.1672 - val_accuracy: 0.9423\n",
      "Epoch 604/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1525 - accuracy: 0.9643 - val_loss: 0.0743 - val_accuracy: 0.9795\n",
      "Epoch 605/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1129 - accuracy: 0.9740 - val_loss: 0.1018 - val_accuracy: 0.9715\n",
      "Epoch 606/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1279 - accuracy: 0.9694 - val_loss: 0.0909 - val_accuracy: 0.9697\n",
      "Epoch 607/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1134 - accuracy: 0.9737 - val_loss: 0.0933 - val_accuracy: 0.9728\n",
      "Epoch 608/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0918 - accuracy: 0.9798 - val_loss: 0.0804 - val_accuracy: 0.9783\n",
      "Epoch 609/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0728 - accuracy: 0.9823 - val_loss: 0.0656 - val_accuracy: 0.9830\n",
      "Epoch 610/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0695 - accuracy: 0.9842 - val_loss: 0.0704 - val_accuracy: 0.9797\n",
      "Epoch 611/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0663 - accuracy: 0.9841 - val_loss: 0.0750 - val_accuracy: 0.9778\n",
      "Epoch 612/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0590 - accuracy: 0.9846 - val_loss: 0.0624 - val_accuracy: 0.9827\n",
      "Epoch 613/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0600 - accuracy: 0.9847 - val_loss: 0.0680 - val_accuracy: 0.9810\n",
      "Epoch 614/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0798 - accuracy: 0.9834 - val_loss: 0.1482 - val_accuracy: 0.9605\n",
      "Epoch 615/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1001 - accuracy: 0.9775 - val_loss: 0.0697 - val_accuracy: 0.9837\n",
      "Epoch 616/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0844 - accuracy: 0.9779 - val_loss: 0.0941 - val_accuracy: 0.9743\n",
      "Epoch 617/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0879 - accuracy: 0.9796 - val_loss: 0.0833 - val_accuracy: 0.9762\n",
      "Epoch 618/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0783 - accuracy: 0.9848 - val_loss: 0.0988 - val_accuracy: 0.9680\n",
      "Epoch 619/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0795 - accuracy: 0.9786 - val_loss: 0.0746 - val_accuracy: 0.9820\n",
      "Epoch 620/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0920 - accuracy: 0.9791 - val_loss: 0.1192 - val_accuracy: 0.9632\n",
      "Epoch 621/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1102 - accuracy: 0.9759 - val_loss: 0.0938 - val_accuracy: 0.9730\n",
      "Epoch 622/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0981 - accuracy: 0.9714 - val_loss: 0.0804 - val_accuracy: 0.9785\n",
      "Epoch 623/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0848 - accuracy: 0.9797 - val_loss: 0.0781 - val_accuracy: 0.9797\n",
      "Epoch 624/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0742 - accuracy: 0.9800 - val_loss: 0.0753 - val_accuracy: 0.9800\n",
      "Epoch 625/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0680 - accuracy: 0.9847 - val_loss: 0.0825 - val_accuracy: 0.9783\n",
      "Epoch 626/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0623 - accuracy: 0.9849 - val_loss: 0.0731 - val_accuracy: 0.9830\n",
      "Epoch 627/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0610 - accuracy: 0.9833 - val_loss: 0.0741 - val_accuracy: 0.9825\n",
      "Epoch 628/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0610 - accuracy: 0.9856 - val_loss: 0.0853 - val_accuracy: 0.9775\n",
      "Epoch 629/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0546 - accuracy: 0.9868 - val_loss: 0.0677 - val_accuracy: 0.9852\n",
      "Epoch 630/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0497 - accuracy: 0.9888 - val_loss: 0.0757 - val_accuracy: 0.9825\n",
      "Epoch 631/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0592 - accuracy: 0.9892 - val_loss: 0.0946 - val_accuracy: 0.9728\n",
      "Epoch 632/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0845 - accuracy: 0.9719 - val_loss: 0.0674 - val_accuracy: 0.9855\n",
      "Epoch 633/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0715 - accuracy: 0.9818 - val_loss: 0.0817 - val_accuracy: 0.9818\n",
      "Epoch 634/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0727 - accuracy: 0.9837 - val_loss: 0.0813 - val_accuracy: 0.9793\n",
      "Epoch 635/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0581 - accuracy: 0.9868 - val_loss: 0.0710 - val_accuracy: 0.9825\n",
      "Epoch 636/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0536 - accuracy: 0.9869 - val_loss: 0.0754 - val_accuracy: 0.9825\n",
      "Epoch 637/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0501 - accuracy: 0.9871 - val_loss: 0.0703 - val_accuracy: 0.9860\n",
      "Epoch 638/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0473 - accuracy: 0.9902 - val_loss: 0.0745 - val_accuracy: 0.9833\n",
      "Epoch 639/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0487 - accuracy: 0.9883 - val_loss: 0.0722 - val_accuracy: 0.9843\n",
      "Epoch 640/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0465 - accuracy: 0.9881 - val_loss: 0.0718 - val_accuracy: 0.9847\n",
      "Epoch 641/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0504 - accuracy: 0.9921 - val_loss: 0.0751 - val_accuracy: 0.9833\n",
      "Epoch 642/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0536 - accuracy: 0.9851 - val_loss: 0.0717 - val_accuracy: 0.9837\n",
      "Epoch 643/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0495 - accuracy: 0.9899 - val_loss: 0.0738 - val_accuracy: 0.9825\n",
      "Epoch 644/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0463 - accuracy: 0.9884 - val_loss: 0.0779 - val_accuracy: 0.9812\n",
      "Epoch 645/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0441 - accuracy: 0.9877 - val_loss: 0.0699 - val_accuracy: 0.9850\n",
      "Epoch 646/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0385 - accuracy: 0.9914 - val_loss: 0.0684 - val_accuracy: 0.9845\n",
      "Epoch 647/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0379 - accuracy: 0.9916 - val_loss: 0.0689 - val_accuracy: 0.9855\n",
      "Epoch 648/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0367 - accuracy: 0.9911 - val_loss: 0.0664 - val_accuracy: 0.9875\n",
      "Epoch 649/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0364 - accuracy: 0.9926 - val_loss: 0.0758 - val_accuracy: 0.9830\n",
      "Epoch 650/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0404 - accuracy: 0.9898 - val_loss: 0.0661 - val_accuracy: 0.9877\n",
      "Epoch 651/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0387 - accuracy: 0.9904 - val_loss: 0.0686 - val_accuracy: 0.9852\n",
      "Epoch 652/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0355 - accuracy: 0.9918 - val_loss: 0.0707 - val_accuracy: 0.9840\n",
      "Epoch 653/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0382 - accuracy: 0.9906 - val_loss: 0.0781 - val_accuracy: 0.9815\n",
      "Epoch 654/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0383 - accuracy: 0.9895 - val_loss: 0.0635 - val_accuracy: 0.9898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 655/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0774 - accuracy: 0.9807 - val_loss: 0.0942 - val_accuracy: 0.9768\n",
      "Epoch 656/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0744 - accuracy: 0.9836 - val_loss: 0.0896 - val_accuracy: 0.9753\n",
      "Epoch 657/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0635 - accuracy: 0.9862 - val_loss: 0.0922 - val_accuracy: 0.9750\n",
      "Epoch 658/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0623 - accuracy: 0.9834 - val_loss: 0.0702 - val_accuracy: 0.9855\n",
      "Epoch 659/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0608 - accuracy: 0.9846 - val_loss: 0.0885 - val_accuracy: 0.9805\n",
      "Epoch 660/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0529 - accuracy: 0.9891 - val_loss: 0.0668 - val_accuracy: 0.9852\n",
      "Epoch 661/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0609 - accuracy: 0.9854 - val_loss: 0.0692 - val_accuracy: 0.9835\n",
      "Epoch 662/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0497 - accuracy: 0.9886 - val_loss: 0.0706 - val_accuracy: 0.9862\n",
      "Epoch 663/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0544 - accuracy: 0.9873 - val_loss: 0.0644 - val_accuracy: 0.9872\n",
      "Epoch 664/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0519 - accuracy: 0.9869 - val_loss: 0.0692 - val_accuracy: 0.9845\n",
      "Epoch 665/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0447 - accuracy: 0.9896 - val_loss: 0.0668 - val_accuracy: 0.9845\n",
      "Epoch 666/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0398 - accuracy: 0.9915 - val_loss: 0.0669 - val_accuracy: 0.9855\n",
      "Epoch 667/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0402 - accuracy: 0.9910 - val_loss: 0.0708 - val_accuracy: 0.9837\n",
      "Epoch 668/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0384 - accuracy: 0.9890 - val_loss: 0.0663 - val_accuracy: 0.9870\n",
      "Epoch 669/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0360 - accuracy: 0.9920 - val_loss: 0.0759 - val_accuracy: 0.9833\n",
      "Epoch 670/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0445 - accuracy: 0.9886 - val_loss: 0.0721 - val_accuracy: 0.9840\n",
      "Epoch 671/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0389 - accuracy: 0.9911 - val_loss: 0.0689 - val_accuracy: 0.9847\n",
      "Epoch 672/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0390 - accuracy: 0.9909 - val_loss: 0.0696 - val_accuracy: 0.9870\n",
      "Epoch 673/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0430 - accuracy: 0.9892 - val_loss: 0.0739 - val_accuracy: 0.9815\n",
      "Epoch 674/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0437 - accuracy: 0.9898 - val_loss: 0.0655 - val_accuracy: 0.9855\n",
      "Epoch 675/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0476 - accuracy: 0.9882 - val_loss: 0.0731 - val_accuracy: 0.9812\n",
      "Epoch 676/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0402 - accuracy: 0.9906 - val_loss: 0.0694 - val_accuracy: 0.9850\n",
      "Epoch 677/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0379 - accuracy: 0.9922 - val_loss: 0.0749 - val_accuracy: 0.9833\n",
      "Epoch 678/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0391 - accuracy: 0.9891 - val_loss: 0.0736 - val_accuracy: 0.9827\n",
      "Epoch 679/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0361 - accuracy: 0.9916 - val_loss: 0.0674 - val_accuracy: 0.9845\n",
      "Epoch 680/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0341 - accuracy: 0.9911 - val_loss: 0.0668 - val_accuracy: 0.9862\n",
      "Epoch 681/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0333 - accuracy: 0.9927 - val_loss: 0.0707 - val_accuracy: 0.9860\n",
      "Epoch 682/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0321 - accuracy: 0.9921 - val_loss: 0.0647 - val_accuracy: 0.9875\n",
      "Epoch 683/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0325 - accuracy: 0.9917 - val_loss: 0.0690 - val_accuracy: 0.9860\n",
      "Epoch 684/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0319 - accuracy: 0.9929 - val_loss: 0.0690 - val_accuracy: 0.9855\n",
      "Epoch 685/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0291 - accuracy: 0.9929 - val_loss: 0.0651 - val_accuracy: 0.9875\n",
      "Epoch 686/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0299 - accuracy: 0.9934 - val_loss: 0.0691 - val_accuracy: 0.9865\n",
      "Epoch 687/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0290 - accuracy: 0.9933 - val_loss: 0.0684 - val_accuracy: 0.9868\n",
      "Epoch 688/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0288 - accuracy: 0.9923 - val_loss: 0.0674 - val_accuracy: 0.9875\n",
      "Epoch 689/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0290 - accuracy: 0.9939 - val_loss: 0.0740 - val_accuracy: 0.9850\n",
      "Epoch 690/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0355 - accuracy: 0.9918 - val_loss: 0.0769 - val_accuracy: 0.9830\n",
      "Epoch 691/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0429 - accuracy: 0.9874 - val_loss: 0.0659 - val_accuracy: 0.9870\n",
      "Epoch 692/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0468 - accuracy: 0.9871 - val_loss: 0.0773 - val_accuracy: 0.9833\n",
      "Epoch 693/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0448 - accuracy: 0.9904 - val_loss: 0.0739 - val_accuracy: 0.9843\n",
      "Epoch 694/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0491 - accuracy: 0.9891 - val_loss: 0.0737 - val_accuracy: 0.9835\n",
      "Epoch 695/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0430 - accuracy: 0.9891 - val_loss: 0.0770 - val_accuracy: 0.9833\n",
      "Epoch 696/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0453 - accuracy: 0.9898 - val_loss: 0.0826 - val_accuracy: 0.9810\n",
      "Epoch 697/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0570 - accuracy: 0.9851 - val_loss: 0.0842 - val_accuracy: 0.9803\n",
      "Epoch 698/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0680 - accuracy: 0.9830 - val_loss: 0.0748 - val_accuracy: 0.9850\n",
      "Epoch 699/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0911 - accuracy: 0.9768 - val_loss: 0.0857 - val_accuracy: 0.9795\n",
      "Epoch 700/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0971 - accuracy: 0.9744 - val_loss: 0.0871 - val_accuracy: 0.9762\n",
      "Epoch 701/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0775 - accuracy: 0.9854 - val_loss: 0.1171 - val_accuracy: 0.9672\n",
      "Epoch 702/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0963 - accuracy: 0.9785 - val_loss: 0.0821 - val_accuracy: 0.9810\n",
      "Epoch 703/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0890 - accuracy: 0.9803 - val_loss: 0.1227 - val_accuracy: 0.9655\n",
      "Epoch 704/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0850 - accuracy: 0.9795 - val_loss: 0.0970 - val_accuracy: 0.9697\n",
      "Epoch 705/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0666 - accuracy: 0.9818 - val_loss: 0.0677 - val_accuracy: 0.9845\n",
      "Epoch 706/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0716 - accuracy: 0.9812 - val_loss: 0.0789 - val_accuracy: 0.9810\n",
      "Epoch 707/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0726 - accuracy: 0.9813 - val_loss: 0.0874 - val_accuracy: 0.9770\n",
      "Epoch 708/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0625 - accuracy: 0.9876 - val_loss: 0.0817 - val_accuracy: 0.9800\n",
      "Epoch 709/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0606 - accuracy: 0.9858 - val_loss: 0.0828 - val_accuracy: 0.9797\n",
      "Epoch 710/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0717 - accuracy: 0.9793 - val_loss: 0.0950 - val_accuracy: 0.9775\n",
      "Epoch 711/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0847 - accuracy: 0.9809 - val_loss: 0.0931 - val_accuracy: 0.9735\n",
      "Epoch 712/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0884 - accuracy: 0.9803 - val_loss: 0.1053 - val_accuracy: 0.9753\n",
      "Epoch 713/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0935 - accuracy: 0.9819 - val_loss: 0.1072 - val_accuracy: 0.9712\n",
      "Epoch 714/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2678 - accuracy: 0.9571 - val_loss: 0.3085 - val_accuracy: 0.9402\n",
      "Epoch 715/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3744 - accuracy: 0.9393 - val_loss: 0.1786 - val_accuracy: 0.9560\n",
      "Epoch 716/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3379 - accuracy: 0.9409 - val_loss: 0.2074 - val_accuracy: 0.9492\n",
      "Epoch 717/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2952 - accuracy: 0.9478 - val_loss: 0.1394 - val_accuracy: 0.9580\n",
      "Epoch 718/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2241 - accuracy: 0.9542 - val_loss: 0.1403 - val_accuracy: 0.9567\n",
      "Epoch 719/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2105 - accuracy: 0.9494 - val_loss: 0.1244 - val_accuracy: 0.9653\n",
      "Epoch 720/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2374 - accuracy: 0.9554 - val_loss: 0.2291 - val_accuracy: 0.9295\n",
      "Epoch 721/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1391 - accuracy: 0.9686 - val_loss: 0.1132 - val_accuracy: 0.9720\n",
      "Epoch 722/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1674 - accuracy: 0.9668 - val_loss: 0.1043 - val_accuracy: 0.9753\n",
      "Epoch 723/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1142 - accuracy: 0.9752 - val_loss: 0.1041 - val_accuracy: 0.9735\n",
      "Epoch 724/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1032 - accuracy: 0.9749 - val_loss: 0.1474 - val_accuracy: 0.9565\n",
      "Epoch 725/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1239 - accuracy: 0.9751 - val_loss: 0.1121 - val_accuracy: 0.9685\n",
      "Epoch 726/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1035 - accuracy: 0.9682 - val_loss: 0.0715 - val_accuracy: 0.9840\n",
      "Epoch 727/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1456 - accuracy: 0.9666 - val_loss: 0.1205 - val_accuracy: 0.9655\n",
      "Epoch 728/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1962 - accuracy: 0.9652 - val_loss: 0.3746 - val_accuracy: 0.8875\n",
      "Epoch 729/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3057 - accuracy: 0.9479 - val_loss: 0.3809 - val_accuracy: 0.9410\n",
      "Epoch 730/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2433 - accuracy: 0.9631 - val_loss: 0.1124 - val_accuracy: 0.9663\n",
      "Epoch 731/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1869 - accuracy: 0.9681 - val_loss: 0.1344 - val_accuracy: 0.9572\n",
      "Epoch 732/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1649 - accuracy: 0.9636 - val_loss: 0.1326 - val_accuracy: 0.9565\n",
      "Epoch 733/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1231 - accuracy: 0.9668 - val_loss: 0.1048 - val_accuracy: 0.9720\n",
      "Epoch 734/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1160 - accuracy: 0.9722 - val_loss: 0.0998 - val_accuracy: 0.9730\n",
      "Epoch 735/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0933 - accuracy: 0.9799 - val_loss: 0.0869 - val_accuracy: 0.9783\n",
      "Epoch 736/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0774 - accuracy: 0.9819 - val_loss: 0.0867 - val_accuracy: 0.9768\n",
      "Epoch 737/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0676 - accuracy: 0.9849 - val_loss: 0.0928 - val_accuracy: 0.9740\n",
      "Epoch 738/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0683 - accuracy: 0.9818 - val_loss: 0.0711 - val_accuracy: 0.9835\n",
      "Epoch 739/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0611 - accuracy: 0.9871 - val_loss: 0.0723 - val_accuracy: 0.9833\n",
      "Epoch 740/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0607 - accuracy: 0.9871 - val_loss: 0.0743 - val_accuracy: 0.9827\n",
      "Epoch 741/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0613 - accuracy: 0.9854 - val_loss: 0.0684 - val_accuracy: 0.9850\n",
      "Epoch 742/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0633 - accuracy: 0.9839 - val_loss: 0.0923 - val_accuracy: 0.9745\n",
      "Epoch 743/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0579 - accuracy: 0.9858 - val_loss: 0.0756 - val_accuracy: 0.9815\n",
      "Epoch 744/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0718 - accuracy: 0.9801 - val_loss: 0.0705 - val_accuracy: 0.9833\n",
      "Epoch 745/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0682 - accuracy: 0.9841 - val_loss: 0.0996 - val_accuracy: 0.9772\n",
      "Epoch 746/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0805 - accuracy: 0.9829 - val_loss: 0.1232 - val_accuracy: 0.9660\n",
      "Epoch 747/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0807 - accuracy: 0.9793 - val_loss: 0.0961 - val_accuracy: 0.9800\n",
      "Epoch 748/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0837 - accuracy: 0.9836 - val_loss: 0.0843 - val_accuracy: 0.9810\n",
      "Epoch 749/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0653 - accuracy: 0.9812 - val_loss: 0.0769 - val_accuracy: 0.9818\n",
      "Epoch 750/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0614 - accuracy: 0.9860 - val_loss: 0.0879 - val_accuracy: 0.9770\n",
      "Epoch 751/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.0631 - accuracy: 0.9847 - val_loss: 0.0856 - val_accuracy: 0.9790\n",
      "Epoch 752/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0793 - accuracy: 0.9866 - val_loss: 0.0898 - val_accuracy: 0.9778\n",
      "Epoch 753/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.1965 - accuracy: 0.9663 - val_loss: 0.0859 - val_accuracy: 0.9762\n",
      "Epoch 754/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1853 - accuracy: 0.9567 - val_loss: 0.1065 - val_accuracy: 0.9697\n",
      "Epoch 755/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1699 - accuracy: 0.9610 - val_loss: 0.1058 - val_accuracy: 0.9743\n",
      "Epoch 756/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1353 - accuracy: 0.9722 - val_loss: 0.1013 - val_accuracy: 0.9720\n",
      "Epoch 757/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1305 - accuracy: 0.9669 - val_loss: 0.1343 - val_accuracy: 0.9597\n",
      "Epoch 758/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1345 - accuracy: 0.9691 - val_loss: 0.1402 - val_accuracy: 0.9680\n",
      "Epoch 759/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1190 - accuracy: 0.9747 - val_loss: 0.1452 - val_accuracy: 0.9590\n",
      "Epoch 760/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1800 - accuracy: 0.9732 - val_loss: 0.1453 - val_accuracy: 0.9597\n",
      "Epoch 761/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.2783 - accuracy: 0.9352 - val_loss: 0.0746 - val_accuracy: 0.9800\n",
      "Epoch 762/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.1409 - accuracy: 0.9679 - val_loss: 0.1368 - val_accuracy: 0.9607\n",
      "Epoch 763/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.1544 - accuracy: 0.9663 - val_loss: 0.1500 - val_accuracy: 0.9532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 764/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1306 - accuracy: 0.9716 - val_loss: 0.0877 - val_accuracy: 0.9755\n",
      "Epoch 765/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1218 - accuracy: 0.9624 - val_loss: 0.0833 - val_accuracy: 0.9760\n",
      "Epoch 766/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1094 - accuracy: 0.9774 - val_loss: 0.1057 - val_accuracy: 0.9693\n",
      "Epoch 767/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1112 - accuracy: 0.9759 - val_loss: 0.0980 - val_accuracy: 0.9750\n",
      "Epoch 768/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0887 - accuracy: 0.9759 - val_loss: 0.0811 - val_accuracy: 0.9805\n",
      "Epoch 769/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0753 - accuracy: 0.9807 - val_loss: 0.0773 - val_accuracy: 0.9818\n",
      "Epoch 770/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0625 - accuracy: 0.9844 - val_loss: 0.0790 - val_accuracy: 0.9803\n",
      "Epoch 771/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0578 - accuracy: 0.9871 - val_loss: 0.0750 - val_accuracy: 0.9822\n",
      "Epoch 772/1000\n",
      "16000/16000 [==============================] - 0s 7us/step - loss: 0.0521 - accuracy: 0.9852 - val_loss: 0.0724 - val_accuracy: 0.9835\n",
      "Epoch 773/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0484 - accuracy: 0.9894 - val_loss: 0.0781 - val_accuracy: 0.9808\n",
      "Epoch 774/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0462 - accuracy: 0.9881 - val_loss: 0.0721 - val_accuracy: 0.9825\n",
      "Epoch 775/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0422 - accuracy: 0.9889 - val_loss: 0.0717 - val_accuracy: 0.9830\n",
      "Epoch 776/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0445 - accuracy: 0.9898 - val_loss: 0.0767 - val_accuracy: 0.9825\n",
      "Epoch 777/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0429 - accuracy: 0.9889 - val_loss: 0.0761 - val_accuracy: 0.9825\n",
      "Epoch 778/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0424 - accuracy: 0.9908 - val_loss: 0.0776 - val_accuracy: 0.9827\n",
      "Epoch 779/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0435 - accuracy: 0.9885 - val_loss: 0.0782 - val_accuracy: 0.9833\n",
      "Epoch 780/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0485 - accuracy: 0.9908 - val_loss: 0.0954 - val_accuracy: 0.9735\n",
      "Epoch 781/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0589 - accuracy: 0.9818 - val_loss: 0.0705 - val_accuracy: 0.9858\n",
      "Epoch 782/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0946 - accuracy: 0.9789 - val_loss: 0.1148 - val_accuracy: 0.9693\n",
      "Epoch 783/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0655 - accuracy: 0.9847 - val_loss: 0.0748 - val_accuracy: 0.9835\n",
      "Epoch 784/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0565 - accuracy: 0.9858 - val_loss: 0.0929 - val_accuracy: 0.9755\n",
      "Epoch 785/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0550 - accuracy: 0.9840 - val_loss: 0.0776 - val_accuracy: 0.9843\n",
      "Epoch 786/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0662 - accuracy: 0.9832 - val_loss: 0.0919 - val_accuracy: 0.9775\n",
      "Epoch 787/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0564 - accuracy: 0.9869 - val_loss: 0.0813 - val_accuracy: 0.9818\n",
      "Epoch 788/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0487 - accuracy: 0.9873 - val_loss: 0.0807 - val_accuracy: 0.9820\n",
      "Epoch 789/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0452 - accuracy: 0.9901 - val_loss: 0.0798 - val_accuracy: 0.9833\n",
      "Epoch 790/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0446 - accuracy: 0.9890 - val_loss: 0.0777 - val_accuracy: 0.9843\n",
      "Epoch 791/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0433 - accuracy: 0.9892 - val_loss: 0.0821 - val_accuracy: 0.9818\n",
      "Epoch 792/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0416 - accuracy: 0.9893 - val_loss: 0.0765 - val_accuracy: 0.9843\n",
      "Epoch 793/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0412 - accuracy: 0.9899 - val_loss: 0.0804 - val_accuracy: 0.9822\n",
      "Epoch 794/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0413 - accuracy: 0.9891 - val_loss: 0.0793 - val_accuracy: 0.9827\n",
      "Epoch 795/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0400 - accuracy: 0.9902 - val_loss: 0.0770 - val_accuracy: 0.9845\n",
      "Epoch 796/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0396 - accuracy: 0.9906 - val_loss: 0.0786 - val_accuracy: 0.9837\n",
      "Epoch 797/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0401 - accuracy: 0.9893 - val_loss: 0.0789 - val_accuracy: 0.9833\n",
      "Epoch 798/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0407 - accuracy: 0.9899 - val_loss: 0.0787 - val_accuracy: 0.9830\n",
      "Epoch 799/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0389 - accuracy: 0.9899 - val_loss: 0.0757 - val_accuracy: 0.9845\n",
      "Epoch 800/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0394 - accuracy: 0.9891 - val_loss: 0.0804 - val_accuracy: 0.9820\n",
      "Epoch 801/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0396 - accuracy: 0.9905 - val_loss: 0.0768 - val_accuracy: 0.9847\n",
      "Epoch 802/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0387 - accuracy: 0.9903 - val_loss: 0.0761 - val_accuracy: 0.9843\n",
      "Epoch 803/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0375 - accuracy: 0.9908 - val_loss: 0.0772 - val_accuracy: 0.9840\n",
      "Epoch 804/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0380 - accuracy: 0.9908 - val_loss: 0.0790 - val_accuracy: 0.9837\n",
      "Epoch 805/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0427 - accuracy: 0.9883 - val_loss: 0.0816 - val_accuracy: 0.9822\n",
      "Epoch 806/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0402 - accuracy: 0.9896 - val_loss: 0.0783 - val_accuracy: 0.9840\n",
      "Epoch 807/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0451 - accuracy: 0.9898 - val_loss: 0.0846 - val_accuracy: 0.9800\n",
      "Epoch 808/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0475 - accuracy: 0.9902 - val_loss: 0.0908 - val_accuracy: 0.9780\n",
      "Epoch 809/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0615 - accuracy: 0.9836 - val_loss: 0.0874 - val_accuracy: 0.9795\n",
      "Epoch 810/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0776 - accuracy: 0.9889 - val_loss: 0.1048 - val_accuracy: 0.9743\n",
      "Epoch 811/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1221 - accuracy: 0.9663 - val_loss: 0.0849 - val_accuracy: 0.9793\n",
      "Epoch 812/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0780 - accuracy: 0.9804 - val_loss: 0.1035 - val_accuracy: 0.9710\n",
      "Epoch 813/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0699 - accuracy: 0.9814 - val_loss: 0.0812 - val_accuracy: 0.9830\n",
      "Epoch 814/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.0713 - accuracy: 0.9827 - val_loss: 0.0824 - val_accuracy: 0.9835\n",
      "Epoch 815/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0494 - accuracy: 0.9881 - val_loss: 0.0840 - val_accuracy: 0.9805\n",
      "Epoch 816/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0460 - accuracy: 0.9901 - val_loss: 0.0808 - val_accuracy: 0.9833\n",
      "Epoch 817/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0415 - accuracy: 0.9877 - val_loss: 0.0779 - val_accuracy: 0.9850\n",
      "Epoch 818/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0423 - accuracy: 0.9925 - val_loss: 0.0858 - val_accuracy: 0.9815\n",
      "Epoch 819/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0402 - accuracy: 0.9892 - val_loss: 0.0750 - val_accuracy: 0.9858\n",
      "Epoch 820/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0454 - accuracy: 0.9893 - val_loss: 0.0876 - val_accuracy: 0.9800\n",
      "Epoch 821/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0797 - accuracy: 0.9894 - val_loss: 0.2338 - val_accuracy: 0.9402\n",
      "Epoch 822/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2558 - accuracy: 0.9485 - val_loss: 0.0850 - val_accuracy: 0.9840\n",
      "Epoch 823/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1724 - accuracy: 0.9558 - val_loss: 0.1222 - val_accuracy: 0.9758\n",
      "Epoch 824/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1350 - accuracy: 0.9791 - val_loss: 0.0970 - val_accuracy: 0.9787\n",
      "Epoch 825/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1178 - accuracy: 0.9800 - val_loss: 0.1029 - val_accuracy: 0.9732\n",
      "Epoch 826/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0812 - accuracy: 0.9820 - val_loss: 0.0817 - val_accuracy: 0.9818\n",
      "Epoch 827/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0734 - accuracy: 0.9854 - val_loss: 0.1030 - val_accuracy: 0.9735\n",
      "Epoch 828/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0902 - accuracy: 0.9760 - val_loss: 0.0836 - val_accuracy: 0.9812\n",
      "Epoch 829/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0876 - accuracy: 0.9823 - val_loss: 0.1135 - val_accuracy: 0.9712\n",
      "Epoch 830/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0792 - accuracy: 0.9809 - val_loss: 0.0992 - val_accuracy: 0.9760\n",
      "Epoch 831/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0720 - accuracy: 0.9819 - val_loss: 0.0873 - val_accuracy: 0.9785\n",
      "Epoch 832/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0899 - accuracy: 0.9736 - val_loss: 0.0819 - val_accuracy: 0.9835\n",
      "Epoch 833/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0746 - accuracy: 0.9868 - val_loss: 0.1166 - val_accuracy: 0.9728\n",
      "Epoch 834/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0696 - accuracy: 0.9831 - val_loss: 0.0934 - val_accuracy: 0.9800\n",
      "Epoch 835/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0619 - accuracy: 0.9824 - val_loss: 0.0861 - val_accuracy: 0.9822\n",
      "Epoch 836/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0551 - accuracy: 0.9871 - val_loss: 0.0948 - val_accuracy: 0.9818\n",
      "Epoch 837/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0496 - accuracy: 0.9886 - val_loss: 0.0928 - val_accuracy: 0.9812\n",
      "Epoch 838/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0450 - accuracy: 0.9872 - val_loss: 0.0823 - val_accuracy: 0.9840\n",
      "Epoch 839/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0490 - accuracy: 0.9903 - val_loss: 0.1035 - val_accuracy: 0.9770\n",
      "Epoch 840/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0517 - accuracy: 0.9856 - val_loss: 0.0805 - val_accuracy: 0.9870\n",
      "Epoch 841/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0735 - accuracy: 0.9868 - val_loss: 0.1257 - val_accuracy: 0.9725\n",
      "Epoch 842/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0683 - accuracy: 0.9846 - val_loss: 0.0893 - val_accuracy: 0.9800\n",
      "Epoch 843/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0649 - accuracy: 0.9786 - val_loss: 0.0911 - val_accuracy: 0.9793\n",
      "Epoch 844/1000\n",
      "16000/16000 [==============================] - 0s 9us/step - loss: 0.0588 - accuracy: 0.9887 - val_loss: 0.1113 - val_accuracy: 0.9705\n",
      "Epoch 845/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.0740 - accuracy: 0.9794 - val_loss: 0.0736 - val_accuracy: 0.9870\n",
      "Epoch 846/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0723 - accuracy: 0.9824 - val_loss: 0.0875 - val_accuracy: 0.9815\n",
      "Epoch 847/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0590 - accuracy: 0.9914 - val_loss: 0.0979 - val_accuracy: 0.9775\n",
      "Epoch 848/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0740 - accuracy: 0.9766 - val_loss: 0.0818 - val_accuracy: 0.9850\n",
      "Epoch 849/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0726 - accuracy: 0.9814 - val_loss: 0.0917 - val_accuracy: 0.9772\n",
      "Epoch 850/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0844 - accuracy: 0.9840 - val_loss: 0.1603 - val_accuracy: 0.9515\n",
      "Epoch 851/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1095 - accuracy: 0.9708 - val_loss: 0.0769 - val_accuracy: 0.9847\n",
      "Epoch 852/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0682 - accuracy: 0.9841 - val_loss: 0.0877 - val_accuracy: 0.9800\n",
      "Epoch 853/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0570 - accuracy: 0.9852 - val_loss: 0.0779 - val_accuracy: 0.9822\n",
      "Epoch 854/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0576 - accuracy: 0.9896 - val_loss: 0.0854 - val_accuracy: 0.9795\n",
      "Epoch 855/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0564 - accuracy: 0.9829 - val_loss: 0.0819 - val_accuracy: 0.9837\n",
      "Epoch 856/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0650 - accuracy: 0.9869 - val_loss: 0.1168 - val_accuracy: 0.9675\n",
      "Epoch 857/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0723 - accuracy: 0.9804 - val_loss: 0.1008 - val_accuracy: 0.9722\n",
      "Epoch 858/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0619 - accuracy: 0.9841 - val_loss: 0.0789 - val_accuracy: 0.9845\n",
      "Epoch 859/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0449 - accuracy: 0.9895 - val_loss: 0.0843 - val_accuracy: 0.9815\n",
      "Epoch 860/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0442 - accuracy: 0.9891 - val_loss: 0.0791 - val_accuracy: 0.9835\n",
      "Epoch 861/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0425 - accuracy: 0.9877 - val_loss: 0.0770 - val_accuracy: 0.9843\n",
      "Epoch 862/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0478 - accuracy: 0.9909 - val_loss: 0.0894 - val_accuracy: 0.9797\n",
      "Epoch 863/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0468 - accuracy: 0.9875 - val_loss: 0.0798 - val_accuracy: 0.9843\n",
      "Epoch 864/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.0386 - accuracy: 0.9889 - val_loss: 0.0799 - val_accuracy: 0.9833\n",
      "Epoch 865/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.0366 - accuracy: 0.9916 - val_loss: 0.0768 - val_accuracy: 0.9840\n",
      "Epoch 866/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.0352 - accuracy: 0.9907 - val_loss: 0.0799 - val_accuracy: 0.9820\n",
      "Epoch 867/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0347 - accuracy: 0.9916 - val_loss: 0.0747 - val_accuracy: 0.9852\n",
      "Epoch 868/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0340 - accuracy: 0.9909 - val_loss: 0.0754 - val_accuracy: 0.9847\n",
      "Epoch 869/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0372 - accuracy: 0.9917 - val_loss: 0.0855 - val_accuracy: 0.9810\n",
      "Epoch 870/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0426 - accuracy: 0.9894 - val_loss: 0.0826 - val_accuracy: 0.9822\n",
      "Epoch 871/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0415 - accuracy: 0.9874 - val_loss: 0.0764 - val_accuracy: 0.9852\n",
      "Epoch 872/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0421 - accuracy: 0.9894 - val_loss: 0.0803 - val_accuracy: 0.9818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 873/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0445 - accuracy: 0.9894 - val_loss: 0.0880 - val_accuracy: 0.9783\n",
      "Epoch 874/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0574 - accuracy: 0.9898 - val_loss: 0.1083 - val_accuracy: 0.9720\n",
      "Epoch 875/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1083 - accuracy: 0.9743 - val_loss: 0.0895 - val_accuracy: 0.9770\n",
      "Epoch 876/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0841 - accuracy: 0.9760 - val_loss: 0.0962 - val_accuracy: 0.9803\n",
      "Epoch 877/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1495 - accuracy: 0.9674 - val_loss: 0.1023 - val_accuracy: 0.9785\n",
      "Epoch 878/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4731 - accuracy: 0.9183 - val_loss: 0.2536 - val_accuracy: 0.9340\n",
      "Epoch 879/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5078 - accuracy: 0.9324 - val_loss: 0.2872 - val_accuracy: 0.9262\n",
      "Epoch 880/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4743 - accuracy: 0.9279 - val_loss: 0.2876 - val_accuracy: 0.9285\n",
      "Epoch 881/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3193 - accuracy: 0.9625 - val_loss: 0.4926 - val_accuracy: 0.8835\n",
      "Epoch 882/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4200 - accuracy: 0.9271 - val_loss: 0.0783 - val_accuracy: 0.9770\n",
      "Epoch 883/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2585 - accuracy: 0.9477 - val_loss: 0.1296 - val_accuracy: 0.9628\n",
      "Epoch 884/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1745 - accuracy: 0.9621 - val_loss: 0.1330 - val_accuracy: 0.9585\n",
      "Epoch 885/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1297 - accuracy: 0.9718 - val_loss: 0.0925 - val_accuracy: 0.9718\n",
      "Epoch 886/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1097 - accuracy: 0.9726 - val_loss: 0.0888 - val_accuracy: 0.9755\n",
      "Epoch 887/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1067 - accuracy: 0.9769 - val_loss: 0.1290 - val_accuracy: 0.9592\n",
      "Epoch 888/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1027 - accuracy: 0.9739 - val_loss: 0.0676 - val_accuracy: 0.9812\n",
      "Epoch 889/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0880 - accuracy: 0.9801 - val_loss: 0.1086 - val_accuracy: 0.9672\n",
      "Epoch 890/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0940 - accuracy: 0.9728 - val_loss: 0.0828 - val_accuracy: 0.9790\n",
      "Epoch 891/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0720 - accuracy: 0.9830 - val_loss: 0.0813 - val_accuracy: 0.9768\n",
      "Epoch 892/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0653 - accuracy: 0.9840 - val_loss: 0.0784 - val_accuracy: 0.9778\n",
      "Epoch 893/1000\n",
      "16000/16000 [==============================] - 0s 5us/step - loss: 0.0609 - accuracy: 0.9844 - val_loss: 0.0692 - val_accuracy: 0.9830\n",
      "Epoch 894/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.0659 - accuracy: 0.9851 - val_loss: 0.1057 - val_accuracy: 0.9703\n",
      "Epoch 895/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0760 - accuracy: 0.9805 - val_loss: 0.0813 - val_accuracy: 0.9812\n",
      "Epoch 896/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0615 - accuracy: 0.9843 - val_loss: 0.0785 - val_accuracy: 0.9810\n",
      "Epoch 897/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0614 - accuracy: 0.9891 - val_loss: 0.0822 - val_accuracy: 0.9795\n",
      "Epoch 898/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0685 - accuracy: 0.9789 - val_loss: 0.0780 - val_accuracy: 0.9812\n",
      "Epoch 899/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0594 - accuracy: 0.9860 - val_loss: 0.0805 - val_accuracy: 0.9793\n",
      "Epoch 900/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0580 - accuracy: 0.9872 - val_loss: 0.0795 - val_accuracy: 0.9797\n",
      "Epoch 901/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0487 - accuracy: 0.9871 - val_loss: 0.0758 - val_accuracy: 0.9827\n",
      "Epoch 902/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0516 - accuracy: 0.9860 - val_loss: 0.0751 - val_accuracy: 0.9820\n",
      "Epoch 903/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0493 - accuracy: 0.9896 - val_loss: 0.0820 - val_accuracy: 0.9795\n",
      "Epoch 904/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0471 - accuracy: 0.9873 - val_loss: 0.0722 - val_accuracy: 0.9843\n",
      "Epoch 905/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0467 - accuracy: 0.9886 - val_loss: 0.0762 - val_accuracy: 0.9818\n",
      "Epoch 906/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0452 - accuracy: 0.9904 - val_loss: 0.0800 - val_accuracy: 0.9815\n",
      "Epoch 907/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0495 - accuracy: 0.9859 - val_loss: 0.0758 - val_accuracy: 0.9833\n",
      "Epoch 908/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0425 - accuracy: 0.9896 - val_loss: 0.0769 - val_accuracy: 0.9818\n",
      "Epoch 909/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0431 - accuracy: 0.9906 - val_loss: 0.0804 - val_accuracy: 0.9818\n",
      "Epoch 910/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0436 - accuracy: 0.9873 - val_loss: 0.0735 - val_accuracy: 0.9843\n",
      "Epoch 911/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0418 - accuracy: 0.9906 - val_loss: 0.0794 - val_accuracy: 0.9812\n",
      "Epoch 912/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0421 - accuracy: 0.9895 - val_loss: 0.0732 - val_accuracy: 0.9840\n",
      "Epoch 913/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0404 - accuracy: 0.9899 - val_loss: 0.0755 - val_accuracy: 0.9827\n",
      "Epoch 914/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0397 - accuracy: 0.9901 - val_loss: 0.0756 - val_accuracy: 0.9833\n",
      "Epoch 915/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0386 - accuracy: 0.9916 - val_loss: 0.0758 - val_accuracy: 0.9827\n",
      "Epoch 916/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0393 - accuracy: 0.9900 - val_loss: 0.0757 - val_accuracy: 0.9833\n",
      "Epoch 917/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0424 - accuracy: 0.9888 - val_loss: 0.0768 - val_accuracy: 0.9830\n",
      "Epoch 918/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0393 - accuracy: 0.9910 - val_loss: 0.0792 - val_accuracy: 0.9822\n",
      "Epoch 919/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0373 - accuracy: 0.9907 - val_loss: 0.0739 - val_accuracy: 0.9840\n",
      "Epoch 920/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0366 - accuracy: 0.9909 - val_loss: 0.0756 - val_accuracy: 0.9837\n",
      "Epoch 921/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0381 - accuracy: 0.9902 - val_loss: 0.0772 - val_accuracy: 0.9833\n",
      "Epoch 922/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0381 - accuracy: 0.9923 - val_loss: 0.0791 - val_accuracy: 0.9827\n",
      "Epoch 923/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0377 - accuracy: 0.9892 - val_loss: 0.0734 - val_accuracy: 0.9847\n",
      "Epoch 924/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0463 - accuracy: 0.9888 - val_loss: 0.0922 - val_accuracy: 0.9765\n",
      "Epoch 925/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0486 - accuracy: 0.9877 - val_loss: 0.0773 - val_accuracy: 0.9833\n",
      "Epoch 926/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0457 - accuracy: 0.9876 - val_loss: 0.0787 - val_accuracy: 0.9822\n",
      "Epoch 927/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0425 - accuracy: 0.9907 - val_loss: 0.0844 - val_accuracy: 0.9783\n",
      "Epoch 928/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0407 - accuracy: 0.9889 - val_loss: 0.0747 - val_accuracy: 0.9837\n",
      "Epoch 929/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0475 - accuracy: 0.9925 - val_loss: 0.0873 - val_accuracy: 0.9800\n",
      "Epoch 930/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0623 - accuracy: 0.9812 - val_loss: 0.0750 - val_accuracy: 0.9840\n",
      "Epoch 931/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0903 - accuracy: 0.9806 - val_loss: 0.1343 - val_accuracy: 0.9603\n",
      "Epoch 932/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1143 - accuracy: 0.9709 - val_loss: 0.0952 - val_accuracy: 0.9725\n",
      "Epoch 933/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1198 - accuracy: 0.9740 - val_loss: 0.1351 - val_accuracy: 0.9610\n",
      "Epoch 934/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0791 - accuracy: 0.9793 - val_loss: 0.0789 - val_accuracy: 0.9805\n",
      "Epoch 935/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1185 - accuracy: 0.9741 - val_loss: 0.1425 - val_accuracy: 0.9643\n",
      "Epoch 936/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1286 - accuracy: 0.9739 - val_loss: 0.1355 - val_accuracy: 0.9635\n",
      "Epoch 937/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1140 - accuracy: 0.9716 - val_loss: 0.1297 - val_accuracy: 0.9620\n",
      "Epoch 938/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0987 - accuracy: 0.9772 - val_loss: 0.0937 - val_accuracy: 0.9737\n",
      "Epoch 939/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0974 - accuracy: 0.9752 - val_loss: 0.0859 - val_accuracy: 0.9775\n",
      "Epoch 940/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0733 - accuracy: 0.9833 - val_loss: 0.0853 - val_accuracy: 0.9787\n",
      "Epoch 941/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0695 - accuracy: 0.9831 - val_loss: 0.0955 - val_accuracy: 0.9745\n",
      "Epoch 942/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0610 - accuracy: 0.9843 - val_loss: 0.0747 - val_accuracy: 0.9840\n",
      "Epoch 943/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0680 - accuracy: 0.9830 - val_loss: 0.0854 - val_accuracy: 0.9790\n",
      "Epoch 944/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0548 - accuracy: 0.9887 - val_loss: 0.0794 - val_accuracy: 0.9805\n",
      "Epoch 945/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0560 - accuracy: 0.9841 - val_loss: 0.0828 - val_accuracy: 0.9803\n",
      "Epoch 946/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0490 - accuracy: 0.9909 - val_loss: 0.0809 - val_accuracy: 0.9827\n",
      "Epoch 947/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0450 - accuracy: 0.9866 - val_loss: 0.0762 - val_accuracy: 0.9845\n",
      "Epoch 948/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0456 - accuracy: 0.9902 - val_loss: 0.0842 - val_accuracy: 0.9812\n",
      "Epoch 949/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0421 - accuracy: 0.9887 - val_loss: 0.0738 - val_accuracy: 0.9843\n",
      "Epoch 950/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0461 - accuracy: 0.9889 - val_loss: 0.0804 - val_accuracy: 0.9822\n",
      "Epoch 951/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0476 - accuracy: 0.9891 - val_loss: 0.0843 - val_accuracy: 0.9793\n",
      "Epoch 952/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.0438 - accuracy: 0.9897 - val_loss: 0.0766 - val_accuracy: 0.9825\n",
      "Epoch 953/1000\n",
      "16000/16000 [==============================] - 0s 5us/step - loss: 0.0431 - accuracy: 0.9879 - val_loss: 0.0778 - val_accuracy: 0.9830\n",
      "Epoch 954/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0491 - accuracy: 0.9910 - val_loss: 0.0944 - val_accuracy: 0.9775\n",
      "Epoch 955/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0527 - accuracy: 0.9854 - val_loss: 0.0743 - val_accuracy: 0.9840\n",
      "Epoch 956/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0399 - accuracy: 0.9912 - val_loss: 0.0747 - val_accuracy: 0.9845\n",
      "Epoch 957/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0391 - accuracy: 0.9900 - val_loss: 0.0786 - val_accuracy: 0.9820\n",
      "Epoch 958/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0426 - accuracy: 0.9901 - val_loss: 0.0802 - val_accuracy: 0.9827\n",
      "Epoch 959/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0598 - accuracy: 0.9824 - val_loss: 0.0949 - val_accuracy: 0.9768\n",
      "Epoch 960/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0504 - accuracy: 0.9899 - val_loss: 0.0783 - val_accuracy: 0.9830\n",
      "Epoch 961/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.0440 - accuracy: 0.9877 - val_loss: 0.0750 - val_accuracy: 0.9833\n",
      "Epoch 962/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0426 - accuracy: 0.9912 - val_loss: 0.0834 - val_accuracy: 0.9810\n",
      "Epoch 963/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0443 - accuracy: 0.9892 - val_loss: 0.0823 - val_accuracy: 0.9810\n",
      "Epoch 964/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0427 - accuracy: 0.9886 - val_loss: 0.0778 - val_accuracy: 0.9833\n",
      "Epoch 965/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0388 - accuracy: 0.9884 - val_loss: 0.0786 - val_accuracy: 0.9833\n",
      "Epoch 966/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0400 - accuracy: 0.9892 - val_loss: 0.0764 - val_accuracy: 0.9847\n",
      "Epoch 967/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0444 - accuracy: 0.9922 - val_loss: 0.0949 - val_accuracy: 0.9753\n",
      "Epoch 968/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0563 - accuracy: 0.9839 - val_loss: 0.0796 - val_accuracy: 0.9835\n",
      "Epoch 969/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.0383 - accuracy: 0.9902 - val_loss: 0.0747 - val_accuracy: 0.9855\n",
      "Epoch 970/1000\n",
      "16000/16000 [==============================] - 0s 6us/step - loss: 0.0365 - accuracy: 0.9919 - val_loss: 0.0815 - val_accuracy: 0.9825\n",
      "Epoch 971/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0372 - accuracy: 0.9915 - val_loss: 0.0767 - val_accuracy: 0.9843\n",
      "Epoch 972/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0366 - accuracy: 0.9899 - val_loss: 0.0741 - val_accuracy: 0.9843\n",
      "Epoch 973/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0337 - accuracy: 0.9924 - val_loss: 0.0767 - val_accuracy: 0.9837\n",
      "Epoch 974/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0326 - accuracy: 0.9920 - val_loss: 0.0765 - val_accuracy: 0.9840\n",
      "Epoch 975/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0310 - accuracy: 0.9914 - val_loss: 0.0777 - val_accuracy: 0.9840\n",
      "Epoch 976/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0317 - accuracy: 0.9923 - val_loss: 0.0764 - val_accuracy: 0.9840\n",
      "Epoch 977/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0318 - accuracy: 0.9918 - val_loss: 0.0755 - val_accuracy: 0.9833\n",
      "Epoch 978/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0315 - accuracy: 0.9922 - val_loss: 0.0763 - val_accuracy: 0.9837\n",
      "Epoch 979/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0318 - accuracy: 0.9911 - val_loss: 0.0736 - val_accuracy: 0.9855\n",
      "Epoch 980/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0306 - accuracy: 0.9926 - val_loss: 0.0759 - val_accuracy: 0.9843\n",
      "Epoch 981/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0302 - accuracy: 0.9919 - val_loss: 0.0733 - val_accuracy: 0.9850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 982/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0294 - accuracy: 0.9928 - val_loss: 0.0751 - val_accuracy: 0.9850\n",
      "Epoch 983/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0287 - accuracy: 0.9925 - val_loss: 0.0755 - val_accuracy: 0.9847\n",
      "Epoch 984/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0277 - accuracy: 0.9921 - val_loss: 0.0728 - val_accuracy: 0.9858\n",
      "Epoch 985/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0290 - accuracy: 0.9933 - val_loss: 0.0753 - val_accuracy: 0.9837\n",
      "Epoch 986/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0284 - accuracy: 0.9927 - val_loss: 0.0738 - val_accuracy: 0.9847\n",
      "Epoch 987/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0281 - accuracy: 0.9921 - val_loss: 0.0746 - val_accuracy: 0.9847\n",
      "Epoch 988/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0288 - accuracy: 0.9939 - val_loss: 0.0746 - val_accuracy: 0.9850\n",
      "Epoch 989/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0281 - accuracy: 0.9926 - val_loss: 0.0737 - val_accuracy: 0.9858\n",
      "Epoch 990/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0277 - accuracy: 0.9936 - val_loss: 0.0784 - val_accuracy: 0.9840\n",
      "Epoch 991/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0292 - accuracy: 0.9926 - val_loss: 0.0723 - val_accuracy: 0.9865\n",
      "Epoch 992/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0285 - accuracy: 0.9928 - val_loss: 0.0777 - val_accuracy: 0.9837\n",
      "Epoch 993/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0298 - accuracy: 0.9934 - val_loss: 0.0773 - val_accuracy: 0.9843\n",
      "Epoch 994/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0339 - accuracy: 0.9919 - val_loss: 0.0756 - val_accuracy: 0.9847\n",
      "Epoch 995/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0323 - accuracy: 0.9914 - val_loss: 0.0761 - val_accuracy: 0.9852\n",
      "Epoch 996/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0317 - accuracy: 0.9927 - val_loss: 0.0798 - val_accuracy: 0.9837\n",
      "Epoch 997/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0313 - accuracy: 0.9914 - val_loss: 0.0723 - val_accuracy: 0.9870\n",
      "Epoch 998/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0348 - accuracy: 0.9912 - val_loss: 0.0758 - val_accuracy: 0.9852\n",
      "Epoch 999/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0307 - accuracy: 0.9924 - val_loss: 0.0734 - val_accuracy: 0.9855\n",
      "Epoch 1000/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0311 - accuracy: 0.9937 - val_loss: 0.0784 - val_accuracy: 0.9830\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/1000\n",
      "16000/16000 [==============================] - 1s 37us/step - loss: 1.2594 - accuracy: 0.6291 - val_loss: 0.4620 - val_accuracy: 0.6672\n",
      "Epoch 2/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9855 - accuracy: 0.6131 - val_loss: 0.4953 - val_accuracy: 0.6618\n",
      "Epoch 3/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.9513 - accuracy: 0.6869 - val_loss: 0.7893 - val_accuracy: 0.5393\n",
      "Epoch 4/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9824 - accuracy: 0.6426 - val_loss: 0.4319 - val_accuracy: 0.6957\n",
      "Epoch 5/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9833 - accuracy: 0.6004 - val_loss: 0.3960 - val_accuracy: 0.7197\n",
      "Epoch 6/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.9439 - accuracy: 0.6872 - val_loss: 0.6035 - val_accuracy: 0.6158\n",
      "Epoch 7/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8926 - accuracy: 0.6573 - val_loss: 0.6470 - val_accuracy: 0.6058\n",
      "Epoch 8/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8905 - accuracy: 0.6456 - val_loss: 0.4785 - val_accuracy: 0.6580\n",
      "Epoch 9/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8819 - accuracy: 0.6672 - val_loss: 0.4531 - val_accuracy: 0.6888\n",
      "Epoch 10/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.8523 - accuracy: 0.6658 - val_loss: 0.4879 - val_accuracy: 0.6790\n",
      "Epoch 11/1000\n",
      "16000/16000 [==============================] - 0s 5us/step - loss: 0.8527 - accuracy: 0.6946 - val_loss: 0.5853 - val_accuracy: 0.6388\n",
      "Epoch 12/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8574 - accuracy: 0.6833 - val_loss: 0.3529 - val_accuracy: 0.7615\n",
      "Epoch 13/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8509 - accuracy: 0.6816 - val_loss: 0.4250 - val_accuracy: 0.7160\n",
      "Epoch 14/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8104 - accuracy: 0.7143 - val_loss: 0.4827 - val_accuracy: 0.6865\n",
      "Epoch 15/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7907 - accuracy: 0.6965 - val_loss: 0.3060 - val_accuracy: 0.8075\n",
      "Epoch 16/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8453 - accuracy: 0.7039 - val_loss: 0.4046 - val_accuracy: 0.7333\n",
      "Epoch 17/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.8836 - accuracy: 0.7331 - val_loss: 0.9655 - val_accuracy: 0.4895\n",
      "Epoch 18/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9159 - accuracy: 0.7116 - val_loss: 0.5138 - val_accuracy: 0.6595\n",
      "Epoch 19/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8112 - accuracy: 0.6633 - val_loss: 0.4046 - val_accuracy: 0.7343\n",
      "Epoch 20/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8295 - accuracy: 0.7100 - val_loss: 0.6444 - val_accuracy: 0.6170\n",
      "Epoch 21/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.7934 - accuracy: 0.7139 - val_loss: 0.4331 - val_accuracy: 0.7120\n",
      "Epoch 22/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7518 - accuracy: 0.7179 - val_loss: 0.3116 - val_accuracy: 0.8073\n",
      "Epoch 23/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7790 - accuracy: 0.7287 - val_loss: 0.5025 - val_accuracy: 0.6910\n",
      "Epoch 24/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7407 - accuracy: 0.7561 - val_loss: 0.4935 - val_accuracy: 0.6992\n",
      "Epoch 25/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7512 - accuracy: 0.7147 - val_loss: 0.3814 - val_accuracy: 0.7548\n",
      "Epoch 26/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7444 - accuracy: 0.7341 - val_loss: 0.4563 - val_accuracy: 0.7128\n",
      "Epoch 27/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7179 - accuracy: 0.7371 - val_loss: 0.4146 - val_accuracy: 0.7425\n",
      "Epoch 28/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.7063 - accuracy: 0.7518 - val_loss: 0.4324 - val_accuracy: 0.7318\n",
      "Epoch 29/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.6896 - accuracy: 0.7608 - val_loss: 0.3740 - val_accuracy: 0.7770\n",
      "Epoch 30/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.6825 - accuracy: 0.7763 - val_loss: 0.4455 - val_accuracy: 0.7268\n",
      "Epoch 31/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.7123 - accuracy: 0.7509 - val_loss: 0.5654 - val_accuracy: 0.6915\n",
      "Epoch 32/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6826 - accuracy: 0.7841 - val_loss: 0.5017 - val_accuracy: 0.7005\n",
      "Epoch 33/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6649 - accuracy: 0.7691 - val_loss: 0.3977 - val_accuracy: 0.7685\n",
      "Epoch 34/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6462 - accuracy: 0.7883 - val_loss: 0.3711 - val_accuracy: 0.7893\n",
      "Epoch 35/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6645 - accuracy: 0.7912 - val_loss: 0.5853 - val_accuracy: 0.6855\n",
      "Epoch 36/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6608 - accuracy: 0.7700 - val_loss: 0.4163 - val_accuracy: 0.7610\n",
      "Epoch 37/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6472 - accuracy: 0.7882 - val_loss: 0.4321 - val_accuracy: 0.7548\n",
      "Epoch 38/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.6547 - accuracy: 0.8003 - val_loss: 0.6454 - val_accuracy: 0.6733\n",
      "Epoch 39/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6873 - accuracy: 0.7821 - val_loss: 0.5523 - val_accuracy: 0.7010\n",
      "Epoch 40/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6904 - accuracy: 0.7801 - val_loss: 0.5185 - val_accuracy: 0.7155\n",
      "Epoch 41/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6920 - accuracy: 0.7903 - val_loss: 0.5203 - val_accuracy: 0.7175\n",
      "Epoch 42/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6647 - accuracy: 0.7745 - val_loss: 0.3667 - val_accuracy: 0.7785\n",
      "Epoch 43/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6212 - accuracy: 0.7823 - val_loss: 0.3388 - val_accuracy: 0.8155\n",
      "Epoch 44/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.6240 - accuracy: 0.8030 - val_loss: 0.2851 - val_accuracy: 0.8388\n",
      "Epoch 45/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6287 - accuracy: 0.7990 - val_loss: 0.5005 - val_accuracy: 0.7345\n",
      "Epoch 46/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5919 - accuracy: 0.8059 - val_loss: 0.4029 - val_accuracy: 0.7818\n",
      "Epoch 47/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5811 - accuracy: 0.8258 - val_loss: 0.4656 - val_accuracy: 0.7580\n",
      "Epoch 48/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5798 - accuracy: 0.8019 - val_loss: 0.2966 - val_accuracy: 0.8395\n",
      "Epoch 49/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5666 - accuracy: 0.8226 - val_loss: 0.2753 - val_accuracy: 0.8540\n",
      "Epoch 50/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6264 - accuracy: 0.8079 - val_loss: 0.3286 - val_accuracy: 0.8098\n",
      "Epoch 51/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6346 - accuracy: 0.8032 - val_loss: 0.3814 - val_accuracy: 0.8015\n",
      "Epoch 52/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6016 - accuracy: 0.8071 - val_loss: 0.3401 - val_accuracy: 0.8102\n",
      "Epoch 53/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6353 - accuracy: 0.7937 - val_loss: 0.3519 - val_accuracy: 0.8125\n",
      "Epoch 54/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5753 - accuracy: 0.8221 - val_loss: 0.4420 - val_accuracy: 0.7663\n",
      "Epoch 55/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5678 - accuracy: 0.8189 - val_loss: 0.4270 - val_accuracy: 0.7780\n",
      "Epoch 56/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5406 - accuracy: 0.8261 - val_loss: 0.2411 - val_accuracy: 0.8665\n",
      "Epoch 57/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5614 - accuracy: 0.8325 - val_loss: 0.3694 - val_accuracy: 0.8050\n",
      "Epoch 58/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5311 - accuracy: 0.8253 - val_loss: 0.2263 - val_accuracy: 0.8780\n",
      "Epoch 59/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5722 - accuracy: 0.8251 - val_loss: 0.1254 - val_accuracy: 0.9485\n",
      "Epoch 60/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7669 - accuracy: 0.7772 - val_loss: 0.2501 - val_accuracy: 0.8558\n",
      "Epoch 61/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7128 - accuracy: 0.7573 - val_loss: 0.2381 - val_accuracy: 0.8687\n",
      "Epoch 62/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7534 - accuracy: 0.7788 - val_loss: 0.5779 - val_accuracy: 0.6923\n",
      "Epoch 63/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6662 - accuracy: 0.8124 - val_loss: 0.4350 - val_accuracy: 0.7552\n",
      "Epoch 64/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6327 - accuracy: 0.7840 - val_loss: 0.4379 - val_accuracy: 0.7530\n",
      "Epoch 65/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6250 - accuracy: 0.7877 - val_loss: 0.4350 - val_accuracy: 0.7570\n",
      "Epoch 66/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5968 - accuracy: 0.7886 - val_loss: 0.3778 - val_accuracy: 0.7880\n",
      "Epoch 67/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5824 - accuracy: 0.8094 - val_loss: 0.4045 - val_accuracy: 0.7745\n",
      "Epoch 68/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5814 - accuracy: 0.8171 - val_loss: 0.3742 - val_accuracy: 0.8083\n",
      "Epoch 69/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5867 - accuracy: 0.8166 - val_loss: 0.3494 - val_accuracy: 0.8092\n",
      "Epoch 70/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5918 - accuracy: 0.8051 - val_loss: 0.3137 - val_accuracy: 0.8353\n",
      "Epoch 71/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5795 - accuracy: 0.8182 - val_loss: 0.2289 - val_accuracy: 0.8700\n",
      "Epoch 72/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6603 - accuracy: 0.8071 - val_loss: 0.2846 - val_accuracy: 0.8438\n",
      "Epoch 73/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6358 - accuracy: 0.7949 - val_loss: 0.2286 - val_accuracy: 0.8802\n",
      "Epoch 74/1000\n",
      "16000/16000 [==============================] - ETA: 0s - loss: 0.8803 - accuracy: 0.87 - 0s 3us/step - loss: 0.6479 - accuracy: 0.7766 - val_loss: 0.2081 - val_accuracy: 0.8898\n",
      "Epoch 75/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5973 - accuracy: 0.8297 - val_loss: 0.5369 - val_accuracy: 0.7333\n",
      "Epoch 76/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5938 - accuracy: 0.8129 - val_loss: 0.3174 - val_accuracy: 0.8265\n",
      "Epoch 77/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.5550 - accuracy: 0.8173 - val_loss: 0.3769 - val_accuracy: 0.7975\n",
      "Epoch 78/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5513 - accuracy: 0.8151 - val_loss: 0.4158 - val_accuracy: 0.7860\n",
      "Epoch 79/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5361 - accuracy: 0.8401 - val_loss: 0.4417 - val_accuracy: 0.7765\n",
      "Epoch 80/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5428 - accuracy: 0.8173 - val_loss: 0.2672 - val_accuracy: 0.8518\n",
      "Epoch 81/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5379 - accuracy: 0.8232 - val_loss: 0.2953 - val_accuracy: 0.8395\n",
      "Epoch 82/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.5344 - accuracy: 0.8214 - val_loss: 0.3323 - val_accuracy: 0.8223\n",
      "Epoch 83/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5430 - accuracy: 0.8289 - val_loss: 0.4414 - val_accuracy: 0.7772\n",
      "Epoch 84/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5074 - accuracy: 0.8412 - val_loss: 0.3114 - val_accuracy: 0.8345\n",
      "Epoch 85/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5098 - accuracy: 0.8317 - val_loss: 0.3887 - val_accuracy: 0.7970\n",
      "Epoch 86/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.5058 - accuracy: 0.8344 - val_loss: 0.3788 - val_accuracy: 0.8115\n",
      "Epoch 87/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5032 - accuracy: 0.8466 - val_loss: 0.4521 - val_accuracy: 0.7795\n",
      "Epoch 88/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5049 - accuracy: 0.8313 - val_loss: 0.2316 - val_accuracy: 0.8720\n",
      "Epoch 89/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4959 - accuracy: 0.8382 - val_loss: 0.3822 - val_accuracy: 0.8000\n",
      "Epoch 90/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5128 - accuracy: 0.8365 - val_loss: 0.3907 - val_accuracy: 0.7977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5347 - accuracy: 0.8217 - val_loss: 0.3988 - val_accuracy: 0.7915\n",
      "Epoch 92/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5068 - accuracy: 0.8481 - val_loss: 0.3762 - val_accuracy: 0.7995\n",
      "Epoch 93/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5015 - accuracy: 0.8416 - val_loss: 0.3909 - val_accuracy: 0.8083\n",
      "Epoch 94/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5054 - accuracy: 0.8338 - val_loss: 0.3229 - val_accuracy: 0.8305\n",
      "Epoch 95/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5255 - accuracy: 0.8286 - val_loss: 0.3103 - val_accuracy: 0.8330\n",
      "Epoch 96/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4907 - accuracy: 0.8421 - val_loss: 0.3159 - val_accuracy: 0.8388\n",
      "Epoch 97/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4801 - accuracy: 0.8455 - val_loss: 0.3041 - val_accuracy: 0.8372\n",
      "Epoch 98/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.5235 - accuracy: 0.8360 - val_loss: 0.3118 - val_accuracy: 0.8363\n",
      "Epoch 99/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5058 - accuracy: 0.8296 - val_loss: 0.2961 - val_accuracy: 0.8390\n",
      "Epoch 100/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4916 - accuracy: 0.8317 - val_loss: 0.3439 - val_accuracy: 0.8150\n",
      "Epoch 101/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5047 - accuracy: 0.8341 - val_loss: 0.3036 - val_accuracy: 0.8390\n",
      "Epoch 102/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4893 - accuracy: 0.8453 - val_loss: 0.3052 - val_accuracy: 0.8397\n",
      "Epoch 103/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5179 - accuracy: 0.8269 - val_loss: 0.2402 - val_accuracy: 0.8665\n",
      "Epoch 104/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5870 - accuracy: 0.8064 - val_loss: 0.3122 - val_accuracy: 0.8232\n",
      "Epoch 105/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5526 - accuracy: 0.8428 - val_loss: 0.4373 - val_accuracy: 0.7755\n",
      "Epoch 106/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5464 - accuracy: 0.8211 - val_loss: 0.4395 - val_accuracy: 0.7640\n",
      "Epoch 107/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5111 - accuracy: 0.8428 - val_loss: 0.3209 - val_accuracy: 0.8285\n",
      "Epoch 108/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4852 - accuracy: 0.8240 - val_loss: 0.2027 - val_accuracy: 0.8898\n",
      "Epoch 109/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4872 - accuracy: 0.8502 - val_loss: 0.3417 - val_accuracy: 0.8257\n",
      "Epoch 110/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4679 - accuracy: 0.8464 - val_loss: 0.3294 - val_accuracy: 0.8355\n",
      "Epoch 111/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4786 - accuracy: 0.8346 - val_loss: 0.2430 - val_accuracy: 0.8665\n",
      "Epoch 112/1000\n",
      "16000/16000 [==============================] - 0s 6us/step - loss: 0.5107 - accuracy: 0.8421 - val_loss: 0.2890 - val_accuracy: 0.8510\n",
      "Epoch 113/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4629 - accuracy: 0.8480 - val_loss: 0.3191 - val_accuracy: 0.8378\n",
      "Epoch 114/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4717 - accuracy: 0.8546 - val_loss: 0.3255 - val_accuracy: 0.8360\n",
      "Epoch 115/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5035 - accuracy: 0.8394 - val_loss: 0.2924 - val_accuracy: 0.8443\n",
      "Epoch 116/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4997 - accuracy: 0.8281 - val_loss: 0.2881 - val_accuracy: 0.8478\n",
      "Epoch 117/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4878 - accuracy: 0.8542 - val_loss: 0.3204 - val_accuracy: 0.8357\n",
      "Epoch 118/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4895 - accuracy: 0.8263 - val_loss: 0.1979 - val_accuracy: 0.8867\n",
      "Epoch 119/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4815 - accuracy: 0.8465 - val_loss: 0.3091 - val_accuracy: 0.8385\n",
      "Epoch 120/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4593 - accuracy: 0.8530 - val_loss: 0.3383 - val_accuracy: 0.8365\n",
      "Epoch 121/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4649 - accuracy: 0.8494 - val_loss: 0.3692 - val_accuracy: 0.8158\n",
      "Epoch 122/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4564 - accuracy: 0.8656 - val_loss: 0.4329 - val_accuracy: 0.8232\n",
      "Epoch 123/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4942 - accuracy: 0.8472 - val_loss: 0.3509 - val_accuracy: 0.8245\n",
      "Epoch 124/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4821 - accuracy: 0.8473 - val_loss: 0.3496 - val_accuracy: 0.8288\n",
      "Epoch 125/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4898 - accuracy: 0.8413 - val_loss: 0.4306 - val_accuracy: 0.7835\n",
      "Epoch 126/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4781 - accuracy: 0.8534 - val_loss: 0.3226 - val_accuracy: 0.8317\n",
      "Epoch 127/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4560 - accuracy: 0.8464 - val_loss: 0.2900 - val_accuracy: 0.8468\n",
      "Epoch 128/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4369 - accuracy: 0.8531 - val_loss: 0.2216 - val_accuracy: 0.8830\n",
      "Epoch 129/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4485 - accuracy: 0.8543 - val_loss: 0.2638 - val_accuracy: 0.8593\n",
      "Epoch 130/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4613 - accuracy: 0.8489 - val_loss: 0.3490 - val_accuracy: 0.8313\n",
      "Epoch 131/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4586 - accuracy: 0.8583 - val_loss: 0.3950 - val_accuracy: 0.8027\n",
      "Epoch 132/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.4802 - accuracy: 0.8455 - val_loss: 0.3830 - val_accuracy: 0.8105\n",
      "Epoch 133/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4556 - accuracy: 0.8521 - val_loss: 0.3168 - val_accuracy: 0.8385\n",
      "Epoch 134/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.4362 - accuracy: 0.8540 - val_loss: 0.2606 - val_accuracy: 0.8643\n",
      "Epoch 135/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.4382 - accuracy: 0.8522 - val_loss: 0.3246 - val_accuracy: 0.8403\n",
      "Epoch 136/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.4083 - accuracy: 0.8710 - val_loss: 0.3278 - val_accuracy: 0.8418\n",
      "Epoch 137/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.4005 - accuracy: 0.8640 - val_loss: 0.2605 - val_accuracy: 0.8655\n",
      "Epoch 138/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4092 - accuracy: 0.8654 - val_loss: 0.3144 - val_accuracy: 0.8438\n",
      "Epoch 139/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.4078 - accuracy: 0.8693 - val_loss: 0.2724 - val_accuracy: 0.8662\n",
      "Epoch 140/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4151 - accuracy: 0.8640 - val_loss: 0.3033 - val_accuracy: 0.8512\n",
      "Epoch 141/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.4196 - accuracy: 0.8607 - val_loss: 0.3762 - val_accuracy: 0.8317\n",
      "Epoch 142/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4261 - accuracy: 0.8648 - val_loss: 0.4115 - val_accuracy: 0.8052\n",
      "Epoch 143/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4490 - accuracy: 0.8689 - val_loss: 0.4823 - val_accuracy: 0.7997\n",
      "Epoch 144/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5002 - accuracy: 0.8463 - val_loss: 0.3314 - val_accuracy: 0.8338\n",
      "Epoch 145/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4790 - accuracy: 0.8368 - val_loss: 0.2914 - val_accuracy: 0.8420\n",
      "Epoch 146/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4676 - accuracy: 0.8389 - val_loss: 0.2597 - val_accuracy: 0.8618\n",
      "Epoch 147/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4435 - accuracy: 0.8462 - val_loss: 0.2135 - val_accuracy: 0.8723\n",
      "Epoch 148/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4685 - accuracy: 0.8487 - val_loss: 0.2784 - val_accuracy: 0.8537\n",
      "Epoch 149/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4415 - accuracy: 0.8508 - val_loss: 0.2904 - val_accuracy: 0.8490\n",
      "Epoch 150/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4373 - accuracy: 0.8571 - val_loss: 0.2631 - val_accuracy: 0.8635\n",
      "Epoch 151/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4556 - accuracy: 0.8515 - val_loss: 0.3019 - val_accuracy: 0.8378\n",
      "Epoch 152/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4539 - accuracy: 0.8500 - val_loss: 0.1914 - val_accuracy: 0.8957\n",
      "Epoch 153/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4453 - accuracy: 0.8568 - val_loss: 0.3012 - val_accuracy: 0.8447\n",
      "Epoch 154/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4494 - accuracy: 0.8659 - val_loss: 0.5004 - val_accuracy: 0.7893\n",
      "Epoch 155/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4981 - accuracy: 0.8393 - val_loss: 0.3864 - val_accuracy: 0.8167\n",
      "Epoch 156/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4536 - accuracy: 0.8584 - val_loss: 0.3191 - val_accuracy: 0.8365\n",
      "Epoch 157/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4730 - accuracy: 0.8366 - val_loss: 0.2290 - val_accuracy: 0.8727\n",
      "Epoch 158/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4265 - accuracy: 0.8544 - val_loss: 0.2613 - val_accuracy: 0.8633\n",
      "Epoch 159/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4622 - accuracy: 0.8579 - val_loss: 0.2689 - val_accuracy: 0.8612\n",
      "Epoch 160/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4307 - accuracy: 0.8583 - val_loss: 0.2502 - val_accuracy: 0.8692\n",
      "Epoch 161/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4501 - accuracy: 0.8529 - val_loss: 0.2159 - val_accuracy: 0.8810\n",
      "Epoch 162/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4832 - accuracy: 0.8413 - val_loss: 0.2608 - val_accuracy: 0.8487\n",
      "Epoch 163/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4640 - accuracy: 0.8446 - val_loss: 0.2443 - val_accuracy: 0.8702\n",
      "Epoch 164/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4654 - accuracy: 0.8519 - val_loss: 0.2493 - val_accuracy: 0.8633\n",
      "Epoch 165/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4720 - accuracy: 0.8466 - val_loss: 0.2921 - val_accuracy: 0.8447\n",
      "Epoch 166/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4387 - accuracy: 0.8667 - val_loss: 0.2839 - val_accuracy: 0.8518\n",
      "Epoch 167/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4675 - accuracy: 0.8435 - val_loss: 0.1238 - val_accuracy: 0.9467\n",
      "Epoch 168/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5202 - accuracy: 0.8579 - val_loss: 0.4120 - val_accuracy: 0.8117\n",
      "Epoch 169/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4638 - accuracy: 0.8504 - val_loss: 0.4085 - val_accuracy: 0.8085\n",
      "Epoch 170/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4884 - accuracy: 0.8521 - val_loss: 0.4093 - val_accuracy: 0.8073\n",
      "Epoch 171/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4615 - accuracy: 0.8393 - val_loss: 0.2993 - val_accuracy: 0.8390\n",
      "Epoch 172/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4224 - accuracy: 0.8529 - val_loss: 0.2818 - val_accuracy: 0.8462\n",
      "Epoch 173/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4247 - accuracy: 0.8586 - val_loss: 0.2994 - val_accuracy: 0.8455\n",
      "Epoch 174/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4121 - accuracy: 0.8680 - val_loss: 0.3572 - val_accuracy: 0.8295\n",
      "Epoch 175/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4724 - accuracy: 0.8547 - val_loss: 0.4755 - val_accuracy: 0.7747\n",
      "Epoch 176/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5276 - accuracy: 0.8157 - val_loss: 0.2057 - val_accuracy: 0.8890\n",
      "Epoch 177/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5147 - accuracy: 0.8353 - val_loss: 0.2843 - val_accuracy: 0.8435\n",
      "Epoch 178/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5207 - accuracy: 0.8439 - val_loss: 0.3790 - val_accuracy: 0.8108\n",
      "Epoch 179/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4662 - accuracy: 0.8529 - val_loss: 0.4040 - val_accuracy: 0.8070\n",
      "Epoch 180/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4625 - accuracy: 0.8480 - val_loss: 0.3147 - val_accuracy: 0.8325\n",
      "Epoch 181/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4457 - accuracy: 0.8478 - val_loss: 0.3096 - val_accuracy: 0.8380\n",
      "Epoch 182/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4344 - accuracy: 0.8602 - val_loss: 0.3033 - val_accuracy: 0.8472\n",
      "Epoch 183/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4367 - accuracy: 0.8522 - val_loss: 0.2952 - val_accuracy: 0.8462\n",
      "Epoch 184/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4171 - accuracy: 0.8558 - val_loss: 0.2690 - val_accuracy: 0.8625\n",
      "Epoch 185/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4148 - accuracy: 0.8546 - val_loss: 0.2675 - val_accuracy: 0.8530\n",
      "Epoch 186/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4314 - accuracy: 0.8614 - val_loss: 0.3303 - val_accuracy: 0.8367\n",
      "Epoch 187/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4266 - accuracy: 0.8593 - val_loss: 0.3149 - val_accuracy: 0.8340\n",
      "Epoch 188/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4077 - accuracy: 0.8627 - val_loss: 0.2843 - val_accuracy: 0.8545\n",
      "Epoch 189/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3929 - accuracy: 0.8632 - val_loss: 0.2142 - val_accuracy: 0.8830\n",
      "Epoch 190/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4224 - accuracy: 0.8636 - val_loss: 0.3042 - val_accuracy: 0.8482\n",
      "Epoch 191/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4915 - accuracy: 0.8454 - val_loss: 0.3675 - val_accuracy: 0.8248\n",
      "Epoch 192/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4343 - accuracy: 0.8636 - val_loss: 0.3009 - val_accuracy: 0.8322\n",
      "Epoch 193/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4407 - accuracy: 0.8528 - val_loss: 0.3655 - val_accuracy: 0.8213\n",
      "Epoch 194/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4544 - accuracy: 0.8554 - val_loss: 0.4464 - val_accuracy: 0.8075\n",
      "Epoch 195/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5094 - accuracy: 0.8384 - val_loss: 0.4340 - val_accuracy: 0.7933\n",
      "Epoch 196/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.5172 - accuracy: 0.8345 - val_loss: 0.3239 - val_accuracy: 0.8173\n",
      "Epoch 197/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4784 - accuracy: 0.8436 - val_loss: 0.3986 - val_accuracy: 0.8090\n",
      "Epoch 198/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5416 - accuracy: 0.8246 - val_loss: 0.2411 - val_accuracy: 0.8602\n",
      "Epoch 199/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5028 - accuracy: 0.8308 - val_loss: 0.2586 - val_accuracy: 0.8723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4514 - accuracy: 0.8518 - val_loss: 0.3048 - val_accuracy: 0.8298\n",
      "Epoch 201/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4609 - accuracy: 0.8418 - val_loss: 0.3921 - val_accuracy: 0.8087\n",
      "Epoch 202/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4597 - accuracy: 0.8621 - val_loss: 0.4109 - val_accuracy: 0.8108\n",
      "Epoch 203/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4670 - accuracy: 0.8346 - val_loss: 0.1907 - val_accuracy: 0.8913\n",
      "Epoch 204/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.5788 - accuracy: 0.8291 - val_loss: 0.2995 - val_accuracy: 0.8363\n",
      "Epoch 205/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5095 - accuracy: 0.8438 - val_loss: 0.4301 - val_accuracy: 0.7922\n",
      "Epoch 206/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.5065 - accuracy: 0.8496 - val_loss: 0.3734 - val_accuracy: 0.8225\n",
      "Epoch 207/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4539 - accuracy: 0.8483 - val_loss: 0.3173 - val_accuracy: 0.8462\n",
      "Epoch 208/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4189 - accuracy: 0.8627 - val_loss: 0.3345 - val_accuracy: 0.8350\n",
      "Epoch 209/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4265 - accuracy: 0.8666 - val_loss: 0.3852 - val_accuracy: 0.8260\n",
      "Epoch 210/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4456 - accuracy: 0.8484 - val_loss: 0.2994 - val_accuracy: 0.8425\n",
      "Epoch 211/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4257 - accuracy: 0.8604 - val_loss: 0.3432 - val_accuracy: 0.8263\n",
      "Epoch 212/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4351 - accuracy: 0.8504 - val_loss: 0.2264 - val_accuracy: 0.8687\n",
      "Epoch 213/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4506 - accuracy: 0.8409 - val_loss: 0.2324 - val_accuracy: 0.8717\n",
      "Epoch 214/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4219 - accuracy: 0.8667 - val_loss: 0.2824 - val_accuracy: 0.8585\n",
      "Epoch 215/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4799 - accuracy: 0.8546 - val_loss: 0.4603 - val_accuracy: 0.8010\n",
      "Epoch 216/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4580 - accuracy: 0.8648 - val_loss: 0.2951 - val_accuracy: 0.8425\n",
      "Epoch 217/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4570 - accuracy: 0.8429 - val_loss: 0.2692 - val_accuracy: 0.8605\n",
      "Epoch 218/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4155 - accuracy: 0.8583 - val_loss: 0.2913 - val_accuracy: 0.8380\n",
      "Epoch 219/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4061 - accuracy: 0.8711 - val_loss: 0.3210 - val_accuracy: 0.8445\n",
      "Epoch 220/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4005 - accuracy: 0.8669 - val_loss: 0.2820 - val_accuracy: 0.8602\n",
      "Epoch 221/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4079 - accuracy: 0.8750 - val_loss: 0.3220 - val_accuracy: 0.8455\n",
      "Epoch 222/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4191 - accuracy: 0.8501 - val_loss: 0.1569 - val_accuracy: 0.9162\n",
      "Epoch 223/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4233 - accuracy: 0.8633 - val_loss: 0.2822 - val_accuracy: 0.8528\n",
      "Epoch 224/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3908 - accuracy: 0.8786 - val_loss: 0.3198 - val_accuracy: 0.8453\n",
      "Epoch 225/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3894 - accuracy: 0.8674 - val_loss: 0.2461 - val_accuracy: 0.8622\n",
      "Epoch 226/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3660 - accuracy: 0.8682 - val_loss: 0.2236 - val_accuracy: 0.8860\n",
      "Epoch 227/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3638 - accuracy: 0.8767 - val_loss: 0.2480 - val_accuracy: 0.8767\n",
      "Epoch 228/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3715 - accuracy: 0.8838 - val_loss: 0.3941 - val_accuracy: 0.8215\n",
      "Epoch 229/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4127 - accuracy: 0.8723 - val_loss: 0.3165 - val_accuracy: 0.8365\n",
      "Epoch 230/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4103 - accuracy: 0.8439 - val_loss: 0.1978 - val_accuracy: 0.8830\n",
      "Epoch 231/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4115 - accuracy: 0.8598 - val_loss: 0.2229 - val_accuracy: 0.8845\n",
      "Epoch 232/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4129 - accuracy: 0.8622 - val_loss: 0.2784 - val_accuracy: 0.8540\n",
      "Epoch 233/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4278 - accuracy: 0.8611 - val_loss: 0.4416 - val_accuracy: 0.7945\n",
      "Epoch 234/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4491 - accuracy: 0.8559 - val_loss: 0.3087 - val_accuracy: 0.8407\n",
      "Epoch 235/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4424 - accuracy: 0.8489 - val_loss: 0.2944 - val_accuracy: 0.8407\n",
      "Epoch 236/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4389 - accuracy: 0.8499 - val_loss: 0.2588 - val_accuracy: 0.8652\n",
      "Epoch 237/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4229 - accuracy: 0.8583 - val_loss: 0.2786 - val_accuracy: 0.8585\n",
      "Epoch 238/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5055 - accuracy: 0.8394 - val_loss: 0.2589 - val_accuracy: 0.8637\n",
      "Epoch 239/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4313 - accuracy: 0.8648 - val_loss: 0.3582 - val_accuracy: 0.8425\n",
      "Epoch 240/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4354 - accuracy: 0.8566 - val_loss: 0.2922 - val_accuracy: 0.8435\n",
      "Epoch 241/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4055 - accuracy: 0.8696 - val_loss: 0.4294 - val_accuracy: 0.8173\n",
      "Epoch 242/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4282 - accuracy: 0.8586 - val_loss: 0.2752 - val_accuracy: 0.8580\n",
      "Epoch 243/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4112 - accuracy: 0.8562 - val_loss: 0.2183 - val_accuracy: 0.8745\n",
      "Epoch 244/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3816 - accuracy: 0.8798 - val_loss: 0.4548 - val_accuracy: 0.8145\n",
      "Epoch 245/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4248 - accuracy: 0.8600 - val_loss: 0.2150 - val_accuracy: 0.8765\n",
      "Epoch 246/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4080 - accuracy: 0.8569 - val_loss: 0.1864 - val_accuracy: 0.9025\n",
      "Epoch 247/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3845 - accuracy: 0.8758 - val_loss: 0.2400 - val_accuracy: 0.8788\n",
      "Epoch 248/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3974 - accuracy: 0.8648 - val_loss: 0.3106 - val_accuracy: 0.8372\n",
      "Epoch 249/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3917 - accuracy: 0.8784 - val_loss: 0.3466 - val_accuracy: 0.8310\n",
      "Epoch 250/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4124 - accuracy: 0.8589 - val_loss: 0.3227 - val_accuracy: 0.8605\n",
      "Epoch 251/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4163 - accuracy: 0.8647 - val_loss: 0.2781 - val_accuracy: 0.8505\n",
      "Epoch 252/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3852 - accuracy: 0.8728 - val_loss: 0.3275 - val_accuracy: 0.8528\n",
      "Epoch 253/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3855 - accuracy: 0.8711 - val_loss: 0.2843 - val_accuracy: 0.8512\n",
      "Epoch 254/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3926 - accuracy: 0.8540 - val_loss: 0.1800 - val_accuracy: 0.8970\n",
      "Epoch 255/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3980 - accuracy: 0.8718 - val_loss: 0.2745 - val_accuracy: 0.8692\n",
      "Epoch 256/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3885 - accuracy: 0.8742 - val_loss: 0.3440 - val_accuracy: 0.8150\n",
      "Epoch 257/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4148 - accuracy: 0.8593 - val_loss: 0.3358 - val_accuracy: 0.8353\n",
      "Epoch 258/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4072 - accuracy: 0.8592 - val_loss: 0.2640 - val_accuracy: 0.8633\n",
      "Epoch 259/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3845 - accuracy: 0.8691 - val_loss: 0.2871 - val_accuracy: 0.8497\n",
      "Epoch 260/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3779 - accuracy: 0.8698 - val_loss: 0.2628 - val_accuracy: 0.8610\n",
      "Epoch 261/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3574 - accuracy: 0.8811 - val_loss: 0.2828 - val_accuracy: 0.8590\n",
      "Epoch 262/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3677 - accuracy: 0.8692 - val_loss: 0.3067 - val_accuracy: 0.8490\n",
      "Epoch 263/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3758 - accuracy: 0.8714 - val_loss: 0.3467 - val_accuracy: 0.8275\n",
      "Epoch 264/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4329 - accuracy: 0.8577 - val_loss: 0.2735 - val_accuracy: 0.8575\n",
      "Epoch 265/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4380 - accuracy: 0.8574 - val_loss: 0.2620 - val_accuracy: 0.8800\n",
      "Epoch 266/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4154 - accuracy: 0.8740 - val_loss: 0.1860 - val_accuracy: 0.9003\n",
      "Epoch 267/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3786 - accuracy: 0.8736 - val_loss: 0.2370 - val_accuracy: 0.8692\n",
      "Epoch 268/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3715 - accuracy: 0.8736 - val_loss: 0.2900 - val_accuracy: 0.8533\n",
      "Epoch 269/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3733 - accuracy: 0.8766 - val_loss: 0.3056 - val_accuracy: 0.8440\n",
      "Epoch 270/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3995 - accuracy: 0.8693 - val_loss: 0.2146 - val_accuracy: 0.8773\n",
      "Epoch 271/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3810 - accuracy: 0.8773 - val_loss: 0.2781 - val_accuracy: 0.8645\n",
      "Epoch 272/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3844 - accuracy: 0.8643 - val_loss: 0.2280 - val_accuracy: 0.8710\n",
      "Epoch 273/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4039 - accuracy: 0.8797 - val_loss: 0.2439 - val_accuracy: 0.8687\n",
      "Epoch 274/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4339 - accuracy: 0.8609 - val_loss: 0.1964 - val_accuracy: 0.9018\n",
      "Epoch 275/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3984 - accuracy: 0.8746 - val_loss: 0.2459 - val_accuracy: 0.8785\n",
      "Epoch 276/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4086 - accuracy: 0.8648 - val_loss: 0.2219 - val_accuracy: 0.8763\n",
      "Epoch 277/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3877 - accuracy: 0.8700 - val_loss: 0.2825 - val_accuracy: 0.8547\n",
      "Epoch 278/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3765 - accuracy: 0.8662 - val_loss: 0.2034 - val_accuracy: 0.8830\n",
      "Epoch 279/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3694 - accuracy: 0.8755 - val_loss: 0.1899 - val_accuracy: 0.9005\n",
      "Epoch 280/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3678 - accuracy: 0.8786 - val_loss: 0.2639 - val_accuracy: 0.8547\n",
      "Epoch 281/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3634 - accuracy: 0.8789 - val_loss: 0.3282 - val_accuracy: 0.8455\n",
      "Epoch 282/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3645 - accuracy: 0.8712 - val_loss: 0.2242 - val_accuracy: 0.8752\n",
      "Epoch 283/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3502 - accuracy: 0.8840 - val_loss: 0.2599 - val_accuracy: 0.8775\n",
      "Epoch 284/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3387 - accuracy: 0.8819 - val_loss: 0.2187 - val_accuracy: 0.8817\n",
      "Epoch 285/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3512 - accuracy: 0.8805 - val_loss: 0.2852 - val_accuracy: 0.8590\n",
      "Epoch 286/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3384 - accuracy: 0.8812 - val_loss: 0.2462 - val_accuracy: 0.8660\n",
      "Epoch 287/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3248 - accuracy: 0.8859 - val_loss: 0.2045 - val_accuracy: 0.8925\n",
      "Epoch 288/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3436 - accuracy: 0.8789 - val_loss: 0.1743 - val_accuracy: 0.9053\n",
      "Epoch 289/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3748 - accuracy: 0.8695 - val_loss: 0.1878 - val_accuracy: 0.8972\n",
      "Epoch 290/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4361 - accuracy: 0.8569 - val_loss: 0.2424 - val_accuracy: 0.8742\n",
      "Epoch 291/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4106 - accuracy: 0.8612 - val_loss: 0.2362 - val_accuracy: 0.8630\n",
      "Epoch 292/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3626 - accuracy: 0.8816 - val_loss: 0.2841 - val_accuracy: 0.8553\n",
      "Epoch 293/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3454 - accuracy: 0.8776 - val_loss: 0.1967 - val_accuracy: 0.8957\n",
      "Epoch 294/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3371 - accuracy: 0.8792 - val_loss: 0.1895 - val_accuracy: 0.8932\n",
      "Epoch 295/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.3336 - accuracy: 0.8938 - val_loss: 0.2995 - val_accuracy: 0.8618\n",
      "Epoch 296/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3263 - accuracy: 0.8779 - val_loss: 0.2013 - val_accuracy: 0.8845\n",
      "Epoch 297/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3373 - accuracy: 0.8832 - val_loss: 0.2435 - val_accuracy: 0.8815\n",
      "Epoch 298/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3576 - accuracy: 0.8734 - val_loss: 0.1905 - val_accuracy: 0.8860\n",
      "Epoch 299/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3691 - accuracy: 0.8864 - val_loss: 0.3290 - val_accuracy: 0.8612\n",
      "Epoch 300/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3655 - accuracy: 0.8777 - val_loss: 0.3135 - val_accuracy: 0.8425\n",
      "Epoch 301/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3840 - accuracy: 0.8846 - val_loss: 0.3261 - val_accuracy: 0.8500\n",
      "Epoch 302/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4342 - accuracy: 0.8604 - val_loss: 0.2900 - val_accuracy: 0.8692\n",
      "Epoch 303/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3672 - accuracy: 0.8773 - val_loss: 0.2188 - val_accuracy: 0.8820\n",
      "Epoch 304/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3480 - accuracy: 0.8755 - val_loss: 0.2132 - val_accuracy: 0.8917\n",
      "Epoch 305/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4172 - accuracy: 0.8610 - val_loss: 0.2072 - val_accuracy: 0.8820\n",
      "Epoch 306/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4077 - accuracy: 0.8627 - val_loss: 0.2577 - val_accuracy: 0.8610\n",
      "Epoch 307/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3818 - accuracy: 0.8754 - val_loss: 0.2287 - val_accuracy: 0.8745\n",
      "Epoch 308/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4044 - accuracy: 0.8712 - val_loss: 0.2815 - val_accuracy: 0.8727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3995 - accuracy: 0.8668 - val_loss: 0.2180 - val_accuracy: 0.8860\n",
      "Epoch 310/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3521 - accuracy: 0.8780 - val_loss: 0.2240 - val_accuracy: 0.8850\n",
      "Epoch 311/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3536 - accuracy: 0.8804 - val_loss: 0.2320 - val_accuracy: 0.8730\n",
      "Epoch 312/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3484 - accuracy: 0.8804 - val_loss: 0.2301 - val_accuracy: 0.8852\n",
      "Epoch 313/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3455 - accuracy: 0.8783 - val_loss: 0.2536 - val_accuracy: 0.8640\n",
      "Epoch 314/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3398 - accuracy: 0.8828 - val_loss: 0.2980 - val_accuracy: 0.8618\n",
      "Epoch 315/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3358 - accuracy: 0.8908 - val_loss: 0.2742 - val_accuracy: 0.8583\n",
      "Epoch 316/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3454 - accuracy: 0.8737 - val_loss: 0.2907 - val_accuracy: 0.8530\n",
      "Epoch 317/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3511 - accuracy: 0.8844 - val_loss: 0.2855 - val_accuracy: 0.8580\n",
      "Epoch 318/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3369 - accuracy: 0.8800 - val_loss: 0.1794 - val_accuracy: 0.9095\n",
      "Epoch 319/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3203 - accuracy: 0.8857 - val_loss: 0.1886 - val_accuracy: 0.9022\n",
      "Epoch 320/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3688 - accuracy: 0.8794 - val_loss: 0.2370 - val_accuracy: 0.8765\n",
      "Epoch 321/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3516 - accuracy: 0.8795 - val_loss: 0.2441 - val_accuracy: 0.8625\n",
      "Epoch 322/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3534 - accuracy: 0.8836 - val_loss: 0.2919 - val_accuracy: 0.8590\n",
      "Epoch 323/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3751 - accuracy: 0.8687 - val_loss: 0.2385 - val_accuracy: 0.8735\n",
      "Epoch 324/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3465 - accuracy: 0.8759 - val_loss: 0.2058 - val_accuracy: 0.8885\n",
      "Epoch 325/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3309 - accuracy: 0.8832 - val_loss: 0.2350 - val_accuracy: 0.8767\n",
      "Epoch 326/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3765 - accuracy: 0.8628 - val_loss: 0.3297 - val_accuracy: 0.8255\n",
      "Epoch 327/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3653 - accuracy: 0.8864 - val_loss: 0.2765 - val_accuracy: 0.8712\n",
      "Epoch 328/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3599 - accuracy: 0.8821 - val_loss: 0.2784 - val_accuracy: 0.8652\n",
      "Epoch 329/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3376 - accuracy: 0.8768 - val_loss: 0.1717 - val_accuracy: 0.9050\n",
      "Epoch 330/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3258 - accuracy: 0.8862 - val_loss: 0.2529 - val_accuracy: 0.8765\n",
      "Epoch 331/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3207 - accuracy: 0.8898 - val_loss: 0.2989 - val_accuracy: 0.8583\n",
      "Epoch 332/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3228 - accuracy: 0.8912 - val_loss: 0.2752 - val_accuracy: 0.8683\n",
      "Epoch 333/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3383 - accuracy: 0.8891 - val_loss: 0.3096 - val_accuracy: 0.8702\n",
      "Epoch 334/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3469 - accuracy: 0.8801 - val_loss: 0.2181 - val_accuracy: 0.8817\n",
      "Epoch 335/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3214 - accuracy: 0.8861 - val_loss: 0.2290 - val_accuracy: 0.8850\n",
      "Epoch 336/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3048 - accuracy: 0.8938 - val_loss: 0.2333 - val_accuracy: 0.8925\n",
      "Epoch 337/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3243 - accuracy: 0.8928 - val_loss: 0.2622 - val_accuracy: 0.8740\n",
      "Epoch 338/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3441 - accuracy: 0.8886 - val_loss: 0.2000 - val_accuracy: 0.8950\n",
      "Epoch 339/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3515 - accuracy: 0.8730 - val_loss: 0.2158 - val_accuracy: 0.8795\n",
      "Epoch 340/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3200 - accuracy: 0.8875 - val_loss: 0.2416 - val_accuracy: 0.8813\n",
      "Epoch 341/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3013 - accuracy: 0.8934 - val_loss: 0.2610 - val_accuracy: 0.8745\n",
      "Epoch 342/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2901 - accuracy: 0.8919 - val_loss: 0.2000 - val_accuracy: 0.8938\n",
      "Epoch 343/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2996 - accuracy: 0.8981 - val_loss: 0.2125 - val_accuracy: 0.8885\n",
      "Epoch 344/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3030 - accuracy: 0.8861 - val_loss: 0.2167 - val_accuracy: 0.8878\n",
      "Epoch 345/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2877 - accuracy: 0.8991 - val_loss: 0.2258 - val_accuracy: 0.8838\n",
      "Epoch 346/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2908 - accuracy: 0.8966 - val_loss: 0.1972 - val_accuracy: 0.9028\n",
      "Epoch 347/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2923 - accuracy: 0.8953 - val_loss: 0.1992 - val_accuracy: 0.8910\n",
      "Epoch 348/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2948 - accuracy: 0.8981 - val_loss: 0.2142 - val_accuracy: 0.8960\n",
      "Epoch 349/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2777 - accuracy: 0.8995 - val_loss: 0.2163 - val_accuracy: 0.8923\n",
      "Epoch 350/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2822 - accuracy: 0.9009 - val_loss: 0.2308 - val_accuracy: 0.8825\n",
      "Epoch 351/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2876 - accuracy: 0.9026 - val_loss: 0.2266 - val_accuracy: 0.8898\n",
      "Epoch 352/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2737 - accuracy: 0.9019 - val_loss: 0.1927 - val_accuracy: 0.9047\n",
      "Epoch 353/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2771 - accuracy: 0.9052 - val_loss: 0.2604 - val_accuracy: 0.8792\n",
      "Epoch 354/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2849 - accuracy: 0.9024 - val_loss: 0.2454 - val_accuracy: 0.8800\n",
      "Epoch 355/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2902 - accuracy: 0.8939 - val_loss: 0.1800 - val_accuracy: 0.9145\n",
      "Epoch 356/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2843 - accuracy: 0.9058 - val_loss: 0.2219 - val_accuracy: 0.8860\n",
      "Epoch 357/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2895 - accuracy: 0.9011 - val_loss: 0.2910 - val_accuracy: 0.8650\n",
      "Epoch 358/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3262 - accuracy: 0.8892 - val_loss: 0.3359 - val_accuracy: 0.8512\n",
      "Epoch 359/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3349 - accuracy: 0.8845 - val_loss: 0.2476 - val_accuracy: 0.8767\n",
      "Epoch 360/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3465 - accuracy: 0.8926 - val_loss: 0.4869 - val_accuracy: 0.8048\n",
      "Epoch 361/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4231 - accuracy: 0.8707 - val_loss: 0.4079 - val_accuracy: 0.8173\n",
      "Epoch 362/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4151 - accuracy: 0.8668 - val_loss: 0.2546 - val_accuracy: 0.8780\n",
      "Epoch 363/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3696 - accuracy: 0.8706 - val_loss: 0.1897 - val_accuracy: 0.9070\n",
      "Epoch 364/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5184 - accuracy: 0.8675 - val_loss: 0.1782 - val_accuracy: 0.9147\n",
      "Epoch 365/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3785 - accuracy: 0.8838 - val_loss: 0.2023 - val_accuracy: 0.8923\n",
      "Epoch 366/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4187 - accuracy: 0.8682 - val_loss: 0.2113 - val_accuracy: 0.8990\n",
      "Epoch 367/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4344 - accuracy: 0.8813 - val_loss: 0.3008 - val_accuracy: 0.8583\n",
      "Epoch 368/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4433 - accuracy: 0.8476 - val_loss: 0.3028 - val_accuracy: 0.8465\n",
      "Epoch 369/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4254 - accuracy: 0.8677 - val_loss: 0.3724 - val_accuracy: 0.8317\n",
      "Epoch 370/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3784 - accuracy: 0.8835 - val_loss: 0.3644 - val_accuracy: 0.8303\n",
      "Epoch 371/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3926 - accuracy: 0.8707 - val_loss: 0.2230 - val_accuracy: 0.8827\n",
      "Epoch 372/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3381 - accuracy: 0.8932 - val_loss: 0.3839 - val_accuracy: 0.8365\n",
      "Epoch 373/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3771 - accuracy: 0.8855 - val_loss: 0.3510 - val_accuracy: 0.8405\n",
      "Epoch 374/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4211 - accuracy: 0.8585 - val_loss: 0.2012 - val_accuracy: 0.8903\n",
      "Epoch 375/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.3751 - accuracy: 0.8627 - val_loss: 0.2015 - val_accuracy: 0.8790\n",
      "Epoch 376/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3964 - accuracy: 0.8751 - val_loss: 0.2769 - val_accuracy: 0.8608\n",
      "Epoch 377/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3624 - accuracy: 0.8709 - val_loss: 0.3380 - val_accuracy: 0.8528\n",
      "Epoch 378/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3966 - accuracy: 0.8698 - val_loss: 0.3876 - val_accuracy: 0.8080\n",
      "Epoch 379/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4344 - accuracy: 0.8558 - val_loss: 0.3259 - val_accuracy: 0.8497\n",
      "Epoch 380/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3675 - accuracy: 0.8855 - val_loss: 0.2097 - val_accuracy: 0.8890\n",
      "Epoch 381/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3579 - accuracy: 0.8663 - val_loss: 0.2245 - val_accuracy: 0.8800\n",
      "Epoch 382/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3543 - accuracy: 0.8844 - val_loss: 0.2587 - val_accuracy: 0.8742\n",
      "Epoch 383/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3323 - accuracy: 0.8871 - val_loss: 0.2482 - val_accuracy: 0.8685\n",
      "Epoch 384/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3081 - accuracy: 0.8889 - val_loss: 0.2333 - val_accuracy: 0.8795\n",
      "Epoch 385/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2898 - accuracy: 0.8967 - val_loss: 0.2405 - val_accuracy: 0.8880\n",
      "Epoch 386/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2846 - accuracy: 0.8985 - val_loss: 0.2298 - val_accuracy: 0.8850\n",
      "Epoch 387/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2885 - accuracy: 0.8995 - val_loss: 0.2060 - val_accuracy: 0.8953\n",
      "Epoch 388/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3186 - accuracy: 0.8873 - val_loss: 0.2548 - val_accuracy: 0.8755\n",
      "Epoch 389/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2957 - accuracy: 0.8976 - val_loss: 0.2337 - val_accuracy: 0.8838\n",
      "Epoch 390/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2800 - accuracy: 0.9118 - val_loss: 0.2329 - val_accuracy: 0.8832\n",
      "Epoch 391/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2948 - accuracy: 0.8937 - val_loss: 0.1832 - val_accuracy: 0.9040\n",
      "Epoch 392/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2707 - accuracy: 0.9034 - val_loss: 0.2000 - val_accuracy: 0.9078\n",
      "Epoch 393/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2683 - accuracy: 0.9062 - val_loss: 0.1967 - val_accuracy: 0.8997\n",
      "Epoch 394/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2714 - accuracy: 0.9189 - val_loss: 0.2866 - val_accuracy: 0.8775\n",
      "Epoch 395/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3024 - accuracy: 0.8971 - val_loss: 0.2200 - val_accuracy: 0.8882\n",
      "Epoch 396/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3002 - accuracy: 0.8944 - val_loss: 0.2273 - val_accuracy: 0.8865\n",
      "Epoch 397/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2820 - accuracy: 0.9022 - val_loss: 0.1861 - val_accuracy: 0.9053\n",
      "Epoch 398/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2878 - accuracy: 0.8989 - val_loss: 0.1625 - val_accuracy: 0.9193\n",
      "Epoch 399/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2739 - accuracy: 0.9036 - val_loss: 0.2258 - val_accuracy: 0.8875\n",
      "Epoch 400/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2592 - accuracy: 0.9141 - val_loss: 0.2146 - val_accuracy: 0.8972\n",
      "Epoch 401/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2660 - accuracy: 0.9114 - val_loss: 0.2420 - val_accuracy: 0.8857\n",
      "Epoch 402/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3099 - accuracy: 0.9038 - val_loss: 0.2111 - val_accuracy: 0.8975\n",
      "Epoch 403/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2844 - accuracy: 0.9032 - val_loss: 0.1721 - val_accuracy: 0.9187\n",
      "Epoch 404/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3036 - accuracy: 0.9076 - val_loss: 0.2254 - val_accuracy: 0.8967\n",
      "Epoch 405/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2813 - accuracy: 0.9054 - val_loss: 0.2435 - val_accuracy: 0.8923\n",
      "Epoch 406/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2913 - accuracy: 0.9030 - val_loss: 0.2317 - val_accuracy: 0.8900\n",
      "Epoch 407/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3091 - accuracy: 0.9054 - val_loss: 0.3001 - val_accuracy: 0.8783\n",
      "Epoch 408/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3307 - accuracy: 0.8874 - val_loss: 0.1775 - val_accuracy: 0.9075\n",
      "Epoch 409/1000\n",
      "16000/16000 [==============================] - 0s 6us/step - loss: 0.3102 - accuracy: 0.9032 - val_loss: 0.2870 - val_accuracy: 0.8635\n",
      "Epoch 410/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.2784 - accuracy: 0.9061 - val_loss: 0.1965 - val_accuracy: 0.9062\n",
      "Epoch 411/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2738 - accuracy: 0.9054 - val_loss: 0.1600 - val_accuracy: 0.9227\n",
      "Epoch 412/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2927 - accuracy: 0.9085 - val_loss: 0.2386 - val_accuracy: 0.8925\n",
      "Epoch 413/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2840 - accuracy: 0.9064 - val_loss: 0.2731 - val_accuracy: 0.8775\n",
      "Epoch 414/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2827 - accuracy: 0.9018 - val_loss: 0.1924 - val_accuracy: 0.9053\n",
      "Epoch 415/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.2629 - accuracy: 0.9124 - val_loss: 0.1557 - val_accuracy: 0.9305\n",
      "Epoch 416/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2945 - accuracy: 0.9028 - val_loss: 0.1484 - val_accuracy: 0.9287\n",
      "Epoch 417/1000\n",
      "16000/16000 [==============================] - ETA: 0s - loss: 0.5115 - accuracy: 0.93 - 0s 4us/step - loss: 0.3237 - accuracy: 0.9112 - val_loss: 0.2458 - val_accuracy: 0.8900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 418/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3085 - accuracy: 0.8946 - val_loss: 0.2359 - val_accuracy: 0.8890\n",
      "Epoch 419/1000\n",
      "16000/16000 [==============================] - 0s 6us/step - loss: 0.3027 - accuracy: 0.8981 - val_loss: 0.2576 - val_accuracy: 0.8863\n",
      "Epoch 420/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.3165 - accuracy: 0.9051 - val_loss: 0.3383 - val_accuracy: 0.8453\n",
      "Epoch 421/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3517 - accuracy: 0.8949 - val_loss: 0.3888 - val_accuracy: 0.8320\n",
      "Epoch 422/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4065 - accuracy: 0.8635 - val_loss: 0.3378 - val_accuracy: 0.8410\n",
      "Epoch 423/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3584 - accuracy: 0.8867 - val_loss: 0.3191 - val_accuracy: 0.8712\n",
      "Epoch 424/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4082 - accuracy: 0.8745 - val_loss: 0.3244 - val_accuracy: 0.8510\n",
      "Epoch 425/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3502 - accuracy: 0.8896 - val_loss: 0.2999 - val_accuracy: 0.8733\n",
      "Epoch 426/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3393 - accuracy: 0.8865 - val_loss: 0.2651 - val_accuracy: 0.8742\n",
      "Epoch 427/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3256 - accuracy: 0.8926 - val_loss: 0.2050 - val_accuracy: 0.9038\n",
      "Epoch 428/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3010 - accuracy: 0.9026 - val_loss: 0.2760 - val_accuracy: 0.8742\n",
      "Epoch 429/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2941 - accuracy: 0.9107 - val_loss: 0.2400 - val_accuracy: 0.8890\n",
      "Epoch 430/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2858 - accuracy: 0.8962 - val_loss: 0.1779 - val_accuracy: 0.9185\n",
      "Epoch 431/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2640 - accuracy: 0.9150 - val_loss: 0.1970 - val_accuracy: 0.9025\n",
      "Epoch 432/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2462 - accuracy: 0.9189 - val_loss: 0.2367 - val_accuracy: 0.8928\n",
      "Epoch 433/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2797 - accuracy: 0.9093 - val_loss: 0.1913 - val_accuracy: 0.9038\n",
      "Epoch 434/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2941 - accuracy: 0.8976 - val_loss: 0.2005 - val_accuracy: 0.9045\n",
      "Epoch 435/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2940 - accuracy: 0.9033 - val_loss: 0.1634 - val_accuracy: 0.9170\n",
      "Epoch 436/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2675 - accuracy: 0.9153 - val_loss: 0.2190 - val_accuracy: 0.8930\n",
      "Epoch 437/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2614 - accuracy: 0.9092 - val_loss: 0.1754 - val_accuracy: 0.9180\n",
      "Epoch 438/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2515 - accuracy: 0.9101 - val_loss: 0.1663 - val_accuracy: 0.9183\n",
      "Epoch 439/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2737 - accuracy: 0.9169 - val_loss: 0.2200 - val_accuracy: 0.9028\n",
      "Epoch 440/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2602 - accuracy: 0.9184 - val_loss: 0.2062 - val_accuracy: 0.9030\n",
      "Epoch 441/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2616 - accuracy: 0.9103 - val_loss: 0.2199 - val_accuracy: 0.8992\n",
      "Epoch 442/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2881 - accuracy: 0.9147 - val_loss: 0.3860 - val_accuracy: 0.8595\n",
      "Epoch 443/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2986 - accuracy: 0.9075 - val_loss: 0.2645 - val_accuracy: 0.8692\n",
      "Epoch 444/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3319 - accuracy: 0.8854 - val_loss: 0.2165 - val_accuracy: 0.8940\n",
      "Epoch 445/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2925 - accuracy: 0.9026 - val_loss: 0.1557 - val_accuracy: 0.9285\n",
      "Epoch 446/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2805 - accuracy: 0.9085 - val_loss: 0.2165 - val_accuracy: 0.8965\n",
      "Epoch 447/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2774 - accuracy: 0.9082 - val_loss: 0.2314 - val_accuracy: 0.8882\n",
      "Epoch 448/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2777 - accuracy: 0.9087 - val_loss: 0.2270 - val_accuracy: 0.9003\n",
      "Epoch 449/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2983 - accuracy: 0.9033 - val_loss: 0.2441 - val_accuracy: 0.8890\n",
      "Epoch 450/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2867 - accuracy: 0.9054 - val_loss: 0.2974 - val_accuracy: 0.8740\n",
      "Epoch 451/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3020 - accuracy: 0.8984 - val_loss: 0.2396 - val_accuracy: 0.8840\n",
      "Epoch 452/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3745 - accuracy: 0.8849 - val_loss: 0.4541 - val_accuracy: 0.8375\n",
      "Epoch 453/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4797 - accuracy: 0.8618 - val_loss: 0.3824 - val_accuracy: 0.8353\n",
      "Epoch 454/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3904 - accuracy: 0.8706 - val_loss: 0.2540 - val_accuracy: 0.8597\n",
      "Epoch 455/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3799 - accuracy: 0.8864 - val_loss: 0.3423 - val_accuracy: 0.8543\n",
      "Epoch 456/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4044 - accuracy: 0.8742 - val_loss: 0.4101 - val_accuracy: 0.8253\n",
      "Epoch 457/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4046 - accuracy: 0.8708 - val_loss: 0.3187 - val_accuracy: 0.8680\n",
      "Epoch 458/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3437 - accuracy: 0.8859 - val_loss: 0.2692 - val_accuracy: 0.8673\n",
      "Epoch 459/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3324 - accuracy: 0.8936 - val_loss: 0.2463 - val_accuracy: 0.8788\n",
      "Epoch 460/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2973 - accuracy: 0.8981 - val_loss: 0.2422 - val_accuracy: 0.8875\n",
      "Epoch 461/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2699 - accuracy: 0.9082 - val_loss: 0.2122 - val_accuracy: 0.8923\n",
      "Epoch 462/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2756 - accuracy: 0.9091 - val_loss: 0.2943 - val_accuracy: 0.8660\n",
      "Epoch 463/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3231 - accuracy: 0.8895 - val_loss: 0.1844 - val_accuracy: 0.9028\n",
      "Epoch 464/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2832 - accuracy: 0.8958 - val_loss: 0.1845 - val_accuracy: 0.9095\n",
      "Epoch 465/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2987 - accuracy: 0.8989 - val_loss: 0.1768 - val_accuracy: 0.9035\n",
      "Epoch 466/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2744 - accuracy: 0.9019 - val_loss: 0.1895 - val_accuracy: 0.9105\n",
      "Epoch 467/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2725 - accuracy: 0.9193 - val_loss: 0.2139 - val_accuracy: 0.8963\n",
      "Epoch 468/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2840 - accuracy: 0.8941 - val_loss: 0.1719 - val_accuracy: 0.9197\n",
      "Epoch 469/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3481 - accuracy: 0.8883 - val_loss: 0.2964 - val_accuracy: 0.8630\n",
      "Epoch 470/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2855 - accuracy: 0.9112 - val_loss: 0.1915 - val_accuracy: 0.9130\n",
      "Epoch 471/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2738 - accuracy: 0.9122 - val_loss: 0.1915 - val_accuracy: 0.9060\n",
      "Epoch 472/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2702 - accuracy: 0.9070 - val_loss: 0.1695 - val_accuracy: 0.9130\n",
      "Epoch 473/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2571 - accuracy: 0.9129 - val_loss: 0.1967 - val_accuracy: 0.9053\n",
      "Epoch 474/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2370 - accuracy: 0.9234 - val_loss: 0.2458 - val_accuracy: 0.8898\n",
      "Epoch 475/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2533 - accuracy: 0.9176 - val_loss: 0.2266 - val_accuracy: 0.9047\n",
      "Epoch 476/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2488 - accuracy: 0.9151 - val_loss: 0.1741 - val_accuracy: 0.9143\n",
      "Epoch 477/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3482 - accuracy: 0.9069 - val_loss: 0.3192 - val_accuracy: 0.8690\n",
      "Epoch 478/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3646 - accuracy: 0.8817 - val_loss: 0.2393 - val_accuracy: 0.8857\n",
      "Epoch 479/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3035 - accuracy: 0.8900 - val_loss: 0.1744 - val_accuracy: 0.9130\n",
      "Epoch 480/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3848 - accuracy: 0.8702 - val_loss: 0.2892 - val_accuracy: 0.8545\n",
      "Epoch 481/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3355 - accuracy: 0.9000 - val_loss: 0.2748 - val_accuracy: 0.8865\n",
      "Epoch 482/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3085 - accuracy: 0.8992 - val_loss: 0.2393 - val_accuracy: 0.8838\n",
      "Epoch 483/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2738 - accuracy: 0.9061 - val_loss: 0.2107 - val_accuracy: 0.8940\n",
      "Epoch 484/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2458 - accuracy: 0.9097 - val_loss: 0.1945 - val_accuracy: 0.9082\n",
      "Epoch 485/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.2423 - accuracy: 0.9136 - val_loss: 0.1910 - val_accuracy: 0.9162\n",
      "Epoch 486/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2283 - accuracy: 0.9258 - val_loss: 0.1806 - val_accuracy: 0.9133\n",
      "Epoch 487/1000\n",
      "16000/16000 [==============================] - 0s 5us/step - loss: 0.2189 - accuracy: 0.9252 - val_loss: 0.1427 - val_accuracy: 0.9345\n",
      "Epoch 488/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2486 - accuracy: 0.9174 - val_loss: 0.1641 - val_accuracy: 0.9205\n",
      "Epoch 489/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2208 - accuracy: 0.9302 - val_loss: 0.2065 - val_accuracy: 0.9043\n",
      "Epoch 490/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2251 - accuracy: 0.9249 - val_loss: 0.1710 - val_accuracy: 0.9190\n",
      "Epoch 491/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2311 - accuracy: 0.9233 - val_loss: 0.1670 - val_accuracy: 0.9220\n",
      "Epoch 492/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2529 - accuracy: 0.9212 - val_loss: 0.2343 - val_accuracy: 0.8988\n",
      "Epoch 493/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2574 - accuracy: 0.9199 - val_loss: 0.2903 - val_accuracy: 0.8815\n",
      "Epoch 494/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2625 - accuracy: 0.9196 - val_loss: 0.2306 - val_accuracy: 0.9028\n",
      "Epoch 495/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2355 - accuracy: 0.9176 - val_loss: 0.1856 - val_accuracy: 0.9128\n",
      "Epoch 496/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2338 - accuracy: 0.9212 - val_loss: 0.2070 - val_accuracy: 0.9093\n",
      "Epoch 497/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2241 - accuracy: 0.9269 - val_loss: 0.1558 - val_accuracy: 0.9273\n",
      "Epoch 498/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2351 - accuracy: 0.9281 - val_loss: 0.2718 - val_accuracy: 0.8932\n",
      "Epoch 499/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2675 - accuracy: 0.9135 - val_loss: 0.2434 - val_accuracy: 0.8905\n",
      "Epoch 500/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2796 - accuracy: 0.9161 - val_loss: 0.3553 - val_accuracy: 0.8700\n",
      "Epoch 501/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2863 - accuracy: 0.9131 - val_loss: 0.2149 - val_accuracy: 0.8985\n",
      "Epoch 502/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2597 - accuracy: 0.9083 - val_loss: 0.1624 - val_accuracy: 0.9312\n",
      "Epoch 503/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2572 - accuracy: 0.9166 - val_loss: 0.1894 - val_accuracy: 0.9150\n",
      "Epoch 504/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2267 - accuracy: 0.9309 - val_loss: 0.2138 - val_accuracy: 0.9080\n",
      "Epoch 505/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2448 - accuracy: 0.9186 - val_loss: 0.2082 - val_accuracy: 0.9055\n",
      "Epoch 506/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2442 - accuracy: 0.9266 - val_loss: 0.2704 - val_accuracy: 0.8953\n",
      "Epoch 507/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2370 - accuracy: 0.9180 - val_loss: 0.1535 - val_accuracy: 0.9270\n",
      "Epoch 508/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2434 - accuracy: 0.9286 - val_loss: 0.2532 - val_accuracy: 0.8978\n",
      "Epoch 509/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2484 - accuracy: 0.9212 - val_loss: 0.2085 - val_accuracy: 0.9043\n",
      "Epoch 510/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2764 - accuracy: 0.9164 - val_loss: 0.1831 - val_accuracy: 0.9187\n",
      "Epoch 511/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3109 - accuracy: 0.9123 - val_loss: 0.3195 - val_accuracy: 0.8783\n",
      "Epoch 512/1000\n",
      "16000/16000 [==============================] - 0s 6us/step - loss: 0.3936 - accuracy: 0.8830 - val_loss: 0.2418 - val_accuracy: 0.8920\n",
      "Epoch 513/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.3439 - accuracy: 0.8924 - val_loss: 0.2244 - val_accuracy: 0.9018\n",
      "Epoch 514/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3238 - accuracy: 0.9044 - val_loss: 0.2865 - val_accuracy: 0.8802\n",
      "Epoch 515/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2887 - accuracy: 0.9103 - val_loss: 0.3856 - val_accuracy: 0.8480\n",
      "Epoch 516/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3359 - accuracy: 0.8944 - val_loss: 0.2242 - val_accuracy: 0.9003\n",
      "Epoch 517/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3530 - accuracy: 0.8941 - val_loss: 0.3399 - val_accuracy: 0.8620\n",
      "Epoch 518/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3001 - accuracy: 0.9117 - val_loss: 0.2169 - val_accuracy: 0.8947\n",
      "Epoch 519/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2868 - accuracy: 0.8994 - val_loss: 0.1977 - val_accuracy: 0.9110\n",
      "Epoch 520/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2469 - accuracy: 0.9206 - val_loss: 0.2098 - val_accuracy: 0.9035\n",
      "Epoch 521/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2406 - accuracy: 0.9201 - val_loss: 0.2070 - val_accuracy: 0.9047\n",
      "Epoch 522/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2290 - accuracy: 0.9219 - val_loss: 0.1931 - val_accuracy: 0.9137\n",
      "Epoch 523/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.2221 - accuracy: 0.9301 - val_loss: 0.1754 - val_accuracy: 0.9195\n",
      "Epoch 524/1000\n",
      "16000/16000 [==============================] - 0s 5us/step - loss: 0.2094 - accuracy: 0.9310 - val_loss: 0.1927 - val_accuracy: 0.9128\n",
      "Epoch 525/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2071 - accuracy: 0.9277 - val_loss: 0.1778 - val_accuracy: 0.9185\n",
      "Epoch 526/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2076 - accuracy: 0.9314 - val_loss: 0.2085 - val_accuracy: 0.9065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 527/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2127 - accuracy: 0.9398 - val_loss: 0.2267 - val_accuracy: 0.9022\n",
      "Epoch 528/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2637 - accuracy: 0.9103 - val_loss: 0.1362 - val_accuracy: 0.9370\n",
      "Epoch 529/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2271 - accuracy: 0.9233 - val_loss: 0.1509 - val_accuracy: 0.9280\n",
      "Epoch 530/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2137 - accuracy: 0.9323 - val_loss: 0.2276 - val_accuracy: 0.8997\n",
      "Epoch 531/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2300 - accuracy: 0.9281 - val_loss: 0.1968 - val_accuracy: 0.9175\n",
      "Epoch 532/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2098 - accuracy: 0.9286 - val_loss: 0.1734 - val_accuracy: 0.9225\n",
      "Epoch 533/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2072 - accuracy: 0.9311 - val_loss: 0.1903 - val_accuracy: 0.9147\n",
      "Epoch 534/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2213 - accuracy: 0.9325 - val_loss: 0.2088 - val_accuracy: 0.9105\n",
      "Epoch 535/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2425 - accuracy: 0.9204 - val_loss: 0.1779 - val_accuracy: 0.9218\n",
      "Epoch 536/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2164 - accuracy: 0.9376 - val_loss: 0.2185 - val_accuracy: 0.9032\n",
      "Epoch 537/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2177 - accuracy: 0.9302 - val_loss: 0.1860 - val_accuracy: 0.9180\n",
      "Epoch 538/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2024 - accuracy: 0.9293 - val_loss: 0.2123 - val_accuracy: 0.9050\n",
      "Epoch 539/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2083 - accuracy: 0.9358 - val_loss: 0.1983 - val_accuracy: 0.9137\n",
      "Epoch 540/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1950 - accuracy: 0.9344 - val_loss: 0.1876 - val_accuracy: 0.9193\n",
      "Epoch 541/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2039 - accuracy: 0.9329 - val_loss: 0.1730 - val_accuracy: 0.9227\n",
      "Epoch 542/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1983 - accuracy: 0.9375 - val_loss: 0.2025 - val_accuracy: 0.9168\n",
      "Epoch 543/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1937 - accuracy: 0.9376 - val_loss: 0.1643 - val_accuracy: 0.9258\n",
      "Epoch 544/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1872 - accuracy: 0.9358 - val_loss: 0.1440 - val_accuracy: 0.9395\n",
      "Epoch 545/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1844 - accuracy: 0.9427 - val_loss: 0.2085 - val_accuracy: 0.9137\n",
      "Epoch 546/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2042 - accuracy: 0.9348 - val_loss: 0.2003 - val_accuracy: 0.9130\n",
      "Epoch 547/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2197 - accuracy: 0.9293 - val_loss: 0.1765 - val_accuracy: 0.9250\n",
      "Epoch 548/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2134 - accuracy: 0.9429 - val_loss: 0.2799 - val_accuracy: 0.8970\n",
      "Epoch 549/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3199 - accuracy: 0.9191 - val_loss: 0.5263 - val_accuracy: 0.8250\n",
      "Epoch 550/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4591 - accuracy: 0.8630 - val_loss: 0.2422 - val_accuracy: 0.8892\n",
      "Epoch 551/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4449 - accuracy: 0.8622 - val_loss: 0.3087 - val_accuracy: 0.8493\n",
      "Epoch 552/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4206 - accuracy: 0.8601 - val_loss: 0.3102 - val_accuracy: 0.8465\n",
      "Epoch 553/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3737 - accuracy: 0.8649 - val_loss: 0.2883 - val_accuracy: 0.8637\n",
      "Epoch 554/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3256 - accuracy: 0.8918 - val_loss: 0.2650 - val_accuracy: 0.8792\n",
      "Epoch 555/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3136 - accuracy: 0.8901 - val_loss: 0.2214 - val_accuracy: 0.8865\n",
      "Epoch 556/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3037 - accuracy: 0.8969 - val_loss: 0.2604 - val_accuracy: 0.8840\n",
      "Epoch 557/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3647 - accuracy: 0.8774 - val_loss: 0.3459 - val_accuracy: 0.8315\n",
      "Epoch 558/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3464 - accuracy: 0.8850 - val_loss: 0.2455 - val_accuracy: 0.8765\n",
      "Epoch 559/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3398 - accuracy: 0.8909 - val_loss: 0.2341 - val_accuracy: 0.8835\n",
      "Epoch 560/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3292 - accuracy: 0.8818 - val_loss: 0.1781 - val_accuracy: 0.9260\n",
      "Epoch 561/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3549 - accuracy: 0.8996 - val_loss: 0.3152 - val_accuracy: 0.8580\n",
      "Epoch 562/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3078 - accuracy: 0.8967 - val_loss: 0.2263 - val_accuracy: 0.8892\n",
      "Epoch 563/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2843 - accuracy: 0.8986 - val_loss: 0.2333 - val_accuracy: 0.8900\n",
      "Epoch 564/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2788 - accuracy: 0.9163 - val_loss: 0.2293 - val_accuracy: 0.8932\n",
      "Epoch 565/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2900 - accuracy: 0.9032 - val_loss: 0.2002 - val_accuracy: 0.9022\n",
      "Epoch 566/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3113 - accuracy: 0.9133 - val_loss: 0.3039 - val_accuracy: 0.8685\n",
      "Epoch 567/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3359 - accuracy: 0.8877 - val_loss: 0.2658 - val_accuracy: 0.8817\n",
      "Epoch 568/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2874 - accuracy: 0.9056 - val_loss: 0.1784 - val_accuracy: 0.9137\n",
      "Epoch 569/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3035 - accuracy: 0.9041 - val_loss: 0.2368 - val_accuracy: 0.8870\n",
      "Epoch 570/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2460 - accuracy: 0.9179 - val_loss: 0.2323 - val_accuracy: 0.9043\n",
      "Epoch 571/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2872 - accuracy: 0.9049 - val_loss: 0.3142 - val_accuracy: 0.8680\n",
      "Epoch 572/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2909 - accuracy: 0.9184 - val_loss: 0.2775 - val_accuracy: 0.8770\n",
      "Epoch 573/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2827 - accuracy: 0.9053 - val_loss: 0.2080 - val_accuracy: 0.9035\n",
      "Epoch 574/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2389 - accuracy: 0.9194 - val_loss: 0.1723 - val_accuracy: 0.9212\n",
      "Epoch 575/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2495 - accuracy: 0.9158 - val_loss: 0.2024 - val_accuracy: 0.9085\n",
      "Epoch 576/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2332 - accuracy: 0.9253 - val_loss: 0.2103 - val_accuracy: 0.9025\n",
      "Epoch 577/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2340 - accuracy: 0.9261 - val_loss: 0.2453 - val_accuracy: 0.8885\n",
      "Epoch 578/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2328 - accuracy: 0.9260 - val_loss: 0.1846 - val_accuracy: 0.9087\n",
      "Epoch 579/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2254 - accuracy: 0.9158 - val_loss: 0.1525 - val_accuracy: 0.9283\n",
      "Epoch 580/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2232 - accuracy: 0.9309 - val_loss: 0.2346 - val_accuracy: 0.8975\n",
      "Epoch 581/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2380 - accuracy: 0.9166 - val_loss: 0.1459 - val_accuracy: 0.9320\n",
      "Epoch 582/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2273 - accuracy: 0.9281 - val_loss: 0.2047 - val_accuracy: 0.9170\n",
      "Epoch 583/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2196 - accuracy: 0.9260 - val_loss: 0.1575 - val_accuracy: 0.9277\n",
      "Epoch 584/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2126 - accuracy: 0.9302 - val_loss: 0.1986 - val_accuracy: 0.9140\n",
      "Epoch 585/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1939 - accuracy: 0.9362 - val_loss: 0.1624 - val_accuracy: 0.9283\n",
      "Epoch 586/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1919 - accuracy: 0.9436 - val_loss: 0.2003 - val_accuracy: 0.9150\n",
      "Epoch 587/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1972 - accuracy: 0.9325 - val_loss: 0.1716 - val_accuracy: 0.9277\n",
      "Epoch 588/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1912 - accuracy: 0.9421 - val_loss: 0.1560 - val_accuracy: 0.9367\n",
      "Epoch 589/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2013 - accuracy: 0.9324 - val_loss: 0.1295 - val_accuracy: 0.9492\n",
      "Epoch 590/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1926 - accuracy: 0.9396 - val_loss: 0.1822 - val_accuracy: 0.9243\n",
      "Epoch 591/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1867 - accuracy: 0.9424 - val_loss: 0.2214 - val_accuracy: 0.9085\n",
      "Epoch 592/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2070 - accuracy: 0.9341 - val_loss: 0.1946 - val_accuracy: 0.9165\n",
      "Epoch 593/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2039 - accuracy: 0.9265 - val_loss: 0.1456 - val_accuracy: 0.9373\n",
      "Epoch 594/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1872 - accuracy: 0.9414 - val_loss: 0.1530 - val_accuracy: 0.9360\n",
      "Epoch 595/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1794 - accuracy: 0.9436 - val_loss: 0.1645 - val_accuracy: 0.9330\n",
      "Epoch 596/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1891 - accuracy: 0.9424 - val_loss: 0.2210 - val_accuracy: 0.9162\n",
      "Epoch 597/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1993 - accuracy: 0.9344 - val_loss: 0.1543 - val_accuracy: 0.9350\n",
      "Epoch 598/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1865 - accuracy: 0.9432 - val_loss: 0.1570 - val_accuracy: 0.9375\n",
      "Epoch 599/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1905 - accuracy: 0.9391 - val_loss: 0.1375 - val_accuracy: 0.9457\n",
      "Epoch 600/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1785 - accuracy: 0.9403 - val_loss: 0.1484 - val_accuracy: 0.9415\n",
      "Epoch 601/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1841 - accuracy: 0.9403 - val_loss: 0.1362 - val_accuracy: 0.9477\n",
      "Epoch 602/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1751 - accuracy: 0.9473 - val_loss: 0.1732 - val_accuracy: 0.9317\n",
      "Epoch 603/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1750 - accuracy: 0.9462 - val_loss: 0.2281 - val_accuracy: 0.9060\n",
      "Epoch 604/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1989 - accuracy: 0.9344 - val_loss: 0.1843 - val_accuracy: 0.9260\n",
      "Epoch 605/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1758 - accuracy: 0.9388 - val_loss: 0.1490 - val_accuracy: 0.9385\n",
      "Epoch 606/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2006 - accuracy: 0.9424 - val_loss: 0.2210 - val_accuracy: 0.9140\n",
      "Epoch 607/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2134 - accuracy: 0.9321 - val_loss: 0.1718 - val_accuracy: 0.9293\n",
      "Epoch 608/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1971 - accuracy: 0.9407 - val_loss: 0.2339 - val_accuracy: 0.9080\n",
      "Epoch 609/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2229 - accuracy: 0.9387 - val_loss: 0.1807 - val_accuracy: 0.9273\n",
      "Epoch 610/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2359 - accuracy: 0.9208 - val_loss: 0.2176 - val_accuracy: 0.9125\n",
      "Epoch 611/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2143 - accuracy: 0.9311 - val_loss: 0.1382 - val_accuracy: 0.9402\n",
      "Epoch 612/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2081 - accuracy: 0.9364 - val_loss: 0.2265 - val_accuracy: 0.9105\n",
      "Epoch 613/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1965 - accuracy: 0.9369 - val_loss: 0.1312 - val_accuracy: 0.9463\n",
      "Epoch 614/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2041 - accuracy: 0.9321 - val_loss: 0.1421 - val_accuracy: 0.9448\n",
      "Epoch 615/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1931 - accuracy: 0.9442 - val_loss: 0.2090 - val_accuracy: 0.9222\n",
      "Epoch 616/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1841 - accuracy: 0.9441 - val_loss: 0.1355 - val_accuracy: 0.9467\n",
      "Epoch 617/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1725 - accuracy: 0.9496 - val_loss: 0.1962 - val_accuracy: 0.9200\n",
      "Epoch 618/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1993 - accuracy: 0.9324 - val_loss: 0.1663 - val_accuracy: 0.9290\n",
      "Epoch 619/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1859 - accuracy: 0.9426 - val_loss: 0.1550 - val_accuracy: 0.9377\n",
      "Epoch 620/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1829 - accuracy: 0.9423 - val_loss: 0.2063 - val_accuracy: 0.9153\n",
      "Epoch 621/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2059 - accuracy: 0.9302 - val_loss: 0.1567 - val_accuracy: 0.9360\n",
      "Epoch 622/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1917 - accuracy: 0.9466 - val_loss: 0.2182 - val_accuracy: 0.9175\n",
      "Epoch 623/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1993 - accuracy: 0.9437 - val_loss: 0.2458 - val_accuracy: 0.9047\n",
      "Epoch 624/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2406 - accuracy: 0.9314 - val_loss: 0.1527 - val_accuracy: 0.9377\n",
      "Epoch 625/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2429 - accuracy: 0.9269 - val_loss: 0.2000 - val_accuracy: 0.9243\n",
      "Epoch 626/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2648 - accuracy: 0.9151 - val_loss: 0.1670 - val_accuracy: 0.9308\n",
      "Epoch 627/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1949 - accuracy: 0.9457 - val_loss: 0.1674 - val_accuracy: 0.9390\n",
      "Epoch 628/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1795 - accuracy: 0.9457 - val_loss: 0.2057 - val_accuracy: 0.9202\n",
      "Epoch 629/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1695 - accuracy: 0.9471 - val_loss: 0.1328 - val_accuracy: 0.9498\n",
      "Epoch 630/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1744 - accuracy: 0.9455 - val_loss: 0.1503 - val_accuracy: 0.9438\n",
      "Epoch 631/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1670 - accuracy: 0.9492 - val_loss: 0.1613 - val_accuracy: 0.9335\n",
      "Epoch 632/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1687 - accuracy: 0.9496 - val_loss: 0.1567 - val_accuracy: 0.9417\n",
      "Epoch 633/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1608 - accuracy: 0.9460 - val_loss: 0.1472 - val_accuracy: 0.9413\n",
      "Epoch 634/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1714 - accuracy: 0.9476 - val_loss: 0.1901 - val_accuracy: 0.9227\n",
      "Epoch 635/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1759 - accuracy: 0.9426 - val_loss: 0.1631 - val_accuracy: 0.9337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 636/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2019 - accuracy: 0.9457 - val_loss: 0.1534 - val_accuracy: 0.9388\n",
      "Epoch 637/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2119 - accuracy: 0.9301 - val_loss: 0.1766 - val_accuracy: 0.9310\n",
      "Epoch 638/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1919 - accuracy: 0.9406 - val_loss: 0.1787 - val_accuracy: 0.9290\n",
      "Epoch 639/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1960 - accuracy: 0.9416 - val_loss: 0.1802 - val_accuracy: 0.9262\n",
      "Epoch 640/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1716 - accuracy: 0.9481 - val_loss: 0.1608 - val_accuracy: 0.9355\n",
      "Epoch 641/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1671 - accuracy: 0.9457 - val_loss: 0.1423 - val_accuracy: 0.9460\n",
      "Epoch 642/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1632 - accuracy: 0.9495 - val_loss: 0.1364 - val_accuracy: 0.9480\n",
      "Epoch 643/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1649 - accuracy: 0.9449 - val_loss: 0.1382 - val_accuracy: 0.9463\n",
      "Epoch 644/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.1905 - accuracy: 0.9437 - val_loss: 0.2620 - val_accuracy: 0.9078\n",
      "Epoch 645/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2167 - accuracy: 0.9320 - val_loss: 0.1318 - val_accuracy: 0.9465\n",
      "Epoch 646/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1804 - accuracy: 0.9436 - val_loss: 0.1816 - val_accuracy: 0.9293\n",
      "Epoch 647/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1926 - accuracy: 0.9376 - val_loss: 0.1512 - val_accuracy: 0.9410\n",
      "Epoch 648/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1777 - accuracy: 0.9498 - val_loss: 0.1744 - val_accuracy: 0.9360\n",
      "Epoch 649/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1817 - accuracy: 0.9418 - val_loss: 0.1453 - val_accuracy: 0.9405\n",
      "Epoch 650/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2087 - accuracy: 0.9350 - val_loss: 0.1863 - val_accuracy: 0.9300\n",
      "Epoch 651/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2592 - accuracy: 0.9301 - val_loss: 0.1604 - val_accuracy: 0.9317\n",
      "Epoch 652/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2195 - accuracy: 0.9310 - val_loss: 0.1951 - val_accuracy: 0.9172\n",
      "Epoch 653/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2046 - accuracy: 0.9336 - val_loss: 0.2080 - val_accuracy: 0.9105\n",
      "Epoch 654/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2085 - accuracy: 0.9367 - val_loss: 0.1415 - val_accuracy: 0.9442\n",
      "Epoch 655/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1976 - accuracy: 0.9397 - val_loss: 0.2352 - val_accuracy: 0.9147\n",
      "Epoch 656/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.2046 - accuracy: 0.9379 - val_loss: 0.1612 - val_accuracy: 0.9362\n",
      "Epoch 657/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1766 - accuracy: 0.9417 - val_loss: 0.1558 - val_accuracy: 0.9452\n",
      "Epoch 658/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1808 - accuracy: 0.9509 - val_loss: 0.1950 - val_accuracy: 0.9265\n",
      "Epoch 659/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1908 - accuracy: 0.9381 - val_loss: 0.1696 - val_accuracy: 0.9325\n",
      "Epoch 660/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1865 - accuracy: 0.9392 - val_loss: 0.1081 - val_accuracy: 0.9653\n",
      "Epoch 661/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2410 - accuracy: 0.9326 - val_loss: 0.1451 - val_accuracy: 0.9430\n",
      "Epoch 662/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2112 - accuracy: 0.9331 - val_loss: 0.1682 - val_accuracy: 0.9375\n",
      "Epoch 663/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2385 - accuracy: 0.9362 - val_loss: 0.2314 - val_accuracy: 0.9178\n",
      "Epoch 664/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3095 - accuracy: 0.9239 - val_loss: 0.2564 - val_accuracy: 0.9112\n",
      "Epoch 665/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4117 - accuracy: 0.9072 - val_loss: 0.3426 - val_accuracy: 0.8813\n",
      "Epoch 666/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4596 - accuracy: 0.8846 - val_loss: 0.2361 - val_accuracy: 0.9130\n",
      "Epoch 667/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6330 - accuracy: 0.8658 - val_loss: 0.6053 - val_accuracy: 0.7878\n",
      "Epoch 668/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5276 - accuracy: 0.8639 - val_loss: 0.4092 - val_accuracy: 0.8478\n",
      "Epoch 669/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6369 - accuracy: 0.8668 - val_loss: 0.3775 - val_accuracy: 0.8487\n",
      "Epoch 670/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4840 - accuracy: 0.8809 - val_loss: 0.2984 - val_accuracy: 0.8752\n",
      "Epoch 671/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6999 - accuracy: 0.8792 - val_loss: 0.2725 - val_accuracy: 0.8965\n",
      "Epoch 672/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6984 - accuracy: 0.8456 - val_loss: 0.5075 - val_accuracy: 0.8460\n",
      "Epoch 673/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6377 - accuracy: 0.8706 - val_loss: 0.3488 - val_accuracy: 0.8410\n",
      "Epoch 674/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4006 - accuracy: 0.8818 - val_loss: 0.2424 - val_accuracy: 0.8855\n",
      "Epoch 675/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3148 - accuracy: 0.8971 - val_loss: 0.2423 - val_accuracy: 0.8915\n",
      "Epoch 676/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3359 - accuracy: 0.8908 - val_loss: 0.2387 - val_accuracy: 0.8900\n",
      "Epoch 677/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2881 - accuracy: 0.9181 - val_loss: 0.2363 - val_accuracy: 0.8980\n",
      "Epoch 678/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2670 - accuracy: 0.9173 - val_loss: 0.2131 - val_accuracy: 0.9103\n",
      "Epoch 679/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2849 - accuracy: 0.9155 - val_loss: 0.3114 - val_accuracy: 0.8783\n",
      "Epoch 680/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3105 - accuracy: 0.9074 - val_loss: 0.2117 - val_accuracy: 0.9028\n",
      "Epoch 681/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2970 - accuracy: 0.9075 - val_loss: 0.1892 - val_accuracy: 0.9110\n",
      "Epoch 682/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2754 - accuracy: 0.9187 - val_loss: 0.1659 - val_accuracy: 0.9245\n",
      "Epoch 683/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2514 - accuracy: 0.9342 - val_loss: 0.2418 - val_accuracy: 0.9010\n",
      "Epoch 684/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2583 - accuracy: 0.9149 - val_loss: 0.1598 - val_accuracy: 0.9290\n",
      "Epoch 685/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2888 - accuracy: 0.9170 - val_loss: 0.2812 - val_accuracy: 0.8813\n",
      "Epoch 686/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2672 - accuracy: 0.9147 - val_loss: 0.1626 - val_accuracy: 0.9227\n",
      "Epoch 687/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2542 - accuracy: 0.9315 - val_loss: 0.2070 - val_accuracy: 0.9112\n",
      "Epoch 688/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2587 - accuracy: 0.9170 - val_loss: 0.1459 - val_accuracy: 0.9360\n",
      "Epoch 689/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3411 - accuracy: 0.9000 - val_loss: 0.2644 - val_accuracy: 0.8848\n",
      "Epoch 690/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3488 - accuracy: 0.9139 - val_loss: 0.3026 - val_accuracy: 0.8740\n",
      "Epoch 691/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2951 - accuracy: 0.9122 - val_loss: 0.1687 - val_accuracy: 0.9193\n",
      "Epoch 692/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2566 - accuracy: 0.9129 - val_loss: 0.1902 - val_accuracy: 0.9128\n",
      "Epoch 693/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2470 - accuracy: 0.9380 - val_loss: 0.1967 - val_accuracy: 0.9137\n",
      "Epoch 694/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2542 - accuracy: 0.9129 - val_loss: 0.1984 - val_accuracy: 0.9150\n",
      "Epoch 695/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2241 - accuracy: 0.9412 - val_loss: 0.1855 - val_accuracy: 0.9208\n",
      "Epoch 696/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2418 - accuracy: 0.9194 - val_loss: 0.1712 - val_accuracy: 0.9270\n",
      "Epoch 697/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2322 - accuracy: 0.9354 - val_loss: 0.2031 - val_accuracy: 0.9165\n",
      "Epoch 698/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2319 - accuracy: 0.9336 - val_loss: 0.1914 - val_accuracy: 0.9162\n",
      "Epoch 699/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2240 - accuracy: 0.9248 - val_loss: 0.1531 - val_accuracy: 0.9283\n",
      "Epoch 700/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2156 - accuracy: 0.9318 - val_loss: 0.1865 - val_accuracy: 0.9158\n",
      "Epoch 701/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1935 - accuracy: 0.9369 - val_loss: 0.1328 - val_accuracy: 0.9445\n",
      "Epoch 702/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2118 - accuracy: 0.9399 - val_loss: 0.1802 - val_accuracy: 0.9250\n",
      "Epoch 703/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1908 - accuracy: 0.9462 - val_loss: 0.1942 - val_accuracy: 0.9185\n",
      "Epoch 704/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1941 - accuracy: 0.9364 - val_loss: 0.1261 - val_accuracy: 0.9423\n",
      "Epoch 705/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1918 - accuracy: 0.9396 - val_loss: 0.1944 - val_accuracy: 0.9178\n",
      "Epoch 706/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2350 - accuracy: 0.9291 - val_loss: 0.1893 - val_accuracy: 0.9170\n",
      "Epoch 707/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1999 - accuracy: 0.9396 - val_loss: 0.1835 - val_accuracy: 0.9205\n",
      "Epoch 708/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2134 - accuracy: 0.9365 - val_loss: 0.1350 - val_accuracy: 0.9408\n",
      "Epoch 709/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1923 - accuracy: 0.9380 - val_loss: 0.1800 - val_accuracy: 0.9227\n",
      "Epoch 710/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1843 - accuracy: 0.9445 - val_loss: 0.1469 - val_accuracy: 0.9380\n",
      "Epoch 711/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1761 - accuracy: 0.9477 - val_loss: 0.1688 - val_accuracy: 0.9270\n",
      "Epoch 712/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1722 - accuracy: 0.9417 - val_loss: 0.1217 - val_accuracy: 0.9465\n",
      "Epoch 713/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1736 - accuracy: 0.9529 - val_loss: 0.1859 - val_accuracy: 0.9235\n",
      "Epoch 714/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1765 - accuracy: 0.9418 - val_loss: 0.1307 - val_accuracy: 0.9423\n",
      "Epoch 715/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1676 - accuracy: 0.9478 - val_loss: 0.1591 - val_accuracy: 0.9348\n",
      "Epoch 716/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1731 - accuracy: 0.9475 - val_loss: 0.1552 - val_accuracy: 0.9348\n",
      "Epoch 717/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1749 - accuracy: 0.9398 - val_loss: 0.1229 - val_accuracy: 0.9465\n",
      "Epoch 718/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1767 - accuracy: 0.9477 - val_loss: 0.1695 - val_accuracy: 0.9287\n",
      "Epoch 719/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1727 - accuracy: 0.9508 - val_loss: 0.1338 - val_accuracy: 0.9417\n",
      "Epoch 720/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1850 - accuracy: 0.9404 - val_loss: 0.1735 - val_accuracy: 0.9277\n",
      "Epoch 721/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1891 - accuracy: 0.9433 - val_loss: 0.1407 - val_accuracy: 0.9390\n",
      "Epoch 722/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1611 - accuracy: 0.9473 - val_loss: 0.1423 - val_accuracy: 0.9408\n",
      "Epoch 723/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1680 - accuracy: 0.9452 - val_loss: 0.1296 - val_accuracy: 0.9477\n",
      "Epoch 724/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1779 - accuracy: 0.9471 - val_loss: 0.1711 - val_accuracy: 0.9287\n",
      "Epoch 725/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1670 - accuracy: 0.9509 - val_loss: 0.1570 - val_accuracy: 0.9367\n",
      "Epoch 726/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1629 - accuracy: 0.9478 - val_loss: 0.1492 - val_accuracy: 0.9413\n",
      "Epoch 727/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1665 - accuracy: 0.9470 - val_loss: 0.1420 - val_accuracy: 0.9415\n",
      "Epoch 728/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1702 - accuracy: 0.9469 - val_loss: 0.1636 - val_accuracy: 0.9302\n",
      "Epoch 729/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1808 - accuracy: 0.9433 - val_loss: 0.2070 - val_accuracy: 0.9202\n",
      "Epoch 730/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1901 - accuracy: 0.9424 - val_loss: 0.1693 - val_accuracy: 0.9312\n",
      "Epoch 731/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2140 - accuracy: 0.9415 - val_loss: 0.1825 - val_accuracy: 0.9227\n",
      "Epoch 732/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1956 - accuracy: 0.9341 - val_loss: 0.1520 - val_accuracy: 0.9375\n",
      "Epoch 733/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1754 - accuracy: 0.9493 - val_loss: 0.1627 - val_accuracy: 0.9352\n",
      "Epoch 734/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1638 - accuracy: 0.9483 - val_loss: 0.1380 - val_accuracy: 0.9410\n",
      "Epoch 735/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1659 - accuracy: 0.9489 - val_loss: 0.1406 - val_accuracy: 0.9460\n",
      "Epoch 736/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1600 - accuracy: 0.9534 - val_loss: 0.1466 - val_accuracy: 0.9390\n",
      "Epoch 737/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1571 - accuracy: 0.9487 - val_loss: 0.1208 - val_accuracy: 0.9490\n",
      "Epoch 738/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1584 - accuracy: 0.9524 - val_loss: 0.1338 - val_accuracy: 0.9467\n",
      "Epoch 739/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1533 - accuracy: 0.9489 - val_loss: 0.1260 - val_accuracy: 0.9477\n",
      "Epoch 740/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1677 - accuracy: 0.9475 - val_loss: 0.1777 - val_accuracy: 0.9290\n",
      "Epoch 741/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1737 - accuracy: 0.9523 - val_loss: 0.1525 - val_accuracy: 0.9342\n",
      "Epoch 742/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1881 - accuracy: 0.9420 - val_loss: 0.2097 - val_accuracy: 0.9125\n",
      "Epoch 743/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2053 - accuracy: 0.9430 - val_loss: 0.1458 - val_accuracy: 0.9405\n",
      "Epoch 744/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1879 - accuracy: 0.9424 - val_loss: 0.1891 - val_accuracy: 0.9237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 745/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2108 - accuracy: 0.9368 - val_loss: 0.2036 - val_accuracy: 0.9185\n",
      "Epoch 746/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.2726 - accuracy: 0.9315 - val_loss: 0.1773 - val_accuracy: 0.9283\n",
      "Epoch 747/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4534 - accuracy: 0.8979 - val_loss: 0.3996 - val_accuracy: 0.8723\n",
      "Epoch 748/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4313 - accuracy: 0.8867 - val_loss: 0.3182 - val_accuracy: 0.8800\n",
      "Epoch 749/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3767 - accuracy: 0.8948 - val_loss: 0.3036 - val_accuracy: 0.8770\n",
      "Epoch 750/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4530 - accuracy: 0.8819 - val_loss: 0.3230 - val_accuracy: 0.8820\n",
      "Epoch 751/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4075 - accuracy: 0.8857 - val_loss: 0.2023 - val_accuracy: 0.9137\n",
      "Epoch 752/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3155 - accuracy: 0.9149 - val_loss: 0.2940 - val_accuracy: 0.8848\n",
      "Epoch 753/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2821 - accuracy: 0.9160 - val_loss: 0.2062 - val_accuracy: 0.9128\n",
      "Epoch 754/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2694 - accuracy: 0.9088 - val_loss: 0.1721 - val_accuracy: 0.9220\n",
      "Epoch 755/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2606 - accuracy: 0.9306 - val_loss: 0.2311 - val_accuracy: 0.9015\n",
      "Epoch 756/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2365 - accuracy: 0.9211 - val_loss: 0.1692 - val_accuracy: 0.9258\n",
      "Epoch 757/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2124 - accuracy: 0.9358 - val_loss: 0.1776 - val_accuracy: 0.9212\n",
      "Epoch 758/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2059 - accuracy: 0.9357 - val_loss: 0.1643 - val_accuracy: 0.9252\n",
      "Epoch 759/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1945 - accuracy: 0.9324 - val_loss: 0.1307 - val_accuracy: 0.9430\n",
      "Epoch 760/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2047 - accuracy: 0.9423 - val_loss: 0.2213 - val_accuracy: 0.9068\n",
      "Epoch 761/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2054 - accuracy: 0.9318 - val_loss: 0.1703 - val_accuracy: 0.9295\n",
      "Epoch 762/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1892 - accuracy: 0.9404 - val_loss: 0.1583 - val_accuracy: 0.9337\n",
      "Epoch 763/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2063 - accuracy: 0.9391 - val_loss: 0.2172 - val_accuracy: 0.9153\n",
      "Epoch 764/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2088 - accuracy: 0.9309 - val_loss: 0.1563 - val_accuracy: 0.9350\n",
      "Epoch 765/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2331 - accuracy: 0.9415 - val_loss: 0.2705 - val_accuracy: 0.8940\n",
      "Epoch 766/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3555 - accuracy: 0.8944 - val_loss: 0.2124 - val_accuracy: 0.9122\n",
      "Epoch 767/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3903 - accuracy: 0.8986 - val_loss: 0.2235 - val_accuracy: 0.9025\n",
      "Epoch 768/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3533 - accuracy: 0.8965 - val_loss: 0.2407 - val_accuracy: 0.8938\n",
      "Epoch 769/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2863 - accuracy: 0.9075 - val_loss: 0.2000 - val_accuracy: 0.9095\n",
      "Epoch 770/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2680 - accuracy: 0.9128 - val_loss: 0.1894 - val_accuracy: 0.9105\n",
      "Epoch 771/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2343 - accuracy: 0.9254 - val_loss: 0.1654 - val_accuracy: 0.9247\n",
      "Epoch 772/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2252 - accuracy: 0.9258 - val_loss: 0.1983 - val_accuracy: 0.9120\n",
      "Epoch 773/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2330 - accuracy: 0.9277 - val_loss: 0.2433 - val_accuracy: 0.8997\n",
      "Epoch 774/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2241 - accuracy: 0.9277 - val_loss: 0.1511 - val_accuracy: 0.9260\n",
      "Epoch 775/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1959 - accuracy: 0.9344 - val_loss: 0.1423 - val_accuracy: 0.9365\n",
      "Epoch 776/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1940 - accuracy: 0.9431 - val_loss: 0.1684 - val_accuracy: 0.9280\n",
      "Epoch 777/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1730 - accuracy: 0.9452 - val_loss: 0.1574 - val_accuracy: 0.9317\n",
      "Epoch 778/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1807 - accuracy: 0.9469 - val_loss: 0.1989 - val_accuracy: 0.9250\n",
      "Epoch 779/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2240 - accuracy: 0.9316 - val_loss: 0.2071 - val_accuracy: 0.9200\n",
      "Epoch 780/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1888 - accuracy: 0.9511 - val_loss: 0.1228 - val_accuracy: 0.9520\n",
      "Epoch 781/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1942 - accuracy: 0.9379 - val_loss: 0.1867 - val_accuracy: 0.9225\n",
      "Epoch 782/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1864 - accuracy: 0.9376 - val_loss: 0.1524 - val_accuracy: 0.9358\n",
      "Epoch 783/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1789 - accuracy: 0.9519 - val_loss: 0.1779 - val_accuracy: 0.9317\n",
      "Epoch 784/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1987 - accuracy: 0.9325 - val_loss: 0.1135 - val_accuracy: 0.9535\n",
      "Epoch 785/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1791 - accuracy: 0.9517 - val_loss: 0.2297 - val_accuracy: 0.9165\n",
      "Epoch 786/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1876 - accuracy: 0.9459 - val_loss: 0.1119 - val_accuracy: 0.9560\n",
      "Epoch 787/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1921 - accuracy: 0.9409 - val_loss: 0.1819 - val_accuracy: 0.9237\n",
      "Epoch 788/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1839 - accuracy: 0.9423 - val_loss: 0.1471 - val_accuracy: 0.9400\n",
      "Epoch 789/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1740 - accuracy: 0.9519 - val_loss: 0.1575 - val_accuracy: 0.9355\n",
      "Epoch 790/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1656 - accuracy: 0.9454 - val_loss: 0.1397 - val_accuracy: 0.9430\n",
      "Epoch 791/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1601 - accuracy: 0.9493 - val_loss: 0.1434 - val_accuracy: 0.9435\n",
      "Epoch 792/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1631 - accuracy: 0.9539 - val_loss: 0.1877 - val_accuracy: 0.9270\n",
      "Epoch 793/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1711 - accuracy: 0.9457 - val_loss: 0.1527 - val_accuracy: 0.9390\n",
      "Epoch 794/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1584 - accuracy: 0.9519 - val_loss: 0.1502 - val_accuracy: 0.9435\n",
      "Epoch 795/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1625 - accuracy: 0.9477 - val_loss: 0.1345 - val_accuracy: 0.9467\n",
      "Epoch 796/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1594 - accuracy: 0.9540 - val_loss: 0.1896 - val_accuracy: 0.9280\n",
      "Epoch 797/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1807 - accuracy: 0.9451 - val_loss: 0.1594 - val_accuracy: 0.9388\n",
      "Epoch 798/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1656 - accuracy: 0.9462 - val_loss: 0.1410 - val_accuracy: 0.9473\n",
      "Epoch 799/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2605 - accuracy: 0.9346 - val_loss: 0.2790 - val_accuracy: 0.9075\n",
      "Epoch 800/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2543 - accuracy: 0.9197 - val_loss: 0.1519 - val_accuracy: 0.9358\n",
      "Epoch 801/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2064 - accuracy: 0.9431 - val_loss: 0.2110 - val_accuracy: 0.9187\n",
      "Epoch 802/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2012 - accuracy: 0.9383 - val_loss: 0.1497 - val_accuracy: 0.9415\n",
      "Epoch 803/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1883 - accuracy: 0.9428 - val_loss: 0.1393 - val_accuracy: 0.9488\n",
      "Epoch 804/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1696 - accuracy: 0.9507 - val_loss: 0.1810 - val_accuracy: 0.9342\n",
      "Epoch 805/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1668 - accuracy: 0.9499 - val_loss: 0.1732 - val_accuracy: 0.9345\n",
      "Epoch 806/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1712 - accuracy: 0.9519 - val_loss: 0.1515 - val_accuracy: 0.9455\n",
      "Epoch 807/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1772 - accuracy: 0.9425 - val_loss: 0.1343 - val_accuracy: 0.9500\n",
      "Epoch 808/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1603 - accuracy: 0.9527 - val_loss: 0.1778 - val_accuracy: 0.9317\n",
      "Epoch 809/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1529 - accuracy: 0.9519 - val_loss: 0.1376 - val_accuracy: 0.9475\n",
      "Epoch 810/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1458 - accuracy: 0.9563 - val_loss: 0.1588 - val_accuracy: 0.9417\n",
      "Epoch 811/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1443 - accuracy: 0.9524 - val_loss: 0.1436 - val_accuracy: 0.9473\n",
      "Epoch 812/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1588 - accuracy: 0.9528 - val_loss: 0.1318 - val_accuracy: 0.9528\n",
      "Epoch 813/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1847 - accuracy: 0.9470 - val_loss: 0.1963 - val_accuracy: 0.9252\n",
      "Epoch 814/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1611 - accuracy: 0.9484 - val_loss: 0.1476 - val_accuracy: 0.9448\n",
      "Epoch 815/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1593 - accuracy: 0.9519 - val_loss: 0.1587 - val_accuracy: 0.9425\n",
      "Epoch 816/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1449 - accuracy: 0.9555 - val_loss: 0.1425 - val_accuracy: 0.9467\n",
      "Epoch 817/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1348 - accuracy: 0.9580 - val_loss: 0.1501 - val_accuracy: 0.9455\n",
      "Epoch 818/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1434 - accuracy: 0.9546 - val_loss: 0.1448 - val_accuracy: 0.9477\n",
      "Epoch 819/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1680 - accuracy: 0.9553 - val_loss: 0.1959 - val_accuracy: 0.9315\n",
      "Epoch 820/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1675 - accuracy: 0.9476 - val_loss: 0.1400 - val_accuracy: 0.9455\n",
      "Epoch 821/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1543 - accuracy: 0.9572 - val_loss: 0.1942 - val_accuracy: 0.9300\n",
      "Epoch 822/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1859 - accuracy: 0.9421 - val_loss: 0.1762 - val_accuracy: 0.9367\n",
      "Epoch 823/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1776 - accuracy: 0.9507 - val_loss: 0.2138 - val_accuracy: 0.9222\n",
      "Epoch 824/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1848 - accuracy: 0.9435 - val_loss: 0.1453 - val_accuracy: 0.9410\n",
      "Epoch 825/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1768 - accuracy: 0.9507 - val_loss: 0.1822 - val_accuracy: 0.9320\n",
      "Epoch 826/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1690 - accuracy: 0.9455 - val_loss: 0.1436 - val_accuracy: 0.9470\n",
      "Epoch 827/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1461 - accuracy: 0.9556 - val_loss: 0.1409 - val_accuracy: 0.9495\n",
      "Epoch 828/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2047 - accuracy: 0.9479 - val_loss: 0.2543 - val_accuracy: 0.9150\n",
      "Epoch 829/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2521 - accuracy: 0.9254 - val_loss: 0.1559 - val_accuracy: 0.9390\n",
      "Epoch 830/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2405 - accuracy: 0.9335 - val_loss: 0.2114 - val_accuracy: 0.9287\n",
      "Epoch 831/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2250 - accuracy: 0.9439 - val_loss: 0.3019 - val_accuracy: 0.8940\n",
      "Epoch 832/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2724 - accuracy: 0.9182 - val_loss: 0.2055 - val_accuracy: 0.9227\n",
      "Epoch 833/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2581 - accuracy: 0.9389 - val_loss: 0.1964 - val_accuracy: 0.9275\n",
      "Epoch 834/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2423 - accuracy: 0.9266 - val_loss: 0.2117 - val_accuracy: 0.9185\n",
      "Epoch 835/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2733 - accuracy: 0.9361 - val_loss: 0.3113 - val_accuracy: 0.9025\n",
      "Epoch 836/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4352 - accuracy: 0.9066 - val_loss: 0.4377 - val_accuracy: 0.8687\n",
      "Epoch 837/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4466 - accuracy: 0.8903 - val_loss: 0.2652 - val_accuracy: 0.9000\n",
      "Epoch 838/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3956 - accuracy: 0.9072 - val_loss: 0.2797 - val_accuracy: 0.8915\n",
      "Epoch 839/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3073 - accuracy: 0.9084 - val_loss: 0.2931 - val_accuracy: 0.8957\n",
      "Epoch 840/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2967 - accuracy: 0.9129 - val_loss: 0.2164 - val_accuracy: 0.9137\n",
      "Epoch 841/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2781 - accuracy: 0.9182 - val_loss: 0.1753 - val_accuracy: 0.9250\n",
      "Epoch 842/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2562 - accuracy: 0.9312 - val_loss: 0.2531 - val_accuracy: 0.9000\n",
      "Epoch 843/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2267 - accuracy: 0.9259 - val_loss: 0.1479 - val_accuracy: 0.9373\n",
      "Epoch 844/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2151 - accuracy: 0.9386 - val_loss: 0.2159 - val_accuracy: 0.9128\n",
      "Epoch 845/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2088 - accuracy: 0.9338 - val_loss: 0.1424 - val_accuracy: 0.9392\n",
      "Epoch 846/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1920 - accuracy: 0.9417 - val_loss: 0.1626 - val_accuracy: 0.9312\n",
      "Epoch 847/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1888 - accuracy: 0.9401 - val_loss: 0.1609 - val_accuracy: 0.9323\n",
      "Epoch 848/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1906 - accuracy: 0.9444 - val_loss: 0.1708 - val_accuracy: 0.9265\n",
      "Epoch 849/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2054 - accuracy: 0.9312 - val_loss: 0.1607 - val_accuracy: 0.9320\n",
      "Epoch 850/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1959 - accuracy: 0.9479 - val_loss: 0.1483 - val_accuracy: 0.9383\n",
      "Epoch 851/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1808 - accuracy: 0.9443 - val_loss: 0.1553 - val_accuracy: 0.9385\n",
      "Epoch 852/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1782 - accuracy: 0.9436 - val_loss: 0.1642 - val_accuracy: 0.9302\n",
      "Epoch 853/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1788 - accuracy: 0.9413 - val_loss: 0.1238 - val_accuracy: 0.9492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 854/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1732 - accuracy: 0.9526 - val_loss: 0.1710 - val_accuracy: 0.9330\n",
      "Epoch 855/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1681 - accuracy: 0.9420 - val_loss: 0.1237 - val_accuracy: 0.9500\n",
      "Epoch 856/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1877 - accuracy: 0.9486 - val_loss: 0.2151 - val_accuracy: 0.9180\n",
      "Epoch 857/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1805 - accuracy: 0.9392 - val_loss: 0.1259 - val_accuracy: 0.9480\n",
      "Epoch 858/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1732 - accuracy: 0.9505 - val_loss: 0.1645 - val_accuracy: 0.9342\n",
      "Epoch 859/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1649 - accuracy: 0.9489 - val_loss: 0.1445 - val_accuracy: 0.9405\n",
      "Epoch 860/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1746 - accuracy: 0.9449 - val_loss: 0.1411 - val_accuracy: 0.9430\n",
      "Epoch 861/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1879 - accuracy: 0.9487 - val_loss: 0.1704 - val_accuracy: 0.9325\n",
      "Epoch 862/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2282 - accuracy: 0.9316 - val_loss: 0.1953 - val_accuracy: 0.9210\n",
      "Epoch 863/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1960 - accuracy: 0.9446 - val_loss: 0.1742 - val_accuracy: 0.9333\n",
      "Epoch 864/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1889 - accuracy: 0.9409 - val_loss: 0.1399 - val_accuracy: 0.9430\n",
      "Epoch 865/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1844 - accuracy: 0.9489 - val_loss: 0.2077 - val_accuracy: 0.9215\n",
      "Epoch 866/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1878 - accuracy: 0.9449 - val_loss: 0.1742 - val_accuracy: 0.9317\n",
      "Epoch 867/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1746 - accuracy: 0.9389 - val_loss: 0.1045 - val_accuracy: 0.9592\n",
      "Epoch 868/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1819 - accuracy: 0.9549 - val_loss: 0.2069 - val_accuracy: 0.9252\n",
      "Epoch 869/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1686 - accuracy: 0.9508 - val_loss: 0.1297 - val_accuracy: 0.9473\n",
      "Epoch 870/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1641 - accuracy: 0.9471 - val_loss: 0.1718 - val_accuracy: 0.9317\n",
      "Epoch 871/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1651 - accuracy: 0.9546 - val_loss: 0.1385 - val_accuracy: 0.9435\n",
      "Epoch 872/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1638 - accuracy: 0.9467 - val_loss: 0.1418 - val_accuracy: 0.9417\n",
      "Epoch 873/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1744 - accuracy: 0.9554 - val_loss: 0.1602 - val_accuracy: 0.9327\n",
      "Epoch 874/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1915 - accuracy: 0.9411 - val_loss: 0.1925 - val_accuracy: 0.9252\n",
      "Epoch 875/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1721 - accuracy: 0.9538 - val_loss: 0.1709 - val_accuracy: 0.9355\n",
      "Epoch 876/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2233 - accuracy: 0.9291 - val_loss: 0.1744 - val_accuracy: 0.9302\n",
      "Epoch 877/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1791 - accuracy: 0.9541 - val_loss: 0.1492 - val_accuracy: 0.9390\n",
      "Epoch 878/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1896 - accuracy: 0.9416 - val_loss: 0.1293 - val_accuracy: 0.9467\n",
      "Epoch 879/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1824 - accuracy: 0.9434 - val_loss: 0.1361 - val_accuracy: 0.9450\n",
      "Epoch 880/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1726 - accuracy: 0.9564 - val_loss: 0.2075 - val_accuracy: 0.9200\n",
      "Epoch 881/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1924 - accuracy: 0.9394 - val_loss: 0.1112 - val_accuracy: 0.9557\n",
      "Epoch 882/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1963 - accuracy: 0.9446 - val_loss: 0.1716 - val_accuracy: 0.9330\n",
      "Epoch 883/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1689 - accuracy: 0.9556 - val_loss: 0.1504 - val_accuracy: 0.9390\n",
      "Epoch 884/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1689 - accuracy: 0.9471 - val_loss: 0.1298 - val_accuracy: 0.9470\n",
      "Epoch 885/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1617 - accuracy: 0.9500 - val_loss: 0.1240 - val_accuracy: 0.9538\n",
      "Epoch 886/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1548 - accuracy: 0.9572 - val_loss: 0.1689 - val_accuracy: 0.9323\n",
      "Epoch 887/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1551 - accuracy: 0.9536 - val_loss: 0.1126 - val_accuracy: 0.9507\n",
      "Epoch 888/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1448 - accuracy: 0.9544 - val_loss: 0.1305 - val_accuracy: 0.9513\n",
      "Epoch 889/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1454 - accuracy: 0.9544 - val_loss: 0.1416 - val_accuracy: 0.9470\n",
      "Epoch 890/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2386 - accuracy: 0.9416 - val_loss: 0.3198 - val_accuracy: 0.9183\n",
      "Epoch 891/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4660 - accuracy: 0.9224 - val_loss: 0.4360 - val_accuracy: 0.8792\n",
      "Epoch 892/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5563 - accuracy: 0.8984 - val_loss: 0.4481 - val_accuracy: 0.8675\n",
      "Epoch 893/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.5910 - accuracy: 0.8851 - val_loss: 0.3417 - val_accuracy: 0.8863\n",
      "Epoch 894/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4674 - accuracy: 0.9169 - val_loss: 0.1763 - val_accuracy: 0.9247\n",
      "Epoch 895/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4226 - accuracy: 0.8855 - val_loss: 0.2385 - val_accuracy: 0.9032\n",
      "Epoch 896/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4531 - accuracy: 0.8967 - val_loss: 0.2799 - val_accuracy: 0.8708\n",
      "Epoch 897/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3685 - accuracy: 0.8905 - val_loss: 0.2495 - val_accuracy: 0.8942\n",
      "Epoch 898/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3691 - accuracy: 0.9042 - val_loss: 0.2671 - val_accuracy: 0.8960\n",
      "Epoch 899/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4135 - accuracy: 0.8980 - val_loss: 0.3138 - val_accuracy: 0.8767\n",
      "Epoch 900/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3453 - accuracy: 0.9101 - val_loss: 0.3089 - val_accuracy: 0.8830\n",
      "Epoch 901/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3117 - accuracy: 0.9087 - val_loss: 0.1413 - val_accuracy: 0.9348\n",
      "Epoch 902/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3122 - accuracy: 0.9269 - val_loss: 0.3081 - val_accuracy: 0.8798\n",
      "Epoch 903/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3003 - accuracy: 0.9076 - val_loss: 0.1881 - val_accuracy: 0.9195\n",
      "Epoch 904/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2791 - accuracy: 0.9174 - val_loss: 0.2233 - val_accuracy: 0.9065\n",
      "Epoch 905/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2593 - accuracy: 0.9216 - val_loss: 0.2150 - val_accuracy: 0.9100\n",
      "Epoch 906/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2369 - accuracy: 0.9300 - val_loss: 0.1633 - val_accuracy: 0.9320\n",
      "Epoch 907/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1894 - accuracy: 0.9414 - val_loss: 0.1505 - val_accuracy: 0.9395\n",
      "Epoch 908/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1749 - accuracy: 0.9466 - val_loss: 0.1478 - val_accuracy: 0.9405\n",
      "Epoch 909/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1692 - accuracy: 0.9498 - val_loss: 0.1387 - val_accuracy: 0.9450\n",
      "Epoch 910/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1656 - accuracy: 0.9509 - val_loss: 0.1496 - val_accuracy: 0.9433\n",
      "Epoch 911/1000\n",
      "16000/16000 [==============================] - 0s 5us/step - loss: 0.1672 - accuracy: 0.9516 - val_loss: 0.1626 - val_accuracy: 0.9377\n",
      "Epoch 912/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1585 - accuracy: 0.9546 - val_loss: 0.1427 - val_accuracy: 0.9427\n",
      "Epoch 913/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1739 - accuracy: 0.9456 - val_loss: 0.1608 - val_accuracy: 0.9375\n",
      "Epoch 914/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1583 - accuracy: 0.9533 - val_loss: 0.1444 - val_accuracy: 0.9448\n",
      "Epoch 915/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1829 - accuracy: 0.9497 - val_loss: 0.1857 - val_accuracy: 0.9317\n",
      "Epoch 916/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2032 - accuracy: 0.9367 - val_loss: 0.1187 - val_accuracy: 0.9555\n",
      "Epoch 917/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2310 - accuracy: 0.9439 - val_loss: 0.2094 - val_accuracy: 0.9165\n",
      "Epoch 918/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2234 - accuracy: 0.9276 - val_loss: 0.1730 - val_accuracy: 0.9287\n",
      "Epoch 919/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1974 - accuracy: 0.9351 - val_loss: 0.1564 - val_accuracy: 0.9373\n",
      "Epoch 920/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1682 - accuracy: 0.9568 - val_loss: 0.1487 - val_accuracy: 0.9395\n",
      "Epoch 921/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1721 - accuracy: 0.9420 - val_loss: 0.1355 - val_accuracy: 0.9475\n",
      "Epoch 922/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1546 - accuracy: 0.9577 - val_loss: 0.1596 - val_accuracy: 0.9392\n",
      "Epoch 923/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1611 - accuracy: 0.9468 - val_loss: 0.1171 - val_accuracy: 0.9532\n",
      "Epoch 924/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1670 - accuracy: 0.9520 - val_loss: 0.1885 - val_accuracy: 0.9302\n",
      "Epoch 925/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1522 - accuracy: 0.9538 - val_loss: 0.1083 - val_accuracy: 0.9567\n",
      "Epoch 926/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1682 - accuracy: 0.9482 - val_loss: 0.1726 - val_accuracy: 0.9335\n",
      "Epoch 927/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1491 - accuracy: 0.9551 - val_loss: 0.1364 - val_accuracy: 0.9495\n",
      "Epoch 928/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1392 - accuracy: 0.9605 - val_loss: 0.1404 - val_accuracy: 0.9457\n",
      "Epoch 929/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1369 - accuracy: 0.9529 - val_loss: 0.1203 - val_accuracy: 0.9542\n",
      "Epoch 930/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1383 - accuracy: 0.9583 - val_loss: 0.1347 - val_accuracy: 0.9500\n",
      "Epoch 931/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1330 - accuracy: 0.9645 - val_loss: 0.1478 - val_accuracy: 0.9455\n",
      "Epoch 932/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.1345 - accuracy: 0.9538 - val_loss: 0.1077 - val_accuracy: 0.9607\n",
      "Epoch 933/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1395 - accuracy: 0.9568 - val_loss: 0.1398 - val_accuracy: 0.9477\n",
      "Epoch 934/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1317 - accuracy: 0.9641 - val_loss: 0.1527 - val_accuracy: 0.9430\n",
      "Epoch 935/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1438 - accuracy: 0.9509 - val_loss: 0.1206 - val_accuracy: 0.9545\n",
      "Epoch 936/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1367 - accuracy: 0.9598 - val_loss: 0.1366 - val_accuracy: 0.9475\n",
      "Epoch 937/1000\n",
      "16000/16000 [==============================] - 0s 5us/step - loss: 0.1538 - accuracy: 0.9524 - val_loss: 0.1657 - val_accuracy: 0.9427\n",
      "Epoch 938/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1493 - accuracy: 0.9567 - val_loss: 0.1192 - val_accuracy: 0.9585\n",
      "Epoch 939/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1382 - accuracy: 0.9578 - val_loss: 0.1573 - val_accuracy: 0.9417\n",
      "Epoch 940/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1354 - accuracy: 0.9554 - val_loss: 0.1174 - val_accuracy: 0.9585\n",
      "Epoch 941/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1392 - accuracy: 0.9597 - val_loss: 0.1368 - val_accuracy: 0.9492\n",
      "Epoch 942/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1332 - accuracy: 0.9607 - val_loss: 0.1418 - val_accuracy: 0.9480\n",
      "Epoch 943/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1379 - accuracy: 0.9569 - val_loss: 0.1306 - val_accuracy: 0.9542\n",
      "Epoch 944/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1289 - accuracy: 0.9615 - val_loss: 0.1307 - val_accuracy: 0.9507\n",
      "Epoch 945/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1275 - accuracy: 0.9595 - val_loss: 0.1117 - val_accuracy: 0.9603\n",
      "Epoch 946/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1297 - accuracy: 0.9639 - val_loss: 0.1583 - val_accuracy: 0.9430\n",
      "Epoch 947/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1364 - accuracy: 0.9566 - val_loss: 0.1326 - val_accuracy: 0.9503\n",
      "Epoch 948/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1314 - accuracy: 0.9625 - val_loss: 0.1259 - val_accuracy: 0.9517\n",
      "Epoch 949/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1342 - accuracy: 0.9524 - val_loss: 0.1012 - val_accuracy: 0.9650\n",
      "Epoch 950/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1499 - accuracy: 0.9586 - val_loss: 0.1601 - val_accuracy: 0.9417\n",
      "Epoch 951/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1427 - accuracy: 0.9553 - val_loss: 0.1053 - val_accuracy: 0.9638\n",
      "Epoch 952/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1662 - accuracy: 0.9542 - val_loss: 0.1800 - val_accuracy: 0.9355\n",
      "Epoch 953/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1564 - accuracy: 0.9564 - val_loss: 0.1563 - val_accuracy: 0.9445\n",
      "Epoch 954/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1647 - accuracy: 0.9442 - val_loss: 0.1188 - val_accuracy: 0.9550\n",
      "Epoch 955/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1539 - accuracy: 0.9554 - val_loss: 0.1411 - val_accuracy: 0.9455\n",
      "Epoch 956/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1382 - accuracy: 0.9601 - val_loss: 0.1461 - val_accuracy: 0.9460\n",
      "Epoch 957/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1550 - accuracy: 0.9532 - val_loss: 0.1460 - val_accuracy: 0.9448\n",
      "Epoch 958/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1476 - accuracy: 0.9529 - val_loss: 0.1683 - val_accuracy: 0.9392\n",
      "Epoch 959/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1399 - accuracy: 0.9617 - val_loss: 0.1528 - val_accuracy: 0.9467\n",
      "Epoch 960/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1333 - accuracy: 0.9533 - val_loss: 0.1028 - val_accuracy: 0.9647\n",
      "Epoch 961/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1901 - accuracy: 0.9494 - val_loss: 0.2326 - val_accuracy: 0.9222\n",
      "Epoch 962/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1772 - accuracy: 0.9505 - val_loss: 0.1142 - val_accuracy: 0.9580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 963/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1626 - accuracy: 0.9541 - val_loss: 0.1850 - val_accuracy: 0.9380\n",
      "Epoch 964/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1937 - accuracy: 0.9428 - val_loss: 0.1253 - val_accuracy: 0.9565\n",
      "Epoch 965/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1666 - accuracy: 0.9536 - val_loss: 0.1883 - val_accuracy: 0.9390\n",
      "Epoch 966/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1556 - accuracy: 0.9545 - val_loss: 0.1486 - val_accuracy: 0.9470\n",
      "Epoch 967/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1502 - accuracy: 0.9588 - val_loss: 0.1539 - val_accuracy: 0.9467\n",
      "Epoch 968/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1459 - accuracy: 0.9522 - val_loss: 0.1312 - val_accuracy: 0.9535\n",
      "Epoch 969/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1332 - accuracy: 0.9607 - val_loss: 0.1524 - val_accuracy: 0.9465\n",
      "Epoch 970/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1324 - accuracy: 0.9613 - val_loss: 0.1439 - val_accuracy: 0.9490\n",
      "Epoch 971/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1334 - accuracy: 0.9580 - val_loss: 0.1199 - val_accuracy: 0.9575\n",
      "Epoch 972/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1263 - accuracy: 0.9591 - val_loss: 0.1413 - val_accuracy: 0.9490\n",
      "Epoch 973/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1389 - accuracy: 0.9631 - val_loss: 0.1750 - val_accuracy: 0.9410\n",
      "Epoch 974/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1275 - accuracy: 0.9588 - val_loss: 0.1136 - val_accuracy: 0.9600\n",
      "Epoch 975/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1330 - accuracy: 0.9599 - val_loss: 0.1369 - val_accuracy: 0.9515\n",
      "Epoch 976/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1340 - accuracy: 0.9601 - val_loss: 0.1501 - val_accuracy: 0.9500\n",
      "Epoch 977/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1330 - accuracy: 0.9632 - val_loss: 0.1767 - val_accuracy: 0.9395\n",
      "Epoch 978/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1280 - accuracy: 0.9586 - val_loss: 0.1190 - val_accuracy: 0.9582\n",
      "Epoch 979/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1373 - accuracy: 0.9632 - val_loss: 0.1332 - val_accuracy: 0.9538\n",
      "Epoch 980/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1536 - accuracy: 0.9489 - val_loss: 0.1790 - val_accuracy: 0.9365\n",
      "Epoch 981/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1818 - accuracy: 0.9597 - val_loss: 0.2057 - val_accuracy: 0.9308\n",
      "Epoch 982/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2824 - accuracy: 0.9316 - val_loss: 0.4103 - val_accuracy: 0.8995\n",
      "Epoch 983/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2521 - accuracy: 0.9342 - val_loss: 0.1234 - val_accuracy: 0.9553\n",
      "Epoch 984/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2127 - accuracy: 0.9515 - val_loss: 0.2431 - val_accuracy: 0.9235\n",
      "Epoch 985/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2795 - accuracy: 0.9317 - val_loss: 0.2626 - val_accuracy: 0.9240\n",
      "Epoch 986/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2020 - accuracy: 0.9387 - val_loss: 0.1234 - val_accuracy: 0.9557\n",
      "Epoch 987/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1888 - accuracy: 0.9511 - val_loss: 0.1974 - val_accuracy: 0.9342\n",
      "Epoch 988/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1641 - accuracy: 0.9509 - val_loss: 0.1373 - val_accuracy: 0.9492\n",
      "Epoch 989/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1391 - accuracy: 0.9629 - val_loss: 0.1414 - val_accuracy: 0.9460\n",
      "Epoch 990/1000\n",
      "16000/16000 [==============================] - ETA: 0s - loss: 0.1345 - accuracy: 0.95 - 0s 3us/step - loss: 0.1444 - accuracy: 0.9567 - val_loss: 0.1409 - val_accuracy: 0.9507\n",
      "Epoch 991/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1403 - accuracy: 0.9576 - val_loss: 0.1499 - val_accuracy: 0.9435\n",
      "Epoch 992/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1379 - accuracy: 0.9544 - val_loss: 0.1172 - val_accuracy: 0.9592\n",
      "Epoch 993/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1282 - accuracy: 0.9667 - val_loss: 0.1321 - val_accuracy: 0.9532\n",
      "Epoch 994/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1387 - accuracy: 0.9542 - val_loss: 0.1114 - val_accuracy: 0.9613\n",
      "Epoch 995/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1772 - accuracy: 0.9514 - val_loss: 0.1947 - val_accuracy: 0.9293\n",
      "Epoch 996/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2004 - accuracy: 0.9394 - val_loss: 0.1510 - val_accuracy: 0.9425\n",
      "Epoch 997/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1515 - accuracy: 0.9537 - val_loss: 0.1126 - val_accuracy: 0.9582\n",
      "Epoch 998/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1391 - accuracy: 0.9631 - val_loss: 0.1505 - val_accuracy: 0.9460\n",
      "Epoch 999/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1333 - accuracy: 0.9615 - val_loss: 0.1647 - val_accuracy: 0.9420\n",
      "Epoch 1000/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1498 - accuracy: 0.9488 - val_loss: 0.1210 - val_accuracy: 0.9580\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/1000\n",
      "16000/16000 [==============================] - 1s 45us/step - loss: 1.4298 - accuracy: 0.6747 - val_loss: 0.4680 - val_accuracy: 0.6628\n",
      "Epoch 2/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0150 - accuracy: 0.6274 - val_loss: 0.4090 - val_accuracy: 0.7147\n",
      "Epoch 3/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9938 - accuracy: 0.6061 - val_loss: 0.5877 - val_accuracy: 0.6170\n",
      "Epoch 4/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9500 - accuracy: 0.6769 - val_loss: 0.6018 - val_accuracy: 0.6183\n",
      "Epoch 5/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9083 - accuracy: 0.6127 - val_loss: 0.3676 - val_accuracy: 0.7450\n",
      "Epoch 6/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.9419 - accuracy: 0.7076 - val_loss: 0.7364 - val_accuracy: 0.5750\n",
      "Epoch 7/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8960 - accuracy: 0.6612 - val_loss: 0.5577 - val_accuracy: 0.6335\n",
      "Epoch 8/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8433 - accuracy: 0.6447 - val_loss: 0.3924 - val_accuracy: 0.7218\n",
      "Epoch 9/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8486 - accuracy: 0.6874 - val_loss: 0.5640 - val_accuracy: 0.6385\n",
      "Epoch 10/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8572 - accuracy: 0.6749 - val_loss: 0.6853 - val_accuracy: 0.5935\n",
      "Epoch 11/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8802 - accuracy: 0.6886 - val_loss: 0.6882 - val_accuracy: 0.5920\n",
      "Epoch 12/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8618 - accuracy: 0.6686 - val_loss: 0.4081 - val_accuracy: 0.7130\n",
      "Epoch 13/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8073 - accuracy: 0.6721 - val_loss: 0.4452 - val_accuracy: 0.6945\n",
      "Epoch 14/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8172 - accuracy: 0.6726 - val_loss: 0.2895 - val_accuracy: 0.8177\n",
      "Epoch 15/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8812 - accuracy: 0.7082 - val_loss: 0.5846 - val_accuracy: 0.6315\n",
      "Epoch 16/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8030 - accuracy: 0.7168 - val_loss: 0.4217 - val_accuracy: 0.7067\n",
      "Epoch 17/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8181 - accuracy: 0.6672 - val_loss: 0.3242 - val_accuracy: 0.7742\n",
      "Epoch 18/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7925 - accuracy: 0.7120 - val_loss: 0.4306 - val_accuracy: 0.7078\n",
      "Epoch 19/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7522 - accuracy: 0.7078 - val_loss: 0.3742 - val_accuracy: 0.7465\n",
      "Epoch 20/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7503 - accuracy: 0.7275 - val_loss: 0.4798 - val_accuracy: 0.6900\n",
      "Epoch 21/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7510 - accuracy: 0.7412 - val_loss: 0.5774 - val_accuracy: 0.6545\n",
      "Epoch 22/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7838 - accuracy: 0.7256 - val_loss: 0.6541 - val_accuracy: 0.6327\n",
      "Epoch 23/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8384 - accuracy: 0.7447 - val_loss: 0.6283 - val_accuracy: 0.6298\n",
      "Epoch 24/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8748 - accuracy: 0.6525 - val_loss: 0.2693 - val_accuracy: 0.8353\n",
      "Epoch 25/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8390 - accuracy: 0.7028 - val_loss: 0.5577 - val_accuracy: 0.6500\n",
      "Epoch 26/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7965 - accuracy: 0.7194 - val_loss: 0.5432 - val_accuracy: 0.6547\n",
      "Epoch 27/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.7880 - accuracy: 0.7072 - val_loss: 0.5321 - val_accuracy: 0.6562\n",
      "Epoch 28/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7404 - accuracy: 0.6961 - val_loss: 0.3769 - val_accuracy: 0.7530\n",
      "Epoch 29/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7538 - accuracy: 0.7427 - val_loss: 0.6393 - val_accuracy: 0.6298\n",
      "Epoch 30/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8114 - accuracy: 0.7481 - val_loss: 0.4414 - val_accuracy: 0.7265\n",
      "Epoch 31/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7680 - accuracy: 0.6994 - val_loss: 0.4117 - val_accuracy: 0.7305\n",
      "Epoch 32/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7434 - accuracy: 0.7433 - val_loss: 0.5344 - val_accuracy: 0.6888\n",
      "Epoch 33/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7201 - accuracy: 0.7229 - val_loss: 0.3135 - val_accuracy: 0.8027\n",
      "Epoch 34/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7236 - accuracy: 0.7684 - val_loss: 0.5469 - val_accuracy: 0.6817\n",
      "Epoch 35/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.7100 - accuracy: 0.7456 - val_loss: 0.3772 - val_accuracy: 0.7577\n",
      "Epoch 36/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7345 - accuracy: 0.7283 - val_loss: 0.3110 - val_accuracy: 0.8035\n",
      "Epoch 37/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6911 - accuracy: 0.7601 - val_loss: 0.4765 - val_accuracy: 0.7082\n",
      "Epoch 38/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6745 - accuracy: 0.7564 - val_loss: 0.4030 - val_accuracy: 0.7442\n",
      "Epoch 39/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6723 - accuracy: 0.7816 - val_loss: 0.5119 - val_accuracy: 0.7140\n",
      "Epoch 40/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6817 - accuracy: 0.7722 - val_loss: 0.4928 - val_accuracy: 0.7218\n",
      "Epoch 41/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6511 - accuracy: 0.7809 - val_loss: 0.3846 - val_accuracy: 0.7720\n",
      "Epoch 42/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.6499 - accuracy: 0.7783 - val_loss: 0.3791 - val_accuracy: 0.7705\n",
      "Epoch 43/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6785 - accuracy: 0.7926 - val_loss: 0.4564 - val_accuracy: 0.7452\n",
      "Epoch 44/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6852 - accuracy: 0.7594 - val_loss: 0.3347 - val_accuracy: 0.7918\n",
      "Epoch 45/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6516 - accuracy: 0.7654 - val_loss: 0.4537 - val_accuracy: 0.7455\n",
      "Epoch 46/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7190 - accuracy: 0.7789 - val_loss: 0.8139 - val_accuracy: 0.5932\n",
      "Epoch 47/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7326 - accuracy: 0.7678 - val_loss: 0.3620 - val_accuracy: 0.7663\n",
      "Epoch 48/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6840 - accuracy: 0.7539 - val_loss: 0.3677 - val_accuracy: 0.7715\n",
      "Epoch 49/1000\n",
      "16000/16000 [==============================] - ETA: 0s - loss: 0.7664 - accuracy: 0.78 - 0s 3us/step - loss: 0.6551 - accuracy: 0.7543 - val_loss: 0.2927 - val_accuracy: 0.8230\n",
      "Epoch 50/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6617 - accuracy: 0.7795 - val_loss: 0.4625 - val_accuracy: 0.7360\n",
      "Epoch 51/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6403 - accuracy: 0.8040 - val_loss: 0.5058 - val_accuracy: 0.7195\n",
      "Epoch 52/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.6605 - accuracy: 0.7542 - val_loss: 0.2895 - val_accuracy: 0.8253\n",
      "Epoch 53/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6185 - accuracy: 0.7911 - val_loss: 0.3326 - val_accuracy: 0.8065\n",
      "Epoch 54/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6151 - accuracy: 0.8119 - val_loss: 0.3629 - val_accuracy: 0.7977\n",
      "Epoch 55/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6620 - accuracy: 0.7749 - val_loss: 0.2306 - val_accuracy: 0.8655\n",
      "Epoch 56/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7179 - accuracy: 0.7514 - val_loss: 0.4296 - val_accuracy: 0.7508\n",
      "Epoch 57/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.6821 - accuracy: 0.8106 - val_loss: 0.5464 - val_accuracy: 0.6867\n",
      "Epoch 58/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7370 - accuracy: 0.7384 - val_loss: 0.2955 - val_accuracy: 0.8158\n",
      "Epoch 59/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6619 - accuracy: 0.7623 - val_loss: 0.3253 - val_accuracy: 0.7945\n",
      "Epoch 60/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6930 - accuracy: 0.7691 - val_loss: 0.4115 - val_accuracy: 0.7483\n",
      "Epoch 61/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6389 - accuracy: 0.8095 - val_loss: 0.4684 - val_accuracy: 0.7365\n",
      "Epoch 62/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6191 - accuracy: 0.7782 - val_loss: 0.3001 - val_accuracy: 0.8257\n",
      "Epoch 63/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6015 - accuracy: 0.8070 - val_loss: 0.4356 - val_accuracy: 0.7580\n",
      "Epoch 64/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6039 - accuracy: 0.7965 - val_loss: 0.3872 - val_accuracy: 0.7805\n",
      "Epoch 65/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5831 - accuracy: 0.8164 - val_loss: 0.4153 - val_accuracy: 0.7722\n",
      "Epoch 66/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5823 - accuracy: 0.8082 - val_loss: 0.4214 - val_accuracy: 0.7732\n",
      "Epoch 67/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6123 - accuracy: 0.8030 - val_loss: 0.3383 - val_accuracy: 0.8140\n",
      "Epoch 68/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6013 - accuracy: 0.8128 - val_loss: 0.3437 - val_accuracy: 0.8073\n",
      "Epoch 69/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5900 - accuracy: 0.7998 - val_loss: 0.2649 - val_accuracy: 0.8518\n",
      "Epoch 70/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6144 - accuracy: 0.8003 - val_loss: 0.4629 - val_accuracy: 0.7530\n",
      "Epoch 71/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6147 - accuracy: 0.8024 - val_loss: 0.4301 - val_accuracy: 0.7550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5946 - accuracy: 0.8073 - val_loss: 0.3196 - val_accuracy: 0.8170\n",
      "Epoch 73/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5789 - accuracy: 0.8192 - val_loss: 0.6051 - val_accuracy: 0.7258\n",
      "Epoch 74/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6059 - accuracy: 0.8051 - val_loss: 0.3096 - val_accuracy: 0.8232\n",
      "Epoch 75/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6106 - accuracy: 0.7805 - val_loss: 0.2748 - val_accuracy: 0.8338\n",
      "Epoch 76/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5748 - accuracy: 0.8236 - val_loss: 0.3389 - val_accuracy: 0.8227\n",
      "Epoch 77/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.5731 - accuracy: 0.8164 - val_loss: 0.3600 - val_accuracy: 0.8065\n",
      "Epoch 78/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5641 - accuracy: 0.8221 - val_loss: 0.3718 - val_accuracy: 0.8008\n",
      "Epoch 79/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5993 - accuracy: 0.8061 - val_loss: 0.4756 - val_accuracy: 0.7437\n",
      "Epoch 80/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5597 - accuracy: 0.8198 - val_loss: 0.3871 - val_accuracy: 0.7933\n",
      "Epoch 81/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.5947 - accuracy: 0.7951 - val_loss: 0.3614 - val_accuracy: 0.7855\n",
      "Epoch 82/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.6520 - accuracy: 0.7937 - val_loss: 0.5126 - val_accuracy: 0.7372\n",
      "Epoch 83/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6339 - accuracy: 0.8113 - val_loss: 0.5630 - val_accuracy: 0.7057\n",
      "Epoch 84/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6568 - accuracy: 0.7712 - val_loss: 0.2586 - val_accuracy: 0.8425\n",
      "Epoch 85/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5904 - accuracy: 0.7914 - val_loss: 0.3613 - val_accuracy: 0.7930\n",
      "Epoch 86/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5531 - accuracy: 0.8297 - val_loss: 0.4464 - val_accuracy: 0.7653\n",
      "Epoch 87/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5642 - accuracy: 0.8176 - val_loss: 0.4575 - val_accuracy: 0.7650\n",
      "Epoch 88/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5973 - accuracy: 0.8044 - val_loss: 0.3745 - val_accuracy: 0.7843\n",
      "Epoch 89/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5912 - accuracy: 0.7861 - val_loss: 0.2769 - val_accuracy: 0.8280\n",
      "Epoch 90/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5768 - accuracy: 0.7930 - val_loss: 0.3236 - val_accuracy: 0.8195\n",
      "Epoch 91/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5674 - accuracy: 0.8294 - val_loss: 0.4992 - val_accuracy: 0.7440\n",
      "Epoch 92/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.5741 - accuracy: 0.8102 - val_loss: 0.3664 - val_accuracy: 0.7840\n",
      "Epoch 93/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5384 - accuracy: 0.8094 - val_loss: 0.3076 - val_accuracy: 0.8213\n",
      "Epoch 94/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5407 - accuracy: 0.8229 - val_loss: 0.3760 - val_accuracy: 0.7955\n",
      "Epoch 95/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5273 - accuracy: 0.8209 - val_loss: 0.3454 - val_accuracy: 0.8075\n",
      "Epoch 96/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4965 - accuracy: 0.8264 - val_loss: 0.2139 - val_accuracy: 0.8740\n",
      "Epoch 97/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5381 - accuracy: 0.8215 - val_loss: 0.3337 - val_accuracy: 0.8058\n",
      "Epoch 98/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5458 - accuracy: 0.8189 - val_loss: 0.4178 - val_accuracy: 0.7793\n",
      "Epoch 99/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5337 - accuracy: 0.8282 - val_loss: 0.4016 - val_accuracy: 0.7750\n",
      "Epoch 100/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5369 - accuracy: 0.8256 - val_loss: 0.4535 - val_accuracy: 0.7682\n",
      "Epoch 101/1000\n",
      "16000/16000 [==============================] - 0s 5us/step - loss: 0.5308 - accuracy: 0.8336 - val_loss: 0.4673 - val_accuracy: 0.7613\n",
      "Epoch 102/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.5403 - accuracy: 0.8137 - val_loss: 0.3956 - val_accuracy: 0.7840\n",
      "Epoch 103/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.5302 - accuracy: 0.8297 - val_loss: 0.4581 - val_accuracy: 0.7650\n",
      "Epoch 104/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5544 - accuracy: 0.8249 - val_loss: 0.3358 - val_accuracy: 0.8148\n",
      "Epoch 105/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5182 - accuracy: 0.8055 - val_loss: 0.2259 - val_accuracy: 0.8608\n",
      "Epoch 106/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5125 - accuracy: 0.8285 - val_loss: 0.3080 - val_accuracy: 0.8288\n",
      "Epoch 107/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5141 - accuracy: 0.8421 - val_loss: 0.4223 - val_accuracy: 0.7903\n",
      "Epoch 108/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5221 - accuracy: 0.8362 - val_loss: 0.5459 - val_accuracy: 0.7365\n",
      "Epoch 109/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5896 - accuracy: 0.8057 - val_loss: 0.3187 - val_accuracy: 0.8092\n",
      "Epoch 110/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5712 - accuracy: 0.7849 - val_loss: 0.1772 - val_accuracy: 0.9137\n",
      "Epoch 111/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5798 - accuracy: 0.8234 - val_loss: 0.3953 - val_accuracy: 0.7830\n",
      "Epoch 112/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5411 - accuracy: 0.8140 - val_loss: 0.2373 - val_accuracy: 0.8585\n",
      "Epoch 113/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5304 - accuracy: 0.8213 - val_loss: 0.3092 - val_accuracy: 0.8238\n",
      "Epoch 114/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5097 - accuracy: 0.8366 - val_loss: 0.4192 - val_accuracy: 0.7818\n",
      "Epoch 115/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5079 - accuracy: 0.8312 - val_loss: 0.3657 - val_accuracy: 0.8027\n",
      "Epoch 116/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4949 - accuracy: 0.8385 - val_loss: 0.2861 - val_accuracy: 0.8390\n",
      "Epoch 117/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5151 - accuracy: 0.8341 - val_loss: 0.2625 - val_accuracy: 0.8553\n",
      "Epoch 118/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5202 - accuracy: 0.8319 - val_loss: 0.2841 - val_accuracy: 0.8370\n",
      "Epoch 119/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4808 - accuracy: 0.8380 - val_loss: 0.4157 - val_accuracy: 0.7887\n",
      "Epoch 120/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4908 - accuracy: 0.8303 - val_loss: 0.2489 - val_accuracy: 0.8562\n",
      "Epoch 121/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5150 - accuracy: 0.8223 - val_loss: 0.3184 - val_accuracy: 0.8313\n",
      "Epoch 122/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4868 - accuracy: 0.8407 - val_loss: 0.2943 - val_accuracy: 0.8370\n",
      "Epoch 123/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4619 - accuracy: 0.8520 - val_loss: 0.3378 - val_accuracy: 0.8177\n",
      "Epoch 124/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4559 - accuracy: 0.8534 - val_loss: 0.4093 - val_accuracy: 0.7878\n",
      "Epoch 125/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4993 - accuracy: 0.8342 - val_loss: 0.3756 - val_accuracy: 0.8112\n",
      "Epoch 126/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5213 - accuracy: 0.8326 - val_loss: 0.3311 - val_accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5163 - accuracy: 0.8275 - val_loss: 0.3244 - val_accuracy: 0.8338\n",
      "Epoch 128/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4878 - accuracy: 0.8372 - val_loss: 0.3597 - val_accuracy: 0.8130\n",
      "Epoch 129/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5253 - accuracy: 0.8463 - val_loss: 0.4450 - val_accuracy: 0.7868\n",
      "Epoch 130/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.5509 - accuracy: 0.8050 - val_loss: 0.3738 - val_accuracy: 0.7825\n",
      "Epoch 131/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.5210 - accuracy: 0.8283 - val_loss: 0.2988 - val_accuracy: 0.8288\n",
      "Epoch 132/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5006 - accuracy: 0.8245 - val_loss: 0.3290 - val_accuracy: 0.8067\n",
      "Epoch 133/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4994 - accuracy: 0.8293 - val_loss: 0.3604 - val_accuracy: 0.7897\n",
      "Epoch 134/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4997 - accuracy: 0.8144 - val_loss: 0.2328 - val_accuracy: 0.8630\n",
      "Epoch 135/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4685 - accuracy: 0.8427 - val_loss: 0.3035 - val_accuracy: 0.8370\n",
      "Epoch 136/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4600 - accuracy: 0.8491 - val_loss: 0.2695 - val_accuracy: 0.8587\n",
      "Epoch 137/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4686 - accuracy: 0.8459 - val_loss: 0.3109 - val_accuracy: 0.8173\n",
      "Epoch 138/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4768 - accuracy: 0.8345 - val_loss: 0.3847 - val_accuracy: 0.8023\n",
      "Epoch 139/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4761 - accuracy: 0.8464 - val_loss: 0.4929 - val_accuracy: 0.7632\n",
      "Epoch 140/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4759 - accuracy: 0.8397 - val_loss: 0.3179 - val_accuracy: 0.8270\n",
      "Epoch 141/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4903 - accuracy: 0.8252 - val_loss: 0.3668 - val_accuracy: 0.7937\n",
      "Epoch 142/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5068 - accuracy: 0.8556 - val_loss: 0.5568 - val_accuracy: 0.7383\n",
      "Epoch 143/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6190 - accuracy: 0.8115 - val_loss: 0.5317 - val_accuracy: 0.7347\n",
      "Epoch 144/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6077 - accuracy: 0.7875 - val_loss: 0.3124 - val_accuracy: 0.8110\n",
      "Epoch 145/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5428 - accuracy: 0.8049 - val_loss: 0.3352 - val_accuracy: 0.8070\n",
      "Epoch 146/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5393 - accuracy: 0.8060 - val_loss: 0.2742 - val_accuracy: 0.8335\n",
      "Epoch 147/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4934 - accuracy: 0.8407 - val_loss: 0.3765 - val_accuracy: 0.7975\n",
      "Epoch 148/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4743 - accuracy: 0.8389 - val_loss: 0.2810 - val_accuracy: 0.8367\n",
      "Epoch 149/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4576 - accuracy: 0.8426 - val_loss: 0.2517 - val_accuracy: 0.8622\n",
      "Epoch 150/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4698 - accuracy: 0.8389 - val_loss: 0.2522 - val_accuracy: 0.8550\n",
      "Epoch 151/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.4813 - accuracy: 0.8463 - val_loss: 0.3354 - val_accuracy: 0.8207\n",
      "Epoch 152/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4841 - accuracy: 0.8599 - val_loss: 0.5205 - val_accuracy: 0.7465\n",
      "Epoch 153/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5887 - accuracy: 0.8086 - val_loss: 0.4327 - val_accuracy: 0.7613\n",
      "Epoch 154/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5889 - accuracy: 0.7780 - val_loss: 0.2849 - val_accuracy: 0.8405\n",
      "Epoch 155/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5474 - accuracy: 0.8112 - val_loss: 0.3106 - val_accuracy: 0.8180\n",
      "Epoch 156/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4994 - accuracy: 0.8512 - val_loss: 0.4516 - val_accuracy: 0.7745\n",
      "Epoch 157/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5255 - accuracy: 0.8236 - val_loss: 0.2702 - val_accuracy: 0.8457\n",
      "Epoch 158/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4847 - accuracy: 0.8206 - val_loss: 0.3244 - val_accuracy: 0.8105\n",
      "Epoch 159/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4862 - accuracy: 0.8336 - val_loss: 0.2743 - val_accuracy: 0.8453\n",
      "Epoch 160/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4498 - accuracy: 0.8476 - val_loss: 0.1956 - val_accuracy: 0.8950\n",
      "Epoch 161/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5429 - accuracy: 0.8068 - val_loss: 0.2035 - val_accuracy: 0.8752\n",
      "Epoch 162/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6148 - accuracy: 0.8240 - val_loss: 0.4112 - val_accuracy: 0.7832\n",
      "Epoch 163/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5767 - accuracy: 0.8154 - val_loss: 0.4427 - val_accuracy: 0.7595\n",
      "Epoch 164/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5272 - accuracy: 0.8026 - val_loss: 0.3138 - val_accuracy: 0.8108\n",
      "Epoch 165/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5107 - accuracy: 0.8242 - val_loss: 0.4165 - val_accuracy: 0.7807\n",
      "Epoch 166/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4947 - accuracy: 0.8393 - val_loss: 0.2647 - val_accuracy: 0.8450\n",
      "Epoch 167/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4729 - accuracy: 0.8277 - val_loss: 0.3984 - val_accuracy: 0.7815\n",
      "Epoch 168/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4832 - accuracy: 0.8364 - val_loss: 0.3687 - val_accuracy: 0.7950\n",
      "Epoch 169/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4781 - accuracy: 0.8271 - val_loss: 0.2833 - val_accuracy: 0.8422\n",
      "Epoch 170/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4411 - accuracy: 0.8615 - val_loss: 0.3534 - val_accuracy: 0.8183\n",
      "Epoch 171/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4468 - accuracy: 0.8401 - val_loss: 0.2037 - val_accuracy: 0.8827\n",
      "Epoch 172/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4465 - accuracy: 0.8481 - val_loss: 0.2512 - val_accuracy: 0.8553\n",
      "Epoch 173/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.4273 - accuracy: 0.8671 - val_loss: 0.3056 - val_accuracy: 0.8397\n",
      "Epoch 174/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4269 - accuracy: 0.8502 - val_loss: 0.2554 - val_accuracy: 0.8640\n",
      "Epoch 175/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4519 - accuracy: 0.8512 - val_loss: 0.2970 - val_accuracy: 0.8405\n",
      "Epoch 176/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4456 - accuracy: 0.8508 - val_loss: 0.2367 - val_accuracy: 0.8670\n",
      "Epoch 177/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4753 - accuracy: 0.8533 - val_loss: 0.3625 - val_accuracy: 0.8062\n",
      "Epoch 178/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4503 - accuracy: 0.8581 - val_loss: 0.3920 - val_accuracy: 0.8008\n",
      "Epoch 179/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4484 - accuracy: 0.8482 - val_loss: 0.3242 - val_accuracy: 0.8227\n",
      "Epoch 180/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4516 - accuracy: 0.8396 - val_loss: 0.2506 - val_accuracy: 0.8627\n",
      "Epoch 181/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4379 - accuracy: 0.8549 - val_loss: 0.2795 - val_accuracy: 0.8455\n",
      "Epoch 182/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4394 - accuracy: 0.8526 - val_loss: 0.2531 - val_accuracy: 0.8720\n",
      "Epoch 183/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4514 - accuracy: 0.8482 - val_loss: 0.2595 - val_accuracy: 0.8460\n",
      "Epoch 184/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4397 - accuracy: 0.8691 - val_loss: 0.3140 - val_accuracy: 0.8372\n",
      "Epoch 185/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4387 - accuracy: 0.8560 - val_loss: 0.3603 - val_accuracy: 0.8173\n",
      "Epoch 186/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4247 - accuracy: 0.8600 - val_loss: 0.2727 - val_accuracy: 0.8577\n",
      "Epoch 187/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4048 - accuracy: 0.8631 - val_loss: 0.2221 - val_accuracy: 0.8760\n",
      "Epoch 188/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4079 - accuracy: 0.8648 - val_loss: 0.2792 - val_accuracy: 0.8565\n",
      "Epoch 189/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4053 - accuracy: 0.8697 - val_loss: 0.3165 - val_accuracy: 0.8403\n",
      "Epoch 190/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4274 - accuracy: 0.8755 - val_loss: 0.4099 - val_accuracy: 0.8067\n",
      "Epoch 191/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4560 - accuracy: 0.8466 - val_loss: 0.3012 - val_accuracy: 0.8370\n",
      "Epoch 192/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4546 - accuracy: 0.8631 - val_loss: 0.4677 - val_accuracy: 0.7790\n",
      "Epoch 193/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4852 - accuracy: 0.8421 - val_loss: 0.3151 - val_accuracy: 0.8338\n",
      "Epoch 194/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4719 - accuracy: 0.8393 - val_loss: 0.2543 - val_accuracy: 0.8585\n",
      "Epoch 195/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5262 - accuracy: 0.8354 - val_loss: 0.2726 - val_accuracy: 0.8418\n",
      "Epoch 196/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5414 - accuracy: 0.8274 - val_loss: 0.3323 - val_accuracy: 0.8133\n",
      "Epoch 197/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4760 - accuracy: 0.8287 - val_loss: 0.3069 - val_accuracy: 0.8317\n",
      "Epoch 198/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5211 - accuracy: 0.8441 - val_loss: 0.4098 - val_accuracy: 0.7937\n",
      "Epoch 199/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5469 - accuracy: 0.8087 - val_loss: 0.2141 - val_accuracy: 0.8915\n",
      "Epoch 200/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5450 - accuracy: 0.8304 - val_loss: 0.2511 - val_accuracy: 0.8590\n",
      "Epoch 201/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5153 - accuracy: 0.8226 - val_loss: 0.1764 - val_accuracy: 0.9020\n",
      "Epoch 202/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4789 - accuracy: 0.8392 - val_loss: 0.2623 - val_accuracy: 0.8530\n",
      "Epoch 203/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4359 - accuracy: 0.8568 - val_loss: 0.3064 - val_accuracy: 0.8380\n",
      "Epoch 204/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4173 - accuracy: 0.8710 - val_loss: 0.3296 - val_accuracy: 0.8248\n",
      "Epoch 205/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4094 - accuracy: 0.8564 - val_loss: 0.2491 - val_accuracy: 0.8645\n",
      "Epoch 206/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4007 - accuracy: 0.8687 - val_loss: 0.3024 - val_accuracy: 0.8447\n",
      "Epoch 207/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4145 - accuracy: 0.8480 - val_loss: 0.2390 - val_accuracy: 0.8725\n",
      "Epoch 208/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4418 - accuracy: 0.8631 - val_loss: 0.2859 - val_accuracy: 0.8528\n",
      "Epoch 209/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4533 - accuracy: 0.8428 - val_loss: 0.2292 - val_accuracy: 0.8650\n",
      "Epoch 210/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4489 - accuracy: 0.8546 - val_loss: 0.3080 - val_accuracy: 0.8340\n",
      "Epoch 211/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4570 - accuracy: 0.8442 - val_loss: 0.2633 - val_accuracy: 0.8535\n",
      "Epoch 212/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4581 - accuracy: 0.8545 - val_loss: 0.2997 - val_accuracy: 0.8407\n",
      "Epoch 213/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4228 - accuracy: 0.8676 - val_loss: 0.3195 - val_accuracy: 0.8487\n",
      "Epoch 214/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4113 - accuracy: 0.8716 - val_loss: 0.2748 - val_accuracy: 0.8475\n",
      "Epoch 215/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4095 - accuracy: 0.8654 - val_loss: 0.3796 - val_accuracy: 0.8145\n",
      "Epoch 216/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4228 - accuracy: 0.8612 - val_loss: 0.2608 - val_accuracy: 0.8487\n",
      "Epoch 217/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4331 - accuracy: 0.8385 - val_loss: 0.2317 - val_accuracy: 0.8700\n",
      "Epoch 218/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3931 - accuracy: 0.8788 - val_loss: 0.3423 - val_accuracy: 0.8370\n",
      "Epoch 219/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4013 - accuracy: 0.8665 - val_loss: 0.2868 - val_accuracy: 0.8475\n",
      "Epoch 220/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3762 - accuracy: 0.8781 - val_loss: 0.2459 - val_accuracy: 0.8730\n",
      "Epoch 221/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3861 - accuracy: 0.8753 - val_loss: 0.2523 - val_accuracy: 0.8723\n",
      "Epoch 222/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3667 - accuracy: 0.8752 - val_loss: 0.2915 - val_accuracy: 0.8533\n",
      "Epoch 223/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3741 - accuracy: 0.8775 - val_loss: 0.2930 - val_accuracy: 0.8518\n",
      "Epoch 224/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3902 - accuracy: 0.8684 - val_loss: 0.2643 - val_accuracy: 0.8615\n",
      "Epoch 225/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3746 - accuracy: 0.8788 - val_loss: 0.3490 - val_accuracy: 0.8285\n",
      "Epoch 226/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3907 - accuracy: 0.8641 - val_loss: 0.2830 - val_accuracy: 0.8482\n",
      "Epoch 227/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4009 - accuracy: 0.8775 - val_loss: 0.3480 - val_accuracy: 0.8300\n",
      "Epoch 228/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4486 - accuracy: 0.8565 - val_loss: 0.3235 - val_accuracy: 0.8537\n",
      "Epoch 229/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4662 - accuracy: 0.8468 - val_loss: 0.3582 - val_accuracy: 0.8073\n",
      "Epoch 230/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4153 - accuracy: 0.8491 - val_loss: 0.1937 - val_accuracy: 0.8970\n",
      "Epoch 231/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4385 - accuracy: 0.8760 - val_loss: 0.3944 - val_accuracy: 0.8040\n",
      "Epoch 232/1000\n",
      "16000/16000 [==============================] - ETA: 0s - loss: 0.4091 - accuracy: 0.80 - 0s 3us/step - loss: 0.4875 - accuracy: 0.8082 - val_loss: 0.2522 - val_accuracy: 0.8328\n",
      "Epoch 233/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5052 - accuracy: 0.8113 - val_loss: 0.3162 - val_accuracy: 0.8175\n",
      "Epoch 234/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4628 - accuracy: 0.8399 - val_loss: 0.3240 - val_accuracy: 0.8332\n",
      "Epoch 235/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4251 - accuracy: 0.8629 - val_loss: 0.2919 - val_accuracy: 0.8480\n",
      "Epoch 236/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4446 - accuracy: 0.8579 - val_loss: 0.2600 - val_accuracy: 0.8622\n",
      "Epoch 237/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4354 - accuracy: 0.8478 - val_loss: 0.2171 - val_accuracy: 0.8765\n",
      "Epoch 238/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4275 - accuracy: 0.8714 - val_loss: 0.4254 - val_accuracy: 0.8105\n",
      "Epoch 239/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4712 - accuracy: 0.8515 - val_loss: 0.4142 - val_accuracy: 0.8102\n",
      "Epoch 240/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4353 - accuracy: 0.8556 - val_loss: 0.2500 - val_accuracy: 0.8615\n",
      "Epoch 241/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4476 - accuracy: 0.8517 - val_loss: 0.4539 - val_accuracy: 0.7920\n",
      "Epoch 242/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4650 - accuracy: 0.8586 - val_loss: 0.4175 - val_accuracy: 0.7997\n",
      "Epoch 243/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5006 - accuracy: 0.8306 - val_loss: 0.2159 - val_accuracy: 0.8767\n",
      "Epoch 244/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5468 - accuracy: 0.8388 - val_loss: 0.3190 - val_accuracy: 0.8482\n",
      "Epoch 245/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4715 - accuracy: 0.8453 - val_loss: 0.2605 - val_accuracy: 0.8620\n",
      "Epoch 246/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4400 - accuracy: 0.8595 - val_loss: 0.3170 - val_accuracy: 0.8288\n",
      "Epoch 247/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4340 - accuracy: 0.8549 - val_loss: 0.3533 - val_accuracy: 0.8160\n",
      "Epoch 248/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4147 - accuracy: 0.8506 - val_loss: 0.2396 - val_accuracy: 0.8577\n",
      "Epoch 249/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3819 - accuracy: 0.8783 - val_loss: 0.2719 - val_accuracy: 0.8622\n",
      "Epoch 250/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4048 - accuracy: 0.8606 - val_loss: 0.2932 - val_accuracy: 0.8440\n",
      "Epoch 251/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3850 - accuracy: 0.8980 - val_loss: 0.3764 - val_accuracy: 0.8290\n",
      "Epoch 252/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4140 - accuracy: 0.8600 - val_loss: 0.3405 - val_accuracy: 0.8355\n",
      "Epoch 253/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4139 - accuracy: 0.8648 - val_loss: 0.2534 - val_accuracy: 0.8602\n",
      "Epoch 254/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3879 - accuracy: 0.8717 - val_loss: 0.2941 - val_accuracy: 0.8568\n",
      "Epoch 255/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3869 - accuracy: 0.8721 - val_loss: 0.2463 - val_accuracy: 0.8692\n",
      "Epoch 256/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4359 - accuracy: 0.8531 - val_loss: 0.3170 - val_accuracy: 0.8257\n",
      "Epoch 257/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4471 - accuracy: 0.8470 - val_loss: 0.2864 - val_accuracy: 0.8290\n",
      "Epoch 258/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4364 - accuracy: 0.8460 - val_loss: 0.2382 - val_accuracy: 0.8783\n",
      "Epoch 259/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4189 - accuracy: 0.8631 - val_loss: 0.2984 - val_accuracy: 0.8425\n",
      "Epoch 260/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3932 - accuracy: 0.8614 - val_loss: 0.2399 - val_accuracy: 0.8727\n",
      "Epoch 261/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3665 - accuracy: 0.8767 - val_loss: 0.2431 - val_accuracy: 0.8708\n",
      "Epoch 262/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3924 - accuracy: 0.8809 - val_loss: 0.3370 - val_accuracy: 0.8430\n",
      "Epoch 263/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4476 - accuracy: 0.8649 - val_loss: 0.3876 - val_accuracy: 0.8067\n",
      "Epoch 264/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4425 - accuracy: 0.8631 - val_loss: 0.3369 - val_accuracy: 0.8385\n",
      "Epoch 265/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.4254 - accuracy: 0.8568 - val_loss: 0.3102 - val_accuracy: 0.8493\n",
      "Epoch 266/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4072 - accuracy: 0.8655 - val_loss: 0.2239 - val_accuracy: 0.8792\n",
      "Epoch 267/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3698 - accuracy: 0.8819 - val_loss: 0.2571 - val_accuracy: 0.8715\n",
      "Epoch 268/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3491 - accuracy: 0.8811 - val_loss: 0.2345 - val_accuracy: 0.8810\n",
      "Epoch 269/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3440 - accuracy: 0.8883 - val_loss: 0.2744 - val_accuracy: 0.8637\n",
      "Epoch 270/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3412 - accuracy: 0.8869 - val_loss: 0.2626 - val_accuracy: 0.8702\n",
      "Epoch 271/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3372 - accuracy: 0.8898 - val_loss: 0.2681 - val_accuracy: 0.8687\n",
      "Epoch 272/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3272 - accuracy: 0.8925 - val_loss: 0.3345 - val_accuracy: 0.8525\n",
      "Epoch 273/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3366 - accuracy: 0.8915 - val_loss: 0.2293 - val_accuracy: 0.8855\n",
      "Epoch 274/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3419 - accuracy: 0.8775 - val_loss: 0.2023 - val_accuracy: 0.8920\n",
      "Epoch 275/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3446 - accuracy: 0.8945 - val_loss: 0.2649 - val_accuracy: 0.8737\n",
      "Epoch 276/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3503 - accuracy: 0.8860 - val_loss: 0.2300 - val_accuracy: 0.8792\n",
      "Epoch 277/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3363 - accuracy: 0.8899 - val_loss: 0.3312 - val_accuracy: 0.8540\n",
      "Epoch 278/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3703 - accuracy: 0.8824 - val_loss: 0.3968 - val_accuracy: 0.8177\n",
      "Epoch 279/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4356 - accuracy: 0.8504 - val_loss: 0.2992 - val_accuracy: 0.8357\n",
      "Epoch 280/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4260 - accuracy: 0.8476 - val_loss: 0.1941 - val_accuracy: 0.8850\n",
      "Epoch 281/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3906 - accuracy: 0.8759 - val_loss: 0.2645 - val_accuracy: 0.8700\n",
      "Epoch 282/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3533 - accuracy: 0.8815 - val_loss: 0.2404 - val_accuracy: 0.8645\n",
      "Epoch 283/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3457 - accuracy: 0.8853 - val_loss: 0.2837 - val_accuracy: 0.8717\n",
      "Epoch 284/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3160 - accuracy: 0.8951 - val_loss: 0.1964 - val_accuracy: 0.9025\n",
      "Epoch 285/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3184 - accuracy: 0.8981 - val_loss: 0.2041 - val_accuracy: 0.9003\n",
      "Epoch 286/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3080 - accuracy: 0.9006 - val_loss: 0.2123 - val_accuracy: 0.8932\n",
      "Epoch 287/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3379 - accuracy: 0.8840 - val_loss: 0.2259 - val_accuracy: 0.8823\n",
      "Epoch 288/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3159 - accuracy: 0.8927 - val_loss: 0.2352 - val_accuracy: 0.8855\n",
      "Epoch 289/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3308 - accuracy: 0.8914 - val_loss: 0.1905 - val_accuracy: 0.8995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4269 - accuracy: 0.8741 - val_loss: 0.2754 - val_accuracy: 0.8612\n",
      "Epoch 291/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4367 - accuracy: 0.8413 - val_loss: 0.2486 - val_accuracy: 0.8460\n",
      "Epoch 292/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4231 - accuracy: 0.8499 - val_loss: 0.2163 - val_accuracy: 0.8800\n",
      "Epoch 293/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3878 - accuracy: 0.8687 - val_loss: 0.3210 - val_accuracy: 0.8372\n",
      "Epoch 294/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3704 - accuracy: 0.8659 - val_loss: 0.2516 - val_accuracy: 0.8685\n",
      "Epoch 295/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3485 - accuracy: 0.8824 - val_loss: 0.3180 - val_accuracy: 0.8382\n",
      "Epoch 296/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3498 - accuracy: 0.8786 - val_loss: 0.2556 - val_accuracy: 0.8670\n",
      "Epoch 297/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3170 - accuracy: 0.8877 - val_loss: 0.1748 - val_accuracy: 0.9137\n",
      "Epoch 298/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3243 - accuracy: 0.8937 - val_loss: 0.2384 - val_accuracy: 0.8813\n",
      "Epoch 299/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3081 - accuracy: 0.8999 - val_loss: 0.2445 - val_accuracy: 0.8830\n",
      "Epoch 300/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3034 - accuracy: 0.8992 - val_loss: 0.1774 - val_accuracy: 0.9068\n",
      "Epoch 301/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3150 - accuracy: 0.9021 - val_loss: 0.2495 - val_accuracy: 0.8795\n",
      "Epoch 302/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2948 - accuracy: 0.8991 - val_loss: 0.1864 - val_accuracy: 0.9080\n",
      "Epoch 303/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3044 - accuracy: 0.9014 - val_loss: 0.2309 - val_accuracy: 0.8947\n",
      "Epoch 304/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3137 - accuracy: 0.8920 - val_loss: 0.1818 - val_accuracy: 0.9060\n",
      "Epoch 305/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2946 - accuracy: 0.9024 - val_loss: 0.1408 - val_accuracy: 0.9383\n",
      "Epoch 306/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2922 - accuracy: 0.9150 - val_loss: 0.2244 - val_accuracy: 0.8923\n",
      "Epoch 307/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2855 - accuracy: 0.9031 - val_loss: 0.2042 - val_accuracy: 0.9018\n",
      "Epoch 308/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3132 - accuracy: 0.8988 - val_loss: 0.2643 - val_accuracy: 0.8700\n",
      "Epoch 309/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3252 - accuracy: 0.8960 - val_loss: 0.2211 - val_accuracy: 0.8980\n",
      "Epoch 310/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3930 - accuracy: 0.8842 - val_loss: 0.4161 - val_accuracy: 0.8285\n",
      "Epoch 311/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3966 - accuracy: 0.8649 - val_loss: 0.2801 - val_accuracy: 0.8515\n",
      "Epoch 312/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3561 - accuracy: 0.8883 - val_loss: 0.1779 - val_accuracy: 0.9115\n",
      "Epoch 313/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3615 - accuracy: 0.8786 - val_loss: 0.1647 - val_accuracy: 0.9125\n",
      "Epoch 314/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3443 - accuracy: 0.8979 - val_loss: 0.3095 - val_accuracy: 0.8570\n",
      "Epoch 315/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3448 - accuracy: 0.8859 - val_loss: 0.2095 - val_accuracy: 0.8932\n",
      "Epoch 316/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3832 - accuracy: 0.8696 - val_loss: 0.1979 - val_accuracy: 0.9035\n",
      "Epoch 317/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3447 - accuracy: 0.8903 - val_loss: 0.1964 - val_accuracy: 0.9043\n",
      "Epoch 318/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3362 - accuracy: 0.8924 - val_loss: 0.1530 - val_accuracy: 0.9240\n",
      "Epoch 319/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4014 - accuracy: 0.8746 - val_loss: 0.4173 - val_accuracy: 0.8110\n",
      "Epoch 320/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3885 - accuracy: 0.8816 - val_loss: 0.2834 - val_accuracy: 0.8670\n",
      "Epoch 321/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4550 - accuracy: 0.8460 - val_loss: 0.3147 - val_accuracy: 0.8505\n",
      "Epoch 322/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4405 - accuracy: 0.8648 - val_loss: 0.4083 - val_accuracy: 0.7897\n",
      "Epoch 323/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4708 - accuracy: 0.8606 - val_loss: 0.4616 - val_accuracy: 0.7828\n",
      "Epoch 324/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4977 - accuracy: 0.8367 - val_loss: 0.2824 - val_accuracy: 0.8443\n",
      "Epoch 325/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4610 - accuracy: 0.8313 - val_loss: 0.2646 - val_accuracy: 0.8493\n",
      "Epoch 326/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4305 - accuracy: 0.8453 - val_loss: 0.2559 - val_accuracy: 0.8595\n",
      "Epoch 327/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3873 - accuracy: 0.8788 - val_loss: 0.3121 - val_accuracy: 0.8478\n",
      "Epoch 328/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3959 - accuracy: 0.8807 - val_loss: 0.3325 - val_accuracy: 0.8435\n",
      "Epoch 329/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4083 - accuracy: 0.8617 - val_loss: 0.2350 - val_accuracy: 0.8855\n",
      "Epoch 330/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3989 - accuracy: 0.8716 - val_loss: 0.2679 - val_accuracy: 0.8650\n",
      "Epoch 331/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3522 - accuracy: 0.8849 - val_loss: 0.1983 - val_accuracy: 0.9010\n",
      "Epoch 332/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3409 - accuracy: 0.8948 - val_loss: 0.2546 - val_accuracy: 0.8735\n",
      "Epoch 333/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3443 - accuracy: 0.8921 - val_loss: 0.2864 - val_accuracy: 0.8710\n",
      "Epoch 334/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3353 - accuracy: 0.8950 - val_loss: 0.2354 - val_accuracy: 0.8860\n",
      "Epoch 335/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4693 - accuracy: 0.8521 - val_loss: 0.1873 - val_accuracy: 0.9120\n",
      "Epoch 336/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4774 - accuracy: 0.8569 - val_loss: 0.2708 - val_accuracy: 0.8662\n",
      "Epoch 337/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4382 - accuracy: 0.8608 - val_loss: 0.2541 - val_accuracy: 0.8627\n",
      "Epoch 338/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4007 - accuracy: 0.8638 - val_loss: 0.2962 - val_accuracy: 0.8558\n",
      "Epoch 339/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3534 - accuracy: 0.8916 - val_loss: 0.2570 - val_accuracy: 0.8798\n",
      "Epoch 340/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3454 - accuracy: 0.8826 - val_loss: 0.2706 - val_accuracy: 0.8700\n",
      "Epoch 341/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3328 - accuracy: 0.8891 - val_loss: 0.2437 - val_accuracy: 0.8750\n",
      "Epoch 342/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3155 - accuracy: 0.8963 - val_loss: 0.2958 - val_accuracy: 0.8602\n",
      "Epoch 343/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3125 - accuracy: 0.8980 - val_loss: 0.2172 - val_accuracy: 0.8915\n",
      "Epoch 344/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3207 - accuracy: 0.8959 - val_loss: 0.1847 - val_accuracy: 0.9115\n",
      "Epoch 345/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3142 - accuracy: 0.9031 - val_loss: 0.2674 - val_accuracy: 0.8765\n",
      "Epoch 346/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2967 - accuracy: 0.8992 - val_loss: 0.1963 - val_accuracy: 0.9055\n",
      "Epoch 347/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2883 - accuracy: 0.9087 - val_loss: 0.2684 - val_accuracy: 0.8750\n",
      "Epoch 348/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2934 - accuracy: 0.9081 - val_loss: 0.3067 - val_accuracy: 0.8622\n",
      "Epoch 349/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3173 - accuracy: 0.8827 - val_loss: 0.1730 - val_accuracy: 0.9107\n",
      "Epoch 350/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2887 - accuracy: 0.9219 - val_loss: 0.3105 - val_accuracy: 0.8620\n",
      "Epoch 351/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3164 - accuracy: 0.8884 - val_loss: 0.2326 - val_accuracy: 0.8928\n",
      "Epoch 352/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2988 - accuracy: 0.9013 - val_loss: 0.2362 - val_accuracy: 0.8850\n",
      "Epoch 353/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3005 - accuracy: 0.9028 - val_loss: 0.2586 - val_accuracy: 0.8755\n",
      "Epoch 354/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3009 - accuracy: 0.9026 - val_loss: 0.2019 - val_accuracy: 0.9047\n",
      "Epoch 355/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2960 - accuracy: 0.9031 - val_loss: 0.2304 - val_accuracy: 0.8885\n",
      "Epoch 356/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3165 - accuracy: 0.8924 - val_loss: 0.2646 - val_accuracy: 0.8788\n",
      "Epoch 357/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3174 - accuracy: 0.9044 - val_loss: 0.2283 - val_accuracy: 0.8863\n",
      "Epoch 358/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3097 - accuracy: 0.8981 - val_loss: 0.2407 - val_accuracy: 0.8907\n",
      "Epoch 359/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3121 - accuracy: 0.8950 - val_loss: 0.1875 - val_accuracy: 0.9120\n",
      "Epoch 360/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3664 - accuracy: 0.9028 - val_loss: 0.3368 - val_accuracy: 0.8655\n",
      "Epoch 361/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5546 - accuracy: 0.8417 - val_loss: 0.3725 - val_accuracy: 0.8210\n",
      "Epoch 362/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5647 - accuracy: 0.8389 - val_loss: 0.3512 - val_accuracy: 0.8227\n",
      "Epoch 363/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5426 - accuracy: 0.8451 - val_loss: 0.5018 - val_accuracy: 0.7920\n",
      "Epoch 364/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5071 - accuracy: 0.8574 - val_loss: 0.3223 - val_accuracy: 0.8533\n",
      "Epoch 365/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4198 - accuracy: 0.8723 - val_loss: 0.2210 - val_accuracy: 0.8863\n",
      "Epoch 366/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5153 - accuracy: 0.8574 - val_loss: 0.2935 - val_accuracy: 0.8735\n",
      "Epoch 367/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4901 - accuracy: 0.8743 - val_loss: 0.4115 - val_accuracy: 0.8087\n",
      "Epoch 368/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4935 - accuracy: 0.8503 - val_loss: 0.2566 - val_accuracy: 0.8630\n",
      "Epoch 369/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4886 - accuracy: 0.8627 - val_loss: 0.3549 - val_accuracy: 0.8395\n",
      "Epoch 370/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4612 - accuracy: 0.8572 - val_loss: 0.1867 - val_accuracy: 0.9043\n",
      "Epoch 371/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3808 - accuracy: 0.8841 - val_loss: 0.2781 - val_accuracy: 0.8708\n",
      "Epoch 372/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3644 - accuracy: 0.8836 - val_loss: 0.2502 - val_accuracy: 0.8665\n",
      "Epoch 373/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3968 - accuracy: 0.8714 - val_loss: 0.2802 - val_accuracy: 0.8720\n",
      "Epoch 374/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4186 - accuracy: 0.8726 - val_loss: 0.3069 - val_accuracy: 0.8457\n",
      "Epoch 375/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4731 - accuracy: 0.8582 - val_loss: 0.2624 - val_accuracy: 0.8900\n",
      "Epoch 376/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4130 - accuracy: 0.8761 - val_loss: 0.4051 - val_accuracy: 0.8263\n",
      "Epoch 377/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3688 - accuracy: 0.8858 - val_loss: 0.1856 - val_accuracy: 0.9065\n",
      "Epoch 378/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3460 - accuracy: 0.8828 - val_loss: 0.2574 - val_accuracy: 0.8630\n",
      "Epoch 379/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3536 - accuracy: 0.8802 - val_loss: 0.2467 - val_accuracy: 0.8840\n",
      "Epoch 380/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3487 - accuracy: 0.8919 - val_loss: 0.2402 - val_accuracy: 0.8848\n",
      "Epoch 381/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3173 - accuracy: 0.8987 - val_loss: 0.2435 - val_accuracy: 0.8802\n",
      "Epoch 382/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.2932 - accuracy: 0.8992 - val_loss: 0.1563 - val_accuracy: 0.9265\n",
      "Epoch 383/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2886 - accuracy: 0.9086 - val_loss: 0.1778 - val_accuracy: 0.9168\n",
      "Epoch 384/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2857 - accuracy: 0.9088 - val_loss: 0.2449 - val_accuracy: 0.8917\n",
      "Epoch 385/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2869 - accuracy: 0.9051 - val_loss: 0.2054 - val_accuracy: 0.8995\n",
      "Epoch 386/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2873 - accuracy: 0.9110 - val_loss: 0.2288 - val_accuracy: 0.8988\n",
      "Epoch 387/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3905 - accuracy: 0.8854 - val_loss: 0.2733 - val_accuracy: 0.8777\n",
      "Epoch 388/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4315 - accuracy: 0.8639 - val_loss: 0.2308 - val_accuracy: 0.8660\n",
      "Epoch 389/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3862 - accuracy: 0.8629 - val_loss: 0.2694 - val_accuracy: 0.8730\n",
      "Epoch 390/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3330 - accuracy: 0.8880 - val_loss: 0.2883 - val_accuracy: 0.8590\n",
      "Epoch 391/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3299 - accuracy: 0.8868 - val_loss: 0.2658 - val_accuracy: 0.8708\n",
      "Epoch 392/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3267 - accuracy: 0.8893 - val_loss: 0.2262 - val_accuracy: 0.8838\n",
      "Epoch 393/1000\n",
      "16000/16000 [==============================] - ETA: 0s - loss: 0.3015 - accuracy: 0.88 - 0s 3us/step - loss: 0.3148 - accuracy: 0.8829 - val_loss: 0.2028 - val_accuracy: 0.8980\n",
      "Epoch 394/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3069 - accuracy: 0.9014 - val_loss: 0.2422 - val_accuracy: 0.8873\n",
      "Epoch 395/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2890 - accuracy: 0.9032 - val_loss: 0.1847 - val_accuracy: 0.9103\n",
      "Epoch 396/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2741 - accuracy: 0.9125 - val_loss: 0.2236 - val_accuracy: 0.8955\n",
      "Epoch 397/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2738 - accuracy: 0.9115 - val_loss: 0.2020 - val_accuracy: 0.9038\n",
      "Epoch 398/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3087 - accuracy: 0.9038 - val_loss: 0.1858 - val_accuracy: 0.9128\n",
      "Epoch 399/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2758 - accuracy: 0.9082 - val_loss: 0.1988 - val_accuracy: 0.9055\n",
      "Epoch 400/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2600 - accuracy: 0.9195 - val_loss: 0.2309 - val_accuracy: 0.8905\n",
      "Epoch 401/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2523 - accuracy: 0.9185 - val_loss: 0.2099 - val_accuracy: 0.9028\n",
      "Epoch 402/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2397 - accuracy: 0.9207 - val_loss: 0.1772 - val_accuracy: 0.9185\n",
      "Epoch 403/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2475 - accuracy: 0.9159 - val_loss: 0.1273 - val_accuracy: 0.9440\n",
      "Epoch 404/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2622 - accuracy: 0.9204 - val_loss: 0.1439 - val_accuracy: 0.9317\n",
      "Epoch 405/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2485 - accuracy: 0.9228 - val_loss: 0.2183 - val_accuracy: 0.8935\n",
      "Epoch 406/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2537 - accuracy: 0.9189 - val_loss: 0.2427 - val_accuracy: 0.8963\n",
      "Epoch 407/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3359 - accuracy: 0.9060 - val_loss: 0.3905 - val_accuracy: 0.8447\n",
      "Epoch 408/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4526 - accuracy: 0.8680 - val_loss: 0.4020 - val_accuracy: 0.8167\n",
      "Epoch 409/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4151 - accuracy: 0.8439 - val_loss: 0.1850 - val_accuracy: 0.9003\n",
      "Epoch 410/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4187 - accuracy: 0.8676 - val_loss: 0.2614 - val_accuracy: 0.8660\n",
      "Epoch 411/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4017 - accuracy: 0.8662 - val_loss: 0.2450 - val_accuracy: 0.8723\n",
      "Epoch 412/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3592 - accuracy: 0.8746 - val_loss: 0.2337 - val_accuracy: 0.8795\n",
      "Epoch 413/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3312 - accuracy: 0.8837 - val_loss: 0.2092 - val_accuracy: 0.8870\n",
      "Epoch 414/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3296 - accuracy: 0.8946 - val_loss: 0.2418 - val_accuracy: 0.8740\n",
      "Epoch 415/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3099 - accuracy: 0.8906 - val_loss: 0.2350 - val_accuracy: 0.8827\n",
      "Epoch 416/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.3167 - accuracy: 0.8982 - val_loss: 0.2294 - val_accuracy: 0.8842\n",
      "Epoch 417/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3225 - accuracy: 0.8850 - val_loss: 0.2713 - val_accuracy: 0.8705\n",
      "Epoch 418/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3285 - accuracy: 0.8843 - val_loss: 0.2523 - val_accuracy: 0.8740\n",
      "Epoch 419/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3305 - accuracy: 0.8944 - val_loss: 0.2702 - val_accuracy: 0.8735\n",
      "Epoch 420/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2963 - accuracy: 0.9029 - val_loss: 0.2201 - val_accuracy: 0.8860\n",
      "Epoch 421/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2966 - accuracy: 0.8997 - val_loss: 0.1998 - val_accuracy: 0.8985\n",
      "Epoch 422/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3032 - accuracy: 0.9082 - val_loss: 0.3230 - val_accuracy: 0.8493\n",
      "Epoch 423/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3501 - accuracy: 0.8678 - val_loss: 0.2272 - val_accuracy: 0.8752\n",
      "Epoch 424/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3541 - accuracy: 0.8819 - val_loss: 0.2798 - val_accuracy: 0.8675\n",
      "Epoch 425/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3083 - accuracy: 0.9003 - val_loss: 0.2653 - val_accuracy: 0.8820\n",
      "Epoch 426/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3416 - accuracy: 0.8968 - val_loss: 0.2836 - val_accuracy: 0.8765\n",
      "Epoch 427/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3069 - accuracy: 0.9057 - val_loss: 0.2902 - val_accuracy: 0.8660\n",
      "Epoch 428/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2824 - accuracy: 0.9073 - val_loss: 0.1969 - val_accuracy: 0.9080\n",
      "Epoch 429/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2715 - accuracy: 0.9141 - val_loss: 0.2390 - val_accuracy: 0.8845\n",
      "Epoch 430/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2557 - accuracy: 0.9199 - val_loss: 0.2052 - val_accuracy: 0.9097\n",
      "Epoch 431/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2462 - accuracy: 0.9175 - val_loss: 0.2188 - val_accuracy: 0.8947\n",
      "Epoch 432/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2491 - accuracy: 0.9202 - val_loss: 0.2289 - val_accuracy: 0.8947\n",
      "Epoch 433/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2557 - accuracy: 0.9180 - val_loss: 0.2203 - val_accuracy: 0.8992\n",
      "Epoch 434/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3099 - accuracy: 0.8947 - val_loss: 0.2165 - val_accuracy: 0.8905\n",
      "Epoch 435/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2869 - accuracy: 0.8994 - val_loss: 0.1941 - val_accuracy: 0.9107\n",
      "Epoch 436/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2684 - accuracy: 0.9199 - val_loss: 0.2592 - val_accuracy: 0.8758\n",
      "Epoch 437/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2873 - accuracy: 0.9137 - val_loss: 0.2503 - val_accuracy: 0.8917\n",
      "Epoch 438/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2677 - accuracy: 0.9112 - val_loss: 0.1859 - val_accuracy: 0.9165\n",
      "Epoch 439/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2786 - accuracy: 0.9144 - val_loss: 0.2630 - val_accuracy: 0.8783\n",
      "Epoch 440/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2806 - accuracy: 0.9107 - val_loss: 0.2287 - val_accuracy: 0.8923\n",
      "Epoch 441/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2600 - accuracy: 0.9138 - val_loss: 0.2276 - val_accuracy: 0.9005\n",
      "Epoch 442/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2933 - accuracy: 0.9082 - val_loss: 0.2222 - val_accuracy: 0.8940\n",
      "Epoch 443/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2577 - accuracy: 0.9121 - val_loss: 0.2210 - val_accuracy: 0.8970\n",
      "Epoch 444/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2500 - accuracy: 0.9271 - val_loss: 0.1880 - val_accuracy: 0.9133\n",
      "Epoch 445/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2996 - accuracy: 0.8982 - val_loss: 0.2056 - val_accuracy: 0.9030\n",
      "Epoch 446/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2845 - accuracy: 0.9120 - val_loss: 0.2241 - val_accuracy: 0.8945\n",
      "Epoch 447/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2884 - accuracy: 0.9136 - val_loss: 0.2983 - val_accuracy: 0.8725\n",
      "Epoch 448/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3145 - accuracy: 0.8924 - val_loss: 0.2583 - val_accuracy: 0.8710\n",
      "Epoch 449/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2987 - accuracy: 0.9033 - val_loss: 0.2367 - val_accuracy: 0.8913\n",
      "Epoch 450/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2701 - accuracy: 0.9172 - val_loss: 0.2281 - val_accuracy: 0.9025\n",
      "Epoch 451/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2694 - accuracy: 0.9159 - val_loss: 0.1903 - val_accuracy: 0.9120\n",
      "Epoch 452/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2471 - accuracy: 0.9189 - val_loss: 0.1868 - val_accuracy: 0.9150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 453/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2463 - accuracy: 0.9274 - val_loss: 0.2333 - val_accuracy: 0.9035\n",
      "Epoch 454/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2766 - accuracy: 0.9123 - val_loss: 0.1680 - val_accuracy: 0.9245\n",
      "Epoch 455/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2423 - accuracy: 0.9240 - val_loss: 0.1544 - val_accuracy: 0.9302\n",
      "Epoch 456/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2343 - accuracy: 0.9306 - val_loss: 0.2054 - val_accuracy: 0.9100\n",
      "Epoch 457/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2510 - accuracy: 0.9143 - val_loss: 0.1733 - val_accuracy: 0.9172\n",
      "Epoch 458/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2309 - accuracy: 0.9295 - val_loss: 0.1727 - val_accuracy: 0.9260\n",
      "Epoch 459/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2540 - accuracy: 0.9304 - val_loss: 0.2385 - val_accuracy: 0.8940\n",
      "Epoch 460/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2674 - accuracy: 0.9034 - val_loss: 0.1629 - val_accuracy: 0.9220\n",
      "Epoch 461/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2539 - accuracy: 0.9207 - val_loss: 0.2508 - val_accuracy: 0.8928\n",
      "Epoch 462/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2517 - accuracy: 0.9209 - val_loss: 0.2037 - val_accuracy: 0.9060\n",
      "Epoch 463/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2459 - accuracy: 0.9211 - val_loss: 0.1539 - val_accuracy: 0.9302\n",
      "Epoch 464/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2754 - accuracy: 0.9219 - val_loss: 0.2807 - val_accuracy: 0.8867\n",
      "Epoch 465/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2594 - accuracy: 0.9210 - val_loss: 0.2081 - val_accuracy: 0.9028\n",
      "Epoch 466/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2498 - accuracy: 0.9113 - val_loss: 0.1200 - val_accuracy: 0.9503\n",
      "Epoch 467/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3317 - accuracy: 0.9082 - val_loss: 0.3464 - val_accuracy: 0.8482\n",
      "Epoch 468/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3312 - accuracy: 0.8921 - val_loss: 0.2594 - val_accuracy: 0.8765\n",
      "Epoch 469/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2921 - accuracy: 0.9061 - val_loss: 0.2220 - val_accuracy: 0.8942\n",
      "Epoch 470/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2765 - accuracy: 0.9066 - val_loss: 0.2245 - val_accuracy: 0.8950\n",
      "Epoch 471/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3518 - accuracy: 0.8880 - val_loss: 0.1506 - val_accuracy: 0.9220\n",
      "Epoch 472/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2816 - accuracy: 0.9175 - val_loss: 0.1956 - val_accuracy: 0.9168\n",
      "Epoch 473/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3067 - accuracy: 0.8982 - val_loss: 0.2281 - val_accuracy: 0.8890\n",
      "Epoch 474/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2700 - accuracy: 0.9240 - val_loss: 0.3123 - val_accuracy: 0.8680\n",
      "Epoch 475/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2762 - accuracy: 0.9091 - val_loss: 0.1553 - val_accuracy: 0.9260\n",
      "Epoch 476/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2669 - accuracy: 0.9172 - val_loss: 0.1520 - val_accuracy: 0.9360\n",
      "Epoch 477/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2287 - accuracy: 0.9324 - val_loss: 0.2054 - val_accuracy: 0.9068\n",
      "Epoch 478/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2207 - accuracy: 0.9288 - val_loss: 0.1921 - val_accuracy: 0.9168\n",
      "Epoch 479/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2193 - accuracy: 0.9329 - val_loss: 0.2484 - val_accuracy: 0.8947\n",
      "Epoch 480/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2317 - accuracy: 0.9279 - val_loss: 0.2523 - val_accuracy: 0.8957\n",
      "Epoch 481/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2635 - accuracy: 0.9135 - val_loss: 0.1493 - val_accuracy: 0.9290\n",
      "Epoch 482/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2225 - accuracy: 0.9356 - val_loss: 0.2169 - val_accuracy: 0.9115\n",
      "Epoch 483/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2170 - accuracy: 0.9347 - val_loss: 0.2057 - val_accuracy: 0.9110\n",
      "Epoch 484/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2091 - accuracy: 0.9337 - val_loss: 0.1883 - val_accuracy: 0.9187\n",
      "Epoch 485/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2085 - accuracy: 0.9296 - val_loss: 0.1365 - val_accuracy: 0.9423\n",
      "Epoch 486/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1989 - accuracy: 0.9386 - val_loss: 0.1329 - val_accuracy: 0.9445\n",
      "Epoch 487/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2111 - accuracy: 0.9321 - val_loss: 0.1243 - val_accuracy: 0.9455\n",
      "Epoch 488/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2164 - accuracy: 0.9291 - val_loss: 0.1589 - val_accuracy: 0.9320\n",
      "Epoch 489/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2309 - accuracy: 0.9311 - val_loss: 0.2146 - val_accuracy: 0.9128\n",
      "Epoch 490/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2558 - accuracy: 0.9281 - val_loss: 0.3175 - val_accuracy: 0.8760\n",
      "Epoch 491/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2524 - accuracy: 0.9197 - val_loss: 0.1584 - val_accuracy: 0.9260\n",
      "Epoch 492/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2631 - accuracy: 0.9217 - val_loss: 0.3472 - val_accuracy: 0.8643\n",
      "Epoch 493/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3588 - accuracy: 0.8916 - val_loss: 0.3743 - val_accuracy: 0.8418\n",
      "Epoch 494/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3093 - accuracy: 0.9033 - val_loss: 0.2427 - val_accuracy: 0.9100\n",
      "Epoch 495/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2975 - accuracy: 0.9084 - val_loss: 0.1849 - val_accuracy: 0.9212\n",
      "Epoch 496/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2468 - accuracy: 0.9278 - val_loss: 0.1777 - val_accuracy: 0.9165\n",
      "Epoch 497/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2272 - accuracy: 0.9272 - val_loss: 0.1554 - val_accuracy: 0.9337\n",
      "Epoch 498/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2261 - accuracy: 0.9280 - val_loss: 0.1859 - val_accuracy: 0.9230\n",
      "Epoch 499/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2304 - accuracy: 0.9311 - val_loss: 0.2579 - val_accuracy: 0.8955\n",
      "Epoch 500/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2207 - accuracy: 0.9394 - val_loss: 0.2256 - val_accuracy: 0.9110\n",
      "Epoch 501/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2309 - accuracy: 0.9243 - val_loss: 0.1537 - val_accuracy: 0.9367\n",
      "Epoch 502/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2131 - accuracy: 0.9364 - val_loss: 0.1602 - val_accuracy: 0.9337\n",
      "Epoch 503/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2455 - accuracy: 0.9273 - val_loss: 0.2790 - val_accuracy: 0.8890\n",
      "Epoch 504/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2644 - accuracy: 0.9134 - val_loss: 0.1818 - val_accuracy: 0.9227\n",
      "Epoch 505/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2220 - accuracy: 0.9325 - val_loss: 0.1568 - val_accuracy: 0.9380\n",
      "Epoch 506/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2333 - accuracy: 0.9264 - val_loss: 0.1702 - val_accuracy: 0.9270\n",
      "Epoch 507/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2455 - accuracy: 0.9323 - val_loss: 0.2442 - val_accuracy: 0.9010\n",
      "Epoch 508/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2653 - accuracy: 0.9137 - val_loss: 0.2304 - val_accuracy: 0.8953\n",
      "Epoch 509/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2455 - accuracy: 0.9254 - val_loss: 0.2201 - val_accuracy: 0.9080\n",
      "Epoch 510/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2651 - accuracy: 0.9146 - val_loss: 0.1495 - val_accuracy: 0.9330\n",
      "Epoch 511/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2813 - accuracy: 0.9206 - val_loss: 0.2351 - val_accuracy: 0.8965\n",
      "Epoch 512/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2852 - accuracy: 0.9086 - val_loss: 0.1348 - val_accuracy: 0.9480\n",
      "Epoch 513/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3548 - accuracy: 0.8996 - val_loss: 0.2783 - val_accuracy: 0.8763\n",
      "Epoch 514/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2848 - accuracy: 0.9066 - val_loss: 0.1978 - val_accuracy: 0.9137\n",
      "Epoch 515/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2401 - accuracy: 0.9285 - val_loss: 0.2338 - val_accuracy: 0.8990\n",
      "Epoch 516/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2261 - accuracy: 0.9348 - val_loss: 0.2447 - val_accuracy: 0.8990\n",
      "Epoch 517/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2264 - accuracy: 0.9286 - val_loss: 0.1568 - val_accuracy: 0.9337\n",
      "Epoch 518/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2001 - accuracy: 0.9331 - val_loss: 0.1405 - val_accuracy: 0.9377\n",
      "Epoch 519/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2041 - accuracy: 0.9379 - val_loss: 0.1792 - val_accuracy: 0.9270\n",
      "Epoch 520/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1882 - accuracy: 0.9399 - val_loss: 0.1551 - val_accuracy: 0.9352\n",
      "Epoch 521/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1800 - accuracy: 0.9431 - val_loss: 0.1400 - val_accuracy: 0.9433\n",
      "Epoch 522/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1784 - accuracy: 0.9463 - val_loss: 0.1414 - val_accuracy: 0.9402\n",
      "Epoch 523/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1755 - accuracy: 0.9438 - val_loss: 0.1412 - val_accuracy: 0.9400\n",
      "Epoch 524/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1735 - accuracy: 0.9451 - val_loss: 0.1704 - val_accuracy: 0.9310\n",
      "Epoch 525/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1736 - accuracy: 0.9445 - val_loss: 0.1491 - val_accuracy: 0.9362\n",
      "Epoch 526/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1799 - accuracy: 0.9411 - val_loss: 0.1352 - val_accuracy: 0.9450\n",
      "Epoch 527/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1808 - accuracy: 0.9456 - val_loss: 0.1193 - val_accuracy: 0.9530\n",
      "Epoch 528/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1835 - accuracy: 0.9466 - val_loss: 0.1715 - val_accuracy: 0.9312\n",
      "Epoch 529/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1882 - accuracy: 0.9403 - val_loss: 0.1290 - val_accuracy: 0.9480\n",
      "Epoch 530/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1681 - accuracy: 0.9473 - val_loss: 0.1653 - val_accuracy: 0.9342\n",
      "Epoch 531/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1885 - accuracy: 0.9469 - val_loss: 0.2792 - val_accuracy: 0.8938\n",
      "Epoch 532/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2177 - accuracy: 0.9279 - val_loss: 0.1590 - val_accuracy: 0.9392\n",
      "Epoch 533/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2351 - accuracy: 0.9326 - val_loss: 0.1408 - val_accuracy: 0.9392\n",
      "Epoch 534/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2051 - accuracy: 0.9386 - val_loss: 0.1909 - val_accuracy: 0.9255\n",
      "Epoch 535/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2801 - accuracy: 0.9239 - val_loss: 0.2224 - val_accuracy: 0.9128\n",
      "Epoch 536/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2769 - accuracy: 0.9189 - val_loss: 0.2397 - val_accuracy: 0.9018\n",
      "Epoch 537/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2566 - accuracy: 0.9175 - val_loss: 0.2745 - val_accuracy: 0.8942\n",
      "Epoch 538/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2417 - accuracy: 0.9270 - val_loss: 0.2581 - val_accuracy: 0.9003\n",
      "Epoch 539/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2274 - accuracy: 0.9271 - val_loss: 0.2064 - val_accuracy: 0.9175\n",
      "Epoch 540/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2146 - accuracy: 0.9416 - val_loss: 0.1998 - val_accuracy: 0.9190\n",
      "Epoch 541/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.2195 - accuracy: 0.9348 - val_loss: 0.1847 - val_accuracy: 0.9215\n",
      "Epoch 542/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2215 - accuracy: 0.9261 - val_loss: 0.1641 - val_accuracy: 0.9252\n",
      "Epoch 543/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2087 - accuracy: 0.9313 - val_loss: 0.1600 - val_accuracy: 0.9345\n",
      "Epoch 544/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2165 - accuracy: 0.9368 - val_loss: 0.1953 - val_accuracy: 0.9183\n",
      "Epoch 545/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2214 - accuracy: 0.9315 - val_loss: 0.1725 - val_accuracy: 0.9320\n",
      "Epoch 546/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2135 - accuracy: 0.9344 - val_loss: 0.1741 - val_accuracy: 0.9258\n",
      "Epoch 547/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2129 - accuracy: 0.9383 - val_loss: 0.2252 - val_accuracy: 0.9135\n",
      "Epoch 548/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2372 - accuracy: 0.9399 - val_loss: 0.2236 - val_accuracy: 0.9133\n",
      "Epoch 549/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2539 - accuracy: 0.9157 - val_loss: 0.2034 - val_accuracy: 0.9200\n",
      "Epoch 550/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2686 - accuracy: 0.9343 - val_loss: 0.2055 - val_accuracy: 0.9112\n",
      "Epoch 551/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3076 - accuracy: 0.9036 - val_loss: 0.2129 - val_accuracy: 0.9060\n",
      "Epoch 552/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2959 - accuracy: 0.9132 - val_loss: 0.2121 - val_accuracy: 0.9155\n",
      "Epoch 553/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2608 - accuracy: 0.9357 - val_loss: 0.1536 - val_accuracy: 0.9405\n",
      "Epoch 554/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2226 - accuracy: 0.9368 - val_loss: 0.2051 - val_accuracy: 0.9175\n",
      "Epoch 555/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2394 - accuracy: 0.9278 - val_loss: 0.2150 - val_accuracy: 0.9118\n",
      "Epoch 556/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2367 - accuracy: 0.9297 - val_loss: 0.2717 - val_accuracy: 0.9045\n",
      "Epoch 557/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2838 - accuracy: 0.9277 - val_loss: 0.2764 - val_accuracy: 0.8905\n",
      "Epoch 558/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2581 - accuracy: 0.9208 - val_loss: 0.2188 - val_accuracy: 0.9122\n",
      "Epoch 559/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2581 - accuracy: 0.9193 - val_loss: 0.2215 - val_accuracy: 0.9025\n",
      "Epoch 560/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2471 - accuracy: 0.9219 - val_loss: 0.1698 - val_accuracy: 0.9262\n",
      "Epoch 561/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2239 - accuracy: 0.9374 - val_loss: 0.1975 - val_accuracy: 0.9205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 562/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3133 - accuracy: 0.9181 - val_loss: 0.2668 - val_accuracy: 0.8950\n",
      "Epoch 563/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3947 - accuracy: 0.8845 - val_loss: 0.3328 - val_accuracy: 0.8600\n",
      "Epoch 564/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4066 - accuracy: 0.8745 - val_loss: 0.2038 - val_accuracy: 0.9170\n",
      "Epoch 565/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3095 - accuracy: 0.9020 - val_loss: 0.1321 - val_accuracy: 0.9448\n",
      "Epoch 566/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2822 - accuracy: 0.9184 - val_loss: 0.2373 - val_accuracy: 0.9070\n",
      "Epoch 567/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2412 - accuracy: 0.9306 - val_loss: 0.1834 - val_accuracy: 0.9233\n",
      "Epoch 568/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2468 - accuracy: 0.9256 - val_loss: 0.2202 - val_accuracy: 0.9145\n",
      "Epoch 569/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2277 - accuracy: 0.9299 - val_loss: 0.1687 - val_accuracy: 0.9337\n",
      "Epoch 570/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2161 - accuracy: 0.9359 - val_loss: 0.1747 - val_accuracy: 0.9293\n",
      "Epoch 571/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2176 - accuracy: 0.9334 - val_loss: 0.1822 - val_accuracy: 0.9258\n",
      "Epoch 572/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2061 - accuracy: 0.9394 - val_loss: 0.2184 - val_accuracy: 0.9172\n",
      "Epoch 573/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2515 - accuracy: 0.9210 - val_loss: 0.2290 - val_accuracy: 0.9018\n",
      "Epoch 574/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2155 - accuracy: 0.9326 - val_loss: 0.1876 - val_accuracy: 0.9258\n",
      "Epoch 575/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2012 - accuracy: 0.9356 - val_loss: 0.2088 - val_accuracy: 0.9165\n",
      "Epoch 576/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1811 - accuracy: 0.9445 - val_loss: 0.1626 - val_accuracy: 0.9410\n",
      "Epoch 577/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1842 - accuracy: 0.9446 - val_loss: 0.1683 - val_accuracy: 0.9337\n",
      "Epoch 578/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1775 - accuracy: 0.9485 - val_loss: 0.1985 - val_accuracy: 0.9277\n",
      "Epoch 579/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2196 - accuracy: 0.9399 - val_loss: 0.2276 - val_accuracy: 0.9130\n",
      "Epoch 580/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2714 - accuracy: 0.9118 - val_loss: 0.2230 - val_accuracy: 0.9105\n",
      "Epoch 581/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2160 - accuracy: 0.9336 - val_loss: 0.1768 - val_accuracy: 0.9308\n",
      "Epoch 582/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2171 - accuracy: 0.9356 - val_loss: 0.2119 - val_accuracy: 0.9133\n",
      "Epoch 583/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2099 - accuracy: 0.9326 - val_loss: 0.1646 - val_accuracy: 0.9405\n",
      "Epoch 584/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2358 - accuracy: 0.9315 - val_loss: 0.1881 - val_accuracy: 0.9237\n",
      "Epoch 585/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2043 - accuracy: 0.9398 - val_loss: 0.1647 - val_accuracy: 0.9408\n",
      "Epoch 586/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3232 - accuracy: 0.9216 - val_loss: 0.3161 - val_accuracy: 0.8817\n",
      "Epoch 587/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3356 - accuracy: 0.8906 - val_loss: 0.2875 - val_accuracy: 0.8815\n",
      "Epoch 588/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2927 - accuracy: 0.9105 - val_loss: 0.1972 - val_accuracy: 0.9197\n",
      "Epoch 589/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4770 - accuracy: 0.8892 - val_loss: 0.8623 - val_accuracy: 0.7640\n",
      "Epoch 590/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5742 - accuracy: 0.8709 - val_loss: 0.2334 - val_accuracy: 0.8970\n",
      "Epoch 591/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3698 - accuracy: 0.8978 - val_loss: 0.3308 - val_accuracy: 0.8767\n",
      "Epoch 592/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3351 - accuracy: 0.9065 - val_loss: 0.2685 - val_accuracy: 0.8882\n",
      "Epoch 593/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2915 - accuracy: 0.9223 - val_loss: 0.2376 - val_accuracy: 0.8940\n",
      "Epoch 594/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3154 - accuracy: 0.8880 - val_loss: 0.2043 - val_accuracy: 0.9105\n",
      "Epoch 595/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2641 - accuracy: 0.9304 - val_loss: 0.2714 - val_accuracy: 0.8950\n",
      "Epoch 596/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2648 - accuracy: 0.9181 - val_loss: 0.2223 - val_accuracy: 0.9100\n",
      "Epoch 597/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2293 - accuracy: 0.9254 - val_loss: 0.1671 - val_accuracy: 0.9308\n",
      "Epoch 598/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2228 - accuracy: 0.9252 - val_loss: 0.1839 - val_accuracy: 0.9252\n",
      "Epoch 599/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2189 - accuracy: 0.9306 - val_loss: 0.2115 - val_accuracy: 0.9110\n",
      "Epoch 600/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2133 - accuracy: 0.9354 - val_loss: 0.1819 - val_accuracy: 0.9243\n",
      "Epoch 601/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2080 - accuracy: 0.9285 - val_loss: 0.1374 - val_accuracy: 0.9455\n",
      "Epoch 602/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2321 - accuracy: 0.9311 - val_loss: 0.2836 - val_accuracy: 0.8813\n",
      "Epoch 603/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2452 - accuracy: 0.9211 - val_loss: 0.1867 - val_accuracy: 0.9212\n",
      "Epoch 604/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2352 - accuracy: 0.9178 - val_loss: 0.1646 - val_accuracy: 0.9320\n",
      "Epoch 605/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2636 - accuracy: 0.9283 - val_loss: 0.3008 - val_accuracy: 0.8825\n",
      "Epoch 606/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2520 - accuracy: 0.9094 - val_loss: 0.1422 - val_accuracy: 0.9430\n",
      "Epoch 607/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2244 - accuracy: 0.9276 - val_loss: 0.1975 - val_accuracy: 0.9178\n",
      "Epoch 608/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2105 - accuracy: 0.9354 - val_loss: 0.1635 - val_accuracy: 0.9327\n",
      "Epoch 609/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1965 - accuracy: 0.9365 - val_loss: 0.1675 - val_accuracy: 0.9310\n",
      "Epoch 610/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1912 - accuracy: 0.9393 - val_loss: 0.1549 - val_accuracy: 0.9395\n",
      "Epoch 611/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1964 - accuracy: 0.9379 - val_loss: 0.1618 - val_accuracy: 0.9365\n",
      "Epoch 612/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1970 - accuracy: 0.9400 - val_loss: 0.1943 - val_accuracy: 0.9175\n",
      "Epoch 613/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1918 - accuracy: 0.9346 - val_loss: 0.1446 - val_accuracy: 0.9427\n",
      "Epoch 614/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1835 - accuracy: 0.9493 - val_loss: 0.1563 - val_accuracy: 0.9390\n",
      "Epoch 615/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1763 - accuracy: 0.9396 - val_loss: 0.1576 - val_accuracy: 0.9385\n",
      "Epoch 616/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1886 - accuracy: 0.9408 - val_loss: 0.2099 - val_accuracy: 0.9170\n",
      "Epoch 617/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1851 - accuracy: 0.9390 - val_loss: 0.1444 - val_accuracy: 0.9413\n",
      "Epoch 618/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1829 - accuracy: 0.9463 - val_loss: 0.1977 - val_accuracy: 0.9187\n",
      "Epoch 619/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1857 - accuracy: 0.9383 - val_loss: 0.1531 - val_accuracy: 0.9402\n",
      "Epoch 620/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1795 - accuracy: 0.9444 - val_loss: 0.1799 - val_accuracy: 0.9270\n",
      "Epoch 621/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1720 - accuracy: 0.9432 - val_loss: 0.1380 - val_accuracy: 0.9455\n",
      "Epoch 622/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1766 - accuracy: 0.9448 - val_loss: 0.1535 - val_accuracy: 0.9413\n",
      "Epoch 623/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1823 - accuracy: 0.9450 - val_loss: 0.1968 - val_accuracy: 0.9187\n",
      "Epoch 624/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1850 - accuracy: 0.9365 - val_loss: 0.1275 - val_accuracy: 0.9525\n",
      "Epoch 625/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1837 - accuracy: 0.9443 - val_loss: 0.1551 - val_accuracy: 0.9417\n",
      "Epoch 626/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1750 - accuracy: 0.9471 - val_loss: 0.1483 - val_accuracy: 0.9440\n",
      "Epoch 627/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1679 - accuracy: 0.9450 - val_loss: 0.1425 - val_accuracy: 0.9473\n",
      "Epoch 628/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1701 - accuracy: 0.9499 - val_loss: 0.1793 - val_accuracy: 0.9340\n",
      "Epoch 629/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1802 - accuracy: 0.9404 - val_loss: 0.1463 - val_accuracy: 0.9423\n",
      "Epoch 630/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1664 - accuracy: 0.9516 - val_loss: 0.1789 - val_accuracy: 0.9320\n",
      "Epoch 631/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1706 - accuracy: 0.9427 - val_loss: 0.1492 - val_accuracy: 0.9433\n",
      "Epoch 632/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1745 - accuracy: 0.9477 - val_loss: 0.1622 - val_accuracy: 0.9362\n",
      "Epoch 633/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1648 - accuracy: 0.9480 - val_loss: 0.1500 - val_accuracy: 0.9465\n",
      "Epoch 634/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1611 - accuracy: 0.9457 - val_loss: 0.1406 - val_accuracy: 0.9477\n",
      "Epoch 635/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1618 - accuracy: 0.9529 - val_loss: 0.1645 - val_accuracy: 0.9337\n",
      "Epoch 636/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1586 - accuracy: 0.9479 - val_loss: 0.1505 - val_accuracy: 0.9435\n",
      "Epoch 637/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1521 - accuracy: 0.9515 - val_loss: 0.1397 - val_accuracy: 0.9480\n",
      "Epoch 638/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1551 - accuracy: 0.9505 - val_loss: 0.1260 - val_accuracy: 0.9570\n",
      "Epoch 639/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1691 - accuracy: 0.9470 - val_loss: 0.1642 - val_accuracy: 0.9390\n",
      "Epoch 640/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2294 - accuracy: 0.9383 - val_loss: 0.2314 - val_accuracy: 0.9145\n",
      "Epoch 641/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2260 - accuracy: 0.9254 - val_loss: 0.2136 - val_accuracy: 0.9210\n",
      "Epoch 642/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1958 - accuracy: 0.9454 - val_loss: 0.1733 - val_accuracy: 0.9370\n",
      "Epoch 643/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1871 - accuracy: 0.9378 - val_loss: 0.1600 - val_accuracy: 0.9383\n",
      "Epoch 644/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1933 - accuracy: 0.9471 - val_loss: 0.2512 - val_accuracy: 0.9107\n",
      "Epoch 645/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1984 - accuracy: 0.9400 - val_loss: 0.1825 - val_accuracy: 0.9310\n",
      "Epoch 646/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1797 - accuracy: 0.9427 - val_loss: 0.1235 - val_accuracy: 0.9590\n",
      "Epoch 647/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1883 - accuracy: 0.9448 - val_loss: 0.1704 - val_accuracy: 0.9360\n",
      "Epoch 648/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1771 - accuracy: 0.9475 - val_loss: 0.1793 - val_accuracy: 0.9362\n",
      "Epoch 649/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1745 - accuracy: 0.9459 - val_loss: 0.1314 - val_accuracy: 0.9540\n",
      "Epoch 650/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1614 - accuracy: 0.9465 - val_loss: 0.1373 - val_accuracy: 0.9473\n",
      "Epoch 651/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1601 - accuracy: 0.9501 - val_loss: 0.1424 - val_accuracy: 0.9513\n",
      "Epoch 652/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1498 - accuracy: 0.9603 - val_loss: 0.1435 - val_accuracy: 0.9488\n",
      "Epoch 653/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1404 - accuracy: 0.9511 - val_loss: 0.1291 - val_accuracy: 0.9542\n",
      "Epoch 654/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1490 - accuracy: 0.9571 - val_loss: 0.1920 - val_accuracy: 0.9290\n",
      "Epoch 655/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2106 - accuracy: 0.9359 - val_loss: 0.2057 - val_accuracy: 0.9227\n",
      "Epoch 656/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1718 - accuracy: 0.9444 - val_loss: 0.1759 - val_accuracy: 0.9402\n",
      "Epoch 657/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1617 - accuracy: 0.9534 - val_loss: 0.1344 - val_accuracy: 0.9550\n",
      "Epoch 658/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1467 - accuracy: 0.9521 - val_loss: 0.1309 - val_accuracy: 0.9530\n",
      "Epoch 659/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1460 - accuracy: 0.9565 - val_loss: 0.1559 - val_accuracy: 0.9482\n",
      "Epoch 660/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1442 - accuracy: 0.9590 - val_loss: 0.1358 - val_accuracy: 0.9530\n",
      "Epoch 661/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1461 - accuracy: 0.9540 - val_loss: 0.1525 - val_accuracy: 0.9475\n",
      "Epoch 662/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1438 - accuracy: 0.9591 - val_loss: 0.1510 - val_accuracy: 0.9510\n",
      "Epoch 663/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1394 - accuracy: 0.9558 - val_loss: 0.1267 - val_accuracy: 0.9570\n",
      "Epoch 664/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1515 - accuracy: 0.9530 - val_loss: 0.1422 - val_accuracy: 0.9498\n",
      "Epoch 665/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1627 - accuracy: 0.9534 - val_loss: 0.2075 - val_accuracy: 0.9308\n",
      "Epoch 666/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1810 - accuracy: 0.9475 - val_loss: 0.1572 - val_accuracy: 0.9470\n",
      "Epoch 667/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1665 - accuracy: 0.9466 - val_loss: 0.1446 - val_accuracy: 0.9503\n",
      "Epoch 668/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1710 - accuracy: 0.9541 - val_loss: 0.2747 - val_accuracy: 0.9075\n",
      "Epoch 669/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1965 - accuracy: 0.9415 - val_loss: 0.1642 - val_accuracy: 0.9377\n",
      "Epoch 670/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1920 - accuracy: 0.9350 - val_loss: 0.1648 - val_accuracy: 0.9365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 671/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1859 - accuracy: 0.9461 - val_loss: 0.1752 - val_accuracy: 0.9340\n",
      "Epoch 672/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1859 - accuracy: 0.9407 - val_loss: 0.1742 - val_accuracy: 0.9380\n",
      "Epoch 673/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1755 - accuracy: 0.9496 - val_loss: 0.1459 - val_accuracy: 0.9477\n",
      "Epoch 674/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1592 - accuracy: 0.9492 - val_loss: 0.1557 - val_accuracy: 0.9448\n",
      "Epoch 675/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1536 - accuracy: 0.9539 - val_loss: 0.1376 - val_accuracy: 0.9517\n",
      "Epoch 676/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2000 - accuracy: 0.9435 - val_loss: 0.2172 - val_accuracy: 0.9172\n",
      "Epoch 677/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2226 - accuracy: 0.9259 - val_loss: 0.2031 - val_accuracy: 0.9298\n",
      "Epoch 678/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2456 - accuracy: 0.9436 - val_loss: 0.2545 - val_accuracy: 0.9087\n",
      "Epoch 679/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2658 - accuracy: 0.9173 - val_loss: 0.2534 - val_accuracy: 0.9043\n",
      "Epoch 680/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2050 - accuracy: 0.9333 - val_loss: 0.1818 - val_accuracy: 0.9280\n",
      "Epoch 681/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2067 - accuracy: 0.9516 - val_loss: 0.2244 - val_accuracy: 0.9200\n",
      "Epoch 682/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1786 - accuracy: 0.9441 - val_loss: 0.1460 - val_accuracy: 0.9450\n",
      "Epoch 683/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1605 - accuracy: 0.9499 - val_loss: 0.1639 - val_accuracy: 0.9433\n",
      "Epoch 684/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1538 - accuracy: 0.9579 - val_loss: 0.1571 - val_accuracy: 0.9452\n",
      "Epoch 685/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1576 - accuracy: 0.9486 - val_loss: 0.1540 - val_accuracy: 0.9450\n",
      "Epoch 686/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1679 - accuracy: 0.9498 - val_loss: 0.1665 - val_accuracy: 0.9455\n",
      "Epoch 687/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2500 - accuracy: 0.9394 - val_loss: 0.2849 - val_accuracy: 0.9080\n",
      "Epoch 688/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2044 - accuracy: 0.9432 - val_loss: 0.1398 - val_accuracy: 0.9495\n",
      "Epoch 689/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1814 - accuracy: 0.9448 - val_loss: 0.1841 - val_accuracy: 0.9348\n",
      "Epoch 690/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1539 - accuracy: 0.9534 - val_loss: 0.1635 - val_accuracy: 0.9440\n",
      "Epoch 691/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1440 - accuracy: 0.9500 - val_loss: 0.1402 - val_accuracy: 0.9507\n",
      "Epoch 692/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1326 - accuracy: 0.9668 - val_loss: 0.1425 - val_accuracy: 0.9528\n",
      "Epoch 693/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1372 - accuracy: 0.9550 - val_loss: 0.1559 - val_accuracy: 0.9477\n",
      "Epoch 694/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1354 - accuracy: 0.9636 - val_loss: 0.1509 - val_accuracy: 0.9492\n",
      "Epoch 695/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1354 - accuracy: 0.9554 - val_loss: 0.1640 - val_accuracy: 0.9433\n",
      "Epoch 696/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1283 - accuracy: 0.9624 - val_loss: 0.1522 - val_accuracy: 0.9517\n",
      "Epoch 697/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1517 - accuracy: 0.9595 - val_loss: 0.1973 - val_accuracy: 0.9295\n",
      "Epoch 698/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1843 - accuracy: 0.9424 - val_loss: 0.1757 - val_accuracy: 0.9410\n",
      "Epoch 699/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1674 - accuracy: 0.9512 - val_loss: 0.1651 - val_accuracy: 0.9503\n",
      "Epoch 700/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1487 - accuracy: 0.9569 - val_loss: 0.1575 - val_accuracy: 0.9457\n",
      "Epoch 701/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1341 - accuracy: 0.9585 - val_loss: 0.1344 - val_accuracy: 0.9567\n",
      "Epoch 702/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1240 - accuracy: 0.9663 - val_loss: 0.1505 - val_accuracy: 0.9515\n",
      "Epoch 703/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1437 - accuracy: 0.9559 - val_loss: 0.1469 - val_accuracy: 0.9480\n",
      "Epoch 704/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1602 - accuracy: 0.9578 - val_loss: 0.2266 - val_accuracy: 0.9245\n",
      "Epoch 705/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2008 - accuracy: 0.9423 - val_loss: 0.2307 - val_accuracy: 0.9250\n",
      "Epoch 706/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1920 - accuracy: 0.9446 - val_loss: 0.1834 - val_accuracy: 0.9410\n",
      "Epoch 707/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1565 - accuracy: 0.9526 - val_loss: 0.1760 - val_accuracy: 0.9380\n",
      "Epoch 708/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1450 - accuracy: 0.9571 - val_loss: 0.1869 - val_accuracy: 0.9405\n",
      "Epoch 709/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1503 - accuracy: 0.9574 - val_loss: 0.1291 - val_accuracy: 0.9592\n",
      "Epoch 710/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1355 - accuracy: 0.9553 - val_loss: 0.1392 - val_accuracy: 0.9525\n",
      "Epoch 711/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1304 - accuracy: 0.9621 - val_loss: 0.1978 - val_accuracy: 0.9350\n",
      "Epoch 712/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1326 - accuracy: 0.9572 - val_loss: 0.1109 - val_accuracy: 0.9630\n",
      "Epoch 713/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2791 - accuracy: 0.9336 - val_loss: 0.2964 - val_accuracy: 0.9007\n",
      "Epoch 714/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4162 - accuracy: 0.8949 - val_loss: 0.4694 - val_accuracy: 0.8670\n",
      "Epoch 715/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4380 - accuracy: 0.8878 - val_loss: 0.2251 - val_accuracy: 0.9047\n",
      "Epoch 716/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2976 - accuracy: 0.9191 - val_loss: 0.2768 - val_accuracy: 0.8947\n",
      "Epoch 717/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2521 - accuracy: 0.9242 - val_loss: 0.2234 - val_accuracy: 0.9130\n",
      "Epoch 718/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2161 - accuracy: 0.9297 - val_loss: 0.1641 - val_accuracy: 0.9395\n",
      "Epoch 719/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2095 - accuracy: 0.9447 - val_loss: 0.2420 - val_accuracy: 0.9097\n",
      "Epoch 720/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2519 - accuracy: 0.9157 - val_loss: 0.1604 - val_accuracy: 0.9395\n",
      "Epoch 721/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1933 - accuracy: 0.9435 - val_loss: 0.1930 - val_accuracy: 0.9327\n",
      "Epoch 722/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1797 - accuracy: 0.9405 - val_loss: 0.1526 - val_accuracy: 0.9457\n",
      "Epoch 723/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2326 - accuracy: 0.9311 - val_loss: 0.1982 - val_accuracy: 0.9298\n",
      "Epoch 724/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1687 - accuracy: 0.9573 - val_loss: 0.1593 - val_accuracy: 0.9475\n",
      "Epoch 725/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2109 - accuracy: 0.9567 - val_loss: 0.1814 - val_accuracy: 0.9413\n",
      "Epoch 726/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2189 - accuracy: 0.9388 - val_loss: 0.1888 - val_accuracy: 0.9320\n",
      "Epoch 727/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2502 - accuracy: 0.9307 - val_loss: 0.1773 - val_accuracy: 0.9400\n",
      "Epoch 728/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3389 - accuracy: 0.9376 - val_loss: 0.3401 - val_accuracy: 0.9082\n",
      "Epoch 729/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3747 - accuracy: 0.9126 - val_loss: 0.1799 - val_accuracy: 0.9268\n",
      "Epoch 730/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3258 - accuracy: 0.9203 - val_loss: 0.2648 - val_accuracy: 0.9112\n",
      "Epoch 731/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3365 - accuracy: 0.9174 - val_loss: 0.3180 - val_accuracy: 0.8935\n",
      "Epoch 732/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.4672 - accuracy: 0.9043 - val_loss: 0.3167 - val_accuracy: 0.9172\n",
      "Epoch 733/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6336 - accuracy: 0.9044 - val_loss: 0.5029 - val_accuracy: 0.8677\n",
      "Epoch 734/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4751 - accuracy: 0.9107 - val_loss: 0.1961 - val_accuracy: 0.9320\n",
      "Epoch 735/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4523 - accuracy: 0.9101 - val_loss: 0.2790 - val_accuracy: 0.9135\n",
      "Epoch 736/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2698 - accuracy: 0.9383 - val_loss: 0.2466 - val_accuracy: 0.9100\n",
      "Epoch 737/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2906 - accuracy: 0.9153 - val_loss: 0.2099 - val_accuracy: 0.9160\n",
      "Epoch 738/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1938 - accuracy: 0.9369 - val_loss: 0.1459 - val_accuracy: 0.9410\n",
      "Epoch 739/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1993 - accuracy: 0.9471 - val_loss: 0.1728 - val_accuracy: 0.9335\n",
      "Epoch 740/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1643 - accuracy: 0.9508 - val_loss: 0.1155 - val_accuracy: 0.9563\n",
      "Epoch 741/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2710 - accuracy: 0.9424 - val_loss: 0.2731 - val_accuracy: 0.9143\n",
      "Epoch 742/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3636 - accuracy: 0.9294 - val_loss: 0.2627 - val_accuracy: 0.9175\n",
      "Epoch 743/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3877 - accuracy: 0.9244 - val_loss: 0.3126 - val_accuracy: 0.8947\n",
      "Epoch 744/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3141 - accuracy: 0.9189 - val_loss: 0.2408 - val_accuracy: 0.9140\n",
      "Epoch 745/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3108 - accuracy: 0.9237 - val_loss: 0.1738 - val_accuracy: 0.9542\n",
      "Epoch 746/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2421 - accuracy: 0.9386 - val_loss: 0.1923 - val_accuracy: 0.9330\n",
      "Epoch 747/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2462 - accuracy: 0.9362 - val_loss: 0.1607 - val_accuracy: 0.9388\n",
      "Epoch 748/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1852 - accuracy: 0.9512 - val_loss: 0.1758 - val_accuracy: 0.9305\n",
      "Epoch 749/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1677 - accuracy: 0.9489 - val_loss: 0.1495 - val_accuracy: 0.9415\n",
      "Epoch 750/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1871 - accuracy: 0.9457 - val_loss: 0.1625 - val_accuracy: 0.9377\n",
      "Epoch 751/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2114 - accuracy: 0.9346 - val_loss: 0.2041 - val_accuracy: 0.9187\n",
      "Epoch 752/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1970 - accuracy: 0.9456 - val_loss: 0.1773 - val_accuracy: 0.9402\n",
      "Epoch 753/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2198 - accuracy: 0.9397 - val_loss: 0.1740 - val_accuracy: 0.9367\n",
      "Epoch 754/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2231 - accuracy: 0.9405 - val_loss: 0.2539 - val_accuracy: 0.9107\n",
      "Epoch 755/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2395 - accuracy: 0.9306 - val_loss: 0.1413 - val_accuracy: 0.9477\n",
      "Epoch 756/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1733 - accuracy: 0.9464 - val_loss: 0.1511 - val_accuracy: 0.9450\n",
      "Epoch 757/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1517 - accuracy: 0.9598 - val_loss: 0.1627 - val_accuracy: 0.9405\n",
      "Epoch 758/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1435 - accuracy: 0.9561 - val_loss: 0.1552 - val_accuracy: 0.9433\n",
      "Epoch 759/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1356 - accuracy: 0.9601 - val_loss: 0.1553 - val_accuracy: 0.9448\n",
      "Epoch 760/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1422 - accuracy: 0.9578 - val_loss: 0.1516 - val_accuracy: 0.9465\n",
      "Epoch 761/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1361 - accuracy: 0.9569 - val_loss: 0.1216 - val_accuracy: 0.9597\n",
      "Epoch 762/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1315 - accuracy: 0.9634 - val_loss: 0.1472 - val_accuracy: 0.9510\n",
      "Epoch 763/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1281 - accuracy: 0.9614 - val_loss: 0.1378 - val_accuracy: 0.9548\n",
      "Epoch 764/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1370 - accuracy: 0.9574 - val_loss: 0.1682 - val_accuracy: 0.9440\n",
      "Epoch 765/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1349 - accuracy: 0.9624 - val_loss: 0.1419 - val_accuracy: 0.9553\n",
      "Epoch 766/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1296 - accuracy: 0.9594 - val_loss: 0.1396 - val_accuracy: 0.9535\n",
      "Epoch 767/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.1325 - accuracy: 0.9600 - val_loss: 0.1676 - val_accuracy: 0.9413\n",
      "Epoch 768/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.1241 - accuracy: 0.9642 - val_loss: 0.1373 - val_accuracy: 0.9553\n",
      "Epoch 769/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1255 - accuracy: 0.9642 - val_loss: 0.1240 - val_accuracy: 0.9592\n",
      "Epoch 770/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1467 - accuracy: 0.9557 - val_loss: 0.1630 - val_accuracy: 0.9450\n",
      "Epoch 771/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1257 - accuracy: 0.9636 - val_loss: 0.1784 - val_accuracy: 0.9440\n",
      "Epoch 772/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1387 - accuracy: 0.9607 - val_loss: 0.1624 - val_accuracy: 0.9463\n",
      "Epoch 773/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1559 - accuracy: 0.9498 - val_loss: 0.1736 - val_accuracy: 0.9442\n",
      "Epoch 774/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.1273 - accuracy: 0.9650 - val_loss: 0.1349 - val_accuracy: 0.9580\n",
      "Epoch 775/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1208 - accuracy: 0.9613 - val_loss: 0.1262 - val_accuracy: 0.9605\n",
      "Epoch 776/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1239 - accuracy: 0.9676 - val_loss: 0.1648 - val_accuracy: 0.9480\n",
      "Epoch 777/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1231 - accuracy: 0.9626 - val_loss: 0.1577 - val_accuracy: 0.9477\n",
      "Epoch 778/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1379 - accuracy: 0.9599 - val_loss: 0.1462 - val_accuracy: 0.9555\n",
      "Epoch 779/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1166 - accuracy: 0.9646 - val_loss: 0.1356 - val_accuracy: 0.9575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 780/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1152 - accuracy: 0.9648 - val_loss: 0.1153 - val_accuracy: 0.9660\n",
      "Epoch 781/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1082 - accuracy: 0.9672 - val_loss: 0.1244 - val_accuracy: 0.9607\n",
      "Epoch 782/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1127 - accuracy: 0.9682 - val_loss: 0.1444 - val_accuracy: 0.9563\n",
      "Epoch 783/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1050 - accuracy: 0.9670 - val_loss: 0.1211 - val_accuracy: 0.9632\n",
      "Epoch 784/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1053 - accuracy: 0.9709 - val_loss: 0.1430 - val_accuracy: 0.9563\n",
      "Epoch 785/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1258 - accuracy: 0.9625 - val_loss: 0.1461 - val_accuracy: 0.9520\n",
      "Epoch 786/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1192 - accuracy: 0.9651 - val_loss: 0.1723 - val_accuracy: 0.9450\n",
      "Epoch 787/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1613 - accuracy: 0.9519 - val_loss: 0.1814 - val_accuracy: 0.9417\n",
      "Epoch 788/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.1945 - accuracy: 0.9535 - val_loss: 0.2449 - val_accuracy: 0.9200\n",
      "Epoch 789/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2906 - accuracy: 0.9277 - val_loss: 0.2774 - val_accuracy: 0.9072\n",
      "Epoch 790/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2769 - accuracy: 0.9154 - val_loss: 0.1657 - val_accuracy: 0.9415\n",
      "Epoch 791/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3062 - accuracy: 0.9284 - val_loss: 0.2571 - val_accuracy: 0.9180\n",
      "Epoch 792/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2609 - accuracy: 0.9291 - val_loss: 0.1871 - val_accuracy: 0.9342\n",
      "Epoch 793/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3364 - accuracy: 0.9297 - val_loss: 0.3017 - val_accuracy: 0.8950\n",
      "Epoch 794/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3645 - accuracy: 0.8981 - val_loss: 0.3209 - val_accuracy: 0.8960\n",
      "Epoch 795/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3359 - accuracy: 0.9063 - val_loss: 0.1560 - val_accuracy: 0.9588\n",
      "Epoch 796/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3545 - accuracy: 0.9146 - val_loss: 0.1692 - val_accuracy: 0.9415\n",
      "Epoch 797/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3983 - accuracy: 0.8956 - val_loss: 0.2884 - val_accuracy: 0.8945\n",
      "Epoch 798/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2656 - accuracy: 0.9245 - val_loss: 0.1948 - val_accuracy: 0.9218\n",
      "Epoch 799/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1998 - accuracy: 0.9406 - val_loss: 0.1742 - val_accuracy: 0.9355\n",
      "Epoch 800/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2032 - accuracy: 0.9438 - val_loss: 0.1907 - val_accuracy: 0.9317\n",
      "Epoch 801/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2114 - accuracy: 0.9327 - val_loss: 0.1932 - val_accuracy: 0.9302\n",
      "Epoch 802/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1860 - accuracy: 0.9486 - val_loss: 0.1567 - val_accuracy: 0.9448\n",
      "Epoch 803/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1915 - accuracy: 0.9420 - val_loss: 0.1518 - val_accuracy: 0.9465\n",
      "Epoch 804/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1561 - accuracy: 0.9494 - val_loss: 0.1285 - val_accuracy: 0.9515\n",
      "Epoch 805/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1691 - accuracy: 0.9538 - val_loss: 0.2027 - val_accuracy: 0.9310\n",
      "Epoch 806/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1745 - accuracy: 0.9491 - val_loss: 0.1421 - val_accuracy: 0.9498\n",
      "Epoch 807/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1498 - accuracy: 0.9521 - val_loss: 0.1229 - val_accuracy: 0.9610\n",
      "Epoch 808/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1382 - accuracy: 0.9614 - val_loss: 0.1460 - val_accuracy: 0.9515\n",
      "Epoch 809/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1389 - accuracy: 0.9581 - val_loss: 0.1397 - val_accuracy: 0.9535\n",
      "Epoch 810/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1386 - accuracy: 0.9601 - val_loss: 0.1590 - val_accuracy: 0.9452\n",
      "Epoch 811/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1327 - accuracy: 0.9609 - val_loss: 0.1461 - val_accuracy: 0.9525\n",
      "Epoch 812/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1271 - accuracy: 0.9629 - val_loss: 0.1276 - val_accuracy: 0.9592\n",
      "Epoch 813/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1326 - accuracy: 0.9614 - val_loss: 0.1756 - val_accuracy: 0.9460\n",
      "Epoch 814/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1282 - accuracy: 0.9616 - val_loss: 0.1099 - val_accuracy: 0.9653\n",
      "Epoch 815/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1206 - accuracy: 0.9646 - val_loss: 0.1509 - val_accuracy: 0.9530\n",
      "Epoch 816/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1375 - accuracy: 0.9660 - val_loss: 0.1821 - val_accuracy: 0.9440\n",
      "Epoch 817/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1711 - accuracy: 0.9446 - val_loss: 0.1572 - val_accuracy: 0.9442\n",
      "Epoch 818/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1880 - accuracy: 0.9487 - val_loss: 0.1526 - val_accuracy: 0.9510\n",
      "Epoch 819/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1355 - accuracy: 0.9614 - val_loss: 0.1644 - val_accuracy: 0.9442\n",
      "Epoch 820/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1340 - accuracy: 0.9591 - val_loss: 0.1882 - val_accuracy: 0.9408\n",
      "Epoch 821/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1547 - accuracy: 0.9571 - val_loss: 0.1242 - val_accuracy: 0.9605\n",
      "Epoch 822/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1224 - accuracy: 0.9626 - val_loss: 0.1369 - val_accuracy: 0.9580\n",
      "Epoch 823/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1103 - accuracy: 0.9672 - val_loss: 0.1364 - val_accuracy: 0.9557\n",
      "Epoch 824/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1098 - accuracy: 0.9678 - val_loss: 0.1390 - val_accuracy: 0.9545\n",
      "Epoch 825/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1117 - accuracy: 0.9704 - val_loss: 0.1556 - val_accuracy: 0.9503\n",
      "Epoch 826/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1217 - accuracy: 0.9624 - val_loss: 0.1593 - val_accuracy: 0.9505\n",
      "Epoch 827/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1393 - accuracy: 0.9617 - val_loss: 0.1357 - val_accuracy: 0.9578\n",
      "Epoch 828/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1191 - accuracy: 0.9649 - val_loss: 0.1295 - val_accuracy: 0.9635\n",
      "Epoch 829/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1082 - accuracy: 0.9681 - val_loss: 0.1387 - val_accuracy: 0.9565\n",
      "Epoch 830/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1059 - accuracy: 0.9710 - val_loss: 0.1487 - val_accuracy: 0.9572\n",
      "Epoch 831/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1114 - accuracy: 0.9651 - val_loss: 0.1133 - val_accuracy: 0.9675\n",
      "Epoch 832/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1084 - accuracy: 0.9691 - val_loss: 0.1377 - val_accuracy: 0.9585\n",
      "Epoch 833/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1424 - accuracy: 0.9647 - val_loss: 0.2040 - val_accuracy: 0.9352\n",
      "Epoch 834/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1444 - accuracy: 0.9559 - val_loss: 0.1853 - val_accuracy: 0.9417\n",
      "Epoch 835/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1273 - accuracy: 0.9630 - val_loss: 0.1111 - val_accuracy: 0.9700\n",
      "Epoch 836/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1346 - accuracy: 0.9617 - val_loss: 0.1581 - val_accuracy: 0.9477\n",
      "Epoch 837/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1347 - accuracy: 0.9640 - val_loss: 0.1799 - val_accuracy: 0.9448\n",
      "Epoch 838/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1441 - accuracy: 0.9549 - val_loss: 0.1485 - val_accuracy: 0.9532\n",
      "Epoch 839/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1151 - accuracy: 0.9650 - val_loss: 0.1412 - val_accuracy: 0.9592\n",
      "Epoch 840/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1086 - accuracy: 0.9693 - val_loss: 0.1477 - val_accuracy: 0.9535\n",
      "Epoch 841/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1082 - accuracy: 0.9678 - val_loss: 0.1270 - val_accuracy: 0.9630\n",
      "Epoch 842/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1016 - accuracy: 0.9708 - val_loss: 0.1302 - val_accuracy: 0.9603\n",
      "Epoch 843/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1023 - accuracy: 0.9704 - val_loss: 0.1402 - val_accuracy: 0.9595\n",
      "Epoch 844/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0971 - accuracy: 0.9709 - val_loss: 0.1139 - val_accuracy: 0.9703\n",
      "Epoch 845/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0923 - accuracy: 0.9743 - val_loss: 0.1434 - val_accuracy: 0.9582\n",
      "Epoch 846/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1052 - accuracy: 0.9697 - val_loss: 0.1423 - val_accuracy: 0.9560\n",
      "Epoch 847/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1032 - accuracy: 0.9689 - val_loss: 0.1459 - val_accuracy: 0.9557\n",
      "Epoch 848/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1000 - accuracy: 0.9727 - val_loss: 0.1272 - val_accuracy: 0.9632\n",
      "Epoch 849/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1270 - accuracy: 0.9615 - val_loss: 0.1448 - val_accuracy: 0.9540\n",
      "Epoch 850/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1175 - accuracy: 0.9685 - val_loss: 0.1665 - val_accuracy: 0.9492\n",
      "Epoch 851/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1051 - accuracy: 0.9684 - val_loss: 0.1456 - val_accuracy: 0.9542\n",
      "Epoch 852/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1439 - accuracy: 0.9601 - val_loss: 0.1251 - val_accuracy: 0.9650\n",
      "Epoch 853/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1178 - accuracy: 0.9651 - val_loss: 0.1608 - val_accuracy: 0.9498\n",
      "Epoch 854/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1046 - accuracy: 0.9693 - val_loss: 0.1370 - val_accuracy: 0.9592\n",
      "Epoch 855/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0972 - accuracy: 0.9732 - val_loss: 0.1360 - val_accuracy: 0.9600\n",
      "Epoch 856/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1082 - accuracy: 0.9674 - val_loss: 0.1357 - val_accuracy: 0.9613\n",
      "Epoch 857/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0957 - accuracy: 0.9729 - val_loss: 0.1384 - val_accuracy: 0.9597\n",
      "Epoch 858/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0974 - accuracy: 0.9704 - val_loss: 0.1313 - val_accuracy: 0.9607\n",
      "Epoch 859/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1057 - accuracy: 0.9720 - val_loss: 0.1643 - val_accuracy: 0.9507\n",
      "Epoch 860/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1273 - accuracy: 0.9636 - val_loss: 0.1621 - val_accuracy: 0.9498\n",
      "Epoch 861/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1365 - accuracy: 0.9627 - val_loss: 0.1857 - val_accuracy: 0.9455\n",
      "Epoch 862/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1587 - accuracy: 0.9526 - val_loss: 0.1990 - val_accuracy: 0.9402\n",
      "Epoch 863/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1240 - accuracy: 0.9656 - val_loss: 0.1589 - val_accuracy: 0.9548\n",
      "Epoch 864/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1235 - accuracy: 0.9613 - val_loss: 0.1114 - val_accuracy: 0.9675\n",
      "Epoch 865/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1441 - accuracy: 0.9666 - val_loss: 0.1493 - val_accuracy: 0.9603\n",
      "Epoch 866/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1397 - accuracy: 0.9583 - val_loss: 0.1826 - val_accuracy: 0.9442\n",
      "Epoch 867/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1310 - accuracy: 0.9637 - val_loss: 0.1547 - val_accuracy: 0.9563\n",
      "Epoch 868/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1066 - accuracy: 0.9698 - val_loss: 0.1449 - val_accuracy: 0.9570\n",
      "Epoch 869/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1076 - accuracy: 0.9694 - val_loss: 0.1447 - val_accuracy: 0.9580\n",
      "Epoch 870/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1492 - accuracy: 0.9558 - val_loss: 0.1395 - val_accuracy: 0.9570\n",
      "Epoch 871/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1150 - accuracy: 0.9703 - val_loss: 0.1474 - val_accuracy: 0.9610\n",
      "Epoch 872/1000\n",
      "16000/16000 [==============================] - ETA: 0s - loss: 0.1036 - accuracy: 0.97 - 0s 3us/step - loss: 0.1047 - accuracy: 0.9711 - val_loss: 0.1180 - val_accuracy: 0.9670\n",
      "Epoch 873/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1335 - accuracy: 0.9644 - val_loss: 0.1703 - val_accuracy: 0.9473\n",
      "Epoch 874/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1618 - accuracy: 0.9556 - val_loss: 0.1879 - val_accuracy: 0.9450\n",
      "Epoch 875/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1440 - accuracy: 0.9621 - val_loss: 0.2428 - val_accuracy: 0.9295\n",
      "Epoch 876/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1851 - accuracy: 0.9475 - val_loss: 0.2447 - val_accuracy: 0.9247\n",
      "Epoch 877/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1620 - accuracy: 0.9538 - val_loss: 0.1657 - val_accuracy: 0.9510\n",
      "Epoch 878/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1758 - accuracy: 0.9477 - val_loss: 0.1502 - val_accuracy: 0.9542\n",
      "Epoch 879/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1538 - accuracy: 0.9603 - val_loss: 0.1729 - val_accuracy: 0.9498\n",
      "Epoch 880/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1426 - accuracy: 0.9613 - val_loss: 0.1347 - val_accuracy: 0.9595\n",
      "Epoch 881/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1172 - accuracy: 0.9657 - val_loss: 0.1304 - val_accuracy: 0.9595\n",
      "Epoch 882/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1143 - accuracy: 0.9670 - val_loss: 0.1632 - val_accuracy: 0.9510\n",
      "Epoch 883/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1119 - accuracy: 0.9695 - val_loss: 0.1607 - val_accuracy: 0.9532\n",
      "Epoch 884/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1011 - accuracy: 0.9695 - val_loss: 0.1208 - val_accuracy: 0.9670\n",
      "Epoch 885/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0922 - accuracy: 0.9733 - val_loss: 0.1425 - val_accuracy: 0.9590\n",
      "Epoch 886/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0942 - accuracy: 0.9707 - val_loss: 0.1144 - val_accuracy: 0.9705\n",
      "Epoch 887/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1013 - accuracy: 0.9701 - val_loss: 0.1608 - val_accuracy: 0.9507\n",
      "Epoch 888/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1015 - accuracy: 0.9730 - val_loss: 0.1488 - val_accuracy: 0.9615\n",
      "Epoch 889/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1134 - accuracy: 0.9720 - val_loss: 0.1666 - val_accuracy: 0.9513\n",
      "Epoch 890/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1533 - accuracy: 0.9556 - val_loss: 0.1621 - val_accuracy: 0.9510\n",
      "Epoch 891/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1442 - accuracy: 0.9589 - val_loss: 0.1681 - val_accuracy: 0.9520\n",
      "Epoch 892/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1198 - accuracy: 0.9718 - val_loss: 0.1716 - val_accuracy: 0.9505\n",
      "Epoch 893/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1339 - accuracy: 0.9571 - val_loss: 0.1408 - val_accuracy: 0.9578\n",
      "Epoch 894/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1138 - accuracy: 0.9714 - val_loss: 0.1648 - val_accuracy: 0.9525\n",
      "Epoch 895/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1209 - accuracy: 0.9636 - val_loss: 0.1567 - val_accuracy: 0.9553\n",
      "Epoch 896/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1086 - accuracy: 0.9686 - val_loss: 0.1151 - val_accuracy: 0.9712\n",
      "Epoch 897/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1159 - accuracy: 0.9633 - val_loss: 0.1475 - val_accuracy: 0.9575\n",
      "Epoch 898/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1041 - accuracy: 0.9714 - val_loss: 0.1466 - val_accuracy: 0.9603\n",
      "Epoch 899/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1294 - accuracy: 0.9694 - val_loss: 0.1606 - val_accuracy: 0.9532\n",
      "Epoch 900/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1470 - accuracy: 0.9534 - val_loss: 0.2020 - val_accuracy: 0.9402\n",
      "Epoch 901/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1436 - accuracy: 0.9611 - val_loss: 0.1628 - val_accuracy: 0.9555\n",
      "Epoch 902/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1686 - accuracy: 0.9544 - val_loss: 0.1884 - val_accuracy: 0.9430\n",
      "Epoch 903/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1525 - accuracy: 0.9607 - val_loss: 0.2484 - val_accuracy: 0.9247\n",
      "Epoch 904/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.2023 - accuracy: 0.9407 - val_loss: 0.1861 - val_accuracy: 0.9438\n",
      "Epoch 905/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1609 - accuracy: 0.9628 - val_loss: 0.1902 - val_accuracy: 0.9545\n",
      "Epoch 906/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1572 - accuracy: 0.9563 - val_loss: 0.1470 - val_accuracy: 0.9595\n",
      "Epoch 907/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1695 - accuracy: 0.9553 - val_loss: 0.2395 - val_accuracy: 0.9342\n",
      "Epoch 908/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1785 - accuracy: 0.9541 - val_loss: 0.1321 - val_accuracy: 0.9590\n",
      "Epoch 909/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1504 - accuracy: 0.9601 - val_loss: 0.1492 - val_accuracy: 0.9538\n",
      "Epoch 910/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1973 - accuracy: 0.9480 - val_loss: 0.2111 - val_accuracy: 0.9298\n",
      "Epoch 911/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1993 - accuracy: 0.9433 - val_loss: 0.1457 - val_accuracy: 0.9515\n",
      "Epoch 912/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1446 - accuracy: 0.9619 - val_loss: 0.1306 - val_accuracy: 0.9625\n",
      "Epoch 913/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1316 - accuracy: 0.9629 - val_loss: 0.1610 - val_accuracy: 0.9460\n",
      "Epoch 914/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1195 - accuracy: 0.9675 - val_loss: 0.1584 - val_accuracy: 0.9498\n",
      "Epoch 915/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1188 - accuracy: 0.9646 - val_loss: 0.0984 - val_accuracy: 0.9655\n",
      "Epoch 916/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1113 - accuracy: 0.9683 - val_loss: 0.1290 - val_accuracy: 0.9630\n",
      "Epoch 917/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0988 - accuracy: 0.9728 - val_loss: 0.1238 - val_accuracy: 0.9588\n",
      "Epoch 918/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0935 - accuracy: 0.9717 - val_loss: 0.1117 - val_accuracy: 0.9685\n",
      "Epoch 919/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1077 - accuracy: 0.9718 - val_loss: 0.1634 - val_accuracy: 0.9452\n",
      "Epoch 920/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2098 - accuracy: 0.9498 - val_loss: 0.2232 - val_accuracy: 0.9315\n",
      "Epoch 921/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1632 - accuracy: 0.9563 - val_loss: 0.1901 - val_accuracy: 0.9548\n",
      "Epoch 922/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2287 - accuracy: 0.9482 - val_loss: 0.2960 - val_accuracy: 0.9137\n",
      "Epoch 923/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2816 - accuracy: 0.9277 - val_loss: 0.2896 - val_accuracy: 0.9122\n",
      "Epoch 924/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2260 - accuracy: 0.9377 - val_loss: 0.1688 - val_accuracy: 0.9473\n",
      "Epoch 925/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4752 - accuracy: 0.9184 - val_loss: 0.5751 - val_accuracy: 0.8453\n",
      "Epoch 926/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5612 - accuracy: 0.8708 - val_loss: 0.6411 - val_accuracy: 0.8257\n",
      "Epoch 927/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.4709 - accuracy: 0.8821 - val_loss: 0.2375 - val_accuracy: 0.9237\n",
      "Epoch 928/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.4243 - accuracy: 0.9049 - val_loss: 0.3418 - val_accuracy: 0.8780\n",
      "Epoch 929/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5074 - accuracy: 0.9024 - val_loss: 0.5076 - val_accuracy: 0.8600\n",
      "Epoch 930/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5156 - accuracy: 0.8857 - val_loss: 0.2834 - val_accuracy: 0.8915\n",
      "Epoch 931/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.3381 - accuracy: 0.9004 - val_loss: 0.2101 - val_accuracy: 0.9143\n",
      "Epoch 932/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2883 - accuracy: 0.9067 - val_loss: 0.2274 - val_accuracy: 0.9072\n",
      "Epoch 933/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2627 - accuracy: 0.9214 - val_loss: 0.2547 - val_accuracy: 0.9078\n",
      "Epoch 934/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2637 - accuracy: 0.9206 - val_loss: 0.1908 - val_accuracy: 0.9327\n",
      "Epoch 935/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2440 - accuracy: 0.9293 - val_loss: 0.2398 - val_accuracy: 0.9115\n",
      "Epoch 936/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2426 - accuracy: 0.9321 - val_loss: 0.2504 - val_accuracy: 0.9075\n",
      "Epoch 937/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2641 - accuracy: 0.9162 - val_loss: 0.1963 - val_accuracy: 0.9197\n",
      "Epoch 938/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2944 - accuracy: 0.9096 - val_loss: 0.1639 - val_accuracy: 0.9350\n",
      "Epoch 939/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.2529 - accuracy: 0.9240 - val_loss: 0.2184 - val_accuracy: 0.9168\n",
      "Epoch 940/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2481 - accuracy: 0.9291 - val_loss: 0.2290 - val_accuracy: 0.9135\n",
      "Epoch 941/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2297 - accuracy: 0.9340 - val_loss: 0.2612 - val_accuracy: 0.8980\n",
      "Epoch 942/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2469 - accuracy: 0.9249 - val_loss: 0.1957 - val_accuracy: 0.9162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 943/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2373 - accuracy: 0.9237 - val_loss: 0.1952 - val_accuracy: 0.9197\n",
      "Epoch 944/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2163 - accuracy: 0.9298 - val_loss: 0.2013 - val_accuracy: 0.9195\n",
      "Epoch 945/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.2050 - accuracy: 0.9354 - val_loss: 0.1770 - val_accuracy: 0.9327\n",
      "Epoch 946/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1883 - accuracy: 0.9373 - val_loss: 0.1523 - val_accuracy: 0.9410\n",
      "Epoch 947/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1794 - accuracy: 0.9460 - val_loss: 0.1698 - val_accuracy: 0.9385\n",
      "Epoch 948/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1558 - accuracy: 0.9574 - val_loss: 0.1779 - val_accuracy: 0.9358\n",
      "Epoch 949/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1543 - accuracy: 0.9520 - val_loss: 0.1529 - val_accuracy: 0.9452\n",
      "Epoch 950/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1570 - accuracy: 0.9541 - val_loss: 0.1622 - val_accuracy: 0.9448\n",
      "Epoch 951/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1474 - accuracy: 0.9513 - val_loss: 0.1551 - val_accuracy: 0.9467\n",
      "Epoch 952/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1387 - accuracy: 0.9584 - val_loss: 0.1686 - val_accuracy: 0.9433\n",
      "Epoch 953/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1422 - accuracy: 0.9598 - val_loss: 0.1694 - val_accuracy: 0.9423\n",
      "Epoch 954/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1382 - accuracy: 0.9548 - val_loss: 0.1318 - val_accuracy: 0.9572\n",
      "Epoch 955/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1387 - accuracy: 0.9563 - val_loss: 0.1695 - val_accuracy: 0.9392\n",
      "Epoch 956/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1256 - accuracy: 0.9662 - val_loss: 0.1485 - val_accuracy: 0.9510\n",
      "Epoch 957/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1362 - accuracy: 0.9576 - val_loss: 0.1343 - val_accuracy: 0.9563\n",
      "Epoch 958/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1248 - accuracy: 0.9627 - val_loss: 0.1647 - val_accuracy: 0.9435\n",
      "Epoch 959/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1199 - accuracy: 0.9663 - val_loss: 0.1529 - val_accuracy: 0.9488\n",
      "Epoch 960/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1155 - accuracy: 0.9641 - val_loss: 0.1279 - val_accuracy: 0.9600\n",
      "Epoch 961/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1120 - accuracy: 0.9671 - val_loss: 0.1343 - val_accuracy: 0.9582\n",
      "Epoch 962/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1102 - accuracy: 0.9681 - val_loss: 0.1346 - val_accuracy: 0.9565\n",
      "Epoch 963/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1070 - accuracy: 0.9672 - val_loss: 0.1258 - val_accuracy: 0.9600\n",
      "Epoch 964/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1092 - accuracy: 0.9693 - val_loss: 0.1366 - val_accuracy: 0.9570\n",
      "Epoch 965/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1092 - accuracy: 0.9686 - val_loss: 0.1430 - val_accuracy: 0.9553\n",
      "Epoch 966/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1057 - accuracy: 0.9672 - val_loss: 0.1254 - val_accuracy: 0.9605\n",
      "Epoch 967/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1144 - accuracy: 0.9703 - val_loss: 0.1755 - val_accuracy: 0.9482\n",
      "Epoch 968/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1194 - accuracy: 0.9616 - val_loss: 0.1150 - val_accuracy: 0.9655\n",
      "Epoch 969/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1172 - accuracy: 0.9676 - val_loss: 0.1570 - val_accuracy: 0.9555\n",
      "Epoch 970/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1097 - accuracy: 0.9709 - val_loss: 0.1460 - val_accuracy: 0.9563\n",
      "Epoch 971/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1154 - accuracy: 0.9621 - val_loss: 0.1312 - val_accuracy: 0.9582\n",
      "Epoch 972/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1040 - accuracy: 0.9741 - val_loss: 0.1490 - val_accuracy: 0.9592\n",
      "Epoch 973/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1155 - accuracy: 0.9651 - val_loss: 0.1280 - val_accuracy: 0.9628\n",
      "Epoch 974/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0993 - accuracy: 0.9703 - val_loss: 0.1430 - val_accuracy: 0.9590\n",
      "Epoch 975/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0984 - accuracy: 0.9746 - val_loss: 0.1558 - val_accuracy: 0.9545\n",
      "Epoch 976/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1122 - accuracy: 0.9665 - val_loss: 0.1162 - val_accuracy: 0.9655\n",
      "Epoch 977/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1068 - accuracy: 0.9704 - val_loss: 0.1437 - val_accuracy: 0.9567\n",
      "Epoch 978/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1123 - accuracy: 0.9681 - val_loss: 0.1275 - val_accuracy: 0.9620\n",
      "Epoch 979/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1037 - accuracy: 0.9679 - val_loss: 0.1415 - val_accuracy: 0.9565\n",
      "Epoch 980/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0972 - accuracy: 0.9726 - val_loss: 0.1409 - val_accuracy: 0.9595\n",
      "Epoch 981/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.0934 - accuracy: 0.9728 - val_loss: 0.1256 - val_accuracy: 0.9655\n",
      "Epoch 982/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0905 - accuracy: 0.9759 - val_loss: 0.1475 - val_accuracy: 0.9570\n",
      "Epoch 983/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1057 - accuracy: 0.9693 - val_loss: 0.1236 - val_accuracy: 0.9640\n",
      "Epoch 984/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0921 - accuracy: 0.9707 - val_loss: 0.1309 - val_accuracy: 0.9643\n",
      "Epoch 985/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0870 - accuracy: 0.9748 - val_loss: 0.1212 - val_accuracy: 0.9663\n",
      "Epoch 986/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0959 - accuracy: 0.9726 - val_loss: 0.1389 - val_accuracy: 0.9607\n",
      "Epoch 987/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0930 - accuracy: 0.9725 - val_loss: 0.1205 - val_accuracy: 0.9685\n",
      "Epoch 988/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0876 - accuracy: 0.9759 - val_loss: 0.1320 - val_accuracy: 0.9625\n",
      "Epoch 989/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.0949 - accuracy: 0.9725 - val_loss: 0.1613 - val_accuracy: 0.9488\n",
      "Epoch 990/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1097 - accuracy: 0.9723 - val_loss: 0.1448 - val_accuracy: 0.9570\n",
      "Epoch 991/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1073 - accuracy: 0.9653 - val_loss: 0.1148 - val_accuracy: 0.9695\n",
      "Epoch 992/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1073 - accuracy: 0.9699 - val_loss: 0.1794 - val_accuracy: 0.9460\n",
      "Epoch 993/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1186 - accuracy: 0.9694 - val_loss: 0.1435 - val_accuracy: 0.9560\n",
      "Epoch 994/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1309 - accuracy: 0.9613 - val_loss: 0.1556 - val_accuracy: 0.9490\n",
      "Epoch 995/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1109 - accuracy: 0.9693 - val_loss: 0.1660 - val_accuracy: 0.9553\n",
      "Epoch 996/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.1100 - accuracy: 0.9693 - val_loss: 0.1389 - val_accuracy: 0.9625\n",
      "Epoch 997/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1085 - accuracy: 0.9732 - val_loss: 0.1728 - val_accuracy: 0.9495\n",
      "Epoch 998/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1187 - accuracy: 0.9656 - val_loss: 0.1143 - val_accuracy: 0.9685\n",
      "Epoch 999/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1096 - accuracy: 0.9708 - val_loss: 0.1706 - val_accuracy: 0.9470\n",
      "Epoch 1000/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.1124 - accuracy: 0.9707 - val_loss: 0.1666 - val_accuracy: 0.9503\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/1000\n",
      "16000/16000 [==============================] - 0s 29us/step - loss: 2.0391 - accuracy: 0.4551 - val_loss: 1.3133 - val_accuracy: 0.1963\n",
      "Epoch 2/1000\n",
      "16000/16000 [==============================] - 0s 5us/step - loss: 1.3555 - accuracy: 0.4392 - val_loss: 0.5926 - val_accuracy: 0.7945\n",
      "Epoch 3/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2886 - accuracy: 0.6157 - val_loss: 0.8078 - val_accuracy: 0.2163\n",
      "Epoch 4/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2643 - accuracy: 0.2061 - val_loss: 0.7539 - val_accuracy: 0.2455\n",
      "Epoch 5/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2474 - accuracy: 0.4573 - val_loss: 0.7049 - val_accuracy: 0.3640\n",
      "Epoch 6/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2393 - accuracy: 0.2736 - val_loss: 0.7657 - val_accuracy: 0.2455\n",
      "Epoch 7/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2368 - accuracy: 0.2904 - val_loss: 0.7066 - val_accuracy: 0.3352\n",
      "Epoch 8/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2336 - accuracy: 0.2781 - val_loss: 0.7404 - val_accuracy: 0.2570\n",
      "Epoch 9/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2308 - accuracy: 0.2743 - val_loss: 0.7316 - val_accuracy: 0.2680\n",
      "Epoch 10/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2284 - accuracy: 0.3116 - val_loss: 0.7141 - val_accuracy: 0.3122\n",
      "Epoch 11/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2255 - accuracy: 0.2907 - val_loss: 0.7424 - val_accuracy: 0.2673\n",
      "Epoch 12/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 1.2238 - accuracy: 0.3259 - val_loss: 0.7355 - val_accuracy: 0.2772\n",
      "Epoch 13/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2206 - accuracy: 0.2957 - val_loss: 0.7271 - val_accuracy: 0.3015\n",
      "Epoch 14/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2195 - accuracy: 0.3528 - val_loss: 0.7511 - val_accuracy: 0.2693\n",
      "Epoch 15/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2167 - accuracy: 0.2960 - val_loss: 0.6995 - val_accuracy: 0.4185\n",
      "Epoch 16/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2149 - accuracy: 0.4029 - val_loss: 0.7623 - val_accuracy: 0.2760\n",
      "Epoch 17/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2116 - accuracy: 0.3394 - val_loss: 0.7099 - val_accuracy: 0.3970\n",
      "Epoch 18/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2105 - accuracy: 0.3594 - val_loss: 0.7395 - val_accuracy: 0.3248\n",
      "Epoch 19/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2078 - accuracy: 0.4436 - val_loss: 0.7552 - val_accuracy: 0.3043\n",
      "Epoch 20/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2068 - accuracy: 0.3764 - val_loss: 0.7159 - val_accuracy: 0.3950\n",
      "Epoch 21/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2028 - accuracy: 0.3624 - val_loss: 0.7109 - val_accuracy: 0.4225\n",
      "Epoch 22/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2000 - accuracy: 0.4302 - val_loss: 0.7521 - val_accuracy: 0.3257\n",
      "Epoch 23/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1983 - accuracy: 0.4005 - val_loss: 0.7188 - val_accuracy: 0.4060\n",
      "Epoch 24/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1960 - accuracy: 0.4104 - val_loss: 0.7416 - val_accuracy: 0.3535\n",
      "Epoch 25/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1940 - accuracy: 0.4269 - val_loss: 0.7369 - val_accuracy: 0.3753\n",
      "Epoch 26/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1908 - accuracy: 0.4255 - val_loss: 0.7203 - val_accuracy: 0.4198\n",
      "Epoch 27/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1903 - accuracy: 0.4130 - val_loss: 0.7002 - val_accuracy: 0.4733\n",
      "Epoch 28/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1894 - accuracy: 0.4264 - val_loss: 0.7005 - val_accuracy: 0.4818\n",
      "Epoch 29/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1871 - accuracy: 0.4401 - val_loss: 0.7302 - val_accuracy: 0.4083\n",
      "Epoch 30/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1832 - accuracy: 0.4679 - val_loss: 0.7463 - val_accuracy: 0.3790\n",
      "Epoch 31/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1794 - accuracy: 0.4512 - val_loss: 0.7066 - val_accuracy: 0.4855\n",
      "Epoch 32/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1785 - accuracy: 0.4640 - val_loss: 0.7137 - val_accuracy: 0.4440\n",
      "Epoch 33/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1737 - accuracy: 0.4399 - val_loss: 0.7446 - val_accuracy: 0.3860\n",
      "Epoch 34/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1704 - accuracy: 0.4664 - val_loss: 0.7621 - val_accuracy: 0.3692\n",
      "Epoch 35/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1717 - accuracy: 0.4505 - val_loss: 0.7174 - val_accuracy: 0.4615\n",
      "Epoch 36/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1670 - accuracy: 0.4717 - val_loss: 0.6870 - val_accuracy: 0.5182\n",
      "Epoch 37/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1652 - accuracy: 0.4665 - val_loss: 0.7131 - val_accuracy: 0.4670\n",
      "Epoch 38/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1623 - accuracy: 0.4724 - val_loss: 0.6748 - val_accuracy: 0.5675\n",
      "Epoch 39/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1612 - accuracy: 0.4811 - val_loss: 0.6882 - val_accuracy: 0.5180\n",
      "Epoch 40/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1560 - accuracy: 0.4688 - val_loss: 0.7040 - val_accuracy: 0.4840\n",
      "Epoch 41/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 1.1505 - accuracy: 0.5042 - val_loss: 0.7331 - val_accuracy: 0.4478\n",
      "Epoch 42/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1476 - accuracy: 0.4876 - val_loss: 0.7014 - val_accuracy: 0.5140\n",
      "Epoch 43/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1410 - accuracy: 0.5138 - val_loss: 0.7148 - val_accuracy: 0.4832\n",
      "Epoch 44/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1384 - accuracy: 0.5264 - val_loss: 0.7153 - val_accuracy: 0.4888\n",
      "Epoch 45/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1351 - accuracy: 0.5275 - val_loss: 0.7435 - val_accuracy: 0.4272\n",
      "Epoch 46/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1312 - accuracy: 0.5366 - val_loss: 0.7019 - val_accuracy: 0.5238\n",
      "Epoch 47/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1247 - accuracy: 0.5354 - val_loss: 0.6784 - val_accuracy: 0.5882\n",
      "Epoch 48/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1238 - accuracy: 0.5394 - val_loss: 0.6996 - val_accuracy: 0.5518\n",
      "Epoch 49/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1215 - accuracy: 0.5539 - val_loss: 0.6923 - val_accuracy: 0.5585\n",
      "Epoch 50/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1154 - accuracy: 0.5614 - val_loss: 0.7021 - val_accuracy: 0.5238\n",
      "Epoch 51/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1135 - accuracy: 0.5592 - val_loss: 0.6837 - val_accuracy: 0.5727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1154 - accuracy: 0.5357 - val_loss: 0.7003 - val_accuracy: 0.5947\n",
      "Epoch 53/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1216 - accuracy: 0.5556 - val_loss: 0.6825 - val_accuracy: 0.5707\n",
      "Epoch 54/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1127 - accuracy: 0.5343 - val_loss: 0.6888 - val_accuracy: 0.5500\n",
      "Epoch 55/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1083 - accuracy: 0.5931 - val_loss: 0.6987 - val_accuracy: 0.5408\n",
      "Epoch 56/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1013 - accuracy: 0.5525 - val_loss: 0.6659 - val_accuracy: 0.6310\n",
      "Epoch 57/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0956 - accuracy: 0.5923 - val_loss: 0.6697 - val_accuracy: 0.6342\n",
      "Epoch 58/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0894 - accuracy: 0.5834 - val_loss: 0.6705 - val_accuracy: 0.6258\n",
      "Epoch 59/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0870 - accuracy: 0.6073 - val_loss: 0.7283 - val_accuracy: 0.4820\n",
      "Epoch 60/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0852 - accuracy: 0.5845 - val_loss: 0.7164 - val_accuracy: 0.5188\n",
      "Epoch 61/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0820 - accuracy: 0.5824 - val_loss: 0.6846 - val_accuracy: 0.5807\n",
      "Epoch 62/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0809 - accuracy: 0.6033 - val_loss: 0.6518 - val_accuracy: 0.6672\n",
      "Epoch 63/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0777 - accuracy: 0.6031 - val_loss: 0.6684 - val_accuracy: 0.6183\n",
      "Epoch 64/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0753 - accuracy: 0.6012 - val_loss: 0.6621 - val_accuracy: 0.6230\n",
      "Epoch 65/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0677 - accuracy: 0.6089 - val_loss: 0.6670 - val_accuracy: 0.6053\n",
      "Epoch 66/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0724 - accuracy: 0.6150 - val_loss: 0.6989 - val_accuracy: 0.5347\n",
      "Epoch 67/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0723 - accuracy: 0.6074 - val_loss: 0.7102 - val_accuracy: 0.5345\n",
      "Epoch 68/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0722 - accuracy: 0.5591 - val_loss: 0.6711 - val_accuracy: 0.6225\n",
      "Epoch 69/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0677 - accuracy: 0.6261 - val_loss: 0.6682 - val_accuracy: 0.6105\n",
      "Epoch 70/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 1.0588 - accuracy: 0.6302 - val_loss: 0.6833 - val_accuracy: 0.5928\n",
      "Epoch 71/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0529 - accuracy: 0.6342 - val_loss: 0.6988 - val_accuracy: 0.5540\n",
      "Epoch 72/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 1.0508 - accuracy: 0.6447 - val_loss: 0.7048 - val_accuracy: 0.5530\n",
      "Epoch 73/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0557 - accuracy: 0.6095 - val_loss: 0.7162 - val_accuracy: 0.5203\n",
      "Epoch 74/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0517 - accuracy: 0.6329 - val_loss: 0.7218 - val_accuracy: 0.5100\n",
      "Epoch 75/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0409 - accuracy: 0.6270 - val_loss: 0.6643 - val_accuracy: 0.6330\n",
      "Epoch 76/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0391 - accuracy: 0.6400 - val_loss: 0.6944 - val_accuracy: 0.5753\n",
      "Epoch 77/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0366 - accuracy: 0.6352 - val_loss: 0.6809 - val_accuracy: 0.5753\n",
      "Epoch 78/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0409 - accuracy: 0.6220 - val_loss: 0.6808 - val_accuracy: 0.6105\n",
      "Epoch 79/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0367 - accuracy: 0.6553 - val_loss: 0.6859 - val_accuracy: 0.5935\n",
      "Epoch 80/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0358 - accuracy: 0.6325 - val_loss: 0.6523 - val_accuracy: 0.6310\n",
      "Epoch 81/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0324 - accuracy: 0.6476 - val_loss: 0.6443 - val_accuracy: 0.6730\n",
      "Epoch 82/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 1.0261 - accuracy: 0.6578 - val_loss: 0.6731 - val_accuracy: 0.6252\n",
      "Epoch 83/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0235 - accuracy: 0.6356 - val_loss: 0.6497 - val_accuracy: 0.6683\n",
      "Epoch 84/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0196 - accuracy: 0.6460 - val_loss: 0.6243 - val_accuracy: 0.7060\n",
      "Epoch 85/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0270 - accuracy: 0.6620 - val_loss: 0.6617 - val_accuracy: 0.6317\n",
      "Epoch 86/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0209 - accuracy: 0.6399 - val_loss: 0.6595 - val_accuracy: 0.6630\n",
      "Epoch 87/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 1.0189 - accuracy: 0.6672 - val_loss: 0.6679 - val_accuracy: 0.6288\n",
      "Epoch 88/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0146 - accuracy: 0.6544 - val_loss: 0.7072 - val_accuracy: 0.5925\n",
      "Epoch 89/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0228 - accuracy: 0.6631 - val_loss: 0.6893 - val_accuracy: 0.6077\n",
      "Epoch 90/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0161 - accuracy: 0.6544 - val_loss: 0.7695 - val_accuracy: 0.5190\n",
      "Epoch 91/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0218 - accuracy: 0.6434 - val_loss: 0.6464 - val_accuracy: 0.6690\n",
      "Epoch 92/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0248 - accuracy: 0.6438 - val_loss: 0.6492 - val_accuracy: 0.6823\n",
      "Epoch 93/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0193 - accuracy: 0.6576 - val_loss: 0.6466 - val_accuracy: 0.6930\n",
      "Epoch 94/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0089 - accuracy: 0.6739 - val_loss: 0.6690 - val_accuracy: 0.6590\n",
      "Epoch 95/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0061 - accuracy: 0.6761 - val_loss: 0.6800 - val_accuracy: 0.6267\n",
      "Epoch 96/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0040 - accuracy: 0.6598 - val_loss: 0.6675 - val_accuracy: 0.6575\n",
      "Epoch 97/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0091 - accuracy: 0.6544 - val_loss: 0.6149 - val_accuracy: 0.7197\n",
      "Epoch 98/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0066 - accuracy: 0.6780 - val_loss: 0.6499 - val_accuracy: 0.6718\n",
      "Epoch 99/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9978 - accuracy: 0.6692 - val_loss: 0.6661 - val_accuracy: 0.6532\n",
      "Epoch 100/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9984 - accuracy: 0.6794 - val_loss: 0.6511 - val_accuracy: 0.6798\n",
      "Epoch 101/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0004 - accuracy: 0.6733 - val_loss: 0.6361 - val_accuracy: 0.6898\n",
      "Epoch 102/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9985 - accuracy: 0.6776 - val_loss: 0.6337 - val_accuracy: 0.6795\n",
      "Epoch 103/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9962 - accuracy: 0.6709 - val_loss: 0.7069 - val_accuracy: 0.5673\n",
      "Epoch 104/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9914 - accuracy: 0.6763 - val_loss: 0.6875 - val_accuracy: 0.6327\n",
      "Epoch 105/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9848 - accuracy: 0.6758 - val_loss: 0.6795 - val_accuracy: 0.6313\n",
      "Epoch 106/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9776 - accuracy: 0.6799 - val_loss: 0.6697 - val_accuracy: 0.6450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9776 - accuracy: 0.6808 - val_loss: 0.6210 - val_accuracy: 0.7212\n",
      "Epoch 108/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9800 - accuracy: 0.7005 - val_loss: 0.7110 - val_accuracy: 0.5970\n",
      "Epoch 109/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9850 - accuracy: 0.6772 - val_loss: 0.7049 - val_accuracy: 0.5972\n",
      "Epoch 110/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9791 - accuracy: 0.6721 - val_loss: 0.6330 - val_accuracy: 0.6942\n",
      "Epoch 111/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9778 - accuracy: 0.7012 - val_loss: 0.6920 - val_accuracy: 0.6158\n",
      "Epoch 112/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.9771 - accuracy: 0.6826 - val_loss: 0.6930 - val_accuracy: 0.6305\n",
      "Epoch 113/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9732 - accuracy: 0.6781 - val_loss: 0.6836 - val_accuracy: 0.6230\n",
      "Epoch 114/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9771 - accuracy: 0.6902 - val_loss: 0.6869 - val_accuracy: 0.6165\n",
      "Epoch 115/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9769 - accuracy: 0.6874 - val_loss: 0.6326 - val_accuracy: 0.6875\n",
      "Epoch 116/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9768 - accuracy: 0.7013 - val_loss: 0.6913 - val_accuracy: 0.6145\n",
      "Epoch 117/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9774 - accuracy: 0.6626 - val_loss: 0.6467 - val_accuracy: 0.6910\n",
      "Epoch 118/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9705 - accuracy: 0.6869 - val_loss: 0.6410 - val_accuracy: 0.6855\n",
      "Epoch 119/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.9750 - accuracy: 0.7046 - val_loss: 0.6658 - val_accuracy: 0.6530\n",
      "Epoch 120/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9679 - accuracy: 0.6816 - val_loss: 0.6413 - val_accuracy: 0.6845\n",
      "Epoch 121/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9739 - accuracy: 0.6885 - val_loss: 0.6545 - val_accuracy: 0.6722\n",
      "Epoch 122/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9708 - accuracy: 0.6973 - val_loss: 0.6625 - val_accuracy: 0.6715\n",
      "Epoch 123/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9652 - accuracy: 0.6881 - val_loss: 0.6840 - val_accuracy: 0.6428\n",
      "Epoch 124/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9745 - accuracy: 0.6761 - val_loss: 0.6615 - val_accuracy: 0.6722\n",
      "Epoch 125/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9760 - accuracy: 0.6908 - val_loss: 0.7127 - val_accuracy: 0.5932\n",
      "Epoch 126/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9676 - accuracy: 0.6880 - val_loss: 0.6736 - val_accuracy: 0.6553\n",
      "Epoch 127/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9639 - accuracy: 0.6963 - val_loss: 0.6837 - val_accuracy: 0.6415\n",
      "Epoch 128/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9513 - accuracy: 0.6984 - val_loss: 0.6299 - val_accuracy: 0.7063\n",
      "Epoch 129/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9505 - accuracy: 0.7044 - val_loss: 0.6154 - val_accuracy: 0.7143\n",
      "Epoch 130/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9569 - accuracy: 0.6953 - val_loss: 0.6896 - val_accuracy: 0.6315\n",
      "Epoch 131/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9541 - accuracy: 0.6950 - val_loss: 0.6908 - val_accuracy: 0.6348\n",
      "Epoch 132/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9615 - accuracy: 0.6874 - val_loss: 0.6745 - val_accuracy: 0.6345\n",
      "Epoch 133/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9589 - accuracy: 0.7011 - val_loss: 0.6576 - val_accuracy: 0.6532\n",
      "Epoch 134/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9554 - accuracy: 0.7063 - val_loss: 0.6950 - val_accuracy: 0.6215\n",
      "Epoch 135/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9459 - accuracy: 0.7029 - val_loss: 0.6832 - val_accuracy: 0.6280\n",
      "Epoch 136/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9472 - accuracy: 0.6877 - val_loss: 0.6445 - val_accuracy: 0.6900\n",
      "Epoch 137/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9431 - accuracy: 0.7113 - val_loss: 0.6545 - val_accuracy: 0.6693\n",
      "Epoch 138/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9371 - accuracy: 0.7132 - val_loss: 0.6373 - val_accuracy: 0.6862\n",
      "Epoch 139/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9383 - accuracy: 0.7002 - val_loss: 0.6265 - val_accuracy: 0.7120\n",
      "Epoch 140/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9397 - accuracy: 0.7112 - val_loss: 0.6339 - val_accuracy: 0.6902\n",
      "Epoch 141/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9390 - accuracy: 0.7047 - val_loss: 0.7102 - val_accuracy: 0.6275\n",
      "Epoch 142/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9309 - accuracy: 0.7023 - val_loss: 0.6703 - val_accuracy: 0.6720\n",
      "Epoch 143/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9320 - accuracy: 0.7060 - val_loss: 0.6654 - val_accuracy: 0.6695\n",
      "Epoch 144/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9403 - accuracy: 0.6880 - val_loss: 0.6058 - val_accuracy: 0.7230\n",
      "Epoch 145/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9336 - accuracy: 0.7125 - val_loss: 0.6145 - val_accuracy: 0.7165\n",
      "Epoch 146/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9281 - accuracy: 0.7086 - val_loss: 0.6017 - val_accuracy: 0.7333\n",
      "Epoch 147/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.9297 - accuracy: 0.7134 - val_loss: 0.6572 - val_accuracy: 0.6888\n",
      "Epoch 148/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9324 - accuracy: 0.7025 - val_loss: 0.6492 - val_accuracy: 0.6925\n",
      "Epoch 149/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9289 - accuracy: 0.7091 - val_loss: 0.6401 - val_accuracy: 0.6980\n",
      "Epoch 150/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9309 - accuracy: 0.7066 - val_loss: 0.6867 - val_accuracy: 0.6327\n",
      "Epoch 151/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9462 - accuracy: 0.7082 - val_loss: 0.6634 - val_accuracy: 0.6770\n",
      "Epoch 152/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9352 - accuracy: 0.7126 - val_loss: 0.6761 - val_accuracy: 0.6392\n",
      "Epoch 153/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9324 - accuracy: 0.6974 - val_loss: 0.6785 - val_accuracy: 0.6432\n",
      "Epoch 154/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9299 - accuracy: 0.7131 - val_loss: 0.7020 - val_accuracy: 0.6047\n",
      "Epoch 155/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9285 - accuracy: 0.6987 - val_loss: 0.6526 - val_accuracy: 0.6825\n",
      "Epoch 156/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9223 - accuracy: 0.7079 - val_loss: 0.6684 - val_accuracy: 0.6640\n",
      "Epoch 157/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.9155 - accuracy: 0.7241 - val_loss: 0.6758 - val_accuracy: 0.6503\n",
      "Epoch 158/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.9172 - accuracy: 0.7122 - val_loss: 0.6748 - val_accuracy: 0.6518\n",
      "Epoch 159/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9315 - accuracy: 0.7145 - val_loss: 0.6343 - val_accuracy: 0.7048\n",
      "Epoch 160/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9149 - accuracy: 0.7216 - val_loss: 0.6784 - val_accuracy: 0.6600\n",
      "Epoch 161/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9145 - accuracy: 0.7156 - val_loss: 0.6678 - val_accuracy: 0.6618\n",
      "Epoch 162/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9039 - accuracy: 0.7163 - val_loss: 0.6489 - val_accuracy: 0.6870\n",
      "Epoch 163/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9112 - accuracy: 0.7215 - val_loss: 0.6445 - val_accuracy: 0.6900\n",
      "Epoch 164/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9111 - accuracy: 0.7193 - val_loss: 0.6908 - val_accuracy: 0.6340\n",
      "Epoch 165/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9164 - accuracy: 0.7107 - val_loss: 0.7359 - val_accuracy: 0.5760\n",
      "Epoch 166/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9211 - accuracy: 0.7006 - val_loss: 0.6791 - val_accuracy: 0.6708\n",
      "Epoch 167/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9106 - accuracy: 0.7154 - val_loss: 0.6237 - val_accuracy: 0.7107\n",
      "Epoch 168/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9070 - accuracy: 0.7275 - val_loss: 0.6900 - val_accuracy: 0.6398\n",
      "Epoch 169/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9085 - accuracy: 0.7109 - val_loss: 0.6674 - val_accuracy: 0.6715\n",
      "Epoch 170/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.8982 - accuracy: 0.7179 - val_loss: 0.6260 - val_accuracy: 0.7042\n",
      "Epoch 171/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8972 - accuracy: 0.7292 - val_loss: 0.6518 - val_accuracy: 0.6827\n",
      "Epoch 172/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8960 - accuracy: 0.7134 - val_loss: 0.6721 - val_accuracy: 0.6582\n",
      "Epoch 173/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8969 - accuracy: 0.7196 - val_loss: 0.6680 - val_accuracy: 0.6637\n",
      "Epoch 174/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8958 - accuracy: 0.7183 - val_loss: 0.6296 - val_accuracy: 0.7085\n",
      "Epoch 175/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9044 - accuracy: 0.7241 - val_loss: 0.6459 - val_accuracy: 0.6973\n",
      "Epoch 176/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8990 - accuracy: 0.7319 - val_loss: 0.6672 - val_accuracy: 0.6570\n",
      "Epoch 177/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8958 - accuracy: 0.7261 - val_loss: 0.6497 - val_accuracy: 0.6905\n",
      "Epoch 178/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8884 - accuracy: 0.7236 - val_loss: 0.6648 - val_accuracy: 0.6702\n",
      "Epoch 179/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8948 - accuracy: 0.7296 - val_loss: 0.6533 - val_accuracy: 0.7015\n",
      "Epoch 180/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8901 - accuracy: 0.7138 - val_loss: 0.6748 - val_accuracy: 0.6595\n",
      "Epoch 181/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8844 - accuracy: 0.7276 - val_loss: 0.6855 - val_accuracy: 0.6655\n",
      "Epoch 182/1000\n",
      "16000/16000 [==============================] - ETA: 0s - loss: 0.8629 - accuracy: 0.72 - 0s 3us/step - loss: 0.8839 - accuracy: 0.7304 - val_loss: 0.6749 - val_accuracy: 0.6585\n",
      "Epoch 183/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8813 - accuracy: 0.7320 - val_loss: 0.6577 - val_accuracy: 0.6837\n",
      "Epoch 184/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8939 - accuracy: 0.7144 - val_loss: 0.7350 - val_accuracy: 0.5893\n",
      "Epoch 185/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8923 - accuracy: 0.7212 - val_loss: 0.6482 - val_accuracy: 0.6975\n",
      "Epoch 186/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8866 - accuracy: 0.7215 - val_loss: 0.6293 - val_accuracy: 0.7132\n",
      "Epoch 187/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8854 - accuracy: 0.7319 - val_loss: 0.6925 - val_accuracy: 0.6475\n",
      "Epoch 188/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8781 - accuracy: 0.7322 - val_loss: 0.6868 - val_accuracy: 0.6413\n",
      "Epoch 189/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8889 - accuracy: 0.7144 - val_loss: 0.6917 - val_accuracy: 0.6633\n",
      "Epoch 190/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8851 - accuracy: 0.7261 - val_loss: 0.6363 - val_accuracy: 0.6955\n",
      "Epoch 191/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8904 - accuracy: 0.7206 - val_loss: 0.6657 - val_accuracy: 0.6860\n",
      "Epoch 192/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8979 - accuracy: 0.7226 - val_loss: 0.7132 - val_accuracy: 0.6235\n",
      "Epoch 193/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8891 - accuracy: 0.7254 - val_loss: 0.6550 - val_accuracy: 0.6895\n",
      "Epoch 194/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8873 - accuracy: 0.7294 - val_loss: 0.6409 - val_accuracy: 0.7120\n",
      "Epoch 195/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.8830 - accuracy: 0.7289 - val_loss: 0.6604 - val_accuracy: 0.6655\n",
      "Epoch 196/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8836 - accuracy: 0.7130 - val_loss: 0.6857 - val_accuracy: 0.6570\n",
      "Epoch 197/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8775 - accuracy: 0.7286 - val_loss: 0.6485 - val_accuracy: 0.6883\n",
      "Epoch 198/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8692 - accuracy: 0.7354 - val_loss: 0.6625 - val_accuracy: 0.6852\n",
      "Epoch 199/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8668 - accuracy: 0.7389 - val_loss: 0.6658 - val_accuracy: 0.6790\n",
      "Epoch 200/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8733 - accuracy: 0.7299 - val_loss: 0.7106 - val_accuracy: 0.6217\n",
      "Epoch 201/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8790 - accuracy: 0.7269 - val_loss: 0.6607 - val_accuracy: 0.6913\n",
      "Epoch 202/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8844 - accuracy: 0.7191 - val_loss: 0.6119 - val_accuracy: 0.7395\n",
      "Epoch 203/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8941 - accuracy: 0.7386 - val_loss: 0.6963 - val_accuracy: 0.6507\n",
      "Epoch 204/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8806 - accuracy: 0.7283 - val_loss: 0.6937 - val_accuracy: 0.6378\n",
      "Epoch 205/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8805 - accuracy: 0.7239 - val_loss: 0.6832 - val_accuracy: 0.6467\n",
      "Epoch 206/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8695 - accuracy: 0.7309 - val_loss: 0.6256 - val_accuracy: 0.7015\n",
      "Epoch 207/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8644 - accuracy: 0.7401 - val_loss: 0.6091 - val_accuracy: 0.7315\n",
      "Epoch 208/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8664 - accuracy: 0.7446 - val_loss: 0.6537 - val_accuracy: 0.6942\n",
      "Epoch 209/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8601 - accuracy: 0.7347 - val_loss: 0.7105 - val_accuracy: 0.6275\n",
      "Epoch 210/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8705 - accuracy: 0.7209 - val_loss: 0.6603 - val_accuracy: 0.6900\n",
      "Epoch 211/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8684 - accuracy: 0.7334 - val_loss: 0.6105 - val_accuracy: 0.7325\n",
      "Epoch 212/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8687 - accuracy: 0.7439 - val_loss: 0.6931 - val_accuracy: 0.6597\n",
      "Epoch 213/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8675 - accuracy: 0.7228 - val_loss: 0.6829 - val_accuracy: 0.6587\n",
      "Epoch 214/1000\n",
      "16000/16000 [==============================] - ETA: 0s - loss: 0.8807 - accuracy: 0.71 - 0s 3us/step - loss: 0.8608 - accuracy: 0.7430 - val_loss: 0.6297 - val_accuracy: 0.7193\n",
      "Epoch 215/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8524 - accuracy: 0.7387 - val_loss: 0.6339 - val_accuracy: 0.7095\n",
      "Epoch 216/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8576 - accuracy: 0.7465 - val_loss: 0.6793 - val_accuracy: 0.6607\n",
      "Epoch 217/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8593 - accuracy: 0.7259 - val_loss: 0.7345 - val_accuracy: 0.6143\n",
      "Epoch 218/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8551 - accuracy: 0.7296 - val_loss: 0.6428 - val_accuracy: 0.7045\n",
      "Epoch 219/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8563 - accuracy: 0.7436 - val_loss: 0.6613 - val_accuracy: 0.6873\n",
      "Epoch 220/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8539 - accuracy: 0.7347 - val_loss: 0.6328 - val_accuracy: 0.7185\n",
      "Epoch 221/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8621 - accuracy: 0.7511 - val_loss: 0.6912 - val_accuracy: 0.6547\n",
      "Epoch 222/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8649 - accuracy: 0.7208 - val_loss: 0.6976 - val_accuracy: 0.6530\n",
      "Epoch 223/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8572 - accuracy: 0.7373 - val_loss: 0.6614 - val_accuracy: 0.6925\n",
      "Epoch 224/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8540 - accuracy: 0.7391 - val_loss: 0.6355 - val_accuracy: 0.7200\n",
      "Epoch 225/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8595 - accuracy: 0.7386 - val_loss: 0.6830 - val_accuracy: 0.6680\n",
      "Epoch 226/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8535 - accuracy: 0.7392 - val_loss: 0.6638 - val_accuracy: 0.6835\n",
      "Epoch 227/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8429 - accuracy: 0.7436 - val_loss: 0.6518 - val_accuracy: 0.7048\n",
      "Epoch 228/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8375 - accuracy: 0.7427 - val_loss: 0.6962 - val_accuracy: 0.6575\n",
      "Epoch 229/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8435 - accuracy: 0.7396 - val_loss: 0.6572 - val_accuracy: 0.6833\n",
      "Epoch 230/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8439 - accuracy: 0.7440 - val_loss: 0.6388 - val_accuracy: 0.7165\n",
      "Epoch 231/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8451 - accuracy: 0.7445 - val_loss: 0.7373 - val_accuracy: 0.6083\n",
      "Epoch 232/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8426 - accuracy: 0.7382 - val_loss: 0.6951 - val_accuracy: 0.6693\n",
      "Epoch 233/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8458 - accuracy: 0.7392 - val_loss: 0.6140 - val_accuracy: 0.7387\n",
      "Epoch 234/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8416 - accuracy: 0.7480 - val_loss: 0.6827 - val_accuracy: 0.6765\n",
      "Epoch 235/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8385 - accuracy: 0.7413 - val_loss: 0.6971 - val_accuracy: 0.6568\n",
      "Epoch 236/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8386 - accuracy: 0.7375 - val_loss: 0.6537 - val_accuracy: 0.7000\n",
      "Epoch 237/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8329 - accuracy: 0.7533 - val_loss: 0.6673 - val_accuracy: 0.6885\n",
      "Epoch 238/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8378 - accuracy: 0.7430 - val_loss: 0.6700 - val_accuracy: 0.6875\n",
      "Epoch 239/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8416 - accuracy: 0.7456 - val_loss: 0.6962 - val_accuracy: 0.6702\n",
      "Epoch 240/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8323 - accuracy: 0.7496 - val_loss: 0.6564 - val_accuracy: 0.6890\n",
      "Epoch 241/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8328 - accuracy: 0.7446 - val_loss: 0.7242 - val_accuracy: 0.6430\n",
      "Epoch 242/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8348 - accuracy: 0.7371 - val_loss: 0.6641 - val_accuracy: 0.6975\n",
      "Epoch 243/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8319 - accuracy: 0.7523 - val_loss: 0.6969 - val_accuracy: 0.6570\n",
      "Epoch 244/1000\n",
      "16000/16000 [==============================] - ETA: 0s - loss: 0.8014 - accuracy: 0.71 - 0s 3us/step - loss: 0.8356 - accuracy: 0.7391 - val_loss: 0.6436 - val_accuracy: 0.7157\n",
      "Epoch 245/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8316 - accuracy: 0.7459 - val_loss: 0.7010 - val_accuracy: 0.6628\n",
      "Epoch 246/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8285 - accuracy: 0.7542 - val_loss: 0.7134 - val_accuracy: 0.6392\n",
      "Epoch 247/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8262 - accuracy: 0.7403 - val_loss: 0.6188 - val_accuracy: 0.7278\n",
      "Epoch 248/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8264 - accuracy: 0.7505 - val_loss: 0.6816 - val_accuracy: 0.6762\n",
      "Epoch 249/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8228 - accuracy: 0.7413 - val_loss: 0.6142 - val_accuracy: 0.7458\n",
      "Epoch 250/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8335 - accuracy: 0.7587 - val_loss: 0.7187 - val_accuracy: 0.6587\n",
      "Epoch 251/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8330 - accuracy: 0.7321 - val_loss: 0.7148 - val_accuracy: 0.6570\n",
      "Epoch 252/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8301 - accuracy: 0.7441 - val_loss: 0.6884 - val_accuracy: 0.6635\n",
      "Epoch 253/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8332 - accuracy: 0.7395 - val_loss: 0.6348 - val_accuracy: 0.7235\n",
      "Epoch 254/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8238 - accuracy: 0.7525 - val_loss: 0.6413 - val_accuracy: 0.7232\n",
      "Epoch 255/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8333 - accuracy: 0.7506 - val_loss: 0.6994 - val_accuracy: 0.6702\n",
      "Epoch 256/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8342 - accuracy: 0.7436 - val_loss: 0.7099 - val_accuracy: 0.6650\n",
      "Epoch 257/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8279 - accuracy: 0.7491 - val_loss: 0.6660 - val_accuracy: 0.6945\n",
      "Epoch 258/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8257 - accuracy: 0.7516 - val_loss: 0.6681 - val_accuracy: 0.6963\n",
      "Epoch 259/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8182 - accuracy: 0.7525 - val_loss: 0.7194 - val_accuracy: 0.6455\n",
      "Epoch 260/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8158 - accuracy: 0.7517 - val_loss: 0.6506 - val_accuracy: 0.7135\n",
      "Epoch 261/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8270 - accuracy: 0.7509 - val_loss: 0.7013 - val_accuracy: 0.6715\n",
      "Epoch 262/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8221 - accuracy: 0.7384 - val_loss: 0.6661 - val_accuracy: 0.6845\n",
      "Epoch 263/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.8240 - accuracy: 0.7551 - val_loss: 0.6417 - val_accuracy: 0.7150\n",
      "Epoch 264/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8177 - accuracy: 0.7522 - val_loss: 0.7044 - val_accuracy: 0.6580\n",
      "Epoch 265/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8142 - accuracy: 0.7428 - val_loss: 0.6511 - val_accuracy: 0.7160\n",
      "Epoch 266/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8188 - accuracy: 0.7557 - val_loss: 0.6706 - val_accuracy: 0.6998\n",
      "Epoch 267/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8271 - accuracy: 0.7462 - val_loss: 0.6625 - val_accuracy: 0.7023\n",
      "Epoch 268/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8138 - accuracy: 0.7530 - val_loss: 0.6876 - val_accuracy: 0.6783\n",
      "Epoch 269/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8116 - accuracy: 0.7523 - val_loss: 0.7260 - val_accuracy: 0.6562\n",
      "Epoch 270/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8186 - accuracy: 0.7464 - val_loss: 0.6572 - val_accuracy: 0.7200\n",
      "Epoch 271/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8115 - accuracy: 0.7515 - val_loss: 0.7371 - val_accuracy: 0.6415\n",
      "Epoch 272/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8232 - accuracy: 0.7425 - val_loss: 0.6661 - val_accuracy: 0.7128\n",
      "Epoch 273/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8078 - accuracy: 0.7544 - val_loss: 0.7420 - val_accuracy: 0.6345\n",
      "Epoch 274/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8204 - accuracy: 0.7337 - val_loss: 0.6302 - val_accuracy: 0.7410\n",
      "Epoch 275/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.8332 - accuracy: 0.7544 - val_loss: 0.6476 - val_accuracy: 0.7132\n",
      "Epoch 276/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8088 - accuracy: 0.7548 - val_loss: 0.6867 - val_accuracy: 0.6825\n",
      "Epoch 277/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.8083 - accuracy: 0.7639 - val_loss: 0.6994 - val_accuracy: 0.6730\n",
      "Epoch 278/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.8093 - accuracy: 0.7400 - val_loss: 0.6795 - val_accuracy: 0.6985\n",
      "Epoch 279/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8077 - accuracy: 0.7613 - val_loss: 0.6973 - val_accuracy: 0.6773\n",
      "Epoch 280/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8131 - accuracy: 0.7450 - val_loss: 0.7036 - val_accuracy: 0.6702\n",
      "Epoch 281/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.8170 - accuracy: 0.7544 - val_loss: 0.6815 - val_accuracy: 0.6923\n",
      "Epoch 282/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8104 - accuracy: 0.7494 - val_loss: 0.6477 - val_accuracy: 0.7308\n",
      "Epoch 283/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8099 - accuracy: 0.7665 - val_loss: 0.7173 - val_accuracy: 0.6625\n",
      "Epoch 284/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8012 - accuracy: 0.7545 - val_loss: 0.6980 - val_accuracy: 0.6793\n",
      "Epoch 285/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7925 - accuracy: 0.7551 - val_loss: 0.6753 - val_accuracy: 0.7053\n",
      "Epoch 286/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7918 - accuracy: 0.7574 - val_loss: 0.6811 - val_accuracy: 0.7053\n",
      "Epoch 287/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7873 - accuracy: 0.7673 - val_loss: 0.7190 - val_accuracy: 0.6737\n",
      "Epoch 288/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.8028 - accuracy: 0.7474 - val_loss: 0.6681 - val_accuracy: 0.7115\n",
      "Epoch 289/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8023 - accuracy: 0.7665 - val_loss: 0.7644 - val_accuracy: 0.6255\n",
      "Epoch 290/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8100 - accuracy: 0.7374 - val_loss: 0.6411 - val_accuracy: 0.7352\n",
      "Epoch 291/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8101 - accuracy: 0.7663 - val_loss: 0.6648 - val_accuracy: 0.7065\n",
      "Epoch 292/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7983 - accuracy: 0.7527 - val_loss: 0.7049 - val_accuracy: 0.6777\n",
      "Epoch 293/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8006 - accuracy: 0.7628 - val_loss: 0.6532 - val_accuracy: 0.7185\n",
      "Epoch 294/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8077 - accuracy: 0.7459 - val_loss: 0.7371 - val_accuracy: 0.6555\n",
      "Epoch 295/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8053 - accuracy: 0.7499 - val_loss: 0.6956 - val_accuracy: 0.6855\n",
      "Epoch 296/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8047 - accuracy: 0.7628 - val_loss: 0.6928 - val_accuracy: 0.6908\n",
      "Epoch 297/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7919 - accuracy: 0.7597 - val_loss: 0.7260 - val_accuracy: 0.6680\n",
      "Epoch 298/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7868 - accuracy: 0.7602 - val_loss: 0.6957 - val_accuracy: 0.6823\n",
      "Epoch 299/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7886 - accuracy: 0.7604 - val_loss: 0.6717 - val_accuracy: 0.7090\n",
      "Epoch 300/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7933 - accuracy: 0.7614 - val_loss: 0.6949 - val_accuracy: 0.6768\n",
      "Epoch 301/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.7866 - accuracy: 0.7659 - val_loss: 0.7001 - val_accuracy: 0.6773\n",
      "Epoch 302/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7807 - accuracy: 0.7544 - val_loss: 0.6660 - val_accuracy: 0.7147\n",
      "Epoch 303/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7828 - accuracy: 0.7661 - val_loss: 0.7386 - val_accuracy: 0.6463\n",
      "Epoch 304/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7853 - accuracy: 0.7578 - val_loss: 0.6741 - val_accuracy: 0.6990\n",
      "Epoch 305/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7878 - accuracy: 0.7581 - val_loss: 0.6869 - val_accuracy: 0.6920\n",
      "Epoch 306/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7888 - accuracy: 0.7641 - val_loss: 0.6871 - val_accuracy: 0.7015\n",
      "Epoch 307/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7909 - accuracy: 0.7598 - val_loss: 0.7020 - val_accuracy: 0.6823\n",
      "Epoch 308/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7854 - accuracy: 0.7554 - val_loss: 0.6722 - val_accuracy: 0.7032\n",
      "Epoch 309/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7857 - accuracy: 0.7633 - val_loss: 0.6800 - val_accuracy: 0.7048\n",
      "Epoch 310/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7815 - accuracy: 0.7678 - val_loss: 0.7106 - val_accuracy: 0.6607\n",
      "Epoch 311/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7871 - accuracy: 0.7600 - val_loss: 0.6797 - val_accuracy: 0.7070\n",
      "Epoch 312/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7836 - accuracy: 0.7636 - val_loss: 0.6833 - val_accuracy: 0.7055\n",
      "Epoch 313/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.7817 - accuracy: 0.7587 - val_loss: 0.6368 - val_accuracy: 0.7387\n",
      "Epoch 314/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7816 - accuracy: 0.7686 - val_loss: 0.7530 - val_accuracy: 0.6373\n",
      "Epoch 315/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7906 - accuracy: 0.7651 - val_loss: 0.7357 - val_accuracy: 0.6463\n",
      "Epoch 316/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7873 - accuracy: 0.7507 - val_loss: 0.6650 - val_accuracy: 0.7147\n",
      "Epoch 317/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7885 - accuracy: 0.7589 - val_loss: 0.6675 - val_accuracy: 0.7200\n",
      "Epoch 318/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7887 - accuracy: 0.7612 - val_loss: 0.7002 - val_accuracy: 0.7015\n",
      "Epoch 319/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7871 - accuracy: 0.7625 - val_loss: 0.7054 - val_accuracy: 0.6785\n",
      "Epoch 320/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7859 - accuracy: 0.7536 - val_loss: 0.6564 - val_accuracy: 0.7320\n",
      "Epoch 321/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7913 - accuracy: 0.7572 - val_loss: 0.7102 - val_accuracy: 0.6768\n",
      "Epoch 322/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7835 - accuracy: 0.7681 - val_loss: 0.6792 - val_accuracy: 0.7105\n",
      "Epoch 323/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7799 - accuracy: 0.7522 - val_loss: 0.7324 - val_accuracy: 0.6618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 324/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8041 - accuracy: 0.7631 - val_loss: 0.6353 - val_accuracy: 0.7448\n",
      "Epoch 325/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7926 - accuracy: 0.7623 - val_loss: 0.7607 - val_accuracy: 0.6425\n",
      "Epoch 326/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7845 - accuracy: 0.7574 - val_loss: 0.7255 - val_accuracy: 0.6658\n",
      "Epoch 327/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7777 - accuracy: 0.7599 - val_loss: 0.6523 - val_accuracy: 0.7290\n",
      "Epoch 328/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7746 - accuracy: 0.7730 - val_loss: 0.6999 - val_accuracy: 0.6877\n",
      "Epoch 329/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7723 - accuracy: 0.7661 - val_loss: 0.7239 - val_accuracy: 0.6633\n",
      "Epoch 330/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7714 - accuracy: 0.7635 - val_loss: 0.6765 - val_accuracy: 0.7082\n",
      "Epoch 331/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7769 - accuracy: 0.7690 - val_loss: 0.7055 - val_accuracy: 0.6877\n",
      "Epoch 332/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7828 - accuracy: 0.7532 - val_loss: 0.7008 - val_accuracy: 0.6923\n",
      "Epoch 333/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7830 - accuracy: 0.7572 - val_loss: 0.6674 - val_accuracy: 0.7245\n",
      "Epoch 334/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7866 - accuracy: 0.7656 - val_loss: 0.7003 - val_accuracy: 0.6890\n",
      "Epoch 335/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7748 - accuracy: 0.7554 - val_loss: 0.6579 - val_accuracy: 0.7235\n",
      "Epoch 336/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7686 - accuracy: 0.7767 - val_loss: 0.7064 - val_accuracy: 0.6795\n",
      "Epoch 337/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7674 - accuracy: 0.7604 - val_loss: 0.6523 - val_accuracy: 0.7278\n",
      "Epoch 338/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7629 - accuracy: 0.7747 - val_loss: 0.6586 - val_accuracy: 0.7243\n",
      "Epoch 339/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7662 - accuracy: 0.7692 - val_loss: 0.6898 - val_accuracy: 0.6917\n",
      "Epoch 340/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7671 - accuracy: 0.7617 - val_loss: 0.6748 - val_accuracy: 0.7140\n",
      "Epoch 341/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7630 - accuracy: 0.7709 - val_loss: 0.7160 - val_accuracy: 0.6827\n",
      "Epoch 342/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7643 - accuracy: 0.7709 - val_loss: 0.7275 - val_accuracy: 0.6625\n",
      "Epoch 343/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7587 - accuracy: 0.7706 - val_loss: 0.7027 - val_accuracy: 0.6955\n",
      "Epoch 344/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7558 - accuracy: 0.7678 - val_loss: 0.6840 - val_accuracy: 0.7157\n",
      "Epoch 345/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7723 - accuracy: 0.7626 - val_loss: 0.6584 - val_accuracy: 0.7305\n",
      "Epoch 346/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7708 - accuracy: 0.7680 - val_loss: 0.6995 - val_accuracy: 0.7032\n",
      "Epoch 347/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7580 - accuracy: 0.7702 - val_loss: 0.6857 - val_accuracy: 0.7120\n",
      "Epoch 348/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7599 - accuracy: 0.7766 - val_loss: 0.7681 - val_accuracy: 0.6345\n",
      "Epoch 349/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7603 - accuracy: 0.7684 - val_loss: 0.7134 - val_accuracy: 0.6915\n",
      "Epoch 350/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7570 - accuracy: 0.7696 - val_loss: 0.7035 - val_accuracy: 0.6890\n",
      "Epoch 351/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7507 - accuracy: 0.7729 - val_loss: 0.6536 - val_accuracy: 0.7312\n",
      "Epoch 352/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7527 - accuracy: 0.7714 - val_loss: 0.7114 - val_accuracy: 0.6885\n",
      "Epoch 353/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7580 - accuracy: 0.7731 - val_loss: 0.7126 - val_accuracy: 0.6848\n",
      "Epoch 354/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7516 - accuracy: 0.7634 - val_loss: 0.6782 - val_accuracy: 0.7075\n",
      "Epoch 355/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7404 - accuracy: 0.7773 - val_loss: 0.6751 - val_accuracy: 0.7210\n",
      "Epoch 356/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7502 - accuracy: 0.7778 - val_loss: 0.7309 - val_accuracy: 0.6730\n",
      "Epoch 357/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7481 - accuracy: 0.7701 - val_loss: 0.6558 - val_accuracy: 0.7320\n",
      "Epoch 358/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7464 - accuracy: 0.7836 - val_loss: 0.7369 - val_accuracy: 0.6765\n",
      "Epoch 359/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7584 - accuracy: 0.7651 - val_loss: 0.7254 - val_accuracy: 0.6875\n",
      "Epoch 360/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7820 - accuracy: 0.7623 - val_loss: 0.7507 - val_accuracy: 0.6653\n",
      "Epoch 361/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7769 - accuracy: 0.7607 - val_loss: 0.6785 - val_accuracy: 0.7132\n",
      "Epoch 362/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7728 - accuracy: 0.7697 - val_loss: 0.7520 - val_accuracy: 0.6562\n",
      "Epoch 363/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7560 - accuracy: 0.7681 - val_loss: 0.7071 - val_accuracy: 0.7085\n",
      "Epoch 364/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7647 - accuracy: 0.7725 - val_loss: 0.7448 - val_accuracy: 0.6597\n",
      "Epoch 365/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7656 - accuracy: 0.7634 - val_loss: 0.7116 - val_accuracy: 0.6880\n",
      "Epoch 366/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7550 - accuracy: 0.7741 - val_loss: 0.7038 - val_accuracy: 0.6957\n",
      "Epoch 367/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7438 - accuracy: 0.7753 - val_loss: 0.7237 - val_accuracy: 0.6855\n",
      "Epoch 368/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7422 - accuracy: 0.7756 - val_loss: 0.6699 - val_accuracy: 0.7240\n",
      "Epoch 369/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7364 - accuracy: 0.7856 - val_loss: 0.7348 - val_accuracy: 0.6773\n",
      "Epoch 370/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7421 - accuracy: 0.7631 - val_loss: 0.6532 - val_accuracy: 0.7523\n",
      "Epoch 371/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7547 - accuracy: 0.7836 - val_loss: 0.7786 - val_accuracy: 0.6355\n",
      "Epoch 372/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.7509 - accuracy: 0.7632 - val_loss: 0.6522 - val_accuracy: 0.7510\n",
      "Epoch 373/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7490 - accuracy: 0.7897 - val_loss: 0.7166 - val_accuracy: 0.6877\n",
      "Epoch 374/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7561 - accuracy: 0.7636 - val_loss: 0.6890 - val_accuracy: 0.7103\n",
      "Epoch 375/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7450 - accuracy: 0.7826 - val_loss: 0.7260 - val_accuracy: 0.6775\n",
      "Epoch 376/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7438 - accuracy: 0.7684 - val_loss: 0.7408 - val_accuracy: 0.6805\n",
      "Epoch 377/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7402 - accuracy: 0.7760 - val_loss: 0.6639 - val_accuracy: 0.7312\n",
      "Epoch 378/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7334 - accuracy: 0.7838 - val_loss: 0.6970 - val_accuracy: 0.7193\n",
      "Epoch 379/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7400 - accuracy: 0.7826 - val_loss: 0.7254 - val_accuracy: 0.7000\n",
      "Epoch 380/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7409 - accuracy: 0.7761 - val_loss: 0.6918 - val_accuracy: 0.7172\n",
      "Epoch 381/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7453 - accuracy: 0.7783 - val_loss: 0.7879 - val_accuracy: 0.6365\n",
      "Epoch 382/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7578 - accuracy: 0.7562 - val_loss: 0.6495 - val_accuracy: 0.7533\n",
      "Epoch 383/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7532 - accuracy: 0.7841 - val_loss: 0.7112 - val_accuracy: 0.7013\n",
      "Epoch 384/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7457 - accuracy: 0.7657 - val_loss: 0.7865 - val_accuracy: 0.6423\n",
      "Epoch 385/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7464 - accuracy: 0.7774 - val_loss: 0.6909 - val_accuracy: 0.7188\n",
      "Epoch 386/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7413 - accuracy: 0.7751 - val_loss: 0.7745 - val_accuracy: 0.6447\n",
      "Epoch 387/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7347 - accuracy: 0.7807 - val_loss: 0.7492 - val_accuracy: 0.6848\n",
      "Epoch 388/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7395 - accuracy: 0.7713 - val_loss: 0.6902 - val_accuracy: 0.7107\n",
      "Epoch 389/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7477 - accuracy: 0.7796 - val_loss: 0.7583 - val_accuracy: 0.6612\n",
      "Epoch 390/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7425 - accuracy: 0.7768 - val_loss: 0.7358 - val_accuracy: 0.6825\n",
      "Epoch 391/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.7361 - accuracy: 0.7816 - val_loss: 0.7171 - val_accuracy: 0.6938\n",
      "Epoch 392/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.7358 - accuracy: 0.7724 - val_loss: 0.6842 - val_accuracy: 0.7195\n",
      "Epoch 393/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.7277 - accuracy: 0.7857 - val_loss: 0.7470 - val_accuracy: 0.6808\n",
      "Epoch 394/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.7306 - accuracy: 0.7754 - val_loss: 0.6703 - val_accuracy: 0.7350\n",
      "Epoch 395/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7293 - accuracy: 0.7863 - val_loss: 0.7080 - val_accuracy: 0.7067\n",
      "Epoch 396/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7264 - accuracy: 0.7826 - val_loss: 0.7249 - val_accuracy: 0.6952\n",
      "Epoch 397/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7306 - accuracy: 0.7875 - val_loss: 0.7897 - val_accuracy: 0.6565\n",
      "Epoch 398/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7287 - accuracy: 0.7753 - val_loss: 0.7074 - val_accuracy: 0.7138\n",
      "Epoch 399/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7324 - accuracy: 0.7814 - val_loss: 0.7304 - val_accuracy: 0.6940\n",
      "Epoch 400/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7242 - accuracy: 0.7766 - val_loss: 0.6966 - val_accuracy: 0.7222\n",
      "Epoch 401/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7256 - accuracy: 0.7886 - val_loss: 0.7682 - val_accuracy: 0.6593\n",
      "Epoch 402/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7332 - accuracy: 0.7719 - val_loss: 0.6842 - val_accuracy: 0.7293\n",
      "Epoch 403/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7334 - accuracy: 0.7862 - val_loss: 0.7916 - val_accuracy: 0.6590\n",
      "Epoch 404/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7358 - accuracy: 0.7784 - val_loss: 0.7066 - val_accuracy: 0.7207\n",
      "Epoch 405/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7316 - accuracy: 0.7864 - val_loss: 0.7068 - val_accuracy: 0.7145\n",
      "Epoch 406/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7303 - accuracy: 0.7824 - val_loss: 0.7289 - val_accuracy: 0.7200\n",
      "Epoch 407/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7241 - accuracy: 0.7911 - val_loss: 0.7288 - val_accuracy: 0.7007\n",
      "Epoch 408/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7275 - accuracy: 0.7736 - val_loss: 0.7290 - val_accuracy: 0.6985\n",
      "Epoch 409/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7357 - accuracy: 0.7843 - val_loss: 0.6880 - val_accuracy: 0.7327\n",
      "Epoch 410/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.7428 - accuracy: 0.7725 - val_loss: 0.8380 - val_accuracy: 0.6388\n",
      "Epoch 411/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7523 - accuracy: 0.7705 - val_loss: 0.6735 - val_accuracy: 0.7552\n",
      "Epoch 412/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7285 - accuracy: 0.7864 - val_loss: 0.7513 - val_accuracy: 0.6915\n",
      "Epoch 413/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7180 - accuracy: 0.7868 - val_loss: 0.7307 - val_accuracy: 0.6955\n",
      "Epoch 414/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7130 - accuracy: 0.7905 - val_loss: 0.7491 - val_accuracy: 0.6973\n",
      "Epoch 415/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7089 - accuracy: 0.7856 - val_loss: 0.7270 - val_accuracy: 0.7053\n",
      "Epoch 416/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7067 - accuracy: 0.7956 - val_loss: 0.6932 - val_accuracy: 0.7330\n",
      "Epoch 417/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7101 - accuracy: 0.7869 - val_loss: 0.7487 - val_accuracy: 0.6890\n",
      "Epoch 418/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7104 - accuracy: 0.7861 - val_loss: 0.7273 - val_accuracy: 0.7120\n",
      "Epoch 419/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7086 - accuracy: 0.7948 - val_loss: 0.7293 - val_accuracy: 0.7147\n",
      "Epoch 420/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7174 - accuracy: 0.7898 - val_loss: 0.7328 - val_accuracy: 0.7122\n",
      "Epoch 421/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7105 - accuracy: 0.7885 - val_loss: 0.7442 - val_accuracy: 0.6877\n",
      "Epoch 422/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7062 - accuracy: 0.7896 - val_loss: 0.7017 - val_accuracy: 0.7387\n",
      "Epoch 423/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7050 - accuracy: 0.7895 - val_loss: 0.7272 - val_accuracy: 0.7200\n",
      "Epoch 424/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7109 - accuracy: 0.7841 - val_loss: 0.7183 - val_accuracy: 0.7225\n",
      "Epoch 425/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7191 - accuracy: 0.7972 - val_loss: 0.7938 - val_accuracy: 0.6660\n",
      "Epoch 426/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7249 - accuracy: 0.7729 - val_loss: 0.7221 - val_accuracy: 0.7222\n",
      "Epoch 427/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7093 - accuracy: 0.7960 - val_loss: 0.7519 - val_accuracy: 0.6908\n",
      "Epoch 428/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7149 - accuracy: 0.7778 - val_loss: 0.7486 - val_accuracy: 0.6955\n",
      "Epoch 429/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7066 - accuracy: 0.7943 - val_loss: 0.7173 - val_accuracy: 0.7100\n",
      "Epoch 430/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6998 - accuracy: 0.7903 - val_loss: 0.7142 - val_accuracy: 0.7247\n",
      "Epoch 431/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7039 - accuracy: 0.7928 - val_loss: 0.7566 - val_accuracy: 0.6963\n",
      "Epoch 432/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7033 - accuracy: 0.7901 - val_loss: 0.7078 - val_accuracy: 0.7337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 433/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7093 - accuracy: 0.7876 - val_loss: 0.8062 - val_accuracy: 0.6737\n",
      "Epoch 434/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7158 - accuracy: 0.7878 - val_loss: 0.7232 - val_accuracy: 0.7150\n",
      "Epoch 435/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7143 - accuracy: 0.7820 - val_loss: 0.7776 - val_accuracy: 0.6745\n",
      "Epoch 436/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7152 - accuracy: 0.7923 - val_loss: 0.7384 - val_accuracy: 0.7040\n",
      "Epoch 437/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7185 - accuracy: 0.7851 - val_loss: 0.7971 - val_accuracy: 0.6653\n",
      "Epoch 438/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7044 - accuracy: 0.7820 - val_loss: 0.7130 - val_accuracy: 0.7245\n",
      "Epoch 439/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7062 - accuracy: 0.7872 - val_loss: 0.7868 - val_accuracy: 0.6685\n",
      "Epoch 440/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7106 - accuracy: 0.7939 - val_loss: 0.7429 - val_accuracy: 0.6980\n",
      "Epoch 441/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7028 - accuracy: 0.7891 - val_loss: 0.7829 - val_accuracy: 0.6773\n",
      "Epoch 442/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7075 - accuracy: 0.7872 - val_loss: 0.7531 - val_accuracy: 0.6988\n",
      "Epoch 443/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7112 - accuracy: 0.7945 - val_loss: 0.7770 - val_accuracy: 0.6700\n",
      "Epoch 444/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7148 - accuracy: 0.7747 - val_loss: 0.7421 - val_accuracy: 0.7038\n",
      "Epoch 445/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6955 - accuracy: 0.7980 - val_loss: 0.7221 - val_accuracy: 0.7072\n",
      "Epoch 446/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7024 - accuracy: 0.7927 - val_loss: 0.7991 - val_accuracy: 0.6685\n",
      "Epoch 447/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7132 - accuracy: 0.7801 - val_loss: 0.7273 - val_accuracy: 0.7290\n",
      "Epoch 448/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7080 - accuracy: 0.7944 - val_loss: 0.8528 - val_accuracy: 0.6345\n",
      "Epoch 449/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7158 - accuracy: 0.7783 - val_loss: 0.6741 - val_accuracy: 0.7552\n",
      "Epoch 450/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.7162 - accuracy: 0.7898 - val_loss: 0.7609 - val_accuracy: 0.6930\n",
      "Epoch 451/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7120 - accuracy: 0.7788 - val_loss: 0.7496 - val_accuracy: 0.6892\n",
      "Epoch 452/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7055 - accuracy: 0.7880 - val_loss: 0.7494 - val_accuracy: 0.7063\n",
      "Epoch 453/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6954 - accuracy: 0.7932 - val_loss: 0.7192 - val_accuracy: 0.7345\n",
      "Epoch 454/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7066 - accuracy: 0.7921 - val_loss: 0.7939 - val_accuracy: 0.6765\n",
      "Epoch 455/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7059 - accuracy: 0.7789 - val_loss: 0.7061 - val_accuracy: 0.7460\n",
      "Epoch 456/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7050 - accuracy: 0.8005 - val_loss: 0.7245 - val_accuracy: 0.7215\n",
      "Epoch 457/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6956 - accuracy: 0.7901 - val_loss: 0.7679 - val_accuracy: 0.6835\n",
      "Epoch 458/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6982 - accuracy: 0.7958 - val_loss: 0.7492 - val_accuracy: 0.6960\n",
      "Epoch 459/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6939 - accuracy: 0.7921 - val_loss: 0.7566 - val_accuracy: 0.7025\n",
      "Epoch 460/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6931 - accuracy: 0.7967 - val_loss: 0.7436 - val_accuracy: 0.7128\n",
      "Epoch 461/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.6965 - accuracy: 0.7917 - val_loss: 0.7729 - val_accuracy: 0.6842\n",
      "Epoch 462/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6921 - accuracy: 0.7945 - val_loss: 0.7152 - val_accuracy: 0.7365\n",
      "Epoch 463/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6849 - accuracy: 0.7989 - val_loss: 0.7831 - val_accuracy: 0.6802\n",
      "Epoch 464/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6904 - accuracy: 0.7878 - val_loss: 0.6999 - val_accuracy: 0.7565\n",
      "Epoch 465/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6832 - accuracy: 0.8033 - val_loss: 0.7838 - val_accuracy: 0.6768\n",
      "Epoch 466/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6858 - accuracy: 0.7900 - val_loss: 0.7126 - val_accuracy: 0.7375\n",
      "Epoch 467/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6799 - accuracy: 0.8045 - val_loss: 0.7465 - val_accuracy: 0.7135\n",
      "Epoch 468/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6800 - accuracy: 0.7982 - val_loss: 0.7602 - val_accuracy: 0.7097\n",
      "Epoch 469/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6795 - accuracy: 0.8006 - val_loss: 0.7779 - val_accuracy: 0.6867\n",
      "Epoch 470/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6949 - accuracy: 0.7929 - val_loss: 0.7645 - val_accuracy: 0.6925\n",
      "Epoch 471/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6894 - accuracy: 0.8002 - val_loss: 0.7678 - val_accuracy: 0.7025\n",
      "Epoch 472/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6832 - accuracy: 0.7976 - val_loss: 0.8115 - val_accuracy: 0.6660\n",
      "Epoch 473/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6859 - accuracy: 0.7968 - val_loss: 0.7243 - val_accuracy: 0.7450\n",
      "Epoch 474/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6910 - accuracy: 0.7936 - val_loss: 0.7756 - val_accuracy: 0.6860\n",
      "Epoch 475/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6784 - accuracy: 0.8041 - val_loss: 0.7512 - val_accuracy: 0.7132\n",
      "Epoch 476/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6807 - accuracy: 0.7947 - val_loss: 0.7703 - val_accuracy: 0.6920\n",
      "Epoch 477/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6773 - accuracy: 0.8001 - val_loss: 0.7421 - val_accuracy: 0.7318\n",
      "Epoch 478/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6813 - accuracy: 0.7980 - val_loss: 0.7801 - val_accuracy: 0.6877\n",
      "Epoch 479/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6849 - accuracy: 0.7911 - val_loss: 0.7171 - val_accuracy: 0.7402\n",
      "Epoch 480/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6775 - accuracy: 0.8018 - val_loss: 0.7651 - val_accuracy: 0.6892\n",
      "Epoch 481/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6791 - accuracy: 0.7979 - val_loss: 0.7176 - val_accuracy: 0.7387\n",
      "Epoch 482/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6752 - accuracy: 0.7989 - val_loss: 0.7754 - val_accuracy: 0.6957\n",
      "Epoch 483/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6786 - accuracy: 0.8020 - val_loss: 0.7386 - val_accuracy: 0.7250\n",
      "Epoch 484/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6760 - accuracy: 0.7971 - val_loss: 0.7571 - val_accuracy: 0.7140\n",
      "Epoch 485/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6848 - accuracy: 0.8026 - val_loss: 0.7538 - val_accuracy: 0.7132\n",
      "Epoch 486/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6768 - accuracy: 0.7986 - val_loss: 0.7837 - val_accuracy: 0.6780\n",
      "Epoch 487/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6746 - accuracy: 0.8014 - val_loss: 0.7826 - val_accuracy: 0.7072\n",
      "Epoch 488/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6787 - accuracy: 0.8061 - val_loss: 0.8019 - val_accuracy: 0.6637\n",
      "Epoch 489/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6839 - accuracy: 0.7922 - val_loss: 0.7224 - val_accuracy: 0.7370\n",
      "Epoch 490/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6749 - accuracy: 0.8004 - val_loss: 0.7790 - val_accuracy: 0.6930\n",
      "Epoch 491/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6684 - accuracy: 0.8039 - val_loss: 0.7573 - val_accuracy: 0.7207\n",
      "Epoch 492/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6829 - accuracy: 0.8079 - val_loss: 0.8335 - val_accuracy: 0.6637\n",
      "Epoch 493/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6822 - accuracy: 0.7828 - val_loss: 0.6980 - val_accuracy: 0.7678\n",
      "Epoch 494/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6822 - accuracy: 0.8008 - val_loss: 0.8001 - val_accuracy: 0.6920\n",
      "Epoch 495/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6795 - accuracy: 0.8032 - val_loss: 0.7525 - val_accuracy: 0.7110\n",
      "Epoch 496/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6795 - accuracy: 0.7917 - val_loss: 0.7384 - val_accuracy: 0.7212\n",
      "Epoch 497/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6785 - accuracy: 0.8050 - val_loss: 0.7913 - val_accuracy: 0.6973\n",
      "Epoch 498/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6706 - accuracy: 0.7972 - val_loss: 0.7405 - val_accuracy: 0.7300\n",
      "Epoch 499/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6763 - accuracy: 0.8058 - val_loss: 0.7697 - val_accuracy: 0.7190\n",
      "Epoch 500/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6735 - accuracy: 0.7994 - val_loss: 0.7834 - val_accuracy: 0.7015\n",
      "Epoch 501/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6770 - accuracy: 0.8056 - val_loss: 0.7687 - val_accuracy: 0.7163\n",
      "Epoch 502/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6840 - accuracy: 0.7944 - val_loss: 0.8539 - val_accuracy: 0.6457\n",
      "Epoch 503/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6879 - accuracy: 0.7969 - val_loss: 0.7561 - val_accuracy: 0.7322\n",
      "Epoch 504/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6901 - accuracy: 0.7951 - val_loss: 0.7904 - val_accuracy: 0.6938\n",
      "Epoch 505/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6881 - accuracy: 0.7941 - val_loss: 0.7594 - val_accuracy: 0.7265\n",
      "Epoch 506/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6818 - accuracy: 0.8074 - val_loss: 0.7921 - val_accuracy: 0.6875\n",
      "Epoch 507/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6660 - accuracy: 0.8004 - val_loss: 0.7508 - val_accuracy: 0.7207\n",
      "Epoch 508/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6544 - accuracy: 0.8092 - val_loss: 0.7386 - val_accuracy: 0.7408\n",
      "Epoch 509/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6605 - accuracy: 0.8099 - val_loss: 0.8043 - val_accuracy: 0.6862\n",
      "Epoch 510/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6658 - accuracy: 0.8012 - val_loss: 0.7436 - val_accuracy: 0.7318\n",
      "Epoch 511/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6640 - accuracy: 0.8005 - val_loss: 0.7304 - val_accuracy: 0.7440\n",
      "Epoch 512/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6714 - accuracy: 0.7996 - val_loss: 0.7794 - val_accuracy: 0.6990\n",
      "Epoch 513/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6697 - accuracy: 0.8070 - val_loss: 0.7513 - val_accuracy: 0.7290\n",
      "Epoch 514/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6644 - accuracy: 0.8017 - val_loss: 0.8398 - val_accuracy: 0.6668\n",
      "Epoch 515/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6684 - accuracy: 0.8006 - val_loss: 0.7376 - val_accuracy: 0.7343\n",
      "Epoch 516/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6631 - accuracy: 0.8053 - val_loss: 0.8225 - val_accuracy: 0.6762\n",
      "Epoch 517/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6585 - accuracy: 0.8003 - val_loss: 0.7367 - val_accuracy: 0.7377\n",
      "Epoch 518/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6558 - accuracy: 0.8171 - val_loss: 0.8148 - val_accuracy: 0.6845\n",
      "Epoch 519/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6596 - accuracy: 0.7986 - val_loss: 0.7536 - val_accuracy: 0.7300\n",
      "Epoch 520/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.6756 - accuracy: 0.7999 - val_loss: 0.7411 - val_accuracy: 0.7360\n",
      "Epoch 521/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6663 - accuracy: 0.8041 - val_loss: 0.7631 - val_accuracy: 0.7283\n",
      "Epoch 522/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6684 - accuracy: 0.7977 - val_loss: 0.7606 - val_accuracy: 0.7225\n",
      "Epoch 523/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6690 - accuracy: 0.8081 - val_loss: 0.7816 - val_accuracy: 0.7197\n",
      "Epoch 524/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6740 - accuracy: 0.8037 - val_loss: 0.8413 - val_accuracy: 0.6637\n",
      "Epoch 525/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6768 - accuracy: 0.7949 - val_loss: 0.7652 - val_accuracy: 0.7260\n",
      "Epoch 526/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6718 - accuracy: 0.8052 - val_loss: 0.7870 - val_accuracy: 0.7107\n",
      "Epoch 527/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6635 - accuracy: 0.7989 - val_loss: 0.7733 - val_accuracy: 0.7163\n",
      "Epoch 528/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6596 - accuracy: 0.8096 - val_loss: 0.7693 - val_accuracy: 0.7220\n",
      "Epoch 529/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6762 - accuracy: 0.7979 - val_loss: 0.7958 - val_accuracy: 0.7048\n",
      "Epoch 530/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6665 - accuracy: 0.8081 - val_loss: 0.7909 - val_accuracy: 0.7115\n",
      "Epoch 531/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6597 - accuracy: 0.7997 - val_loss: 0.7350 - val_accuracy: 0.7635\n",
      "Epoch 532/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6627 - accuracy: 0.8071 - val_loss: 0.8550 - val_accuracy: 0.6630\n",
      "Epoch 533/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6569 - accuracy: 0.8046 - val_loss: 0.7814 - val_accuracy: 0.7215\n",
      "Epoch 534/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6562 - accuracy: 0.8084 - val_loss: 0.8130 - val_accuracy: 0.6917\n",
      "Epoch 535/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6515 - accuracy: 0.8030 - val_loss: 0.7913 - val_accuracy: 0.7082\n",
      "Epoch 536/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6495 - accuracy: 0.8115 - val_loss: 0.7461 - val_accuracy: 0.7368\n",
      "Epoch 537/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6510 - accuracy: 0.8108 - val_loss: 0.8409 - val_accuracy: 0.6835\n",
      "Epoch 538/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6513 - accuracy: 0.8045 - val_loss: 0.7670 - val_accuracy: 0.7283\n",
      "Epoch 539/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6537 - accuracy: 0.8103 - val_loss: 0.7545 - val_accuracy: 0.7435\n",
      "Epoch 540/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6537 - accuracy: 0.8056 - val_loss: 0.7904 - val_accuracy: 0.7128\n",
      "Epoch 541/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6610 - accuracy: 0.8061 - val_loss: 0.7886 - val_accuracy: 0.7303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 542/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6672 - accuracy: 0.8070 - val_loss: 0.7993 - val_accuracy: 0.7100\n",
      "Epoch 543/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6545 - accuracy: 0.8073 - val_loss: 0.7961 - val_accuracy: 0.7100\n",
      "Epoch 544/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6550 - accuracy: 0.8101 - val_loss: 0.7966 - val_accuracy: 0.6995\n",
      "Epoch 545/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6509 - accuracy: 0.8090 - val_loss: 0.7885 - val_accuracy: 0.7243\n",
      "Epoch 546/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6484 - accuracy: 0.8098 - val_loss: 0.8075 - val_accuracy: 0.6998\n",
      "Epoch 547/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6488 - accuracy: 0.8126 - val_loss: 0.7822 - val_accuracy: 0.7145\n",
      "Epoch 548/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6516 - accuracy: 0.8116 - val_loss: 0.8376 - val_accuracy: 0.6867\n",
      "Epoch 549/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6506 - accuracy: 0.7993 - val_loss: 0.7525 - val_accuracy: 0.7545\n",
      "Epoch 550/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6703 - accuracy: 0.8107 - val_loss: 0.8466 - val_accuracy: 0.6842\n",
      "Epoch 551/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6645 - accuracy: 0.8024 - val_loss: 0.8450 - val_accuracy: 0.6727\n",
      "Epoch 552/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6609 - accuracy: 0.7990 - val_loss: 0.7481 - val_accuracy: 0.7458\n",
      "Epoch 553/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6623 - accuracy: 0.8146 - val_loss: 0.8778 - val_accuracy: 0.6597\n",
      "Epoch 554/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6777 - accuracy: 0.7883 - val_loss: 0.7431 - val_accuracy: 0.7508\n",
      "Epoch 555/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6790 - accuracy: 0.8032 - val_loss: 0.8248 - val_accuracy: 0.7072\n",
      "Epoch 556/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6753 - accuracy: 0.7969 - val_loss: 0.7474 - val_accuracy: 0.7545\n",
      "Epoch 557/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6681 - accuracy: 0.8049 - val_loss: 0.8200 - val_accuracy: 0.7042\n",
      "Epoch 558/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6565 - accuracy: 0.8042 - val_loss: 0.7848 - val_accuracy: 0.7327\n",
      "Epoch 559/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6556 - accuracy: 0.8142 - val_loss: 0.8690 - val_accuracy: 0.6840\n",
      "Epoch 560/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6619 - accuracy: 0.8030 - val_loss: 0.8117 - val_accuracy: 0.7025\n",
      "Epoch 561/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6597 - accuracy: 0.8052 - val_loss: 0.7821 - val_accuracy: 0.7308\n",
      "Epoch 562/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6562 - accuracy: 0.8083 - val_loss: 0.8251 - val_accuracy: 0.6950\n",
      "Epoch 563/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6446 - accuracy: 0.8141 - val_loss: 0.8272 - val_accuracy: 0.6915\n",
      "Epoch 564/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6388 - accuracy: 0.8069 - val_loss: 0.7866 - val_accuracy: 0.7265\n",
      "Epoch 565/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6365 - accuracy: 0.8186 - val_loss: 0.7855 - val_accuracy: 0.7293\n",
      "Epoch 566/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6330 - accuracy: 0.8156 - val_loss: 0.7902 - val_accuracy: 0.7155\n",
      "Epoch 567/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6340 - accuracy: 0.8143 - val_loss: 0.8000 - val_accuracy: 0.7290\n",
      "Epoch 568/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6417 - accuracy: 0.8119 - val_loss: 0.8026 - val_accuracy: 0.7182\n",
      "Epoch 569/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6402 - accuracy: 0.8090 - val_loss: 0.7840 - val_accuracy: 0.7295\n",
      "Epoch 570/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6394 - accuracy: 0.8225 - val_loss: 0.8203 - val_accuracy: 0.7080\n",
      "Epoch 571/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6425 - accuracy: 0.8033 - val_loss: 0.8081 - val_accuracy: 0.7193\n",
      "Epoch 572/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6476 - accuracy: 0.8149 - val_loss: 0.7703 - val_accuracy: 0.7473\n",
      "Epoch 573/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6424 - accuracy: 0.8114 - val_loss: 0.7925 - val_accuracy: 0.7315\n",
      "Epoch 574/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.6402 - accuracy: 0.8091 - val_loss: 0.8311 - val_accuracy: 0.6985\n",
      "Epoch 575/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6390 - accuracy: 0.8149 - val_loss: 0.8347 - val_accuracy: 0.6975\n",
      "Epoch 576/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6400 - accuracy: 0.8104 - val_loss: 0.7942 - val_accuracy: 0.7225\n",
      "Epoch 577/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6328 - accuracy: 0.8091 - val_loss: 0.8019 - val_accuracy: 0.7170\n",
      "Epoch 578/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6379 - accuracy: 0.8202 - val_loss: 0.8254 - val_accuracy: 0.7025\n",
      "Epoch 579/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6500 - accuracy: 0.8038 - val_loss: 0.7887 - val_accuracy: 0.7285\n",
      "Epoch 580/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6595 - accuracy: 0.8026 - val_loss: 0.8596 - val_accuracy: 0.6873\n",
      "Epoch 581/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6539 - accuracy: 0.8031 - val_loss: 0.7836 - val_accuracy: 0.7297\n",
      "Epoch 582/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6438 - accuracy: 0.8187 - val_loss: 0.8318 - val_accuracy: 0.7032\n",
      "Epoch 583/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6373 - accuracy: 0.8094 - val_loss: 0.8083 - val_accuracy: 0.7157\n",
      "Epoch 584/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6332 - accuracy: 0.8079 - val_loss: 0.7773 - val_accuracy: 0.7467\n",
      "Epoch 585/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6268 - accuracy: 0.8161 - val_loss: 0.8217 - val_accuracy: 0.7120\n",
      "Epoch 586/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6364 - accuracy: 0.8182 - val_loss: 0.8073 - val_accuracy: 0.7155\n",
      "Epoch 587/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6409 - accuracy: 0.8004 - val_loss: 0.7833 - val_accuracy: 0.7487\n",
      "Epoch 588/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6409 - accuracy: 0.8213 - val_loss: 0.8305 - val_accuracy: 0.6992\n",
      "Epoch 589/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6364 - accuracy: 0.8123 - val_loss: 0.7763 - val_accuracy: 0.7473\n",
      "Epoch 590/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6298 - accuracy: 0.8165 - val_loss: 0.8388 - val_accuracy: 0.6955\n",
      "Epoch 591/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6381 - accuracy: 0.8079 - val_loss: 0.7449 - val_accuracy: 0.7700\n",
      "Epoch 592/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6441 - accuracy: 0.8097 - val_loss: 0.8845 - val_accuracy: 0.6618\n",
      "Epoch 593/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6352 - accuracy: 0.8117 - val_loss: 0.7857 - val_accuracy: 0.7437\n",
      "Epoch 594/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6361 - accuracy: 0.8138 - val_loss: 0.8551 - val_accuracy: 0.6805\n",
      "Epoch 595/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6332 - accuracy: 0.8126 - val_loss: 0.7698 - val_accuracy: 0.7505\n",
      "Epoch 596/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6329 - accuracy: 0.8137 - val_loss: 0.8509 - val_accuracy: 0.6915\n",
      "Epoch 597/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6565 - accuracy: 0.8067 - val_loss: 0.8319 - val_accuracy: 0.7147\n",
      "Epoch 598/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6466 - accuracy: 0.8087 - val_loss: 0.8292 - val_accuracy: 0.7175\n",
      "Epoch 599/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6476 - accuracy: 0.8071 - val_loss: 0.7946 - val_accuracy: 0.7308\n",
      "Epoch 600/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6354 - accuracy: 0.8170 - val_loss: 0.8481 - val_accuracy: 0.6960\n",
      "Epoch 601/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6320 - accuracy: 0.8110 - val_loss: 0.8188 - val_accuracy: 0.7150\n",
      "Epoch 602/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6255 - accuracy: 0.8159 - val_loss: 0.8232 - val_accuracy: 0.7025\n",
      "Epoch 603/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6205 - accuracy: 0.8216 - val_loss: 0.8234 - val_accuracy: 0.7125\n",
      "Epoch 604/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6236 - accuracy: 0.8163 - val_loss: 0.8128 - val_accuracy: 0.7347\n",
      "Epoch 605/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6209 - accuracy: 0.8182 - val_loss: 0.8203 - val_accuracy: 0.7207\n",
      "Epoch 606/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6211 - accuracy: 0.8223 - val_loss: 0.8110 - val_accuracy: 0.7240\n",
      "Epoch 607/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6220 - accuracy: 0.8158 - val_loss: 0.8454 - val_accuracy: 0.7017\n",
      "Epoch 608/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6221 - accuracy: 0.8197 - val_loss: 0.8239 - val_accuracy: 0.7200\n",
      "Epoch 609/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6195 - accuracy: 0.8153 - val_loss: 0.7822 - val_accuracy: 0.7475\n",
      "Epoch 610/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6377 - accuracy: 0.8099 - val_loss: 0.8345 - val_accuracy: 0.7120\n",
      "Epoch 611/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6339 - accuracy: 0.8173 - val_loss: 0.8137 - val_accuracy: 0.7300\n",
      "Epoch 612/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6268 - accuracy: 0.8139 - val_loss: 0.8511 - val_accuracy: 0.6935\n",
      "Epoch 613/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6182 - accuracy: 0.8224 - val_loss: 0.8582 - val_accuracy: 0.6965\n",
      "Epoch 614/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6204 - accuracy: 0.8144 - val_loss: 0.8372 - val_accuracy: 0.7013\n",
      "Epoch 615/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6380 - accuracy: 0.8131 - val_loss: 0.7929 - val_accuracy: 0.7427\n",
      "Epoch 616/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6264 - accuracy: 0.8195 - val_loss: 0.8919 - val_accuracy: 0.6808\n",
      "Epoch 617/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6248 - accuracy: 0.8138 - val_loss: 0.8293 - val_accuracy: 0.7272\n",
      "Epoch 618/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6237 - accuracy: 0.8159 - val_loss: 0.8446 - val_accuracy: 0.7088\n",
      "Epoch 619/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6306 - accuracy: 0.8259 - val_loss: 0.8688 - val_accuracy: 0.6870\n",
      "Epoch 620/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6377 - accuracy: 0.8081 - val_loss: 0.8163 - val_accuracy: 0.7255\n",
      "Epoch 621/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6451 - accuracy: 0.8077 - val_loss: 0.8300 - val_accuracy: 0.7188\n",
      "Epoch 622/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6320 - accuracy: 0.8174 - val_loss: 0.8371 - val_accuracy: 0.7218\n",
      "Epoch 623/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6335 - accuracy: 0.8049 - val_loss: 0.7680 - val_accuracy: 0.7540\n",
      "Epoch 624/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6404 - accuracy: 0.8178 - val_loss: 0.8793 - val_accuracy: 0.7005\n",
      "Epoch 625/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6355 - accuracy: 0.8196 - val_loss: 0.8821 - val_accuracy: 0.6647\n",
      "Epoch 626/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6401 - accuracy: 0.8024 - val_loss: 0.7973 - val_accuracy: 0.7535\n",
      "Epoch 627/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6339 - accuracy: 0.8145 - val_loss: 0.8647 - val_accuracy: 0.7025\n",
      "Epoch 628/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6280 - accuracy: 0.8159 - val_loss: 0.8126 - val_accuracy: 0.7445\n",
      "Epoch 629/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6314 - accuracy: 0.8108 - val_loss: 0.8858 - val_accuracy: 0.6722\n",
      "Epoch 630/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6370 - accuracy: 0.8127 - val_loss: 0.7414 - val_accuracy: 0.7660\n",
      "Epoch 631/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.6364 - accuracy: 0.8098 - val_loss: 0.8843 - val_accuracy: 0.6952\n",
      "Epoch 632/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6549 - accuracy: 0.8073 - val_loss: 0.7950 - val_accuracy: 0.7435\n",
      "Epoch 633/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6535 - accuracy: 0.8111 - val_loss: 0.9060 - val_accuracy: 0.6752\n",
      "Epoch 634/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6411 - accuracy: 0.8041 - val_loss: 0.7661 - val_accuracy: 0.7580\n",
      "Epoch 635/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6298 - accuracy: 0.8167 - val_loss: 0.8301 - val_accuracy: 0.7100\n",
      "Epoch 636/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6203 - accuracy: 0.8176 - val_loss: 0.8295 - val_accuracy: 0.7000\n",
      "Epoch 637/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6288 - accuracy: 0.8167 - val_loss: 0.7998 - val_accuracy: 0.7315\n",
      "Epoch 638/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6182 - accuracy: 0.8212 - val_loss: 0.8308 - val_accuracy: 0.7205\n",
      "Epoch 639/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6100 - accuracy: 0.8181 - val_loss: 0.8511 - val_accuracy: 0.7030\n",
      "Epoch 640/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6087 - accuracy: 0.8209 - val_loss: 0.7813 - val_accuracy: 0.7462\n",
      "Epoch 641/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6046 - accuracy: 0.8238 - val_loss: 0.8353 - val_accuracy: 0.7130\n",
      "Epoch 642/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6090 - accuracy: 0.8241 - val_loss: 0.8345 - val_accuracy: 0.7067\n",
      "Epoch 643/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6181 - accuracy: 0.8154 - val_loss: 0.8162 - val_accuracy: 0.7188\n",
      "Epoch 644/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6217 - accuracy: 0.8150 - val_loss: 0.8104 - val_accuracy: 0.7275\n",
      "Epoch 645/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6198 - accuracy: 0.8212 - val_loss: 0.8724 - val_accuracy: 0.6973\n",
      "Epoch 646/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6253 - accuracy: 0.8086 - val_loss: 0.7904 - val_accuracy: 0.7395\n",
      "Epoch 647/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6221 - accuracy: 0.8294 - val_loss: 0.9090 - val_accuracy: 0.6760\n",
      "Epoch 648/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6262 - accuracy: 0.8043 - val_loss: 0.7918 - val_accuracy: 0.7480\n",
      "Epoch 649/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6121 - accuracy: 0.8279 - val_loss: 0.8139 - val_accuracy: 0.7272\n",
      "Epoch 650/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6060 - accuracy: 0.8146 - val_loss: 0.8137 - val_accuracy: 0.7293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 651/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6135 - accuracy: 0.8282 - val_loss: 0.8468 - val_accuracy: 0.7128\n",
      "Epoch 652/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6207 - accuracy: 0.8176 - val_loss: 0.8339 - val_accuracy: 0.7225\n",
      "Epoch 653/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6138 - accuracy: 0.8237 - val_loss: 0.8433 - val_accuracy: 0.7163\n",
      "Epoch 654/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6056 - accuracy: 0.8259 - val_loss: 0.8933 - val_accuracy: 0.6808\n",
      "Epoch 655/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6098 - accuracy: 0.8142 - val_loss: 0.8117 - val_accuracy: 0.7405\n",
      "Epoch 656/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6012 - accuracy: 0.8245 - val_loss: 0.8234 - val_accuracy: 0.7168\n",
      "Epoch 657/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6025 - accuracy: 0.8245 - val_loss: 0.8186 - val_accuracy: 0.7385\n",
      "Epoch 658/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5987 - accuracy: 0.8234 - val_loss: 0.8490 - val_accuracy: 0.7103\n",
      "Epoch 659/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6007 - accuracy: 0.8249 - val_loss: 0.8561 - val_accuracy: 0.7178\n",
      "Epoch 660/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6062 - accuracy: 0.8277 - val_loss: 0.8190 - val_accuracy: 0.7310\n",
      "Epoch 661/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6047 - accuracy: 0.8200 - val_loss: 0.8323 - val_accuracy: 0.7400\n",
      "Epoch 662/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6076 - accuracy: 0.8261 - val_loss: 0.8226 - val_accuracy: 0.7320\n",
      "Epoch 663/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6042 - accuracy: 0.8240 - val_loss: 0.8383 - val_accuracy: 0.7270\n",
      "Epoch 664/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5971 - accuracy: 0.8276 - val_loss: 0.8237 - val_accuracy: 0.7280\n",
      "Epoch 665/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6031 - accuracy: 0.8256 - val_loss: 0.8862 - val_accuracy: 0.6842\n",
      "Epoch 666/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6029 - accuracy: 0.8210 - val_loss: 0.8057 - val_accuracy: 0.7390\n",
      "Epoch 667/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.6082 - accuracy: 0.8255 - val_loss: 0.8514 - val_accuracy: 0.7113\n",
      "Epoch 668/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6062 - accuracy: 0.8222 - val_loss: 0.8300 - val_accuracy: 0.7265\n",
      "Epoch 669/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6088 - accuracy: 0.8228 - val_loss: 0.8648 - val_accuracy: 0.7082\n",
      "Epoch 670/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6075 - accuracy: 0.8200 - val_loss: 0.8238 - val_accuracy: 0.7412\n",
      "Epoch 671/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6196 - accuracy: 0.8190 - val_loss: 0.8993 - val_accuracy: 0.6780\n",
      "Epoch 672/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6195 - accuracy: 0.8093 - val_loss: 0.8688 - val_accuracy: 0.6902\n",
      "Epoch 673/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6227 - accuracy: 0.8229 - val_loss: 0.8023 - val_accuracy: 0.7425\n",
      "Epoch 674/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.6106 - accuracy: 0.8204 - val_loss: 0.8516 - val_accuracy: 0.7200\n",
      "Epoch 675/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5950 - accuracy: 0.8283 - val_loss: 0.8407 - val_accuracy: 0.7163\n",
      "Epoch 676/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6025 - accuracy: 0.8232 - val_loss: 0.8586 - val_accuracy: 0.7258\n",
      "Epoch 677/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.6145 - accuracy: 0.8188 - val_loss: 0.9075 - val_accuracy: 0.6877\n",
      "Epoch 678/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6149 - accuracy: 0.8162 - val_loss: 0.8056 - val_accuracy: 0.7390\n",
      "Epoch 679/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6059 - accuracy: 0.8209 - val_loss: 0.8489 - val_accuracy: 0.7260\n",
      "Epoch 680/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5958 - accuracy: 0.8258 - val_loss: 0.8135 - val_accuracy: 0.7448\n",
      "Epoch 681/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6081 - accuracy: 0.8234 - val_loss: 0.8346 - val_accuracy: 0.7325\n",
      "Epoch 682/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5996 - accuracy: 0.8268 - val_loss: 0.8610 - val_accuracy: 0.7175\n",
      "Epoch 683/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5991 - accuracy: 0.8272 - val_loss: 0.8441 - val_accuracy: 0.7232\n",
      "Epoch 684/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6090 - accuracy: 0.8247 - val_loss: 0.8300 - val_accuracy: 0.7285\n",
      "Epoch 685/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6083 - accuracy: 0.8203 - val_loss: 0.8347 - val_accuracy: 0.7377\n",
      "Epoch 686/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6025 - accuracy: 0.8264 - val_loss: 0.8453 - val_accuracy: 0.7215\n",
      "Epoch 687/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5966 - accuracy: 0.8288 - val_loss: 0.9017 - val_accuracy: 0.6877\n",
      "Epoch 688/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6100 - accuracy: 0.8168 - val_loss: 0.8003 - val_accuracy: 0.7473\n",
      "Epoch 689/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6007 - accuracy: 0.8171 - val_loss: 0.8549 - val_accuracy: 0.7218\n",
      "Epoch 690/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6139 - accuracy: 0.8193 - val_loss: 0.8683 - val_accuracy: 0.7042\n",
      "Epoch 691/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5980 - accuracy: 0.8185 - val_loss: 0.8344 - val_accuracy: 0.7415\n",
      "Epoch 692/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5982 - accuracy: 0.8297 - val_loss: 0.8878 - val_accuracy: 0.7003\n",
      "Epoch 693/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6021 - accuracy: 0.8206 - val_loss: 0.8214 - val_accuracy: 0.7412\n",
      "Epoch 694/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5910 - accuracy: 0.8278 - val_loss: 0.8727 - val_accuracy: 0.7032\n",
      "Epoch 695/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5819 - accuracy: 0.8279 - val_loss: 0.8539 - val_accuracy: 0.7265\n",
      "Epoch 696/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5915 - accuracy: 0.8283 - val_loss: 0.8665 - val_accuracy: 0.7163\n",
      "Epoch 697/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5961 - accuracy: 0.8208 - val_loss: 0.8203 - val_accuracy: 0.7425\n",
      "Epoch 698/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5959 - accuracy: 0.8284 - val_loss: 0.8652 - val_accuracy: 0.7042\n",
      "Epoch 699/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5899 - accuracy: 0.8295 - val_loss: 0.8399 - val_accuracy: 0.7410\n",
      "Epoch 700/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5887 - accuracy: 0.8257 - val_loss: 0.8522 - val_accuracy: 0.7250\n",
      "Epoch 701/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5897 - accuracy: 0.8269 - val_loss: 0.8374 - val_accuracy: 0.7440\n",
      "Epoch 702/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5930 - accuracy: 0.8247 - val_loss: 0.8490 - val_accuracy: 0.7230\n",
      "Epoch 703/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5872 - accuracy: 0.8272 - val_loss: 0.8513 - val_accuracy: 0.7265\n",
      "Epoch 704/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5854 - accuracy: 0.8281 - val_loss: 0.8458 - val_accuracy: 0.7480\n",
      "Epoch 705/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5939 - accuracy: 0.8316 - val_loss: 0.8894 - val_accuracy: 0.6948\n",
      "Epoch 706/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5935 - accuracy: 0.8227 - val_loss: 0.8129 - val_accuracy: 0.7577\n",
      "Epoch 707/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5962 - accuracy: 0.8181 - val_loss: 0.8295 - val_accuracy: 0.7552\n",
      "Epoch 708/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5922 - accuracy: 0.8287 - val_loss: 0.8298 - val_accuracy: 0.7330\n",
      "Epoch 709/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5815 - accuracy: 0.8333 - val_loss: 0.8809 - val_accuracy: 0.7190\n",
      "Epoch 710/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5756 - accuracy: 0.8304 - val_loss: 0.8219 - val_accuracy: 0.7370\n",
      "Epoch 711/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5832 - accuracy: 0.8289 - val_loss: 0.8653 - val_accuracy: 0.7247\n",
      "Epoch 712/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5830 - accuracy: 0.8300 - val_loss: 0.8851 - val_accuracy: 0.7128\n",
      "Epoch 713/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6001 - accuracy: 0.8271 - val_loss: 0.9353 - val_accuracy: 0.6768\n",
      "Epoch 714/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5904 - accuracy: 0.8264 - val_loss: 0.8572 - val_accuracy: 0.7305\n",
      "Epoch 715/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5817 - accuracy: 0.8278 - val_loss: 0.8589 - val_accuracy: 0.7260\n",
      "Epoch 716/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5676 - accuracy: 0.8371 - val_loss: 0.8897 - val_accuracy: 0.6992\n",
      "Epoch 717/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5766 - accuracy: 0.8283 - val_loss: 0.8325 - val_accuracy: 0.7500\n",
      "Epoch 718/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5730 - accuracy: 0.8349 - val_loss: 0.8796 - val_accuracy: 0.7193\n",
      "Epoch 719/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.5850 - accuracy: 0.8251 - val_loss: 0.8393 - val_accuracy: 0.7320\n",
      "Epoch 720/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5844 - accuracy: 0.8322 - val_loss: 0.8759 - val_accuracy: 0.7197\n",
      "Epoch 721/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5941 - accuracy: 0.8289 - val_loss: 0.9223 - val_accuracy: 0.6790\n",
      "Epoch 722/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5933 - accuracy: 0.8188 - val_loss: 0.8292 - val_accuracy: 0.7525\n",
      "Epoch 723/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5952 - accuracy: 0.8233 - val_loss: 0.8821 - val_accuracy: 0.7122\n",
      "Epoch 724/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6120 - accuracy: 0.8266 - val_loss: 0.9051 - val_accuracy: 0.6992\n",
      "Epoch 725/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5937 - accuracy: 0.8229 - val_loss: 0.8587 - val_accuracy: 0.7300\n",
      "Epoch 726/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5825 - accuracy: 0.8294 - val_loss: 0.9063 - val_accuracy: 0.7040\n",
      "Epoch 727/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5897 - accuracy: 0.8292 - val_loss: 0.8391 - val_accuracy: 0.7345\n",
      "Epoch 728/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5834 - accuracy: 0.8287 - val_loss: 0.8974 - val_accuracy: 0.6955\n",
      "Epoch 729/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5842 - accuracy: 0.8309 - val_loss: 0.8695 - val_accuracy: 0.7260\n",
      "Epoch 730/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5810 - accuracy: 0.8294 - val_loss: 0.8534 - val_accuracy: 0.7368\n",
      "Epoch 731/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5778 - accuracy: 0.8280 - val_loss: 0.8422 - val_accuracy: 0.7510\n",
      "Epoch 732/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5778 - accuracy: 0.8360 - val_loss: 0.8969 - val_accuracy: 0.7040\n",
      "Epoch 733/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5799 - accuracy: 0.8272 - val_loss: 0.8482 - val_accuracy: 0.7418\n",
      "Epoch 734/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5762 - accuracy: 0.8349 - val_loss: 0.8375 - val_accuracy: 0.7548\n",
      "Epoch 735/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5807 - accuracy: 0.8277 - val_loss: 0.9000 - val_accuracy: 0.7143\n",
      "Epoch 736/1000\n",
      "16000/16000 [==============================] - ETA: 0s - loss: 0.5183 - accuracy: 0.82 - 0s 3us/step - loss: 0.5982 - accuracy: 0.8304 - val_loss: 0.9579 - val_accuracy: 0.6700\n",
      "Epoch 737/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5919 - accuracy: 0.8281 - val_loss: 0.8773 - val_accuracy: 0.7237\n",
      "Epoch 738/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6072 - accuracy: 0.8159 - val_loss: 0.8223 - val_accuracy: 0.7650\n",
      "Epoch 739/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5918 - accuracy: 0.8314 - val_loss: 0.9060 - val_accuracy: 0.7057\n",
      "Epoch 740/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5759 - accuracy: 0.8304 - val_loss: 0.8552 - val_accuracy: 0.7515\n",
      "Epoch 741/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5922 - accuracy: 0.8281 - val_loss: 0.8493 - val_accuracy: 0.7262\n",
      "Epoch 742/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5767 - accuracy: 0.8313 - val_loss: 0.8873 - val_accuracy: 0.7218\n",
      "Epoch 743/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5896 - accuracy: 0.8332 - val_loss: 0.9591 - val_accuracy: 0.6675\n",
      "Epoch 744/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6021 - accuracy: 0.8081 - val_loss: 0.8521 - val_accuracy: 0.7552\n",
      "Epoch 745/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6097 - accuracy: 0.8253 - val_loss: 0.9336 - val_accuracy: 0.6975\n",
      "Epoch 746/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5983 - accuracy: 0.8186 - val_loss: 0.8432 - val_accuracy: 0.7600\n",
      "Epoch 747/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5894 - accuracy: 0.8311 - val_loss: 0.8782 - val_accuracy: 0.7245\n",
      "Epoch 748/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5846 - accuracy: 0.8224 - val_loss: 0.8414 - val_accuracy: 0.7470\n",
      "Epoch 749/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5766 - accuracy: 0.8344 - val_loss: 0.9314 - val_accuracy: 0.7007\n",
      "Epoch 750/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5787 - accuracy: 0.8286 - val_loss: 0.8752 - val_accuracy: 0.7278\n",
      "Epoch 751/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5855 - accuracy: 0.8256 - val_loss: 0.8397 - val_accuracy: 0.7538\n",
      "Epoch 752/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5914 - accuracy: 0.8341 - val_loss: 0.9149 - val_accuracy: 0.7110\n",
      "Epoch 753/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5760 - accuracy: 0.8229 - val_loss: 0.8559 - val_accuracy: 0.7508\n",
      "Epoch 754/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5728 - accuracy: 0.8370 - val_loss: 0.8836 - val_accuracy: 0.7370\n",
      "Epoch 755/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5718 - accuracy: 0.8355 - val_loss: 0.8829 - val_accuracy: 0.7330\n",
      "Epoch 756/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5706 - accuracy: 0.8342 - val_loss: 0.8818 - val_accuracy: 0.7290\n",
      "Epoch 757/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5692 - accuracy: 0.8388 - val_loss: 0.9289 - val_accuracy: 0.6982\n",
      "Epoch 758/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5805 - accuracy: 0.8267 - val_loss: 0.8898 - val_accuracy: 0.7250\n",
      "Epoch 759/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5805 - accuracy: 0.8299 - val_loss: 0.8823 - val_accuracy: 0.7343\n",
      "Epoch 760/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5783 - accuracy: 0.8305 - val_loss: 0.8496 - val_accuracy: 0.7542\n",
      "Epoch 761/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5833 - accuracy: 0.8250 - val_loss: 0.8613 - val_accuracy: 0.7517\n",
      "Epoch 762/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5738 - accuracy: 0.8362 - val_loss: 0.9200 - val_accuracy: 0.7132\n",
      "Epoch 763/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5681 - accuracy: 0.8338 - val_loss: 0.8574 - val_accuracy: 0.7460\n",
      "Epoch 764/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5751 - accuracy: 0.8322 - val_loss: 0.9247 - val_accuracy: 0.6967\n",
      "Epoch 765/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5729 - accuracy: 0.8392 - val_loss: 0.8972 - val_accuracy: 0.7172\n",
      "Epoch 766/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5636 - accuracy: 0.8333 - val_loss: 0.8755 - val_accuracy: 0.7358\n",
      "Epoch 767/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5704 - accuracy: 0.8349 - val_loss: 0.8550 - val_accuracy: 0.7490\n",
      "Epoch 768/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5693 - accuracy: 0.8320 - val_loss: 0.8951 - val_accuracy: 0.7380\n",
      "Epoch 769/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5663 - accuracy: 0.8356 - val_loss: 0.9068 - val_accuracy: 0.7305\n",
      "Epoch 770/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5661 - accuracy: 0.8359 - val_loss: 0.9015 - val_accuracy: 0.7130\n",
      "Epoch 771/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5570 - accuracy: 0.8403 - val_loss: 0.8782 - val_accuracy: 0.7365\n",
      "Epoch 772/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5544 - accuracy: 0.8371 - val_loss: 0.8646 - val_accuracy: 0.7555\n",
      "Epoch 773/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5649 - accuracy: 0.8363 - val_loss: 0.8699 - val_accuracy: 0.7360\n",
      "Epoch 774/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5611 - accuracy: 0.8404 - val_loss: 0.9381 - val_accuracy: 0.6990\n",
      "Epoch 775/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5841 - accuracy: 0.8339 - val_loss: 0.9170 - val_accuracy: 0.7050\n",
      "Epoch 776/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5783 - accuracy: 0.8242 - val_loss: 0.8814 - val_accuracy: 0.7372\n",
      "Epoch 777/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5860 - accuracy: 0.8181 - val_loss: 0.8830 - val_accuracy: 0.7290\n",
      "Epoch 778/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5805 - accuracy: 0.8413 - val_loss: 0.9435 - val_accuracy: 0.7030\n",
      "Epoch 779/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5731 - accuracy: 0.8291 - val_loss: 0.9235 - val_accuracy: 0.7095\n",
      "Epoch 780/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5791 - accuracy: 0.8286 - val_loss: 0.8841 - val_accuracy: 0.7465\n",
      "Epoch 781/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5675 - accuracy: 0.8288 - val_loss: 0.8499 - val_accuracy: 0.7595\n",
      "Epoch 782/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5661 - accuracy: 0.8375 - val_loss: 0.9367 - val_accuracy: 0.7122\n",
      "Epoch 783/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5803 - accuracy: 0.8390 - val_loss: 0.9904 - val_accuracy: 0.6640\n",
      "Epoch 784/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5913 - accuracy: 0.8220 - val_loss: 0.9488 - val_accuracy: 0.6992\n",
      "Epoch 785/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5776 - accuracy: 0.8278 - val_loss: 0.9235 - val_accuracy: 0.7205\n",
      "Epoch 786/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5737 - accuracy: 0.8384 - val_loss: 0.9396 - val_accuracy: 0.6930\n",
      "Epoch 787/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5678 - accuracy: 0.8279 - val_loss: 0.8816 - val_accuracy: 0.7383\n",
      "Epoch 788/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5645 - accuracy: 0.8395 - val_loss: 0.9442 - val_accuracy: 0.6940\n",
      "Epoch 789/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5701 - accuracy: 0.8313 - val_loss: 0.8928 - val_accuracy: 0.7337\n",
      "Epoch 790/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5631 - accuracy: 0.8370 - val_loss: 0.8966 - val_accuracy: 0.7235\n",
      "Epoch 791/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5590 - accuracy: 0.8428 - val_loss: 0.9226 - val_accuracy: 0.7225\n",
      "Epoch 792/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5560 - accuracy: 0.8353 - val_loss: 0.8882 - val_accuracy: 0.7203\n",
      "Epoch 793/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5590 - accuracy: 0.8402 - val_loss: 0.9132 - val_accuracy: 0.7222\n",
      "Epoch 794/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5699 - accuracy: 0.8307 - val_loss: 0.8583 - val_accuracy: 0.7492\n",
      "Epoch 795/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5672 - accuracy: 0.8426 - val_loss: 0.9285 - val_accuracy: 0.7147\n",
      "Epoch 796/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5688 - accuracy: 0.8309 - val_loss: 0.8976 - val_accuracy: 0.7485\n",
      "Epoch 797/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6208 - accuracy: 0.8299 - val_loss: 0.9217 - val_accuracy: 0.7172\n",
      "Epoch 798/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6253 - accuracy: 0.8207 - val_loss: 0.9382 - val_accuracy: 0.7103\n",
      "Epoch 799/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6042 - accuracy: 0.8254 - val_loss: 0.9046 - val_accuracy: 0.7212\n",
      "Epoch 800/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5940 - accuracy: 0.8223 - val_loss: 0.8938 - val_accuracy: 0.7243\n",
      "Epoch 801/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5872 - accuracy: 0.8356 - val_loss: 0.9273 - val_accuracy: 0.7007\n",
      "Epoch 802/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5902 - accuracy: 0.8223 - val_loss: 0.8504 - val_accuracy: 0.7525\n",
      "Epoch 803/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5827 - accuracy: 0.8393 - val_loss: 0.9766 - val_accuracy: 0.6722\n",
      "Epoch 804/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.5786 - accuracy: 0.8205 - val_loss: 0.8990 - val_accuracy: 0.7470\n",
      "Epoch 805/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.5609 - accuracy: 0.8408 - val_loss: 0.9179 - val_accuracy: 0.7143\n",
      "Epoch 806/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5569 - accuracy: 0.8418 - val_loss: 0.9622 - val_accuracy: 0.6935\n",
      "Epoch 807/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5628 - accuracy: 0.8266 - val_loss: 0.8692 - val_accuracy: 0.7440\n",
      "Epoch 808/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5555 - accuracy: 0.8439 - val_loss: 0.9183 - val_accuracy: 0.7125\n",
      "Epoch 809/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5414 - accuracy: 0.8453 - val_loss: 0.9079 - val_accuracy: 0.7303\n",
      "Epoch 810/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5578 - accuracy: 0.8416 - val_loss: 0.9028 - val_accuracy: 0.7262\n",
      "Epoch 811/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5501 - accuracy: 0.8406 - val_loss: 0.9020 - val_accuracy: 0.7275\n",
      "Epoch 812/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5450 - accuracy: 0.8406 - val_loss: 0.8985 - val_accuracy: 0.7377\n",
      "Epoch 813/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5478 - accuracy: 0.8420 - val_loss: 0.9340 - val_accuracy: 0.7122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 814/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5548 - accuracy: 0.8324 - val_loss: 0.8837 - val_accuracy: 0.7558\n",
      "Epoch 815/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5797 - accuracy: 0.8323 - val_loss: 0.9521 - val_accuracy: 0.7110\n",
      "Epoch 816/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5890 - accuracy: 0.8284 - val_loss: 0.9006 - val_accuracy: 0.7310\n",
      "Epoch 817/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5691 - accuracy: 0.8354 - val_loss: 0.9419 - val_accuracy: 0.7017\n",
      "Epoch 818/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5597 - accuracy: 0.8367 - val_loss: 0.9112 - val_accuracy: 0.7308\n",
      "Epoch 819/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5510 - accuracy: 0.8413 - val_loss: 0.9421 - val_accuracy: 0.7090\n",
      "Epoch 820/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5495 - accuracy: 0.8368 - val_loss: 0.8970 - val_accuracy: 0.7325\n",
      "Epoch 821/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.5466 - accuracy: 0.8495 - val_loss: 0.9653 - val_accuracy: 0.7030\n",
      "Epoch 822/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5444 - accuracy: 0.8309 - val_loss: 0.8835 - val_accuracy: 0.7533\n",
      "Epoch 823/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5449 - accuracy: 0.8491 - val_loss: 0.9346 - val_accuracy: 0.7170\n",
      "Epoch 824/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5443 - accuracy: 0.8410 - val_loss: 0.8995 - val_accuracy: 0.7393\n",
      "Epoch 825/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5464 - accuracy: 0.8453 - val_loss: 0.9244 - val_accuracy: 0.7290\n",
      "Epoch 826/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5465 - accuracy: 0.8432 - val_loss: 0.9086 - val_accuracy: 0.7305\n",
      "Epoch 827/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5451 - accuracy: 0.8400 - val_loss: 0.8870 - val_accuracy: 0.7502\n",
      "Epoch 828/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5431 - accuracy: 0.8405 - val_loss: 0.9124 - val_accuracy: 0.7470\n",
      "Epoch 829/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5472 - accuracy: 0.8476 - val_loss: 0.9089 - val_accuracy: 0.7285\n",
      "Epoch 830/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5527 - accuracy: 0.8367 - val_loss: 0.8842 - val_accuracy: 0.7548\n",
      "Epoch 831/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5681 - accuracy: 0.8326 - val_loss: 0.9733 - val_accuracy: 0.7103\n",
      "Epoch 832/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6011 - accuracy: 0.8316 - val_loss: 0.9555 - val_accuracy: 0.6940\n",
      "Epoch 833/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5933 - accuracy: 0.8198 - val_loss: 0.8949 - val_accuracy: 0.7555\n",
      "Epoch 834/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6018 - accuracy: 0.8227 - val_loss: 0.9700 - val_accuracy: 0.6837\n",
      "Epoch 835/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5701 - accuracy: 0.8356 - val_loss: 0.9035 - val_accuracy: 0.7427\n",
      "Epoch 836/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5455 - accuracy: 0.8403 - val_loss: 0.9227 - val_accuracy: 0.7337\n",
      "Epoch 837/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5470 - accuracy: 0.8462 - val_loss: 0.9271 - val_accuracy: 0.7345\n",
      "Epoch 838/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5487 - accuracy: 0.8378 - val_loss: 0.9270 - val_accuracy: 0.7347\n",
      "Epoch 839/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5501 - accuracy: 0.8436 - val_loss: 0.9703 - val_accuracy: 0.7003\n",
      "Epoch 840/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5611 - accuracy: 0.8386 - val_loss: 0.9447 - val_accuracy: 0.7030\n",
      "Epoch 841/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5662 - accuracy: 0.8332 - val_loss: 0.9143 - val_accuracy: 0.7483\n",
      "Epoch 842/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5647 - accuracy: 0.8399 - val_loss: 0.9448 - val_accuracy: 0.7115\n",
      "Epoch 843/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5688 - accuracy: 0.8356 - val_loss: 0.9867 - val_accuracy: 0.7020\n",
      "Epoch 844/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5762 - accuracy: 0.8323 - val_loss: 0.9405 - val_accuracy: 0.7180\n",
      "Epoch 845/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5626 - accuracy: 0.8399 - val_loss: 0.9730 - val_accuracy: 0.6982\n",
      "Epoch 846/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.5594 - accuracy: 0.8304 - val_loss: 0.9106 - val_accuracy: 0.7368\n",
      "Epoch 847/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5516 - accuracy: 0.8416 - val_loss: 0.9570 - val_accuracy: 0.7097\n",
      "Epoch 848/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.5602 - accuracy: 0.8370 - val_loss: 0.9210 - val_accuracy: 0.7260\n",
      "Epoch 849/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5480 - accuracy: 0.8367 - val_loss: 0.9152 - val_accuracy: 0.7310\n",
      "Epoch 850/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5421 - accuracy: 0.8489 - val_loss: 0.9846 - val_accuracy: 0.6917\n",
      "Epoch 851/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5626 - accuracy: 0.8353 - val_loss: 0.9464 - val_accuracy: 0.7305\n",
      "Epoch 852/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5658 - accuracy: 0.8300 - val_loss: 0.9781 - val_accuracy: 0.7017\n",
      "Epoch 853/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5599 - accuracy: 0.8431 - val_loss: 0.9017 - val_accuracy: 0.7473\n",
      "Epoch 854/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.5527 - accuracy: 0.8378 - val_loss: 0.9468 - val_accuracy: 0.7178\n",
      "Epoch 855/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5410 - accuracy: 0.8434 - val_loss: 0.9373 - val_accuracy: 0.7285\n",
      "Epoch 856/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5509 - accuracy: 0.8386 - val_loss: 0.8859 - val_accuracy: 0.7665\n",
      "Epoch 857/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5512 - accuracy: 0.8440 - val_loss: 0.9718 - val_accuracy: 0.7080\n",
      "Epoch 858/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5533 - accuracy: 0.8371 - val_loss: 0.8865 - val_accuracy: 0.7590\n",
      "Epoch 859/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5475 - accuracy: 0.8497 - val_loss: 0.9990 - val_accuracy: 0.6862\n",
      "Epoch 860/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.5533 - accuracy: 0.8342 - val_loss: 0.8963 - val_accuracy: 0.7550\n",
      "Epoch 861/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5458 - accuracy: 0.8479 - val_loss: 0.9574 - val_accuracy: 0.7163\n",
      "Epoch 862/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5431 - accuracy: 0.8397 - val_loss: 0.9090 - val_accuracy: 0.7365\n",
      "Epoch 863/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5441 - accuracy: 0.8436 - val_loss: 0.9269 - val_accuracy: 0.7415\n",
      "Epoch 864/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5450 - accuracy: 0.8421 - val_loss: 0.9697 - val_accuracy: 0.7305\n",
      "Epoch 865/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5529 - accuracy: 0.8405 - val_loss: 0.9691 - val_accuracy: 0.7013\n",
      "Epoch 866/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5575 - accuracy: 0.8371 - val_loss: 0.9173 - val_accuracy: 0.7530\n",
      "Epoch 867/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5672 - accuracy: 0.8341 - val_loss: 0.9117 - val_accuracy: 0.7515\n",
      "Epoch 868/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5722 - accuracy: 0.8399 - val_loss: 0.9925 - val_accuracy: 0.6910\n",
      "Epoch 869/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5722 - accuracy: 0.8302 - val_loss: 0.9451 - val_accuracy: 0.7563\n",
      "Epoch 870/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5977 - accuracy: 0.8369 - val_loss: 1.0312 - val_accuracy: 0.6795\n",
      "Epoch 871/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6048 - accuracy: 0.8271 - val_loss: 0.9470 - val_accuracy: 0.7498\n",
      "Epoch 872/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5910 - accuracy: 0.8296 - val_loss: 0.9773 - val_accuracy: 0.7097\n",
      "Epoch 873/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5818 - accuracy: 0.8299 - val_loss: 0.9309 - val_accuracy: 0.7513\n",
      "Epoch 874/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.5586 - accuracy: 0.8406 - val_loss: 0.9091 - val_accuracy: 0.7315\n",
      "Epoch 875/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5518 - accuracy: 0.8406 - val_loss: 0.9127 - val_accuracy: 0.7565\n",
      "Epoch 876/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5577 - accuracy: 0.8339 - val_loss: 0.9217 - val_accuracy: 0.7433\n",
      "Epoch 877/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5536 - accuracy: 0.8505 - val_loss: 1.0066 - val_accuracy: 0.6865\n",
      "Epoch 878/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5493 - accuracy: 0.8344 - val_loss: 0.9222 - val_accuracy: 0.7508\n",
      "Epoch 879/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5387 - accuracy: 0.8459 - val_loss: 0.9344 - val_accuracy: 0.7375\n",
      "Epoch 880/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5355 - accuracy: 0.8508 - val_loss: 1.0184 - val_accuracy: 0.6877\n",
      "Epoch 881/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5353 - accuracy: 0.8402 - val_loss: 0.9520 - val_accuracy: 0.7303\n",
      "Epoch 882/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5322 - accuracy: 0.8445 - val_loss: 0.9093 - val_accuracy: 0.7623\n",
      "Epoch 883/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5392 - accuracy: 0.8434 - val_loss: 0.9435 - val_accuracy: 0.7410\n",
      "Epoch 884/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5492 - accuracy: 0.8469 - val_loss: 0.9871 - val_accuracy: 0.7168\n",
      "Epoch 885/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5436 - accuracy: 0.8375 - val_loss: 0.9038 - val_accuracy: 0.7720\n",
      "Epoch 886/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5415 - accuracy: 0.8529 - val_loss: 0.9370 - val_accuracy: 0.7358\n",
      "Epoch 887/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5366 - accuracy: 0.8381 - val_loss: 0.9356 - val_accuracy: 0.7415\n",
      "Epoch 888/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5535 - accuracy: 0.8435 - val_loss: 0.9983 - val_accuracy: 0.7003\n",
      "Epoch 889/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5554 - accuracy: 0.8387 - val_loss: 0.9590 - val_accuracy: 0.7103\n",
      "Epoch 890/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5531 - accuracy: 0.8425 - val_loss: 0.9839 - val_accuracy: 0.7163\n",
      "Epoch 891/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5468 - accuracy: 0.8338 - val_loss: 0.8989 - val_accuracy: 0.7688\n",
      "Epoch 892/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5503 - accuracy: 0.8450 - val_loss: 0.9652 - val_accuracy: 0.7205\n",
      "Epoch 893/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5391 - accuracy: 0.8421 - val_loss: 0.9278 - val_accuracy: 0.7542\n",
      "Epoch 894/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5455 - accuracy: 0.8374 - val_loss: 0.9335 - val_accuracy: 0.7513\n",
      "Epoch 895/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5394 - accuracy: 0.8513 - val_loss: 0.9704 - val_accuracy: 0.7268\n",
      "Epoch 896/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5394 - accuracy: 0.8381 - val_loss: 0.9360 - val_accuracy: 0.7585\n",
      "Epoch 897/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5478 - accuracy: 0.8485 - val_loss: 1.0054 - val_accuracy: 0.7020\n",
      "Epoch 898/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5369 - accuracy: 0.8444 - val_loss: 0.9108 - val_accuracy: 0.7517\n",
      "Epoch 899/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5380 - accuracy: 0.8461 - val_loss: 0.9942 - val_accuracy: 0.7290\n",
      "Epoch 900/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5430 - accuracy: 0.8418 - val_loss: 0.9270 - val_accuracy: 0.7420\n",
      "Epoch 901/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5516 - accuracy: 0.8429 - val_loss: 0.9614 - val_accuracy: 0.7230\n",
      "Epoch 902/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5458 - accuracy: 0.8454 - val_loss: 0.9792 - val_accuracy: 0.7157\n",
      "Epoch 903/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5448 - accuracy: 0.8359 - val_loss: 0.9571 - val_accuracy: 0.7383\n",
      "Epoch 904/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5336 - accuracy: 0.8523 - val_loss: 0.9862 - val_accuracy: 0.7095\n",
      "Epoch 905/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5402 - accuracy: 0.8391 - val_loss: 0.9180 - val_accuracy: 0.7515\n",
      "Epoch 906/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5449 - accuracy: 0.8478 - val_loss: 1.0594 - val_accuracy: 0.6862\n",
      "Epoch 907/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5443 - accuracy: 0.8399 - val_loss: 0.9482 - val_accuracy: 0.7395\n",
      "Epoch 908/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5309 - accuracy: 0.8512 - val_loss: 1.0207 - val_accuracy: 0.6998\n",
      "Epoch 909/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5411 - accuracy: 0.8370 - val_loss: 0.9617 - val_accuracy: 0.7220\n",
      "Epoch 910/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5396 - accuracy: 0.8446 - val_loss: 0.9556 - val_accuracy: 0.7380\n",
      "Epoch 911/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5311 - accuracy: 0.8468 - val_loss: 1.0037 - val_accuracy: 0.7045\n",
      "Epoch 912/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5277 - accuracy: 0.8470 - val_loss: 0.9733 - val_accuracy: 0.7215\n",
      "Epoch 913/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5355 - accuracy: 0.8502 - val_loss: 0.9834 - val_accuracy: 0.7185\n",
      "Epoch 914/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5283 - accuracy: 0.8484 - val_loss: 0.9820 - val_accuracy: 0.7117\n",
      "Epoch 915/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5305 - accuracy: 0.8417 - val_loss: 0.9563 - val_accuracy: 0.7513\n",
      "Epoch 916/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5360 - accuracy: 0.8478 - val_loss: 0.9754 - val_accuracy: 0.7390\n",
      "Epoch 917/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5304 - accuracy: 0.8469 - val_loss: 0.9886 - val_accuracy: 0.7320\n",
      "Epoch 918/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5320 - accuracy: 0.8512 - val_loss: 0.9972 - val_accuracy: 0.7110\n",
      "Epoch 919/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5431 - accuracy: 0.8307 - val_loss: 0.9008 - val_accuracy: 0.7600\n",
      "Epoch 920/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5405 - accuracy: 0.8494 - val_loss: 1.0121 - val_accuracy: 0.7107\n",
      "Epoch 921/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5280 - accuracy: 0.8449 - val_loss: 0.9498 - val_accuracy: 0.7498\n",
      "Epoch 922/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5271 - accuracy: 0.8488 - val_loss: 0.9436 - val_accuracy: 0.7602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 923/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5281 - accuracy: 0.8439 - val_loss: 0.9846 - val_accuracy: 0.7245\n",
      "Epoch 924/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5233 - accuracy: 0.8524 - val_loss: 0.9354 - val_accuracy: 0.7492\n",
      "Epoch 925/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5263 - accuracy: 0.8534 - val_loss: 1.0384 - val_accuracy: 0.7090\n",
      "Epoch 926/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5333 - accuracy: 0.8427 - val_loss: 0.9618 - val_accuracy: 0.7240\n",
      "Epoch 927/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5297 - accuracy: 0.8485 - val_loss: 1.0160 - val_accuracy: 0.7155\n",
      "Epoch 928/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5280 - accuracy: 0.8418 - val_loss: 0.9419 - val_accuracy: 0.7473\n",
      "Epoch 929/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5249 - accuracy: 0.8554 - val_loss: 0.9793 - val_accuracy: 0.7250\n",
      "Epoch 930/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5189 - accuracy: 0.8516 - val_loss: 0.9901 - val_accuracy: 0.7182\n",
      "Epoch 931/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5188 - accuracy: 0.8472 - val_loss: 0.9465 - val_accuracy: 0.7592\n",
      "Epoch 932/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.5238 - accuracy: 0.8509 - val_loss: 1.0082 - val_accuracy: 0.6992\n",
      "Epoch 933/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5260 - accuracy: 0.8471 - val_loss: 0.9815 - val_accuracy: 0.7350\n",
      "Epoch 934/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5239 - accuracy: 0.8483 - val_loss: 0.9444 - val_accuracy: 0.7582\n",
      "Epoch 935/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5229 - accuracy: 0.8516 - val_loss: 1.0064 - val_accuracy: 0.7260\n",
      "Epoch 936/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5238 - accuracy: 0.8529 - val_loss: 0.9838 - val_accuracy: 0.7350\n",
      "Epoch 937/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5207 - accuracy: 0.8497 - val_loss: 0.9597 - val_accuracy: 0.7527\n",
      "Epoch 938/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5195 - accuracy: 0.8490 - val_loss: 0.9705 - val_accuracy: 0.7475\n",
      "Epoch 939/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.5308 - accuracy: 0.8526 - val_loss: 1.0322 - val_accuracy: 0.6883\n",
      "Epoch 940/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5426 - accuracy: 0.8382 - val_loss: 0.9807 - val_accuracy: 0.7297\n",
      "Epoch 941/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.5218 - accuracy: 0.8482 - val_loss: 0.9355 - val_accuracy: 0.7745\n",
      "Epoch 942/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5515 - accuracy: 0.8368 - val_loss: 1.0143 - val_accuracy: 0.7090\n",
      "Epoch 943/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5548 - accuracy: 0.8491 - val_loss: 1.0521 - val_accuracy: 0.6950\n",
      "Epoch 944/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5508 - accuracy: 0.8351 - val_loss: 0.9430 - val_accuracy: 0.7592\n",
      "Epoch 945/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5438 - accuracy: 0.8476 - val_loss: 1.0664 - val_accuracy: 0.6675\n",
      "Epoch 946/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5556 - accuracy: 0.8364 - val_loss: 0.9769 - val_accuracy: 0.7390\n",
      "Epoch 947/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5618 - accuracy: 0.8422 - val_loss: 1.0013 - val_accuracy: 0.7060\n",
      "Epoch 948/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5764 - accuracy: 0.8279 - val_loss: 0.9834 - val_accuracy: 0.7545\n",
      "Epoch 949/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5571 - accuracy: 0.8362 - val_loss: 0.9856 - val_accuracy: 0.7283\n",
      "Epoch 950/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5538 - accuracy: 0.8478 - val_loss: 1.0195 - val_accuracy: 0.7145\n",
      "Epoch 951/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5476 - accuracy: 0.8331 - val_loss: 0.9523 - val_accuracy: 0.7682\n",
      "Epoch 952/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5456 - accuracy: 0.8502 - val_loss: 1.0334 - val_accuracy: 0.6908\n",
      "Epoch 953/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5321 - accuracy: 0.8467 - val_loss: 0.9614 - val_accuracy: 0.7670\n",
      "Epoch 954/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5221 - accuracy: 0.8471 - val_loss: 0.9767 - val_accuracy: 0.7425\n",
      "Epoch 955/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5235 - accuracy: 0.8562 - val_loss: 0.9866 - val_accuracy: 0.7325\n",
      "Epoch 956/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5185 - accuracy: 0.8492 - val_loss: 0.9406 - val_accuracy: 0.7700\n",
      "Epoch 957/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5214 - accuracy: 0.8537 - val_loss: 0.9849 - val_accuracy: 0.7400\n",
      "Epoch 958/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5271 - accuracy: 0.8436 - val_loss: 0.9517 - val_accuracy: 0.7692\n",
      "Epoch 959/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5318 - accuracy: 0.8568 - val_loss: 1.0829 - val_accuracy: 0.6815\n",
      "Epoch 960/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5414 - accuracy: 0.8383 - val_loss: 0.9677 - val_accuracy: 0.7530\n",
      "Epoch 961/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5193 - accuracy: 0.8503 - val_loss: 1.0284 - val_accuracy: 0.7105\n",
      "Epoch 962/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5196 - accuracy: 0.8529 - val_loss: 1.0426 - val_accuracy: 0.6925\n",
      "Epoch 963/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5181 - accuracy: 0.8481 - val_loss: 0.9771 - val_accuracy: 0.7513\n",
      "Epoch 964/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5109 - accuracy: 0.8541 - val_loss: 1.0286 - val_accuracy: 0.7117\n",
      "Epoch 965/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5151 - accuracy: 0.8541 - val_loss: 0.9999 - val_accuracy: 0.7305\n",
      "Epoch 966/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5279 - accuracy: 0.8399 - val_loss: 0.9554 - val_accuracy: 0.7492\n",
      "Epoch 967/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5277 - accuracy: 0.8559 - val_loss: 1.0546 - val_accuracy: 0.7003\n",
      "Epoch 968/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5182 - accuracy: 0.8472 - val_loss: 0.9527 - val_accuracy: 0.7542\n",
      "Epoch 969/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5173 - accuracy: 0.8476 - val_loss: 0.9821 - val_accuracy: 0.7440\n",
      "Epoch 970/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5054 - accuracy: 0.8602 - val_loss: 1.0075 - val_accuracy: 0.7360\n",
      "Epoch 971/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5004 - accuracy: 0.8541 - val_loss: 0.9797 - val_accuracy: 0.7473\n",
      "Epoch 972/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5021 - accuracy: 0.8563 - val_loss: 0.9756 - val_accuracy: 0.7508\n",
      "Epoch 973/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5065 - accuracy: 0.8589 - val_loss: 0.9747 - val_accuracy: 0.7523\n",
      "Epoch 974/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5051 - accuracy: 0.8573 - val_loss: 1.0285 - val_accuracy: 0.7270\n",
      "Epoch 975/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5097 - accuracy: 0.8546 - val_loss: 1.0172 - val_accuracy: 0.7330\n",
      "Epoch 976/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5147 - accuracy: 0.8471 - val_loss: 0.9810 - val_accuracy: 0.7645\n",
      "Epoch 977/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5276 - accuracy: 0.8526 - val_loss: 1.0322 - val_accuracy: 0.7155\n",
      "Epoch 978/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5118 - accuracy: 0.8475 - val_loss: 0.9952 - val_accuracy: 0.7595\n",
      "Epoch 979/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5116 - accuracy: 0.8539 - val_loss: 1.0164 - val_accuracy: 0.7275\n",
      "Epoch 980/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5307 - accuracy: 0.8496 - val_loss: 1.0135 - val_accuracy: 0.7285\n",
      "Epoch 981/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5366 - accuracy: 0.8361 - val_loss: 0.9841 - val_accuracy: 0.7530\n",
      "Epoch 982/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5259 - accuracy: 0.8539 - val_loss: 1.0475 - val_accuracy: 0.7120\n",
      "Epoch 983/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5334 - accuracy: 0.8444 - val_loss: 0.9822 - val_accuracy: 0.7595\n",
      "Epoch 984/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5161 - accuracy: 0.8509 - val_loss: 1.0071 - val_accuracy: 0.7435\n",
      "Epoch 985/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5196 - accuracy: 0.8531 - val_loss: 1.0353 - val_accuracy: 0.7185\n",
      "Epoch 986/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5136 - accuracy: 0.8551 - val_loss: 1.0134 - val_accuracy: 0.7402\n",
      "Epoch 987/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5101 - accuracy: 0.8544 - val_loss: 1.0160 - val_accuracy: 0.7325\n",
      "Epoch 988/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5149 - accuracy: 0.8484 - val_loss: 0.9624 - val_accuracy: 0.7657\n",
      "Epoch 989/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5220 - accuracy: 0.8542 - val_loss: 1.0478 - val_accuracy: 0.7128\n",
      "Epoch 990/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5119 - accuracy: 0.8487 - val_loss: 0.9869 - val_accuracy: 0.7585\n",
      "Epoch 991/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5110 - accuracy: 0.8542 - val_loss: 1.0410 - val_accuracy: 0.7220\n",
      "Epoch 992/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5203 - accuracy: 0.8499 - val_loss: 0.9817 - val_accuracy: 0.7600\n",
      "Epoch 993/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5471 - accuracy: 0.8499 - val_loss: 1.0293 - val_accuracy: 0.7092\n",
      "Epoch 994/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5732 - accuracy: 0.8429 - val_loss: 1.0800 - val_accuracy: 0.6935\n",
      "Epoch 995/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5658 - accuracy: 0.8295 - val_loss: 1.0078 - val_accuracy: 0.7455\n",
      "Epoch 996/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5731 - accuracy: 0.8406 - val_loss: 1.0979 - val_accuracy: 0.6820\n",
      "Epoch 997/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5504 - accuracy: 0.8374 - val_loss: 0.9400 - val_accuracy: 0.7628\n",
      "Epoch 998/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5677 - accuracy: 0.8427 - val_loss: 1.0993 - val_accuracy: 0.6690\n",
      "Epoch 999/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5676 - accuracy: 0.8361 - val_loss: 1.0354 - val_accuracy: 0.7293\n",
      "Epoch 1000/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5492 - accuracy: 0.8406 - val_loss: 0.9491 - val_accuracy: 0.7613\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/1000\n",
      "16000/16000 [==============================] - 1s 35us/step - loss: 2.4280 - accuracy: 0.5411 - val_loss: 0.5923 - val_accuracy: 0.7585\n",
      "Epoch 2/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.3878 - accuracy: 0.3280 - val_loss: 0.7931 - val_accuracy: 0.3692\n",
      "Epoch 3/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.3007 - accuracy: 0.6789 - val_loss: 0.7200 - val_accuracy: 0.4038\n",
      "Epoch 4/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2674 - accuracy: 0.2603 - val_loss: 0.7278 - val_accuracy: 0.3250\n",
      "Epoch 5/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2488 - accuracy: 0.4597 - val_loss: 0.7574 - val_accuracy: 0.2720\n",
      "Epoch 6/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2413 - accuracy: 0.2893 - val_loss: 0.7229 - val_accuracy: 0.3565\n",
      "Epoch 7/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2394 - accuracy: 0.3304 - val_loss: 0.7478 - val_accuracy: 0.2903\n",
      "Epoch 8/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2355 - accuracy: 0.3470 - val_loss: 0.7530 - val_accuracy: 0.2905\n",
      "Epoch 9/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2320 - accuracy: 0.2825 - val_loss: 0.7015 - val_accuracy: 0.3877\n",
      "Epoch 10/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2310 - accuracy: 0.3273 - val_loss: 0.7505 - val_accuracy: 0.2810\n",
      "Epoch 11/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2259 - accuracy: 0.3517 - val_loss: 0.7721 - val_accuracy: 0.2680\n",
      "Epoch 12/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2227 - accuracy: 0.3440 - val_loss: 0.7507 - val_accuracy: 0.2842\n",
      "Epoch 13/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2181 - accuracy: 0.3343 - val_loss: 0.7068 - val_accuracy: 0.4035\n",
      "Epoch 14/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2142 - accuracy: 0.3526 - val_loss: 0.7304 - val_accuracy: 0.3455\n",
      "Epoch 15/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2114 - accuracy: 0.3731 - val_loss: 0.7406 - val_accuracy: 0.3582\n",
      "Epoch 16/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2069 - accuracy: 0.3983 - val_loss: 0.7166 - val_accuracy: 0.4182\n",
      "Epoch 17/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2046 - accuracy: 0.4058 - val_loss: 0.7091 - val_accuracy: 0.4487\n",
      "Epoch 18/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2025 - accuracy: 0.4214 - val_loss: 0.7102 - val_accuracy: 0.4523\n",
      "Epoch 19/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2008 - accuracy: 0.4341 - val_loss: 0.7312 - val_accuracy: 0.4087\n",
      "Epoch 20/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2006 - accuracy: 0.4397 - val_loss: 0.7598 - val_accuracy: 0.3543\n",
      "Epoch 21/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2000 - accuracy: 0.4542 - val_loss: 0.7696 - val_accuracy: 0.3165\n",
      "Epoch 22/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1952 - accuracy: 0.4644 - val_loss: 0.7722 - val_accuracy: 0.3343\n",
      "Epoch 23/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1942 - accuracy: 0.4406 - val_loss: 0.7813 - val_accuracy: 0.3180\n",
      "Epoch 24/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1931 - accuracy: 0.4635 - val_loss: 0.8262 - val_accuracy: 0.2752\n",
      "Epoch 25/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1960 - accuracy: 0.4535 - val_loss: 0.7724 - val_accuracy: 0.3615\n",
      "Epoch 26/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1887 - accuracy: 0.4624 - val_loss: 0.7739 - val_accuracy: 0.3478\n",
      "Epoch 27/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1864 - accuracy: 0.4626 - val_loss: 0.7185 - val_accuracy: 0.4557\n",
      "Epoch 28/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1827 - accuracy: 0.4503 - val_loss: 0.7009 - val_accuracy: 0.5150\n",
      "Epoch 29/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1797 - accuracy: 0.4796 - val_loss: 0.7599 - val_accuracy: 0.3885\n",
      "Epoch 30/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1772 - accuracy: 0.4711 - val_loss: 0.7462 - val_accuracy: 0.3988\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1771 - accuracy: 0.4701 - val_loss: 0.7309 - val_accuracy: 0.4320\n",
      "Epoch 32/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1707 - accuracy: 0.4834 - val_loss: 0.7424 - val_accuracy: 0.4295\n",
      "Epoch 33/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1684 - accuracy: 0.4922 - val_loss: 0.6799 - val_accuracy: 0.5650\n",
      "Epoch 34/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1735 - accuracy: 0.4749 - val_loss: 0.6931 - val_accuracy: 0.5455\n",
      "Epoch 35/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1619 - accuracy: 0.4970 - val_loss: 0.7490 - val_accuracy: 0.4195\n",
      "Epoch 36/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 1.1586 - accuracy: 0.5041 - val_loss: 0.7365 - val_accuracy: 0.4482\n",
      "Epoch 37/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1541 - accuracy: 0.5026 - val_loss: 0.7714 - val_accuracy: 0.4137\n",
      "Epoch 38/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1516 - accuracy: 0.4888 - val_loss: 0.7324 - val_accuracy: 0.4635\n",
      "Epoch 39/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1478 - accuracy: 0.5281 - val_loss: 0.6649 - val_accuracy: 0.6053\n",
      "Epoch 40/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1489 - accuracy: 0.5234 - val_loss: 0.7185 - val_accuracy: 0.5020\n",
      "Epoch 41/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1409 - accuracy: 0.5260 - val_loss: 0.7362 - val_accuracy: 0.4807\n",
      "Epoch 42/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1382 - accuracy: 0.5325 - val_loss: 0.6942 - val_accuracy: 0.5418\n",
      "Epoch 43/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1408 - accuracy: 0.5319 - val_loss: 0.7923 - val_accuracy: 0.3840\n",
      "Epoch 44/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1416 - accuracy: 0.5178 - val_loss: 0.7632 - val_accuracy: 0.4060\n",
      "Epoch 45/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1325 - accuracy: 0.5126 - val_loss: 0.7121 - val_accuracy: 0.5420\n",
      "Epoch 46/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1290 - accuracy: 0.5941 - val_loss: 0.7609 - val_accuracy: 0.4040\n",
      "Epoch 47/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1280 - accuracy: 0.5182 - val_loss: 0.6995 - val_accuracy: 0.5625\n",
      "Epoch 48/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1221 - accuracy: 0.5774 - val_loss: 0.7159 - val_accuracy: 0.5320\n",
      "Epoch 49/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1222 - accuracy: 0.5289 - val_loss: 0.7365 - val_accuracy: 0.4832\n",
      "Epoch 50/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1281 - accuracy: 0.5687 - val_loss: 0.7439 - val_accuracy: 0.4940\n",
      "Epoch 51/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1347 - accuracy: 0.5626 - val_loss: 0.6880 - val_accuracy: 0.6090\n",
      "Epoch 52/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1378 - accuracy: 0.5204 - val_loss: 0.7128 - val_accuracy: 0.5490\n",
      "Epoch 53/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1229 - accuracy: 0.5619 - val_loss: 0.6927 - val_accuracy: 0.5767\n",
      "Epoch 54/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1227 - accuracy: 0.5655 - val_loss: 0.6995 - val_accuracy: 0.5500\n",
      "Epoch 55/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1147 - accuracy: 0.5684 - val_loss: 0.7258 - val_accuracy: 0.5293\n",
      "Epoch 56/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1101 - accuracy: 0.5871 - val_loss: 0.7467 - val_accuracy: 0.4647\n",
      "Epoch 57/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1053 - accuracy: 0.6005 - val_loss: 0.7421 - val_accuracy: 0.4825\n",
      "Epoch 58/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1033 - accuracy: 0.5698 - val_loss: 0.7234 - val_accuracy: 0.5260\n",
      "Epoch 59/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1012 - accuracy: 0.5891 - val_loss: 0.7014 - val_accuracy: 0.5425\n",
      "Epoch 60/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1033 - accuracy: 0.5667 - val_loss: 0.7324 - val_accuracy: 0.4950\n",
      "Epoch 61/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0958 - accuracy: 0.6054 - val_loss: 0.6659 - val_accuracy: 0.6110\n",
      "Epoch 62/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0947 - accuracy: 0.5631 - val_loss: 0.7495 - val_accuracy: 0.4685\n",
      "Epoch 63/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0941 - accuracy: 0.5848 - val_loss: 0.6888 - val_accuracy: 0.5790\n",
      "Epoch 64/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0958 - accuracy: 0.6044 - val_loss: 0.6877 - val_accuracy: 0.5720\n",
      "Epoch 65/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0919 - accuracy: 0.5651 - val_loss: 0.6926 - val_accuracy: 0.5707\n",
      "Epoch 66/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0895 - accuracy: 0.5803 - val_loss: 0.6796 - val_accuracy: 0.5890\n",
      "Epoch 67/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0862 - accuracy: 0.5906 - val_loss: 0.6724 - val_accuracy: 0.6258\n",
      "Epoch 68/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0861 - accuracy: 0.5939 - val_loss: 0.6999 - val_accuracy: 0.5683\n",
      "Epoch 69/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0757 - accuracy: 0.5937 - val_loss: 0.6744 - val_accuracy: 0.5943\n",
      "Epoch 70/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0772 - accuracy: 0.6198 - val_loss: 0.6854 - val_accuracy: 0.5825\n",
      "Epoch 71/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0717 - accuracy: 0.6091 - val_loss: 0.6297 - val_accuracy: 0.7028\n",
      "Epoch 72/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0687 - accuracy: 0.6132 - val_loss: 0.6539 - val_accuracy: 0.6830\n",
      "Epoch 73/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0656 - accuracy: 0.6284 - val_loss: 0.7495 - val_accuracy: 0.4658\n",
      "Epoch 74/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0675 - accuracy: 0.6023 - val_loss: 0.6868 - val_accuracy: 0.5888\n",
      "Epoch 75/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0608 - accuracy: 0.6147 - val_loss: 0.6875 - val_accuracy: 0.6298\n",
      "Epoch 76/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0621 - accuracy: 0.6086 - val_loss: 0.7146 - val_accuracy: 0.5220\n",
      "Epoch 77/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0596 - accuracy: 0.6512 - val_loss: 0.6370 - val_accuracy: 0.6785\n",
      "Epoch 78/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0709 - accuracy: 0.6192 - val_loss: 0.6701 - val_accuracy: 0.6398\n",
      "Epoch 79/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0629 - accuracy: 0.6376 - val_loss: 0.7398 - val_accuracy: 0.5102\n",
      "Epoch 80/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0601 - accuracy: 0.6236 - val_loss: 0.7833 - val_accuracy: 0.4593\n",
      "Epoch 81/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 1.0583 - accuracy: 0.6139 - val_loss: 0.7032 - val_accuracy: 0.5947\n",
      "Epoch 82/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0469 - accuracy: 0.6221 - val_loss: 0.6450 - val_accuracy: 0.6810\n",
      "Epoch 83/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0462 - accuracy: 0.6355 - val_loss: 0.6852 - val_accuracy: 0.6295\n",
      "Epoch 84/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0444 - accuracy: 0.6509 - val_loss: 0.6742 - val_accuracy: 0.6317\n",
      "Epoch 85/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0410 - accuracy: 0.6317 - val_loss: 0.6990 - val_accuracy: 0.6145\n",
      "Epoch 86/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0408 - accuracy: 0.6532 - val_loss: 0.7239 - val_accuracy: 0.5288\n",
      "Epoch 87/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0409 - accuracy: 0.6223 - val_loss: 0.6952 - val_accuracy: 0.5903\n",
      "Epoch 88/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0341 - accuracy: 0.6655 - val_loss: 0.6783 - val_accuracy: 0.6125\n",
      "Epoch 89/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0306 - accuracy: 0.6380 - val_loss: 0.6709 - val_accuracy: 0.6550\n",
      "Epoch 90/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0283 - accuracy: 0.6712 - val_loss: 0.6426 - val_accuracy: 0.6653\n",
      "Epoch 91/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0370 - accuracy: 0.6499 - val_loss: 0.6858 - val_accuracy: 0.6158\n",
      "Epoch 92/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0317 - accuracy: 0.6401 - val_loss: 0.7234 - val_accuracy: 0.5677\n",
      "Epoch 93/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0340 - accuracy: 0.6580 - val_loss: 0.6618 - val_accuracy: 0.6668\n",
      "Epoch 94/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0256 - accuracy: 0.6651 - val_loss: 0.7024 - val_accuracy: 0.5910\n",
      "Epoch 95/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0219 - accuracy: 0.6615 - val_loss: 0.6433 - val_accuracy: 0.6845\n",
      "Epoch 96/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0232 - accuracy: 0.6481 - val_loss: 0.6534 - val_accuracy: 0.6727\n",
      "Epoch 97/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0209 - accuracy: 0.6784 - val_loss: 0.6650 - val_accuracy: 0.6560\n",
      "Epoch 98/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0193 - accuracy: 0.6554 - val_loss: 0.6478 - val_accuracy: 0.6910\n",
      "Epoch 99/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0233 - accuracy: 0.6711 - val_loss: 0.6562 - val_accuracy: 0.6633\n",
      "Epoch 100/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0294 - accuracy: 0.6484 - val_loss: 0.6875 - val_accuracy: 0.5990\n",
      "Epoch 101/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0257 - accuracy: 0.6684 - val_loss: 0.6497 - val_accuracy: 0.6633\n",
      "Epoch 102/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0361 - accuracy: 0.6631 - val_loss: 0.7577 - val_accuracy: 0.5013\n",
      "Epoch 103/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0296 - accuracy: 0.6295 - val_loss: 0.6811 - val_accuracy: 0.6332\n",
      "Epoch 104/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0214 - accuracy: 0.6697 - val_loss: 0.6487 - val_accuracy: 0.6895\n",
      "Epoch 105/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0139 - accuracy: 0.6651 - val_loss: 0.6225 - val_accuracy: 0.7143\n",
      "Epoch 106/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0119 - accuracy: 0.6554 - val_loss: 0.6562 - val_accuracy: 0.6745\n",
      "Epoch 107/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0184 - accuracy: 0.6607 - val_loss: 0.6591 - val_accuracy: 0.6823\n",
      "Epoch 108/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0157 - accuracy: 0.6769 - val_loss: 0.6504 - val_accuracy: 0.6842\n",
      "Epoch 109/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 1.0134 - accuracy: 0.6916 - val_loss: 0.7471 - val_accuracy: 0.5142\n",
      "Epoch 110/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0143 - accuracy: 0.6348 - val_loss: 0.6360 - val_accuracy: 0.6952\n",
      "Epoch 111/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0127 - accuracy: 0.7046 - val_loss: 0.7008 - val_accuracy: 0.5940\n",
      "Epoch 112/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0033 - accuracy: 0.6496 - val_loss: 0.7105 - val_accuracy: 0.5832\n",
      "Epoch 113/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 1.0096 - accuracy: 0.6864 - val_loss: 0.6505 - val_accuracy: 0.6665\n",
      "Epoch 114/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0004 - accuracy: 0.6704 - val_loss: 0.7855 - val_accuracy: 0.4873\n",
      "Epoch 115/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0052 - accuracy: 0.6544 - val_loss: 0.6586 - val_accuracy: 0.6622\n",
      "Epoch 116/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9949 - accuracy: 0.6849 - val_loss: 0.6589 - val_accuracy: 0.6635\n",
      "Epoch 117/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9947 - accuracy: 0.6808 - val_loss: 0.7054 - val_accuracy: 0.6140\n",
      "Epoch 118/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9958 - accuracy: 0.6724 - val_loss: 0.6332 - val_accuracy: 0.7023\n",
      "Epoch 119/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9988 - accuracy: 0.6892 - val_loss: 0.6801 - val_accuracy: 0.6570\n",
      "Epoch 120/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9927 - accuracy: 0.6766 - val_loss: 0.6628 - val_accuracy: 0.6625\n",
      "Epoch 121/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9911 - accuracy: 0.6907 - val_loss: 0.6471 - val_accuracy: 0.6860\n",
      "Epoch 122/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9890 - accuracy: 0.6857 - val_loss: 0.6311 - val_accuracy: 0.6998\n",
      "Epoch 123/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9971 - accuracy: 0.6762 - val_loss: 0.7424 - val_accuracy: 0.5775\n",
      "Epoch 124/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0011 - accuracy: 0.6599 - val_loss: 0.6463 - val_accuracy: 0.6628\n",
      "Epoch 125/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9934 - accuracy: 0.7009 - val_loss: 0.6678 - val_accuracy: 0.6560\n",
      "Epoch 126/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9904 - accuracy: 0.6791 - val_loss: 0.6811 - val_accuracy: 0.6507\n",
      "Epoch 127/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9860 - accuracy: 0.6805 - val_loss: 0.6868 - val_accuracy: 0.6403\n",
      "Epoch 128/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9827 - accuracy: 0.6901 - val_loss: 0.6363 - val_accuracy: 0.6938\n",
      "Epoch 129/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9788 - accuracy: 0.7014 - val_loss: 0.7044 - val_accuracy: 0.6215\n",
      "Epoch 130/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9769 - accuracy: 0.6706 - val_loss: 0.6606 - val_accuracy: 0.6693\n",
      "Epoch 131/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9820 - accuracy: 0.6905 - val_loss: 0.6598 - val_accuracy: 0.6495\n",
      "Epoch 132/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9736 - accuracy: 0.6953 - val_loss: 0.7278 - val_accuracy: 0.5805\n",
      "Epoch 133/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9823 - accuracy: 0.6583 - val_loss: 0.6398 - val_accuracy: 0.6825\n",
      "Epoch 134/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9891 - accuracy: 0.7020 - val_loss: 0.6629 - val_accuracy: 0.6557\n",
      "Epoch 135/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9744 - accuracy: 0.6858 - val_loss: 0.6490 - val_accuracy: 0.6842\n",
      "Epoch 136/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9718 - accuracy: 0.6936 - val_loss: 0.6847 - val_accuracy: 0.6355\n",
      "Epoch 137/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9704 - accuracy: 0.6925 - val_loss: 0.6887 - val_accuracy: 0.6320\n",
      "Epoch 138/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9824 - accuracy: 0.6898 - val_loss: 0.6568 - val_accuracy: 0.6672\n",
      "Epoch 139/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9704 - accuracy: 0.6894 - val_loss: 0.6597 - val_accuracy: 0.6525\n",
      "Epoch 140/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9670 - accuracy: 0.7080 - val_loss: 0.6436 - val_accuracy: 0.6752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9713 - accuracy: 0.6906 - val_loss: 0.6471 - val_accuracy: 0.6773\n",
      "Epoch 142/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.9727 - accuracy: 0.6942 - val_loss: 0.6489 - val_accuracy: 0.6618\n",
      "Epoch 143/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9673 - accuracy: 0.7046 - val_loss: 0.6730 - val_accuracy: 0.6428\n",
      "Epoch 144/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9638 - accuracy: 0.6943 - val_loss: 0.6469 - val_accuracy: 0.6725\n",
      "Epoch 145/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9652 - accuracy: 0.6963 - val_loss: 0.6650 - val_accuracy: 0.6612\n",
      "Epoch 146/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9629 - accuracy: 0.6981 - val_loss: 0.7017 - val_accuracy: 0.6320\n",
      "Epoch 147/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9761 - accuracy: 0.6871 - val_loss: 0.6365 - val_accuracy: 0.7090\n",
      "Epoch 148/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9621 - accuracy: 0.6901 - val_loss: 0.6705 - val_accuracy: 0.6600\n",
      "Epoch 149/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9613 - accuracy: 0.6954 - val_loss: 0.6323 - val_accuracy: 0.7122\n",
      "Epoch 150/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9640 - accuracy: 0.7109 - val_loss: 0.7105 - val_accuracy: 0.6133\n",
      "Epoch 151/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9661 - accuracy: 0.6704 - val_loss: 0.6618 - val_accuracy: 0.6555\n",
      "Epoch 152/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9632 - accuracy: 0.7118 - val_loss: 0.7043 - val_accuracy: 0.6003\n",
      "Epoch 153/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9625 - accuracy: 0.6794 - val_loss: 0.5973 - val_accuracy: 0.7293\n",
      "Epoch 154/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9706 - accuracy: 0.7090 - val_loss: 0.7333 - val_accuracy: 0.5715\n",
      "Epoch 155/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9593 - accuracy: 0.6809 - val_loss: 0.6509 - val_accuracy: 0.6730\n",
      "Epoch 156/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9587 - accuracy: 0.6953 - val_loss: 0.6179 - val_accuracy: 0.7100\n",
      "Epoch 157/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9492 - accuracy: 0.7178 - val_loss: 0.7024 - val_accuracy: 0.6300\n",
      "Epoch 158/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9588 - accuracy: 0.6762 - val_loss: 0.6413 - val_accuracy: 0.6817\n",
      "Epoch 159/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9482 - accuracy: 0.7103 - val_loss: 0.6452 - val_accuracy: 0.6775\n",
      "Epoch 160/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9444 - accuracy: 0.7157 - val_loss: 0.6680 - val_accuracy: 0.6607\n",
      "Epoch 161/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9398 - accuracy: 0.7116 - val_loss: 0.7188 - val_accuracy: 0.6177\n",
      "Epoch 162/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9406 - accuracy: 0.6961 - val_loss: 0.6229 - val_accuracy: 0.7228\n",
      "Epoch 163/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9453 - accuracy: 0.7101 - val_loss: 0.6986 - val_accuracy: 0.6395\n",
      "Epoch 164/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9420 - accuracy: 0.6994 - val_loss: 0.6712 - val_accuracy: 0.6560\n",
      "Epoch 165/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9469 - accuracy: 0.7049 - val_loss: 0.6351 - val_accuracy: 0.6970\n",
      "Epoch 166/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9461 - accuracy: 0.6981 - val_loss: 0.7256 - val_accuracy: 0.6127\n",
      "Epoch 167/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9489 - accuracy: 0.7041 - val_loss: 0.6521 - val_accuracy: 0.6758\n",
      "Epoch 168/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9451 - accuracy: 0.7054 - val_loss: 0.6712 - val_accuracy: 0.6535\n",
      "Epoch 169/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9416 - accuracy: 0.7058 - val_loss: 0.6431 - val_accuracy: 0.6890\n",
      "Epoch 170/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9344 - accuracy: 0.7163 - val_loss: 0.6353 - val_accuracy: 0.6827\n",
      "Epoch 171/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9394 - accuracy: 0.6954 - val_loss: 0.7058 - val_accuracy: 0.6245\n",
      "Epoch 172/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9444 - accuracy: 0.7057 - val_loss: 0.6147 - val_accuracy: 0.7143\n",
      "Epoch 173/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9369 - accuracy: 0.7111 - val_loss: 0.6706 - val_accuracy: 0.6665\n",
      "Epoch 174/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9379 - accuracy: 0.6993 - val_loss: 0.6746 - val_accuracy: 0.6595\n",
      "Epoch 175/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9402 - accuracy: 0.7144 - val_loss: 0.6674 - val_accuracy: 0.6672\n",
      "Epoch 176/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9480 - accuracy: 0.6938 - val_loss: 0.6251 - val_accuracy: 0.7042\n",
      "Epoch 177/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9433 - accuracy: 0.6996 - val_loss: 0.6500 - val_accuracy: 0.6758\n",
      "Epoch 178/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9380 - accuracy: 0.7122 - val_loss: 0.6497 - val_accuracy: 0.6860\n",
      "Epoch 179/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9321 - accuracy: 0.7021 - val_loss: 0.6891 - val_accuracy: 0.6503\n",
      "Epoch 180/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9459 - accuracy: 0.7038 - val_loss: 0.6474 - val_accuracy: 0.6812\n",
      "Epoch 181/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9309 - accuracy: 0.7040 - val_loss: 0.6643 - val_accuracy: 0.6687\n",
      "Epoch 182/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9241 - accuracy: 0.7180 - val_loss: 0.7139 - val_accuracy: 0.6202\n",
      "Epoch 183/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.9239 - accuracy: 0.7066 - val_loss: 0.6536 - val_accuracy: 0.6835\n",
      "Epoch 184/1000\n",
      "16000/16000 [==============================] - 0s 6us/step - loss: 0.9274 - accuracy: 0.7007 - val_loss: 0.6981 - val_accuracy: 0.6463\n",
      "Epoch 185/1000\n",
      "16000/16000 [==============================] - 0s 5us/step - loss: 0.9270 - accuracy: 0.7082 - val_loss: 0.6286 - val_accuracy: 0.7063\n",
      "Epoch 186/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.9243 - accuracy: 0.7148 - val_loss: 0.7296 - val_accuracy: 0.5945\n",
      "Epoch 187/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9279 - accuracy: 0.7028 - val_loss: 0.6366 - val_accuracy: 0.6965\n",
      "Epoch 188/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9206 - accuracy: 0.7180 - val_loss: 0.6799 - val_accuracy: 0.6570\n",
      "Epoch 189/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9277 - accuracy: 0.7052 - val_loss: 0.7182 - val_accuracy: 0.6263\n",
      "Epoch 190/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9392 - accuracy: 0.6961 - val_loss: 0.6510 - val_accuracy: 0.6960\n",
      "Epoch 191/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9246 - accuracy: 0.7196 - val_loss: 0.7381 - val_accuracy: 0.6152\n",
      "Epoch 192/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9222 - accuracy: 0.6981 - val_loss: 0.6255 - val_accuracy: 0.7147\n",
      "Epoch 193/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9279 - accuracy: 0.7214 - val_loss: 0.7181 - val_accuracy: 0.6252\n",
      "Epoch 194/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9226 - accuracy: 0.6921 - val_loss: 0.6192 - val_accuracy: 0.7115\n",
      "Epoch 195/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9253 - accuracy: 0.7215 - val_loss: 0.6664 - val_accuracy: 0.6737\n",
      "Epoch 196/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9231 - accuracy: 0.7001 - val_loss: 0.6107 - val_accuracy: 0.7235\n",
      "Epoch 197/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9214 - accuracy: 0.7201 - val_loss: 0.6988 - val_accuracy: 0.6330\n",
      "Epoch 198/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9155 - accuracy: 0.7005 - val_loss: 0.6449 - val_accuracy: 0.6875\n",
      "Epoch 199/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9156 - accuracy: 0.7229 - val_loss: 0.6503 - val_accuracy: 0.6845\n",
      "Epoch 200/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9145 - accuracy: 0.7101 - val_loss: 0.6819 - val_accuracy: 0.6635\n",
      "Epoch 201/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9092 - accuracy: 0.7250 - val_loss: 0.7061 - val_accuracy: 0.6492\n",
      "Epoch 202/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9169 - accuracy: 0.7078 - val_loss: 0.6817 - val_accuracy: 0.6710\n",
      "Epoch 203/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9154 - accuracy: 0.7121 - val_loss: 0.6621 - val_accuracy: 0.6718\n",
      "Epoch 204/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9102 - accuracy: 0.7207 - val_loss: 0.7037 - val_accuracy: 0.6260\n",
      "Epoch 205/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9107 - accuracy: 0.6976 - val_loss: 0.6292 - val_accuracy: 0.7060\n",
      "Epoch 206/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9163 - accuracy: 0.7260 - val_loss: 0.6549 - val_accuracy: 0.6815\n",
      "Epoch 207/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9071 - accuracy: 0.7208 - val_loss: 0.7269 - val_accuracy: 0.5947\n",
      "Epoch 208/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9109 - accuracy: 0.7012 - val_loss: 0.6393 - val_accuracy: 0.6938\n",
      "Epoch 209/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9051 - accuracy: 0.7248 - val_loss: 0.7052 - val_accuracy: 0.6325\n",
      "Epoch 210/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9010 - accuracy: 0.7142 - val_loss: 0.6105 - val_accuracy: 0.7315\n",
      "Epoch 211/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9099 - accuracy: 0.7171 - val_loss: 0.7849 - val_accuracy: 0.5748\n",
      "Epoch 212/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9196 - accuracy: 0.7049 - val_loss: 0.6108 - val_accuracy: 0.7283\n",
      "Epoch 213/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9105 - accuracy: 0.7181 - val_loss: 0.7809 - val_accuracy: 0.5638\n",
      "Epoch 214/1000\n",
      "16000/16000 [==============================] - ETA: 0s - loss: 0.9426 - accuracy: 0.60 - 0s 2us/step - loss: 0.9178 - accuracy: 0.6986 - val_loss: 0.6032 - val_accuracy: 0.7505\n",
      "Epoch 215/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9380 - accuracy: 0.7004 - val_loss: 0.7950 - val_accuracy: 0.5540\n",
      "Epoch 216/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9168 - accuracy: 0.7016 - val_loss: 0.6449 - val_accuracy: 0.7067\n",
      "Epoch 217/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9078 - accuracy: 0.7211 - val_loss: 0.6779 - val_accuracy: 0.6650\n",
      "Epoch 218/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9058 - accuracy: 0.7151 - val_loss: 0.7113 - val_accuracy: 0.6417\n",
      "Epoch 219/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8974 - accuracy: 0.7211 - val_loss: 0.6780 - val_accuracy: 0.6607\n",
      "Epoch 220/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8941 - accuracy: 0.7152 - val_loss: 0.6430 - val_accuracy: 0.7007\n",
      "Epoch 221/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8954 - accuracy: 0.7200 - val_loss: 0.6937 - val_accuracy: 0.6662\n",
      "Epoch 222/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9026 - accuracy: 0.7201 - val_loss: 0.6061 - val_accuracy: 0.7498\n",
      "Epoch 223/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8991 - accuracy: 0.7268 - val_loss: 0.7345 - val_accuracy: 0.6145\n",
      "Epoch 224/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8968 - accuracy: 0.7048 - val_loss: 0.6465 - val_accuracy: 0.7013\n",
      "Epoch 225/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9062 - accuracy: 0.7224 - val_loss: 0.6762 - val_accuracy: 0.6622\n",
      "Epoch 226/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8985 - accuracy: 0.7181 - val_loss: 0.6851 - val_accuracy: 0.6658\n",
      "Epoch 227/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8916 - accuracy: 0.7233 - val_loss: 0.6808 - val_accuracy: 0.6720\n",
      "Epoch 228/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8865 - accuracy: 0.7247 - val_loss: 0.6446 - val_accuracy: 0.7110\n",
      "Epoch 229/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8889 - accuracy: 0.7289 - val_loss: 0.6952 - val_accuracy: 0.6587\n",
      "Epoch 230/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8859 - accuracy: 0.7204 - val_loss: 0.6755 - val_accuracy: 0.6770\n",
      "Epoch 231/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8916 - accuracy: 0.7258 - val_loss: 0.6895 - val_accuracy: 0.6687\n",
      "Epoch 232/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8943 - accuracy: 0.7176 - val_loss: 0.6807 - val_accuracy: 0.6860\n",
      "Epoch 233/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8826 - accuracy: 0.7293 - val_loss: 0.6263 - val_accuracy: 0.7278\n",
      "Epoch 234/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8871 - accuracy: 0.7222 - val_loss: 0.6834 - val_accuracy: 0.6852\n",
      "Epoch 235/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8947 - accuracy: 0.7176 - val_loss: 0.6604 - val_accuracy: 0.7120\n",
      "Epoch 236/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8968 - accuracy: 0.7310 - val_loss: 0.7389 - val_accuracy: 0.6263\n",
      "Epoch 237/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8870 - accuracy: 0.7134 - val_loss: 0.6590 - val_accuracy: 0.6905\n",
      "Epoch 238/1000\n",
      "16000/16000 [==============================] - ETA: 0s - loss: 0.8467 - accuracy: 0.73 - 0s 3us/step - loss: 0.8949 - accuracy: 0.7304 - val_loss: 0.7019 - val_accuracy: 0.6535\n",
      "Epoch 239/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8915 - accuracy: 0.7059 - val_loss: 0.6838 - val_accuracy: 0.6727\n",
      "Epoch 240/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8947 - accuracy: 0.7306 - val_loss: 0.6656 - val_accuracy: 0.6860\n",
      "Epoch 241/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8891 - accuracy: 0.7172 - val_loss: 0.6331 - val_accuracy: 0.7295\n",
      "Epoch 242/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8990 - accuracy: 0.7228 - val_loss: 0.6862 - val_accuracy: 0.6760\n",
      "Epoch 243/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9034 - accuracy: 0.7121 - val_loss: 0.6938 - val_accuracy: 0.6745\n",
      "Epoch 244/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8883 - accuracy: 0.7228 - val_loss: 0.6155 - val_accuracy: 0.7380\n",
      "Epoch 245/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9010 - accuracy: 0.7212 - val_loss: 0.7914 - val_accuracy: 0.5645\n",
      "Epoch 246/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9029 - accuracy: 0.7024 - val_loss: 0.6423 - val_accuracy: 0.7117\n",
      "Epoch 247/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8856 - accuracy: 0.7351 - val_loss: 0.7318 - val_accuracy: 0.6158\n",
      "Epoch 248/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8838 - accuracy: 0.7144 - val_loss: 0.6645 - val_accuracy: 0.6888\n",
      "Epoch 249/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8774 - accuracy: 0.7322 - val_loss: 0.7024 - val_accuracy: 0.6503\n",
      "Epoch 250/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8751 - accuracy: 0.7344 - val_loss: 0.6656 - val_accuracy: 0.6787\n",
      "Epoch 251/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8784 - accuracy: 0.7190 - val_loss: 0.6763 - val_accuracy: 0.6870\n",
      "Epoch 252/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8733 - accuracy: 0.7301 - val_loss: 0.6832 - val_accuracy: 0.6695\n",
      "Epoch 253/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8710 - accuracy: 0.7322 - val_loss: 0.6572 - val_accuracy: 0.7107\n",
      "Epoch 254/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8752 - accuracy: 0.7253 - val_loss: 0.6696 - val_accuracy: 0.6933\n",
      "Epoch 255/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8745 - accuracy: 0.7281 - val_loss: 0.6597 - val_accuracy: 0.6982\n",
      "Epoch 256/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8732 - accuracy: 0.7411 - val_loss: 0.7454 - val_accuracy: 0.6137\n",
      "Epoch 257/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8716 - accuracy: 0.7278 - val_loss: 0.6682 - val_accuracy: 0.6865\n",
      "Epoch 258/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8714 - accuracy: 0.7286 - val_loss: 0.7583 - val_accuracy: 0.5938\n",
      "Epoch 259/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8798 - accuracy: 0.7164 - val_loss: 0.6370 - val_accuracy: 0.7255\n",
      "Epoch 260/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8704 - accuracy: 0.7328 - val_loss: 0.6876 - val_accuracy: 0.6700\n",
      "Epoch 261/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8685 - accuracy: 0.7224 - val_loss: 0.6125 - val_accuracy: 0.7375\n",
      "Epoch 262/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8775 - accuracy: 0.7288 - val_loss: 0.7906 - val_accuracy: 0.5665\n",
      "Epoch 263/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8866 - accuracy: 0.7086 - val_loss: 0.6088 - val_accuracy: 0.7552\n",
      "Epoch 264/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8799 - accuracy: 0.7249 - val_loss: 0.7356 - val_accuracy: 0.6083\n",
      "Epoch 265/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8794 - accuracy: 0.7282 - val_loss: 0.6712 - val_accuracy: 0.6835\n",
      "Epoch 266/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8700 - accuracy: 0.7274 - val_loss: 0.7050 - val_accuracy: 0.6615\n",
      "Epoch 267/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8780 - accuracy: 0.7178 - val_loss: 0.6293 - val_accuracy: 0.7465\n",
      "Epoch 268/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8742 - accuracy: 0.7383 - val_loss: 0.7543 - val_accuracy: 0.6000\n",
      "Epoch 269/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8751 - accuracy: 0.7238 - val_loss: 0.6987 - val_accuracy: 0.6555\n",
      "Epoch 270/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8686 - accuracy: 0.7276 - val_loss: 0.7131 - val_accuracy: 0.6553\n",
      "Epoch 271/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8599 - accuracy: 0.7396 - val_loss: 0.7318 - val_accuracy: 0.6507\n",
      "Epoch 272/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8602 - accuracy: 0.7287 - val_loss: 0.6772 - val_accuracy: 0.7017\n",
      "Epoch 273/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8596 - accuracy: 0.7294 - val_loss: 0.6689 - val_accuracy: 0.7042\n",
      "Epoch 274/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8597 - accuracy: 0.7388 - val_loss: 0.6795 - val_accuracy: 0.6785\n",
      "Epoch 275/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8553 - accuracy: 0.7415 - val_loss: 0.7718 - val_accuracy: 0.5965\n",
      "Epoch 276/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8623 - accuracy: 0.7241 - val_loss: 0.6419 - val_accuracy: 0.7297\n",
      "Epoch 277/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8648 - accuracy: 0.7275 - val_loss: 0.7878 - val_accuracy: 0.5767\n",
      "Epoch 278/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8705 - accuracy: 0.7258 - val_loss: 0.6440 - val_accuracy: 0.7275\n",
      "Epoch 279/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8582 - accuracy: 0.7281 - val_loss: 0.7164 - val_accuracy: 0.6695\n",
      "Epoch 280/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8577 - accuracy: 0.7300 - val_loss: 0.6569 - val_accuracy: 0.7153\n",
      "Epoch 281/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8580 - accuracy: 0.7459 - val_loss: 0.7854 - val_accuracy: 0.5755\n",
      "Epoch 282/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8652 - accuracy: 0.7170 - val_loss: 0.6679 - val_accuracy: 0.7053\n",
      "Epoch 283/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8543 - accuracy: 0.7369 - val_loss: 0.7177 - val_accuracy: 0.6653\n",
      "Epoch 284/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8556 - accuracy: 0.7390 - val_loss: 0.6838 - val_accuracy: 0.6910\n",
      "Epoch 285/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8518 - accuracy: 0.7293 - val_loss: 0.6741 - val_accuracy: 0.7048\n",
      "Epoch 286/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8531 - accuracy: 0.7479 - val_loss: 0.7826 - val_accuracy: 0.6035\n",
      "Epoch 287/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8508 - accuracy: 0.7297 - val_loss: 0.7402 - val_accuracy: 0.6263\n",
      "Epoch 288/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8521 - accuracy: 0.7333 - val_loss: 0.6471 - val_accuracy: 0.7270\n",
      "Epoch 289/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8451 - accuracy: 0.7411 - val_loss: 0.6830 - val_accuracy: 0.6998\n",
      "Epoch 290/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8434 - accuracy: 0.7374 - val_loss: 0.7187 - val_accuracy: 0.6597\n",
      "Epoch 291/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8429 - accuracy: 0.7437 - val_loss: 0.7130 - val_accuracy: 0.6565\n",
      "Epoch 292/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8432 - accuracy: 0.7344 - val_loss: 0.6761 - val_accuracy: 0.7015\n",
      "Epoch 293/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8360 - accuracy: 0.7360 - val_loss: 0.6977 - val_accuracy: 0.6892\n",
      "Epoch 294/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8380 - accuracy: 0.7479 - val_loss: 0.7099 - val_accuracy: 0.6740\n",
      "Epoch 295/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8485 - accuracy: 0.7283 - val_loss: 0.6897 - val_accuracy: 0.6957\n",
      "Epoch 296/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8396 - accuracy: 0.7436 - val_loss: 0.6653 - val_accuracy: 0.7178\n",
      "Epoch 297/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8362 - accuracy: 0.7481 - val_loss: 0.6846 - val_accuracy: 0.6965\n",
      "Epoch 298/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8350 - accuracy: 0.7364 - val_loss: 0.6597 - val_accuracy: 0.7190\n",
      "Epoch 299/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.8369 - accuracy: 0.7467 - val_loss: 0.7285 - val_accuracy: 0.6645\n",
      "Epoch 300/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8359 - accuracy: 0.7400 - val_loss: 0.6907 - val_accuracy: 0.6810\n",
      "Epoch 301/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8481 - accuracy: 0.7377 - val_loss: 0.7143 - val_accuracy: 0.6610\n",
      "Epoch 302/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8405 - accuracy: 0.7314 - val_loss: 0.6920 - val_accuracy: 0.6877\n",
      "Epoch 303/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.8390 - accuracy: 0.7399 - val_loss: 0.6764 - val_accuracy: 0.7170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8437 - accuracy: 0.7365 - val_loss: 0.7346 - val_accuracy: 0.6490\n",
      "Epoch 305/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8458 - accuracy: 0.7416 - val_loss: 0.7096 - val_accuracy: 0.6650\n",
      "Epoch 306/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8485 - accuracy: 0.7228 - val_loss: 0.6835 - val_accuracy: 0.6990\n",
      "Epoch 307/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8500 - accuracy: 0.7419 - val_loss: 0.6925 - val_accuracy: 0.6883\n",
      "Epoch 308/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8459 - accuracy: 0.7297 - val_loss: 0.7166 - val_accuracy: 0.6538\n",
      "Epoch 309/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8517 - accuracy: 0.7398 - val_loss: 0.7937 - val_accuracy: 0.6150\n",
      "Epoch 310/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8632 - accuracy: 0.7205 - val_loss: 0.6634 - val_accuracy: 0.7212\n",
      "Epoch 311/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8488 - accuracy: 0.7263 - val_loss: 0.6818 - val_accuracy: 0.6960\n",
      "Epoch 312/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8458 - accuracy: 0.7505 - val_loss: 0.7726 - val_accuracy: 0.6050\n",
      "Epoch 313/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8539 - accuracy: 0.7109 - val_loss: 0.6471 - val_accuracy: 0.7333\n",
      "Epoch 314/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8389 - accuracy: 0.7483 - val_loss: 0.7169 - val_accuracy: 0.6823\n",
      "Epoch 315/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8327 - accuracy: 0.7449 - val_loss: 0.7830 - val_accuracy: 0.6327\n",
      "Epoch 316/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8401 - accuracy: 0.7357 - val_loss: 0.6727 - val_accuracy: 0.7265\n",
      "Epoch 317/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8403 - accuracy: 0.7346 - val_loss: 0.6989 - val_accuracy: 0.6925\n",
      "Epoch 318/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8374 - accuracy: 0.7484 - val_loss: 0.7171 - val_accuracy: 0.6870\n",
      "Epoch 319/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8285 - accuracy: 0.7396 - val_loss: 0.7167 - val_accuracy: 0.6840\n",
      "Epoch 320/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8369 - accuracy: 0.7324 - val_loss: 0.6882 - val_accuracy: 0.7163\n",
      "Epoch 321/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8473 - accuracy: 0.7377 - val_loss: 0.7301 - val_accuracy: 0.6805\n",
      "Epoch 322/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8350 - accuracy: 0.7420 - val_loss: 0.7095 - val_accuracy: 0.6913\n",
      "Epoch 323/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8401 - accuracy: 0.7270 - val_loss: 0.6778 - val_accuracy: 0.7125\n",
      "Epoch 324/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8317 - accuracy: 0.7567 - val_loss: 0.7323 - val_accuracy: 0.6808\n",
      "Epoch 325/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8463 - accuracy: 0.7203 - val_loss: 0.7180 - val_accuracy: 0.6915\n",
      "Epoch 326/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8500 - accuracy: 0.7469 - val_loss: 0.7481 - val_accuracy: 0.6438\n",
      "Epoch 327/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8396 - accuracy: 0.7324 - val_loss: 0.6826 - val_accuracy: 0.7095\n",
      "Epoch 328/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8304 - accuracy: 0.7397 - val_loss: 0.7799 - val_accuracy: 0.6190\n",
      "Epoch 329/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8262 - accuracy: 0.7446 - val_loss: 0.7024 - val_accuracy: 0.6920\n",
      "Epoch 330/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8257 - accuracy: 0.7423 - val_loss: 0.7446 - val_accuracy: 0.6718\n",
      "Epoch 331/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8328 - accuracy: 0.7399 - val_loss: 0.7055 - val_accuracy: 0.6950\n",
      "Epoch 332/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8421 - accuracy: 0.7436 - val_loss: 0.7486 - val_accuracy: 0.6650\n",
      "Epoch 333/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8346 - accuracy: 0.7303 - val_loss: 0.6926 - val_accuracy: 0.7290\n",
      "Epoch 334/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8384 - accuracy: 0.7453 - val_loss: 0.7062 - val_accuracy: 0.6842\n",
      "Epoch 335/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8273 - accuracy: 0.7438 - val_loss: 0.7296 - val_accuracy: 0.6697\n",
      "Epoch 336/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8247 - accuracy: 0.7445 - val_loss: 0.6872 - val_accuracy: 0.7157\n",
      "Epoch 337/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8188 - accuracy: 0.7534 - val_loss: 0.7541 - val_accuracy: 0.6407\n",
      "Epoch 338/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8180 - accuracy: 0.7506 - val_loss: 0.7270 - val_accuracy: 0.6747\n",
      "Epoch 339/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8245 - accuracy: 0.7347 - val_loss: 0.6875 - val_accuracy: 0.7230\n",
      "Epoch 340/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8296 - accuracy: 0.7518 - val_loss: 0.7611 - val_accuracy: 0.6415\n",
      "Epoch 341/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8351 - accuracy: 0.7444 - val_loss: 0.7556 - val_accuracy: 0.6585\n",
      "Epoch 342/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8180 - accuracy: 0.7379 - val_loss: 0.6979 - val_accuracy: 0.6942\n",
      "Epoch 343/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8174 - accuracy: 0.7451 - val_loss: 0.7450 - val_accuracy: 0.6693\n",
      "Epoch 344/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8207 - accuracy: 0.7568 - val_loss: 0.7855 - val_accuracy: 0.6062\n",
      "Epoch 345/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8236 - accuracy: 0.7304 - val_loss: 0.7057 - val_accuracy: 0.7028\n",
      "Epoch 346/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8159 - accuracy: 0.7525 - val_loss: 0.7549 - val_accuracy: 0.6550\n",
      "Epoch 347/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8196 - accuracy: 0.7389 - val_loss: 0.6918 - val_accuracy: 0.7122\n",
      "Epoch 348/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8129 - accuracy: 0.7516 - val_loss: 0.7392 - val_accuracy: 0.6768\n",
      "Epoch 349/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8138 - accuracy: 0.7452 - val_loss: 0.6774 - val_accuracy: 0.7145\n",
      "Epoch 350/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8215 - accuracy: 0.7607 - val_loss: 0.8217 - val_accuracy: 0.5893\n",
      "Epoch 351/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8190 - accuracy: 0.7426 - val_loss: 0.7171 - val_accuracy: 0.6762\n",
      "Epoch 352/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8165 - accuracy: 0.7401 - val_loss: 0.6868 - val_accuracy: 0.7203\n",
      "Epoch 353/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8210 - accuracy: 0.7543 - val_loss: 0.8235 - val_accuracy: 0.5867\n",
      "Epoch 354/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8144 - accuracy: 0.7360 - val_loss: 0.7220 - val_accuracy: 0.6758\n",
      "Epoch 355/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8123 - accuracy: 0.7496 - val_loss: 0.7522 - val_accuracy: 0.6568\n",
      "Epoch 356/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8103 - accuracy: 0.7553 - val_loss: 0.7323 - val_accuracy: 0.6825\n",
      "Epoch 357/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8103 - accuracy: 0.7341 - val_loss: 0.6603 - val_accuracy: 0.7527\n",
      "Epoch 358/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8264 - accuracy: 0.7607 - val_loss: 0.8666 - val_accuracy: 0.5842\n",
      "Epoch 359/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8358 - accuracy: 0.7240 - val_loss: 0.7084 - val_accuracy: 0.7145\n",
      "Epoch 360/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8190 - accuracy: 0.7452 - val_loss: 0.7190 - val_accuracy: 0.7063\n",
      "Epoch 361/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8118 - accuracy: 0.7460 - val_loss: 0.7308 - val_accuracy: 0.6888\n",
      "Epoch 362/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8068 - accuracy: 0.7550 - val_loss: 0.7504 - val_accuracy: 0.6607\n",
      "Epoch 363/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8124 - accuracy: 0.7527 - val_loss: 0.7808 - val_accuracy: 0.6345\n",
      "Epoch 364/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8189 - accuracy: 0.7314 - val_loss: 0.6506 - val_accuracy: 0.7490\n",
      "Epoch 365/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8117 - accuracy: 0.7572 - val_loss: 0.8152 - val_accuracy: 0.6137\n",
      "Epoch 366/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8114 - accuracy: 0.7432 - val_loss: 0.6937 - val_accuracy: 0.7222\n",
      "Epoch 367/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8079 - accuracy: 0.7514 - val_loss: 0.7685 - val_accuracy: 0.6395\n",
      "Epoch 368/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8145 - accuracy: 0.7471 - val_loss: 0.7085 - val_accuracy: 0.7115\n",
      "Epoch 369/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8078 - accuracy: 0.7506 - val_loss: 0.7598 - val_accuracy: 0.6600\n",
      "Epoch 370/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8064 - accuracy: 0.7456 - val_loss: 0.7152 - val_accuracy: 0.6990\n",
      "Epoch 371/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8109 - accuracy: 0.7405 - val_loss: 0.7119 - val_accuracy: 0.6955\n",
      "Epoch 372/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8180 - accuracy: 0.7516 - val_loss: 0.7587 - val_accuracy: 0.6488\n",
      "Epoch 373/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8202 - accuracy: 0.7443 - val_loss: 0.7202 - val_accuracy: 0.6952\n",
      "Epoch 374/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8066 - accuracy: 0.7493 - val_loss: 0.7376 - val_accuracy: 0.6715\n",
      "Epoch 375/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8014 - accuracy: 0.7565 - val_loss: 0.7208 - val_accuracy: 0.6755\n",
      "Epoch 376/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7992 - accuracy: 0.7523 - val_loss: 0.6917 - val_accuracy: 0.7222\n",
      "Epoch 377/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8065 - accuracy: 0.7558 - val_loss: 0.7965 - val_accuracy: 0.6482\n",
      "Epoch 378/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8151 - accuracy: 0.7406 - val_loss: 0.7530 - val_accuracy: 0.6933\n",
      "Epoch 379/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8182 - accuracy: 0.7359 - val_loss: 0.6706 - val_accuracy: 0.7415\n",
      "Epoch 380/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8198 - accuracy: 0.7481 - val_loss: 0.7163 - val_accuracy: 0.7145\n",
      "Epoch 381/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8172 - accuracy: 0.7466 - val_loss: 0.8118 - val_accuracy: 0.6270\n",
      "Epoch 382/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8072 - accuracy: 0.7430 - val_loss: 0.6774 - val_accuracy: 0.7418\n",
      "Epoch 383/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8030 - accuracy: 0.7593 - val_loss: 0.8462 - val_accuracy: 0.5900\n",
      "Epoch 384/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8066 - accuracy: 0.7471 - val_loss: 0.7350 - val_accuracy: 0.6992\n",
      "Epoch 385/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7959 - accuracy: 0.7566 - val_loss: 0.7273 - val_accuracy: 0.7125\n",
      "Epoch 386/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7950 - accuracy: 0.7612 - val_loss: 0.7624 - val_accuracy: 0.6647\n",
      "Epoch 387/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7955 - accuracy: 0.7442 - val_loss: 0.6905 - val_accuracy: 0.7312\n",
      "Epoch 388/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7974 - accuracy: 0.7569 - val_loss: 0.7998 - val_accuracy: 0.6173\n",
      "Epoch 389/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8022 - accuracy: 0.7539 - val_loss: 0.7167 - val_accuracy: 0.7063\n",
      "Epoch 390/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7944 - accuracy: 0.7511 - val_loss: 0.7610 - val_accuracy: 0.6658\n",
      "Epoch 391/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7917 - accuracy: 0.7531 - val_loss: 0.7102 - val_accuracy: 0.7132\n",
      "Epoch 392/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7926 - accuracy: 0.7616 - val_loss: 0.8141 - val_accuracy: 0.6135\n",
      "Epoch 393/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8107 - accuracy: 0.7439 - val_loss: 0.7217 - val_accuracy: 0.7082\n",
      "Epoch 394/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7964 - accuracy: 0.7448 - val_loss: 0.7120 - val_accuracy: 0.7268\n",
      "Epoch 395/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8005 - accuracy: 0.7571 - val_loss: 0.7983 - val_accuracy: 0.6348\n",
      "Epoch 396/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7948 - accuracy: 0.7534 - val_loss: 0.7105 - val_accuracy: 0.7145\n",
      "Epoch 397/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7902 - accuracy: 0.7536 - val_loss: 0.7765 - val_accuracy: 0.6635\n",
      "Epoch 398/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7900 - accuracy: 0.7653 - val_loss: 0.7841 - val_accuracy: 0.6695\n",
      "Epoch 399/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7849 - accuracy: 0.7558 - val_loss: 0.7216 - val_accuracy: 0.7125\n",
      "Epoch 400/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7829 - accuracy: 0.7591 - val_loss: 0.7503 - val_accuracy: 0.6820\n",
      "Epoch 401/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7756 - accuracy: 0.7666 - val_loss: 0.7626 - val_accuracy: 0.6653\n",
      "Epoch 402/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7792 - accuracy: 0.7625 - val_loss: 0.7415 - val_accuracy: 0.6915\n",
      "Epoch 403/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7824 - accuracy: 0.7586 - val_loss: 0.7092 - val_accuracy: 0.7197\n",
      "Epoch 404/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7796 - accuracy: 0.7616 - val_loss: 0.7745 - val_accuracy: 0.6555\n",
      "Epoch 405/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7738 - accuracy: 0.7681 - val_loss: 0.7342 - val_accuracy: 0.7063\n",
      "Epoch 406/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7774 - accuracy: 0.7537 - val_loss: 0.7338 - val_accuracy: 0.7000\n",
      "Epoch 407/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7798 - accuracy: 0.7651 - val_loss: 0.7565 - val_accuracy: 0.6755\n",
      "Epoch 408/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7826 - accuracy: 0.7614 - val_loss: 0.8002 - val_accuracy: 0.6485\n",
      "Epoch 409/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7812 - accuracy: 0.7628 - val_loss: 0.7704 - val_accuracy: 0.6678\n",
      "Epoch 410/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7757 - accuracy: 0.7612 - val_loss: 0.7331 - val_accuracy: 0.7120\n",
      "Epoch 411/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7761 - accuracy: 0.7655 - val_loss: 0.7729 - val_accuracy: 0.6633\n",
      "Epoch 412/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7738 - accuracy: 0.7577 - val_loss: 0.7740 - val_accuracy: 0.6625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 413/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7784 - accuracy: 0.7679 - val_loss: 0.7682 - val_accuracy: 0.6755\n",
      "Epoch 414/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7778 - accuracy: 0.7466 - val_loss: 0.7178 - val_accuracy: 0.7258\n",
      "Epoch 415/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7881 - accuracy: 0.7652 - val_loss: 0.8455 - val_accuracy: 0.6093\n",
      "Epoch 416/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7877 - accuracy: 0.7529 - val_loss: 0.6970 - val_accuracy: 0.7318\n",
      "Epoch 417/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7817 - accuracy: 0.7497 - val_loss: 0.7751 - val_accuracy: 0.6633\n",
      "Epoch 418/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7800 - accuracy: 0.7684 - val_loss: 0.7935 - val_accuracy: 0.6447\n",
      "Epoch 419/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7852 - accuracy: 0.7601 - val_loss: 0.7509 - val_accuracy: 0.6888\n",
      "Epoch 420/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7774 - accuracy: 0.7522 - val_loss: 0.7538 - val_accuracy: 0.6908\n",
      "Epoch 421/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7890 - accuracy: 0.7581 - val_loss: 0.7877 - val_accuracy: 0.6572\n",
      "Epoch 422/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7839 - accuracy: 0.7592 - val_loss: 0.7324 - val_accuracy: 0.6960\n",
      "Epoch 423/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7766 - accuracy: 0.7671 - val_loss: 0.7987 - val_accuracy: 0.6403\n",
      "Epoch 424/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7759 - accuracy: 0.7514 - val_loss: 0.7063 - val_accuracy: 0.7272\n",
      "Epoch 425/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7804 - accuracy: 0.7717 - val_loss: 0.7938 - val_accuracy: 0.6423\n",
      "Epoch 426/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7819 - accuracy: 0.7524 - val_loss: 0.7748 - val_accuracy: 0.6755\n",
      "Epoch 427/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7827 - accuracy: 0.7632 - val_loss: 0.7952 - val_accuracy: 0.6615\n",
      "Epoch 428/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7893 - accuracy: 0.7561 - val_loss: 0.7612 - val_accuracy: 0.6735\n",
      "Epoch 429/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7880 - accuracy: 0.7556 - val_loss: 0.7370 - val_accuracy: 0.7053\n",
      "Epoch 430/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7994 - accuracy: 0.7560 - val_loss: 0.7345 - val_accuracy: 0.7042\n",
      "Epoch 431/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7979 - accuracy: 0.7550 - val_loss: 0.7759 - val_accuracy: 0.6865\n",
      "Epoch 432/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7939 - accuracy: 0.7582 - val_loss: 0.8102 - val_accuracy: 0.6515\n",
      "Epoch 433/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7807 - accuracy: 0.7544 - val_loss: 0.7297 - val_accuracy: 0.7285\n",
      "Epoch 434/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7840 - accuracy: 0.7536 - val_loss: 0.6756 - val_accuracy: 0.7530\n",
      "Epoch 435/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.8036 - accuracy: 0.7521 - val_loss: 0.8590 - val_accuracy: 0.6215\n",
      "Epoch 436/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7883 - accuracy: 0.7566 - val_loss: 0.6970 - val_accuracy: 0.7368\n",
      "Epoch 437/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7722 - accuracy: 0.7631 - val_loss: 0.7545 - val_accuracy: 0.6973\n",
      "Epoch 438/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7676 - accuracy: 0.7624 - val_loss: 0.7426 - val_accuracy: 0.7128\n",
      "Epoch 439/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7691 - accuracy: 0.7643 - val_loss: 0.7532 - val_accuracy: 0.7028\n",
      "Epoch 440/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7669 - accuracy: 0.7665 - val_loss: 0.7737 - val_accuracy: 0.6672\n",
      "Epoch 441/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7652 - accuracy: 0.7666 - val_loss: 0.7347 - val_accuracy: 0.7188\n",
      "Epoch 442/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7805 - accuracy: 0.7616 - val_loss: 0.7577 - val_accuracy: 0.6842\n",
      "Epoch 443/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7823 - accuracy: 0.7496 - val_loss: 0.7012 - val_accuracy: 0.7465\n",
      "Epoch 444/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7896 - accuracy: 0.7661 - val_loss: 0.8560 - val_accuracy: 0.5947\n",
      "Epoch 445/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7862 - accuracy: 0.7540 - val_loss: 0.8144 - val_accuracy: 0.6568\n",
      "Epoch 446/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7767 - accuracy: 0.7577 - val_loss: 0.7537 - val_accuracy: 0.7050\n",
      "Epoch 447/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7747 - accuracy: 0.7609 - val_loss: 0.7444 - val_accuracy: 0.7153\n",
      "Epoch 448/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7712 - accuracy: 0.7653 - val_loss: 0.7542 - val_accuracy: 0.6845\n",
      "Epoch 449/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7724 - accuracy: 0.7666 - val_loss: 0.7270 - val_accuracy: 0.7182\n",
      "Epoch 450/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7757 - accuracy: 0.7569 - val_loss: 0.7497 - val_accuracy: 0.6935\n",
      "Epoch 451/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7648 - accuracy: 0.7641 - val_loss: 0.7184 - val_accuracy: 0.7380\n",
      "Epoch 452/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7682 - accuracy: 0.7694 - val_loss: 0.8957 - val_accuracy: 0.5788\n",
      "Epoch 453/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7923 - accuracy: 0.7489 - val_loss: 0.7173 - val_accuracy: 0.7337\n",
      "Epoch 454/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7822 - accuracy: 0.7464 - val_loss: 0.7645 - val_accuracy: 0.6890\n",
      "Epoch 455/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7794 - accuracy: 0.7684 - val_loss: 0.7782 - val_accuracy: 0.6812\n",
      "Epoch 456/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7689 - accuracy: 0.7501 - val_loss: 0.7095 - val_accuracy: 0.7502\n",
      "Epoch 457/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7626 - accuracy: 0.7768 - val_loss: 0.7394 - val_accuracy: 0.7132\n",
      "Epoch 458/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7553 - accuracy: 0.7717 - val_loss: 0.7743 - val_accuracy: 0.6760\n",
      "Epoch 459/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7550 - accuracy: 0.7658 - val_loss: 0.7785 - val_accuracy: 0.6848\n",
      "Epoch 460/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7515 - accuracy: 0.7686 - val_loss: 0.7881 - val_accuracy: 0.6802\n",
      "Epoch 461/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7603 - accuracy: 0.7641 - val_loss: 0.7618 - val_accuracy: 0.7120\n",
      "Epoch 462/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7620 - accuracy: 0.7733 - val_loss: 0.8049 - val_accuracy: 0.6810\n",
      "Epoch 463/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7692 - accuracy: 0.7497 - val_loss: 0.7097 - val_accuracy: 0.7505\n",
      "Epoch 464/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7668 - accuracy: 0.7725 - val_loss: 0.8145 - val_accuracy: 0.6593\n",
      "Epoch 465/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7583 - accuracy: 0.7626 - val_loss: 0.7251 - val_accuracy: 0.7337\n",
      "Epoch 466/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7530 - accuracy: 0.7717 - val_loss: 0.8340 - val_accuracy: 0.6500\n",
      "Epoch 467/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7587 - accuracy: 0.7593 - val_loss: 0.6993 - val_accuracy: 0.7483\n",
      "Epoch 468/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7559 - accuracy: 0.7722 - val_loss: 0.8202 - val_accuracy: 0.6425\n",
      "Epoch 469/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7590 - accuracy: 0.7674 - val_loss: 0.7694 - val_accuracy: 0.7020\n",
      "Epoch 470/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7498 - accuracy: 0.7725 - val_loss: 0.7956 - val_accuracy: 0.6820\n",
      "Epoch 471/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7539 - accuracy: 0.7681 - val_loss: 0.7623 - val_accuracy: 0.7105\n",
      "Epoch 472/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7581 - accuracy: 0.7779 - val_loss: 0.8582 - val_accuracy: 0.6062\n",
      "Epoch 473/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7599 - accuracy: 0.7599 - val_loss: 0.7195 - val_accuracy: 0.7458\n",
      "Epoch 474/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7567 - accuracy: 0.7669 - val_loss: 0.8004 - val_accuracy: 0.6650\n",
      "Epoch 475/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7651 - accuracy: 0.7733 - val_loss: 0.7989 - val_accuracy: 0.6730\n",
      "Epoch 476/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7652 - accuracy: 0.7476 - val_loss: 0.7165 - val_accuracy: 0.7360\n",
      "Epoch 477/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7702 - accuracy: 0.7714 - val_loss: 0.7996 - val_accuracy: 0.6595\n",
      "Epoch 478/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7713 - accuracy: 0.7697 - val_loss: 0.7798 - val_accuracy: 0.6780\n",
      "Epoch 479/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7617 - accuracy: 0.7657 - val_loss: 0.8203 - val_accuracy: 0.6877\n",
      "Epoch 480/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7560 - accuracy: 0.7703 - val_loss: 0.7520 - val_accuracy: 0.7080\n",
      "Epoch 481/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7540 - accuracy: 0.7731 - val_loss: 0.8116 - val_accuracy: 0.6662\n",
      "Epoch 482/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7513 - accuracy: 0.7646 - val_loss: 0.7354 - val_accuracy: 0.7410\n",
      "Epoch 483/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7572 - accuracy: 0.7607 - val_loss: 0.7696 - val_accuracy: 0.7045\n",
      "Epoch 484/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7518 - accuracy: 0.7786 - val_loss: 0.7938 - val_accuracy: 0.6710\n",
      "Epoch 485/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7502 - accuracy: 0.7628 - val_loss: 0.7316 - val_accuracy: 0.7372\n",
      "Epoch 486/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7468 - accuracy: 0.7706 - val_loss: 0.7166 - val_accuracy: 0.7485\n",
      "Epoch 487/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7429 - accuracy: 0.7721 - val_loss: 0.7757 - val_accuracy: 0.6982\n",
      "Epoch 488/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7501 - accuracy: 0.7644 - val_loss: 0.7678 - val_accuracy: 0.6990\n",
      "Epoch 489/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7556 - accuracy: 0.7700 - val_loss: 0.7538 - val_accuracy: 0.7212\n",
      "Epoch 490/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7389 - accuracy: 0.7829 - val_loss: 0.8411 - val_accuracy: 0.6325\n",
      "Epoch 491/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7499 - accuracy: 0.7717 - val_loss: 0.7932 - val_accuracy: 0.6762\n",
      "Epoch 492/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7544 - accuracy: 0.7606 - val_loss: 0.7802 - val_accuracy: 0.6995\n",
      "Epoch 493/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7364 - accuracy: 0.7687 - val_loss: 0.7450 - val_accuracy: 0.7345\n",
      "Epoch 494/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7480 - accuracy: 0.7806 - val_loss: 0.7622 - val_accuracy: 0.7017\n",
      "Epoch 495/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7433 - accuracy: 0.7627 - val_loss: 0.7584 - val_accuracy: 0.7178\n",
      "Epoch 496/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7463 - accuracy: 0.7731 - val_loss: 0.8093 - val_accuracy: 0.6660\n",
      "Epoch 497/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7430 - accuracy: 0.7794 - val_loss: 0.8093 - val_accuracy: 0.6795\n",
      "Epoch 498/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7354 - accuracy: 0.7713 - val_loss: 0.7926 - val_accuracy: 0.6900\n",
      "Epoch 499/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7401 - accuracy: 0.7756 - val_loss: 0.8280 - val_accuracy: 0.6687\n",
      "Epoch 500/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7540 - accuracy: 0.7717 - val_loss: 0.7752 - val_accuracy: 0.6942\n",
      "Epoch 501/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7614 - accuracy: 0.7527 - val_loss: 0.7178 - val_accuracy: 0.7523\n",
      "Epoch 502/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7725 - accuracy: 0.7623 - val_loss: 0.8361 - val_accuracy: 0.6585\n",
      "Epoch 503/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7634 - accuracy: 0.7695 - val_loss: 0.8227 - val_accuracy: 0.6690\n",
      "Epoch 504/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7427 - accuracy: 0.7667 - val_loss: 0.7553 - val_accuracy: 0.7180\n",
      "Epoch 505/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7435 - accuracy: 0.7712 - val_loss: 0.7791 - val_accuracy: 0.7130\n",
      "Epoch 506/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7371 - accuracy: 0.7801 - val_loss: 0.7827 - val_accuracy: 0.7080\n",
      "Epoch 507/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7296 - accuracy: 0.7751 - val_loss: 0.7863 - val_accuracy: 0.7050\n",
      "Epoch 508/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7292 - accuracy: 0.7813 - val_loss: 0.7834 - val_accuracy: 0.7003\n",
      "Epoch 509/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7357 - accuracy: 0.7787 - val_loss: 0.7948 - val_accuracy: 0.7040\n",
      "Epoch 510/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7335 - accuracy: 0.7809 - val_loss: 0.8750 - val_accuracy: 0.6310\n",
      "Epoch 511/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7474 - accuracy: 0.7657 - val_loss: 0.7450 - val_accuracy: 0.7435\n",
      "Epoch 512/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7402 - accuracy: 0.7694 - val_loss: 0.7647 - val_accuracy: 0.7193\n",
      "Epoch 513/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7334 - accuracy: 0.7806 - val_loss: 0.8391 - val_accuracy: 0.6510\n",
      "Epoch 514/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7382 - accuracy: 0.7790 - val_loss: 0.8054 - val_accuracy: 0.6755\n",
      "Epoch 515/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7323 - accuracy: 0.7766 - val_loss: 0.8272 - val_accuracy: 0.6762\n",
      "Epoch 516/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7456 - accuracy: 0.7645 - val_loss: 0.7394 - val_accuracy: 0.7365\n",
      "Epoch 517/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7486 - accuracy: 0.7746 - val_loss: 0.8188 - val_accuracy: 0.6683\n",
      "Epoch 518/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7393 - accuracy: 0.7761 - val_loss: 0.7862 - val_accuracy: 0.7023\n",
      "Epoch 519/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7326 - accuracy: 0.7819 - val_loss: 0.8046 - val_accuracy: 0.6768\n",
      "Epoch 520/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7284 - accuracy: 0.7719 - val_loss: 0.7634 - val_accuracy: 0.7212\n",
      "Epoch 521/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7306 - accuracy: 0.7771 - val_loss: 0.7591 - val_accuracy: 0.7310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 522/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7352 - accuracy: 0.7822 - val_loss: 0.8487 - val_accuracy: 0.6695\n",
      "Epoch 523/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7288 - accuracy: 0.7753 - val_loss: 0.8028 - val_accuracy: 0.6960\n",
      "Epoch 524/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7363 - accuracy: 0.7770 - val_loss: 0.7871 - val_accuracy: 0.7063\n",
      "Epoch 525/1000\n",
      "16000/16000 [==============================] - ETA: 0s - loss: 0.7308 - accuracy: 0.78 - 0s 3us/step - loss: 0.7401 - accuracy: 0.7812 - val_loss: 0.8115 - val_accuracy: 0.6705\n",
      "Epoch 526/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7398 - accuracy: 0.7756 - val_loss: 0.8019 - val_accuracy: 0.6710\n",
      "Epoch 527/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7404 - accuracy: 0.7661 - val_loss: 0.7922 - val_accuracy: 0.7042\n",
      "Epoch 528/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7301 - accuracy: 0.7749 - val_loss: 0.7964 - val_accuracy: 0.7032\n",
      "Epoch 529/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7348 - accuracy: 0.7736 - val_loss: 0.7759 - val_accuracy: 0.7245\n",
      "Epoch 530/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7303 - accuracy: 0.7768 - val_loss: 0.7843 - val_accuracy: 0.7190\n",
      "Epoch 531/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.7369 - accuracy: 0.7753 - val_loss: 0.7533 - val_accuracy: 0.7470\n",
      "Epoch 532/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7462 - accuracy: 0.7715 - val_loss: 0.7729 - val_accuracy: 0.7028\n",
      "Epoch 533/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7351 - accuracy: 0.7849 - val_loss: 0.8775 - val_accuracy: 0.6447\n",
      "Epoch 534/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.7324 - accuracy: 0.7768 - val_loss: 0.8851 - val_accuracy: 0.6250\n",
      "Epoch 535/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7668 - accuracy: 0.7648 - val_loss: 0.8084 - val_accuracy: 0.6852\n",
      "Epoch 536/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7694 - accuracy: 0.7436 - val_loss: 0.7488 - val_accuracy: 0.7470\n",
      "Epoch 537/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7394 - accuracy: 0.7822 - val_loss: 0.8082 - val_accuracy: 0.6898\n",
      "Epoch 538/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7293 - accuracy: 0.7838 - val_loss: 0.8936 - val_accuracy: 0.6130\n",
      "Epoch 539/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7437 - accuracy: 0.7711 - val_loss: 0.7773 - val_accuracy: 0.7235\n",
      "Epoch 540/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7361 - accuracy: 0.7673 - val_loss: 0.7571 - val_accuracy: 0.7365\n",
      "Epoch 541/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7317 - accuracy: 0.7871 - val_loss: 0.8742 - val_accuracy: 0.6202\n",
      "Epoch 542/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7327 - accuracy: 0.7733 - val_loss: 0.8087 - val_accuracy: 0.6960\n",
      "Epoch 543/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.7303 - accuracy: 0.7724 - val_loss: 0.7541 - val_accuracy: 0.7372\n",
      "Epoch 544/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7264 - accuracy: 0.7853 - val_loss: 0.8518 - val_accuracy: 0.6518\n",
      "Epoch 545/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7249 - accuracy: 0.7759 - val_loss: 0.7802 - val_accuracy: 0.7300\n",
      "Epoch 546/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7326 - accuracy: 0.7711 - val_loss: 0.7590 - val_accuracy: 0.7430\n",
      "Epoch 547/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7265 - accuracy: 0.7787 - val_loss: 0.8704 - val_accuracy: 0.6572\n",
      "Epoch 548/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7239 - accuracy: 0.7794 - val_loss: 0.8047 - val_accuracy: 0.7063\n",
      "Epoch 549/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7159 - accuracy: 0.7781 - val_loss: 0.7609 - val_accuracy: 0.7435\n",
      "Epoch 550/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7229 - accuracy: 0.7878 - val_loss: 0.8896 - val_accuracy: 0.6265\n",
      "Epoch 551/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7359 - accuracy: 0.7728 - val_loss: 0.7592 - val_accuracy: 0.7435\n",
      "Epoch 552/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7279 - accuracy: 0.7839 - val_loss: 0.8299 - val_accuracy: 0.6683\n",
      "Epoch 553/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7261 - accuracy: 0.7822 - val_loss: 0.8377 - val_accuracy: 0.6745\n",
      "Epoch 554/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7281 - accuracy: 0.7779 - val_loss: 0.8511 - val_accuracy: 0.6933\n",
      "Epoch 555/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7311 - accuracy: 0.7749 - val_loss: 0.8530 - val_accuracy: 0.6752\n",
      "Epoch 556/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7274 - accuracy: 0.7811 - val_loss: 0.7927 - val_accuracy: 0.7092\n",
      "Epoch 557/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7277 - accuracy: 0.7830 - val_loss: 0.8301 - val_accuracy: 0.6798\n",
      "Epoch 558/1000\n",
      "16000/16000 [==============================] - ETA: 0s - loss: 0.7452 - accuracy: 0.75 - 0s 3us/step - loss: 0.7299 - accuracy: 0.7778 - val_loss: 0.7768 - val_accuracy: 0.7120\n",
      "Epoch 559/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7359 - accuracy: 0.7754 - val_loss: 0.8063 - val_accuracy: 0.6820\n",
      "Epoch 560/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7384 - accuracy: 0.7772 - val_loss: 0.7969 - val_accuracy: 0.6938\n",
      "Epoch 561/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7390 - accuracy: 0.7691 - val_loss: 0.7959 - val_accuracy: 0.7305\n",
      "Epoch 562/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7391 - accuracy: 0.7729 - val_loss: 0.7920 - val_accuracy: 0.6988\n",
      "Epoch 563/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7386 - accuracy: 0.7836 - val_loss: 0.8459 - val_accuracy: 0.6490\n",
      "Epoch 564/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7532 - accuracy: 0.7671 - val_loss: 0.7565 - val_accuracy: 0.7390\n",
      "Epoch 565/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7508 - accuracy: 0.7635 - val_loss: 0.8040 - val_accuracy: 0.6920\n",
      "Epoch 566/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7492 - accuracy: 0.7835 - val_loss: 0.8600 - val_accuracy: 0.6510\n",
      "Epoch 567/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7345 - accuracy: 0.7672 - val_loss: 0.7558 - val_accuracy: 0.7455\n",
      "Epoch 568/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7310 - accuracy: 0.7786 - val_loss: 0.7940 - val_accuracy: 0.7045\n",
      "Epoch 569/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7306 - accuracy: 0.7837 - val_loss: 0.8093 - val_accuracy: 0.6795\n",
      "Epoch 570/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7266 - accuracy: 0.7719 - val_loss: 0.7300 - val_accuracy: 0.7580\n",
      "Epoch 571/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.7507 - accuracy: 0.7654 - val_loss: 0.7626 - val_accuracy: 0.7225\n",
      "Epoch 572/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7686 - accuracy: 0.7794 - val_loss: 0.8954 - val_accuracy: 0.6273\n",
      "Epoch 573/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7477 - accuracy: 0.7622 - val_loss: 0.7642 - val_accuracy: 0.7305\n",
      "Epoch 574/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7319 - accuracy: 0.7769 - val_loss: 0.7985 - val_accuracy: 0.6875\n",
      "Epoch 575/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7216 - accuracy: 0.7806 - val_loss: 0.8152 - val_accuracy: 0.6873\n",
      "Epoch 576/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7215 - accuracy: 0.7816 - val_loss: 0.7730 - val_accuracy: 0.7128\n",
      "Epoch 577/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7121 - accuracy: 0.7797 - val_loss: 0.8167 - val_accuracy: 0.6768\n",
      "Epoch 578/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7088 - accuracy: 0.7851 - val_loss: 0.8608 - val_accuracy: 0.6350\n",
      "Epoch 579/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7171 - accuracy: 0.7778 - val_loss: 0.7559 - val_accuracy: 0.7455\n",
      "Epoch 580/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7170 - accuracy: 0.7843 - val_loss: 0.8924 - val_accuracy: 0.6398\n",
      "Epoch 581/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7239 - accuracy: 0.7791 - val_loss: 0.7728 - val_accuracy: 0.7250\n",
      "Epoch 582/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7181 - accuracy: 0.7759 - val_loss: 0.7568 - val_accuracy: 0.7352\n",
      "Epoch 583/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7235 - accuracy: 0.7779 - val_loss: 0.8000 - val_accuracy: 0.7000\n",
      "Epoch 584/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.7162 - accuracy: 0.7924 - val_loss: 0.7785 - val_accuracy: 0.7193\n",
      "Epoch 585/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7183 - accuracy: 0.7708 - val_loss: 0.7398 - val_accuracy: 0.7477\n",
      "Epoch 586/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7182 - accuracy: 0.7908 - val_loss: 0.8419 - val_accuracy: 0.6683\n",
      "Epoch 587/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7096 - accuracy: 0.7812 - val_loss: 0.7940 - val_accuracy: 0.7235\n",
      "Epoch 588/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7134 - accuracy: 0.7876 - val_loss: 0.8496 - val_accuracy: 0.6557\n",
      "Epoch 589/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7325 - accuracy: 0.7811 - val_loss: 0.8315 - val_accuracy: 0.6770\n",
      "Epoch 590/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7371 - accuracy: 0.7644 - val_loss: 0.7441 - val_accuracy: 0.7415\n",
      "Epoch 591/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7179 - accuracy: 0.7860 - val_loss: 0.8428 - val_accuracy: 0.6695\n",
      "Epoch 592/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7075 - accuracy: 0.7919 - val_loss: 0.8105 - val_accuracy: 0.7013\n",
      "Epoch 593/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7069 - accuracy: 0.7764 - val_loss: 0.7381 - val_accuracy: 0.7473\n",
      "Epoch 594/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7010 - accuracy: 0.7922 - val_loss: 0.8403 - val_accuracy: 0.6622\n",
      "Epoch 595/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.7078 - accuracy: 0.7950 - val_loss: 0.8413 - val_accuracy: 0.6710\n",
      "Epoch 596/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7149 - accuracy: 0.7726 - val_loss: 0.7943 - val_accuracy: 0.7200\n",
      "Epoch 597/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7030 - accuracy: 0.7939 - val_loss: 0.8571 - val_accuracy: 0.6543\n",
      "Epoch 598/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7020 - accuracy: 0.7818 - val_loss: 0.7730 - val_accuracy: 0.7305\n",
      "Epoch 599/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7109 - accuracy: 0.7771 - val_loss: 0.8033 - val_accuracy: 0.7320\n",
      "Epoch 600/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7175 - accuracy: 0.7876 - val_loss: 0.8156 - val_accuracy: 0.6970\n",
      "Epoch 601/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7116 - accuracy: 0.7831 - val_loss: 0.8437 - val_accuracy: 0.6618\n",
      "Epoch 602/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7241 - accuracy: 0.7836 - val_loss: 0.8136 - val_accuracy: 0.7168\n",
      "Epoch 603/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7142 - accuracy: 0.7843 - val_loss: 0.8015 - val_accuracy: 0.7050\n",
      "Epoch 604/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7018 - accuracy: 0.7842 - val_loss: 0.7912 - val_accuracy: 0.7235\n",
      "Epoch 605/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7077 - accuracy: 0.7892 - val_loss: 0.7912 - val_accuracy: 0.7032\n",
      "Epoch 606/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7019 - accuracy: 0.7882 - val_loss: 0.8097 - val_accuracy: 0.6957\n",
      "Epoch 607/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7063 - accuracy: 0.7863 - val_loss: 0.8081 - val_accuracy: 0.7168\n",
      "Epoch 608/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7040 - accuracy: 0.7901 - val_loss: 0.7969 - val_accuracy: 0.7010\n",
      "Epoch 609/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7120 - accuracy: 0.7798 - val_loss: 0.7790 - val_accuracy: 0.7290\n",
      "Epoch 610/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7066 - accuracy: 0.7961 - val_loss: 0.8463 - val_accuracy: 0.6645\n",
      "Epoch 611/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7223 - accuracy: 0.7770 - val_loss: 0.7867 - val_accuracy: 0.7322\n",
      "Epoch 612/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7038 - accuracy: 0.7882 - val_loss: 0.8026 - val_accuracy: 0.7120\n",
      "Epoch 613/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7044 - accuracy: 0.7915 - val_loss: 0.8314 - val_accuracy: 0.6783\n",
      "Epoch 614/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7094 - accuracy: 0.7842 - val_loss: 0.8178 - val_accuracy: 0.7145\n",
      "Epoch 615/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7085 - accuracy: 0.7849 - val_loss: 0.7723 - val_accuracy: 0.7433\n",
      "Epoch 616/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6986 - accuracy: 0.7865 - val_loss: 0.7744 - val_accuracy: 0.7318\n",
      "Epoch 617/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6988 - accuracy: 0.7849 - val_loss: 0.7633 - val_accuracy: 0.7405\n",
      "Epoch 618/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7008 - accuracy: 0.7977 - val_loss: 0.8353 - val_accuracy: 0.6913\n",
      "Epoch 619/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7088 - accuracy: 0.7756 - val_loss: 0.7598 - val_accuracy: 0.7490\n",
      "Epoch 620/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7112 - accuracy: 0.7886 - val_loss: 0.8321 - val_accuracy: 0.6810\n",
      "Epoch 621/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6948 - accuracy: 0.7914 - val_loss: 0.7789 - val_accuracy: 0.7400\n",
      "Epoch 622/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7066 - accuracy: 0.7855 - val_loss: 0.7993 - val_accuracy: 0.7115\n",
      "Epoch 623/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7117 - accuracy: 0.7855 - val_loss: 0.8588 - val_accuracy: 0.6620\n",
      "Epoch 624/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7015 - accuracy: 0.7926 - val_loss: 0.8192 - val_accuracy: 0.7193\n",
      "Epoch 625/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6991 - accuracy: 0.7866 - val_loss: 0.8182 - val_accuracy: 0.7075\n",
      "Epoch 626/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7057 - accuracy: 0.7913 - val_loss: 0.9191 - val_accuracy: 0.6110\n",
      "Epoch 627/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7289 - accuracy: 0.7809 - val_loss: 0.8566 - val_accuracy: 0.6712\n",
      "Epoch 628/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7100 - accuracy: 0.7833 - val_loss: 0.8078 - val_accuracy: 0.7168\n",
      "Epoch 629/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7117 - accuracy: 0.7861 - val_loss: 0.8674 - val_accuracy: 0.6820\n",
      "Epoch 630/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6993 - accuracy: 0.7885 - val_loss: 0.7488 - val_accuracy: 0.7558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 631/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6982 - accuracy: 0.7838 - val_loss: 0.7897 - val_accuracy: 0.7318\n",
      "Epoch 632/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6921 - accuracy: 0.7958 - val_loss: 0.8293 - val_accuracy: 0.6902\n",
      "Epoch 633/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6873 - accuracy: 0.7947 - val_loss: 0.8116 - val_accuracy: 0.7097\n",
      "Epoch 634/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6866 - accuracy: 0.7971 - val_loss: 0.8649 - val_accuracy: 0.6860\n",
      "Epoch 635/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7068 - accuracy: 0.7898 - val_loss: 0.8734 - val_accuracy: 0.6622\n",
      "Epoch 636/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6997 - accuracy: 0.7857 - val_loss: 0.8342 - val_accuracy: 0.7050\n",
      "Epoch 637/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6826 - accuracy: 0.7955 - val_loss: 0.8178 - val_accuracy: 0.6998\n",
      "Epoch 638/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6929 - accuracy: 0.7929 - val_loss: 0.7837 - val_accuracy: 0.7415\n",
      "Epoch 639/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7024 - accuracy: 0.7792 - val_loss: 0.7927 - val_accuracy: 0.7285\n",
      "Epoch 640/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7084 - accuracy: 0.7788 - val_loss: 0.7899 - val_accuracy: 0.7390\n",
      "Epoch 641/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7090 - accuracy: 0.7854 - val_loss: 0.8834 - val_accuracy: 0.6747\n",
      "Epoch 642/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7073 - accuracy: 0.7931 - val_loss: 0.8886 - val_accuracy: 0.6478\n",
      "Epoch 643/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6985 - accuracy: 0.7927 - val_loss: 0.8488 - val_accuracy: 0.6865\n",
      "Epoch 644/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6972 - accuracy: 0.7859 - val_loss: 0.8066 - val_accuracy: 0.7362\n",
      "Epoch 645/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6958 - accuracy: 0.7872 - val_loss: 0.8478 - val_accuracy: 0.6785\n",
      "Epoch 646/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6895 - accuracy: 0.7939 - val_loss: 0.8355 - val_accuracy: 0.6825\n",
      "Epoch 647/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6868 - accuracy: 0.7937 - val_loss: 0.8095 - val_accuracy: 0.7325\n",
      "Epoch 648/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6910 - accuracy: 0.7964 - val_loss: 0.9269 - val_accuracy: 0.6263\n",
      "Epoch 649/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7094 - accuracy: 0.7903 - val_loss: 0.8832 - val_accuracy: 0.6672\n",
      "Epoch 650/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6832 - accuracy: 0.7846 - val_loss: 0.8157 - val_accuracy: 0.7050\n",
      "Epoch 651/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6848 - accuracy: 0.7912 - val_loss: 0.8020 - val_accuracy: 0.7168\n",
      "Epoch 652/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6927 - accuracy: 0.7914 - val_loss: 0.8442 - val_accuracy: 0.6858\n",
      "Epoch 653/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6982 - accuracy: 0.7943 - val_loss: 0.8350 - val_accuracy: 0.6970\n",
      "Epoch 654/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7081 - accuracy: 0.7790 - val_loss: 0.7928 - val_accuracy: 0.7440\n",
      "Epoch 655/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6877 - accuracy: 0.7911 - val_loss: 0.7936 - val_accuracy: 0.7433\n",
      "Epoch 656/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6954 - accuracy: 0.7882 - val_loss: 0.8035 - val_accuracy: 0.7280\n",
      "Epoch 657/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6953 - accuracy: 0.7943 - val_loss: 0.8966 - val_accuracy: 0.6525\n",
      "Epoch 658/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6847 - accuracy: 0.7940 - val_loss: 0.7709 - val_accuracy: 0.7485\n",
      "Epoch 659/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6899 - accuracy: 0.7905 - val_loss: 0.8369 - val_accuracy: 0.7007\n",
      "Epoch 660/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6787 - accuracy: 0.8061 - val_loss: 0.9263 - val_accuracy: 0.6472\n",
      "Epoch 661/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6888 - accuracy: 0.7826 - val_loss: 0.7757 - val_accuracy: 0.7625\n",
      "Epoch 662/1000\n",
      "16000/16000 [==============================] - 0s 5us/step - loss: 0.6858 - accuracy: 0.7891 - val_loss: 0.7941 - val_accuracy: 0.7232\n",
      "Epoch 663/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.6888 - accuracy: 0.7959 - val_loss: 0.8954 - val_accuracy: 0.6325\n",
      "Epoch 664/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.6846 - accuracy: 0.8003 - val_loss: 0.8675 - val_accuracy: 0.6755\n",
      "Epoch 665/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6801 - accuracy: 0.7901 - val_loss: 0.7986 - val_accuracy: 0.7405\n",
      "Epoch 666/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6853 - accuracy: 0.7882 - val_loss: 0.8035 - val_accuracy: 0.7390\n",
      "Epoch 667/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6984 - accuracy: 0.7936 - val_loss: 0.8822 - val_accuracy: 0.6582\n",
      "Epoch 668/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6840 - accuracy: 0.7965 - val_loss: 0.8301 - val_accuracy: 0.7193\n",
      "Epoch 669/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6787 - accuracy: 0.7939 - val_loss: 0.7761 - val_accuracy: 0.7440\n",
      "Epoch 670/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6813 - accuracy: 0.7971 - val_loss: 0.8298 - val_accuracy: 0.7090\n",
      "Epoch 671/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6888 - accuracy: 0.7929 - val_loss: 0.8610 - val_accuracy: 0.6963\n",
      "Epoch 672/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6886 - accuracy: 0.7881 - val_loss: 0.8204 - val_accuracy: 0.7250\n",
      "Epoch 673/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6969 - accuracy: 0.7851 - val_loss: 0.8147 - val_accuracy: 0.7268\n",
      "Epoch 674/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6947 - accuracy: 0.8026 - val_loss: 0.8418 - val_accuracy: 0.6975\n",
      "Epoch 675/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6889 - accuracy: 0.7793 - val_loss: 0.7987 - val_accuracy: 0.7492\n",
      "Epoch 676/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6823 - accuracy: 0.7976 - val_loss: 0.8851 - val_accuracy: 0.6780\n",
      "Epoch 677/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6821 - accuracy: 0.7947 - val_loss: 0.7992 - val_accuracy: 0.7473\n",
      "Epoch 678/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6849 - accuracy: 0.7901 - val_loss: 0.8221 - val_accuracy: 0.7305\n",
      "Epoch 679/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6714 - accuracy: 0.7987 - val_loss: 0.8272 - val_accuracy: 0.7207\n",
      "Epoch 680/1000\n",
      "16000/16000 [==============================] - 0s 5us/step - loss: 0.6689 - accuracy: 0.8042 - val_loss: 0.8438 - val_accuracy: 0.7032\n",
      "Epoch 681/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6715 - accuracy: 0.8037 - val_loss: 0.8435 - val_accuracy: 0.7072\n",
      "Epoch 682/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6867 - accuracy: 0.7869 - val_loss: 0.7883 - val_accuracy: 0.7588\n",
      "Epoch 683/1000\n",
      "16000/16000 [==============================] - 0s 6us/step - loss: 0.6847 - accuracy: 0.7954 - val_loss: 0.8615 - val_accuracy: 0.7105\n",
      "Epoch 684/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6848 - accuracy: 0.7924 - val_loss: 0.8797 - val_accuracy: 0.6965\n",
      "Epoch 685/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6986 - accuracy: 0.7945 - val_loss: 0.8677 - val_accuracy: 0.6975\n",
      "Epoch 686/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7162 - accuracy: 0.7894 - val_loss: 0.8521 - val_accuracy: 0.6960\n",
      "Epoch 687/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6977 - accuracy: 0.7851 - val_loss: 0.8731 - val_accuracy: 0.6985\n",
      "Epoch 688/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6980 - accuracy: 0.7846 - val_loss: 0.7757 - val_accuracy: 0.7480\n",
      "Epoch 689/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6985 - accuracy: 0.7894 - val_loss: 0.9116 - val_accuracy: 0.6645\n",
      "Epoch 690/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6900 - accuracy: 0.7972 - val_loss: 0.8764 - val_accuracy: 0.6787\n",
      "Epoch 691/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6878 - accuracy: 0.7864 - val_loss: 0.8020 - val_accuracy: 0.7412\n",
      "Epoch 692/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6875 - accuracy: 0.7985 - val_loss: 0.8771 - val_accuracy: 0.6595\n",
      "Epoch 693/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6876 - accuracy: 0.7942 - val_loss: 0.8914 - val_accuracy: 0.6700\n",
      "Epoch 694/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6747 - accuracy: 0.7947 - val_loss: 0.8369 - val_accuracy: 0.7100\n",
      "Epoch 695/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6844 - accuracy: 0.7900 - val_loss: 0.8331 - val_accuracy: 0.7303\n",
      "Epoch 696/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6717 - accuracy: 0.8006 - val_loss: 0.8547 - val_accuracy: 0.7003\n",
      "Epoch 697/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6775 - accuracy: 0.7907 - val_loss: 0.7923 - val_accuracy: 0.7582\n",
      "Epoch 698/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6843 - accuracy: 0.7962 - val_loss: 0.9042 - val_accuracy: 0.6665\n",
      "Epoch 699/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6914 - accuracy: 0.7923 - val_loss: 0.9120 - val_accuracy: 0.6775\n",
      "Epoch 700/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6878 - accuracy: 0.7938 - val_loss: 0.8642 - val_accuracy: 0.6973\n",
      "Epoch 701/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6791 - accuracy: 0.7993 - val_loss: 0.8765 - val_accuracy: 0.6848\n",
      "Epoch 702/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6686 - accuracy: 0.7999 - val_loss: 0.8455 - val_accuracy: 0.7060\n",
      "Epoch 703/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6704 - accuracy: 0.8005 - val_loss: 0.8208 - val_accuracy: 0.7300\n",
      "Epoch 704/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6645 - accuracy: 0.8061 - val_loss: 0.8703 - val_accuracy: 0.6837\n",
      "Epoch 705/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6620 - accuracy: 0.8037 - val_loss: 0.8196 - val_accuracy: 0.7475\n",
      "Epoch 706/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6765 - accuracy: 0.7934 - val_loss: 0.8327 - val_accuracy: 0.7362\n",
      "Epoch 707/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6696 - accuracy: 0.8036 - val_loss: 0.8846 - val_accuracy: 0.6733\n",
      "Epoch 708/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6665 - accuracy: 0.7986 - val_loss: 0.8781 - val_accuracy: 0.7003\n",
      "Epoch 709/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6742 - accuracy: 0.8016 - val_loss: 0.8983 - val_accuracy: 0.6823\n",
      "Epoch 710/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6727 - accuracy: 0.7928 - val_loss: 0.8806 - val_accuracy: 0.7115\n",
      "Epoch 711/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6826 - accuracy: 0.7976 - val_loss: 0.8489 - val_accuracy: 0.7120\n",
      "Epoch 712/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6853 - accuracy: 0.8026 - val_loss: 0.8565 - val_accuracy: 0.7013\n",
      "Epoch 713/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6765 - accuracy: 0.7919 - val_loss: 0.8297 - val_accuracy: 0.7335\n",
      "Epoch 714/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6656 - accuracy: 0.8012 - val_loss: 0.8180 - val_accuracy: 0.7375\n",
      "Epoch 715/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6736 - accuracy: 0.8069 - val_loss: 0.9408 - val_accuracy: 0.6482\n",
      "Epoch 716/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6826 - accuracy: 0.7950 - val_loss: 0.8935 - val_accuracy: 0.7220\n",
      "Epoch 717/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6853 - accuracy: 0.7934 - val_loss: 0.8397 - val_accuracy: 0.7120\n",
      "Epoch 718/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6795 - accuracy: 0.7957 - val_loss: 0.8563 - val_accuracy: 0.7013\n",
      "Epoch 719/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6867 - accuracy: 0.7956 - val_loss: 0.9098 - val_accuracy: 0.6647\n",
      "Epoch 720/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6674 - accuracy: 0.7992 - val_loss: 0.8731 - val_accuracy: 0.6998\n",
      "Epoch 721/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6715 - accuracy: 0.7937 - val_loss: 0.7863 - val_accuracy: 0.7548\n",
      "Epoch 722/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6751 - accuracy: 0.7949 - val_loss: 0.7999 - val_accuracy: 0.7515\n",
      "Epoch 723/1000\n",
      "16000/16000 [==============================] - 0s 5us/step - loss: 0.6684 - accuracy: 0.8002 - val_loss: 0.8475 - val_accuracy: 0.7205\n",
      "Epoch 724/1000\n",
      "16000/16000 [==============================] - 0s 5us/step - loss: 0.6652 - accuracy: 0.8014 - val_loss: 0.8725 - val_accuracy: 0.6950\n",
      "Epoch 725/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6648 - accuracy: 0.8055 - val_loss: 0.9186 - val_accuracy: 0.6747\n",
      "Epoch 726/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6803 - accuracy: 0.7959 - val_loss: 0.8732 - val_accuracy: 0.6877\n",
      "Epoch 727/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6780 - accuracy: 0.7908 - val_loss: 0.8630 - val_accuracy: 0.6902\n",
      "Epoch 728/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6635 - accuracy: 0.8033 - val_loss: 0.8069 - val_accuracy: 0.7515\n",
      "Epoch 729/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6586 - accuracy: 0.8077 - val_loss: 0.8636 - val_accuracy: 0.7110\n",
      "Epoch 730/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6592 - accuracy: 0.8061 - val_loss: 0.8748 - val_accuracy: 0.7048\n",
      "Epoch 731/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6579 - accuracy: 0.7939 - val_loss: 0.8493 - val_accuracy: 0.7125\n",
      "Epoch 732/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6529 - accuracy: 0.8086 - val_loss: 0.8350 - val_accuracy: 0.7350\n",
      "Epoch 733/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6607 - accuracy: 0.7996 - val_loss: 0.8238 - val_accuracy: 0.7490\n",
      "Epoch 734/1000\n",
      "16000/16000 [==============================] - ETA: 0s - loss: 0.6423 - accuracy: 0.83 - 0s 3us/step - loss: 0.6645 - accuracy: 0.8031 - val_loss: 0.8597 - val_accuracy: 0.7232\n",
      "Epoch 735/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6765 - accuracy: 0.8028 - val_loss: 0.8543 - val_accuracy: 0.7185\n",
      "Epoch 736/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6689 - accuracy: 0.8003 - val_loss: 0.8569 - val_accuracy: 0.7268\n",
      "Epoch 737/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6670 - accuracy: 0.8042 - val_loss: 0.9353 - val_accuracy: 0.6827\n",
      "Epoch 738/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6793 - accuracy: 0.7854 - val_loss: 0.8124 - val_accuracy: 0.7485\n",
      "Epoch 739/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6718 - accuracy: 0.8017 - val_loss: 0.8414 - val_accuracy: 0.7268\n",
      "Epoch 740/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6563 - accuracy: 0.8069 - val_loss: 0.8370 - val_accuracy: 0.7253\n",
      "Epoch 741/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6594 - accuracy: 0.8083 - val_loss: 0.8891 - val_accuracy: 0.6697\n",
      "Epoch 742/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6594 - accuracy: 0.7984 - val_loss: 0.9112 - val_accuracy: 0.6942\n",
      "Epoch 743/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6559 - accuracy: 0.8053 - val_loss: 0.8739 - val_accuracy: 0.7115\n",
      "Epoch 744/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6642 - accuracy: 0.7955 - val_loss: 0.8368 - val_accuracy: 0.7500\n",
      "Epoch 745/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6743 - accuracy: 0.8001 - val_loss: 0.8615 - val_accuracy: 0.6905\n",
      "Epoch 746/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6619 - accuracy: 0.8077 - val_loss: 0.8508 - val_accuracy: 0.7262\n",
      "Epoch 747/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6546 - accuracy: 0.8072 - val_loss: 0.8672 - val_accuracy: 0.7245\n",
      "Epoch 748/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6559 - accuracy: 0.8117 - val_loss: 0.8869 - val_accuracy: 0.7075\n",
      "Epoch 749/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6414 - accuracy: 0.8074 - val_loss: 0.8394 - val_accuracy: 0.7380\n",
      "Epoch 750/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6478 - accuracy: 0.8120 - val_loss: 0.8873 - val_accuracy: 0.6985\n",
      "Epoch 751/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6577 - accuracy: 0.8011 - val_loss: 0.9148 - val_accuracy: 0.6675\n",
      "Epoch 752/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6635 - accuracy: 0.7979 - val_loss: 0.8694 - val_accuracy: 0.7160\n",
      "Epoch 753/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6722 - accuracy: 0.7881 - val_loss: 0.8420 - val_accuracy: 0.7365\n",
      "Epoch 754/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6663 - accuracy: 0.8062 - val_loss: 0.9784 - val_accuracy: 0.6220\n",
      "Epoch 755/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6793 - accuracy: 0.7951 - val_loss: 0.9431 - val_accuracy: 0.6575\n",
      "Epoch 756/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6892 - accuracy: 0.7896 - val_loss: 0.8758 - val_accuracy: 0.7080\n",
      "Epoch 757/1000\n",
      "16000/16000 [==============================] - ETA: 0s - loss: 0.6828 - accuracy: 0.78 - 0s 3us/step - loss: 0.6848 - accuracy: 0.7812 - val_loss: 0.8009 - val_accuracy: 0.7663\n",
      "Epoch 758/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6762 - accuracy: 0.7983 - val_loss: 0.8278 - val_accuracy: 0.7430\n",
      "Epoch 759/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6789 - accuracy: 0.7938 - val_loss: 0.8809 - val_accuracy: 0.7015\n",
      "Epoch 760/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6757 - accuracy: 0.8041 - val_loss: 0.9758 - val_accuracy: 0.6405\n",
      "Epoch 761/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6880 - accuracy: 0.7923 - val_loss: 0.8766 - val_accuracy: 0.7103\n",
      "Epoch 762/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6760 - accuracy: 0.7939 - val_loss: 0.8877 - val_accuracy: 0.6923\n",
      "Epoch 763/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6791 - accuracy: 0.7947 - val_loss: 0.8333 - val_accuracy: 0.7517\n",
      "Epoch 764/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6654 - accuracy: 0.7916 - val_loss: 0.8058 - val_accuracy: 0.7703\n",
      "Epoch 765/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6741 - accuracy: 0.8052 - val_loss: 1.0094 - val_accuracy: 0.6160\n",
      "Epoch 766/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6684 - accuracy: 0.8008 - val_loss: 0.9242 - val_accuracy: 0.6587\n",
      "Epoch 767/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6631 - accuracy: 0.7989 - val_loss: 0.8698 - val_accuracy: 0.7343\n",
      "Epoch 768/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6581 - accuracy: 0.7964 - val_loss: 0.8642 - val_accuracy: 0.7398\n",
      "Epoch 769/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6680 - accuracy: 0.8041 - val_loss: 0.9202 - val_accuracy: 0.6750\n",
      "Epoch 770/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6534 - accuracy: 0.8074 - val_loss: 0.8665 - val_accuracy: 0.7260\n",
      "Epoch 771/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6596 - accuracy: 0.7988 - val_loss: 0.8636 - val_accuracy: 0.7293\n",
      "Epoch 772/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6539 - accuracy: 0.8071 - val_loss: 0.8796 - val_accuracy: 0.7197\n",
      "Epoch 773/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6521 - accuracy: 0.8080 - val_loss: 0.8392 - val_accuracy: 0.7485\n",
      "Epoch 774/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6799 - accuracy: 0.7825 - val_loss: 0.8471 - val_accuracy: 0.7592\n",
      "Epoch 775/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6752 - accuracy: 0.8049 - val_loss: 0.9331 - val_accuracy: 0.6680\n",
      "Epoch 776/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6750 - accuracy: 0.8018 - val_loss: 0.8788 - val_accuracy: 0.7038\n",
      "Epoch 777/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6610 - accuracy: 0.8001 - val_loss: 0.8516 - val_accuracy: 0.7395\n",
      "Epoch 778/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6638 - accuracy: 0.7996 - val_loss: 0.8543 - val_accuracy: 0.7358\n",
      "Epoch 779/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6680 - accuracy: 0.7983 - val_loss: 0.9176 - val_accuracy: 0.6890\n",
      "Epoch 780/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6621 - accuracy: 0.8055 - val_loss: 0.8309 - val_accuracy: 0.7415\n",
      "Epoch 781/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6614 - accuracy: 0.8043 - val_loss: 0.9054 - val_accuracy: 0.7005\n",
      "Epoch 782/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6640 - accuracy: 0.8054 - val_loss: 0.9737 - val_accuracy: 0.6447\n",
      "Epoch 783/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6988 - accuracy: 0.7934 - val_loss: 0.9108 - val_accuracy: 0.6927\n",
      "Epoch 784/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7198 - accuracy: 0.7729 - val_loss: 0.8408 - val_accuracy: 0.7442\n",
      "Epoch 785/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6851 - accuracy: 0.7949 - val_loss: 0.9159 - val_accuracy: 0.7088\n",
      "Epoch 786/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6742 - accuracy: 0.8016 - val_loss: 0.9148 - val_accuracy: 0.6917\n",
      "Epoch 787/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6591 - accuracy: 0.8037 - val_loss: 0.8857 - val_accuracy: 0.7168\n",
      "Epoch 788/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6565 - accuracy: 0.8096 - val_loss: 0.9443 - val_accuracy: 0.6727\n",
      "Epoch 789/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6499 - accuracy: 0.8076 - val_loss: 0.8594 - val_accuracy: 0.7343\n",
      "Epoch 790/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6498 - accuracy: 0.7977 - val_loss: 0.9016 - val_accuracy: 0.6967\n",
      "Epoch 791/1000\n",
      "16000/16000 [==============================] - ETA: 0s - loss: 0.6258 - accuracy: 0.78 - 0s 3us/step - loss: 0.6471 - accuracy: 0.8086 - val_loss: 0.8944 - val_accuracy: 0.7092\n",
      "Epoch 792/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6480 - accuracy: 0.8067 - val_loss: 0.8623 - val_accuracy: 0.7462\n",
      "Epoch 793/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6417 - accuracy: 0.8053 - val_loss: 0.8567 - val_accuracy: 0.7430\n",
      "Epoch 794/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6446 - accuracy: 0.8093 - val_loss: 0.9180 - val_accuracy: 0.6795\n",
      "Epoch 795/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6535 - accuracy: 0.8048 - val_loss: 0.9171 - val_accuracy: 0.7135\n",
      "Epoch 796/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6464 - accuracy: 0.8017 - val_loss: 0.8328 - val_accuracy: 0.7582\n",
      "Epoch 797/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6713 - accuracy: 0.7938 - val_loss: 0.8709 - val_accuracy: 0.7452\n",
      "Epoch 798/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6744 - accuracy: 0.8036 - val_loss: 1.0106 - val_accuracy: 0.6395\n",
      "Epoch 799/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6751 - accuracy: 0.7904 - val_loss: 0.8575 - val_accuracy: 0.7327\n",
      "Epoch 800/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6674 - accuracy: 0.7949 - val_loss: 0.8704 - val_accuracy: 0.7390\n",
      "Epoch 801/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6500 - accuracy: 0.8151 - val_loss: 0.9309 - val_accuracy: 0.6910\n",
      "Epoch 802/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6525 - accuracy: 0.7997 - val_loss: 0.8543 - val_accuracy: 0.7402\n",
      "Epoch 803/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6487 - accuracy: 0.8094 - val_loss: 0.8683 - val_accuracy: 0.7303\n",
      "Epoch 804/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6587 - accuracy: 0.8033 - val_loss: 0.9051 - val_accuracy: 0.7067\n",
      "Epoch 805/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6459 - accuracy: 0.8089 - val_loss: 0.8667 - val_accuracy: 0.7360\n",
      "Epoch 806/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6375 - accuracy: 0.8116 - val_loss: 0.8848 - val_accuracy: 0.7325\n",
      "Epoch 807/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6441 - accuracy: 0.8163 - val_loss: 0.9577 - val_accuracy: 0.6633\n",
      "Epoch 808/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6680 - accuracy: 0.8028 - val_loss: 0.9390 - val_accuracy: 0.6880\n",
      "Epoch 809/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6574 - accuracy: 0.7989 - val_loss: 0.8275 - val_accuracy: 0.7673\n",
      "Epoch 810/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6449 - accuracy: 0.8037 - val_loss: 0.8740 - val_accuracy: 0.7345\n",
      "Epoch 811/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6534 - accuracy: 0.8110 - val_loss: 0.9993 - val_accuracy: 0.6308\n",
      "Epoch 812/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6476 - accuracy: 0.8083 - val_loss: 0.9260 - val_accuracy: 0.7120\n",
      "Epoch 813/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6493 - accuracy: 0.7991 - val_loss: 0.8623 - val_accuracy: 0.7590\n",
      "Epoch 814/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6492 - accuracy: 0.8114 - val_loss: 0.9859 - val_accuracy: 0.6668\n",
      "Epoch 815/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6432 - accuracy: 0.8095 - val_loss: 0.8908 - val_accuracy: 0.7203\n",
      "Epoch 816/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6373 - accuracy: 0.8044 - val_loss: 0.8656 - val_accuracy: 0.7418\n",
      "Epoch 817/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6349 - accuracy: 0.8131 - val_loss: 0.9037 - val_accuracy: 0.7028\n",
      "Epoch 818/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6328 - accuracy: 0.8107 - val_loss: 0.8909 - val_accuracy: 0.7178\n",
      "Epoch 819/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6287 - accuracy: 0.8171 - val_loss: 0.9450 - val_accuracy: 0.6720\n",
      "Epoch 820/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6406 - accuracy: 0.8090 - val_loss: 0.9227 - val_accuracy: 0.6970\n",
      "Epoch 821/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6376 - accuracy: 0.8051 - val_loss: 0.9002 - val_accuracy: 0.7155\n",
      "Epoch 822/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6351 - accuracy: 0.8084 - val_loss: 0.8608 - val_accuracy: 0.7315\n",
      "Epoch 823/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6285 - accuracy: 0.8202 - val_loss: 0.9211 - val_accuracy: 0.6950\n",
      "Epoch 824/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6357 - accuracy: 0.8021 - val_loss: 0.8531 - val_accuracy: 0.7617\n",
      "Epoch 825/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6425 - accuracy: 0.8089 - val_loss: 0.9057 - val_accuracy: 0.7172\n",
      "Epoch 826/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6436 - accuracy: 0.8145 - val_loss: 0.9410 - val_accuracy: 0.6800\n",
      "Epoch 827/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6317 - accuracy: 0.8188 - val_loss: 0.9466 - val_accuracy: 0.6842\n",
      "Epoch 828/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6324 - accuracy: 0.8121 - val_loss: 0.9140 - val_accuracy: 0.7165\n",
      "Epoch 829/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6345 - accuracy: 0.8084 - val_loss: 0.8887 - val_accuracy: 0.7347\n",
      "Epoch 830/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6406 - accuracy: 0.8122 - val_loss: 0.9528 - val_accuracy: 0.6862\n",
      "Epoch 831/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6492 - accuracy: 0.8091 - val_loss: 0.9673 - val_accuracy: 0.6708\n",
      "Epoch 832/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6408 - accuracy: 0.8068 - val_loss: 0.9399 - val_accuracy: 0.6950\n",
      "Epoch 833/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6338 - accuracy: 0.8101 - val_loss: 0.8647 - val_accuracy: 0.7390\n",
      "Epoch 834/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6376 - accuracy: 0.8032 - val_loss: 0.8906 - val_accuracy: 0.7400\n",
      "Epoch 835/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6533 - accuracy: 0.8096 - val_loss: 0.9465 - val_accuracy: 0.6780\n",
      "Epoch 836/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6537 - accuracy: 0.8102 - val_loss: 0.9742 - val_accuracy: 0.6528\n",
      "Epoch 837/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6526 - accuracy: 0.7909 - val_loss: 0.8405 - val_accuracy: 0.7710\n",
      "Epoch 838/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6642 - accuracy: 0.8009 - val_loss: 0.9234 - val_accuracy: 0.6865\n",
      "Epoch 839/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6464 - accuracy: 0.8178 - val_loss: 0.9337 - val_accuracy: 0.6960\n",
      "Epoch 840/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6318 - accuracy: 0.8066 - val_loss: 0.8996 - val_accuracy: 0.7295\n",
      "Epoch 841/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6212 - accuracy: 0.8206 - val_loss: 0.9060 - val_accuracy: 0.7115\n",
      "Epoch 842/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6271 - accuracy: 0.8132 - val_loss: 0.9038 - val_accuracy: 0.7153\n",
      "Epoch 843/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6327 - accuracy: 0.8091 - val_loss: 0.8808 - val_accuracy: 0.7473\n",
      "Epoch 844/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6478 - accuracy: 0.8108 - val_loss: 0.9101 - val_accuracy: 0.7088\n",
      "Epoch 845/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6481 - accuracy: 0.8076 - val_loss: 0.9182 - val_accuracy: 0.7088\n",
      "Epoch 846/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6410 - accuracy: 0.8144 - val_loss: 0.9084 - val_accuracy: 0.7080\n",
      "Epoch 847/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6488 - accuracy: 0.8077 - val_loss: 0.8846 - val_accuracy: 0.7243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 848/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6497 - accuracy: 0.8039 - val_loss: 0.9233 - val_accuracy: 0.7128\n",
      "Epoch 849/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6627 - accuracy: 0.8031 - val_loss: 0.9572 - val_accuracy: 0.6858\n",
      "Epoch 850/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6576 - accuracy: 0.8024 - val_loss: 0.8870 - val_accuracy: 0.7203\n",
      "Epoch 851/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6333 - accuracy: 0.8123 - val_loss: 0.8873 - val_accuracy: 0.7290\n",
      "Epoch 852/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6373 - accuracy: 0.8106 - val_loss: 0.9080 - val_accuracy: 0.7115\n",
      "Epoch 853/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6463 - accuracy: 0.8139 - val_loss: 0.9043 - val_accuracy: 0.7110\n",
      "Epoch 854/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6467 - accuracy: 0.7930 - val_loss: 0.8562 - val_accuracy: 0.7638\n",
      "Epoch 855/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6696 - accuracy: 0.7983 - val_loss: 0.9712 - val_accuracy: 0.6875\n",
      "Epoch 856/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6724 - accuracy: 0.8092 - val_loss: 1.0388 - val_accuracy: 0.6315\n",
      "Epoch 857/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6892 - accuracy: 0.7771 - val_loss: 0.8167 - val_accuracy: 0.7812\n",
      "Epoch 858/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6619 - accuracy: 0.8121 - val_loss: 0.9585 - val_accuracy: 0.6628\n",
      "Epoch 859/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6417 - accuracy: 0.8043 - val_loss: 0.8727 - val_accuracy: 0.7582\n",
      "Epoch 860/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6420 - accuracy: 0.8092 - val_loss: 0.9195 - val_accuracy: 0.7017\n",
      "Epoch 861/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6427 - accuracy: 0.8130 - val_loss: 0.9356 - val_accuracy: 0.6973\n",
      "Epoch 862/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6273 - accuracy: 0.8131 - val_loss: 0.8910 - val_accuracy: 0.7362\n",
      "Epoch 863/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6336 - accuracy: 0.8100 - val_loss: 0.8560 - val_accuracy: 0.7485\n",
      "Epoch 864/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6369 - accuracy: 0.8084 - val_loss: 0.9358 - val_accuracy: 0.6960\n",
      "Epoch 865/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6573 - accuracy: 0.8116 - val_loss: 0.9431 - val_accuracy: 0.7040\n",
      "Epoch 866/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6488 - accuracy: 0.7993 - val_loss: 0.8938 - val_accuracy: 0.7205\n",
      "Epoch 867/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6325 - accuracy: 0.8202 - val_loss: 0.9045 - val_accuracy: 0.7103\n",
      "Epoch 868/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6274 - accuracy: 0.8062 - val_loss: 0.8748 - val_accuracy: 0.7448\n",
      "Epoch 869/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6272 - accuracy: 0.8140 - val_loss: 0.9525 - val_accuracy: 0.6895\n",
      "Epoch 870/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6297 - accuracy: 0.8175 - val_loss: 0.9704 - val_accuracy: 0.6725\n",
      "Epoch 871/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6250 - accuracy: 0.8136 - val_loss: 0.9376 - val_accuracy: 0.7003\n",
      "Epoch 872/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6188 - accuracy: 0.8126 - val_loss: 0.9420 - val_accuracy: 0.7053\n",
      "Epoch 873/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6207 - accuracy: 0.8217 - val_loss: 0.9350 - val_accuracy: 0.7130\n",
      "Epoch 874/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6185 - accuracy: 0.8168 - val_loss: 0.9093 - val_accuracy: 0.7293\n",
      "Epoch 875/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6232 - accuracy: 0.8146 - val_loss: 0.8869 - val_accuracy: 0.7437\n",
      "Epoch 876/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6178 - accuracy: 0.8126 - val_loss: 0.9164 - val_accuracy: 0.7228\n",
      "Epoch 877/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6212 - accuracy: 0.8194 - val_loss: 1.0004 - val_accuracy: 0.6500\n",
      "Epoch 878/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6267 - accuracy: 0.8124 - val_loss: 0.9261 - val_accuracy: 0.7150\n",
      "Epoch 879/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6270 - accuracy: 0.8096 - val_loss: 0.8725 - val_accuracy: 0.7607\n",
      "Epoch 880/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6246 - accuracy: 0.8106 - val_loss: 0.8402 - val_accuracy: 0.7725\n",
      "Epoch 881/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6251 - accuracy: 0.8184 - val_loss: 0.9661 - val_accuracy: 0.6747\n",
      "Epoch 882/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6219 - accuracy: 0.8148 - val_loss: 0.9313 - val_accuracy: 0.7090\n",
      "Epoch 883/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6185 - accuracy: 0.8211 - val_loss: 0.9670 - val_accuracy: 0.6810\n",
      "Epoch 884/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6140 - accuracy: 0.8183 - val_loss: 0.9089 - val_accuracy: 0.7260\n",
      "Epoch 885/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6170 - accuracy: 0.8136 - val_loss: 0.9275 - val_accuracy: 0.7225\n",
      "Epoch 886/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6150 - accuracy: 0.8226 - val_loss: 0.9378 - val_accuracy: 0.7070\n",
      "Epoch 887/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6125 - accuracy: 0.8251 - val_loss: 0.9610 - val_accuracy: 0.6810\n",
      "Epoch 888/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6260 - accuracy: 0.8121 - val_loss: 0.9932 - val_accuracy: 0.6783\n",
      "Epoch 889/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6172 - accuracy: 0.8156 - val_loss: 0.8569 - val_accuracy: 0.7735\n",
      "Epoch 890/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6422 - accuracy: 0.8025 - val_loss: 0.8956 - val_accuracy: 0.7487\n",
      "Epoch 891/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6366 - accuracy: 0.8154 - val_loss: 1.0799 - val_accuracy: 0.6115\n",
      "Epoch 892/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6451 - accuracy: 0.8011 - val_loss: 0.8735 - val_accuracy: 0.7602\n",
      "Epoch 893/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6330 - accuracy: 0.8131 - val_loss: 0.9067 - val_accuracy: 0.7372\n",
      "Epoch 894/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6359 - accuracy: 0.8214 - val_loss: 1.0388 - val_accuracy: 0.6285\n",
      "Epoch 895/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6483 - accuracy: 0.8029 - val_loss: 0.9185 - val_accuracy: 0.7318\n",
      "Epoch 896/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6296 - accuracy: 0.8062 - val_loss: 0.9036 - val_accuracy: 0.7423\n",
      "Epoch 897/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6185 - accuracy: 0.8211 - val_loss: 0.9536 - val_accuracy: 0.7063\n",
      "Epoch 898/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6258 - accuracy: 0.8212 - val_loss: 0.9678 - val_accuracy: 0.7020\n",
      "Epoch 899/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6269 - accuracy: 0.8117 - val_loss: 0.8887 - val_accuracy: 0.7415\n",
      "Epoch 900/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6282 - accuracy: 0.8162 - val_loss: 1.0219 - val_accuracy: 0.6540\n",
      "Epoch 901/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6360 - accuracy: 0.8098 - val_loss: 0.8898 - val_accuracy: 0.7558\n",
      "Epoch 902/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6306 - accuracy: 0.8136 - val_loss: 0.9366 - val_accuracy: 0.7327\n",
      "Epoch 903/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6378 - accuracy: 0.8026 - val_loss: 0.8986 - val_accuracy: 0.7515\n",
      "Epoch 904/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6189 - accuracy: 0.8190 - val_loss: 0.9094 - val_accuracy: 0.7308\n",
      "Epoch 905/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6115 - accuracy: 0.8249 - val_loss: 0.9221 - val_accuracy: 0.7412\n",
      "Epoch 906/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6166 - accuracy: 0.8153 - val_loss: 0.9340 - val_accuracy: 0.7200\n",
      "Epoch 907/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6182 - accuracy: 0.8196 - val_loss: 0.9645 - val_accuracy: 0.7038\n",
      "Epoch 908/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6110 - accuracy: 0.8236 - val_loss: 0.9794 - val_accuracy: 0.6823\n",
      "Epoch 909/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6156 - accuracy: 0.8167 - val_loss: 0.9140 - val_accuracy: 0.7343\n",
      "Epoch 910/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6167 - accuracy: 0.8142 - val_loss: 0.9633 - val_accuracy: 0.7190\n",
      "Epoch 911/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6213 - accuracy: 0.8192 - val_loss: 0.9932 - val_accuracy: 0.6580\n",
      "Epoch 912/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6271 - accuracy: 0.8005 - val_loss: 0.8913 - val_accuracy: 0.7605\n",
      "Epoch 913/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6158 - accuracy: 0.8181 - val_loss: 0.9148 - val_accuracy: 0.7567\n",
      "Epoch 914/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6135 - accuracy: 0.8230 - val_loss: 0.9413 - val_accuracy: 0.7352\n",
      "Epoch 915/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6151 - accuracy: 0.8236 - val_loss: 0.9641 - val_accuracy: 0.6885\n",
      "Epoch 916/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.6122 - accuracy: 0.8056 - val_loss: 0.9224 - val_accuracy: 0.7523\n",
      "Epoch 917/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6090 - accuracy: 0.8233 - val_loss: 0.9412 - val_accuracy: 0.7203\n",
      "Epoch 918/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6163 - accuracy: 0.8229 - val_loss: 0.9836 - val_accuracy: 0.6825\n",
      "Epoch 919/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6172 - accuracy: 0.8177 - val_loss: 0.9658 - val_accuracy: 0.7005\n",
      "Epoch 920/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6055 - accuracy: 0.8206 - val_loss: 0.8901 - val_accuracy: 0.7613\n",
      "Epoch 921/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6050 - accuracy: 0.8254 - val_loss: 0.9344 - val_accuracy: 0.7312\n",
      "Epoch 922/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6034 - accuracy: 0.8214 - val_loss: 0.9012 - val_accuracy: 0.7515\n",
      "Epoch 923/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6157 - accuracy: 0.8096 - val_loss: 0.9229 - val_accuracy: 0.7322\n",
      "Epoch 924/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6121 - accuracy: 0.8193 - val_loss: 0.9637 - val_accuracy: 0.7138\n",
      "Epoch 925/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6124 - accuracy: 0.8213 - val_loss: 0.9156 - val_accuracy: 0.7362\n",
      "Epoch 926/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6062 - accuracy: 0.8186 - val_loss: 0.9369 - val_accuracy: 0.7247\n",
      "Epoch 927/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6032 - accuracy: 0.8242 - val_loss: 0.9510 - val_accuracy: 0.7203\n",
      "Epoch 928/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6077 - accuracy: 0.8255 - val_loss: 1.0026 - val_accuracy: 0.6810\n",
      "Epoch 929/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6241 - accuracy: 0.8115 - val_loss: 0.8758 - val_accuracy: 0.7675\n",
      "Epoch 930/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6235 - accuracy: 0.8117 - val_loss: 0.9644 - val_accuracy: 0.7150\n",
      "Epoch 931/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6104 - accuracy: 0.8238 - val_loss: 0.9275 - val_accuracy: 0.7358\n",
      "Epoch 932/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6089 - accuracy: 0.8239 - val_loss: 0.9569 - val_accuracy: 0.6952\n",
      "Epoch 933/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6292 - accuracy: 0.8142 - val_loss: 0.9977 - val_accuracy: 0.7225\n",
      "Epoch 934/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6405 - accuracy: 0.8056 - val_loss: 0.9691 - val_accuracy: 0.7030\n",
      "Epoch 935/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6477 - accuracy: 0.8183 - val_loss: 1.0183 - val_accuracy: 0.6555\n",
      "Epoch 936/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6653 - accuracy: 0.7971 - val_loss: 0.9145 - val_accuracy: 0.7352\n",
      "Epoch 937/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6588 - accuracy: 0.7934 - val_loss: 0.8808 - val_accuracy: 0.7722\n",
      "Epoch 938/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6317 - accuracy: 0.8105 - val_loss: 0.8755 - val_accuracy: 0.7540\n",
      "Epoch 939/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6375 - accuracy: 0.8158 - val_loss: 0.9072 - val_accuracy: 0.7333\n",
      "Epoch 940/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6354 - accuracy: 0.8189 - val_loss: 1.0209 - val_accuracy: 0.6572\n",
      "Epoch 941/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6405 - accuracy: 0.8018 - val_loss: 0.8995 - val_accuracy: 0.7785\n",
      "Epoch 942/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6273 - accuracy: 0.8111 - val_loss: 0.9225 - val_accuracy: 0.7347\n",
      "Epoch 943/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6109 - accuracy: 0.8209 - val_loss: 0.9867 - val_accuracy: 0.7013\n",
      "Epoch 944/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6050 - accuracy: 0.8253 - val_loss: 0.9608 - val_accuracy: 0.7207\n",
      "Epoch 945/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6069 - accuracy: 0.8159 - val_loss: 0.9743 - val_accuracy: 0.7280\n",
      "Epoch 946/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6043 - accuracy: 0.8290 - val_loss: 0.9536 - val_accuracy: 0.7135\n",
      "Epoch 947/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6061 - accuracy: 0.8132 - val_loss: 0.9484 - val_accuracy: 0.7285\n",
      "Epoch 948/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6216 - accuracy: 0.8186 - val_loss: 1.0371 - val_accuracy: 0.6467\n",
      "Epoch 949/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6261 - accuracy: 0.8173 - val_loss: 0.9744 - val_accuracy: 0.7035\n",
      "Epoch 950/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6257 - accuracy: 0.8117 - val_loss: 0.9302 - val_accuracy: 0.7350\n",
      "Epoch 951/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6271 - accuracy: 0.8179 - val_loss: 0.9442 - val_accuracy: 0.7130\n",
      "Epoch 952/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6108 - accuracy: 0.8188 - val_loss: 0.9688 - val_accuracy: 0.7128\n",
      "Epoch 953/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6026 - accuracy: 0.8229 - val_loss: 0.9874 - val_accuracy: 0.7120\n",
      "Epoch 954/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6144 - accuracy: 0.8194 - val_loss: 0.9268 - val_accuracy: 0.7287\n",
      "Epoch 955/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6092 - accuracy: 0.8221 - val_loss: 0.9872 - val_accuracy: 0.7040\n",
      "Epoch 956/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6110 - accuracy: 0.8213 - val_loss: 0.9650 - val_accuracy: 0.7250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 957/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6156 - accuracy: 0.8174 - val_loss: 0.9422 - val_accuracy: 0.7385\n",
      "Epoch 958/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6114 - accuracy: 0.8234 - val_loss: 0.9801 - val_accuracy: 0.7050\n",
      "Epoch 959/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6057 - accuracy: 0.8249 - val_loss: 0.9863 - val_accuracy: 0.6952\n",
      "Epoch 960/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6031 - accuracy: 0.8204 - val_loss: 0.9377 - val_accuracy: 0.7408\n",
      "Epoch 961/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5991 - accuracy: 0.8196 - val_loss: 0.9448 - val_accuracy: 0.7430\n",
      "Epoch 962/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5999 - accuracy: 0.8224 - val_loss: 0.9395 - val_accuracy: 0.7372\n",
      "Epoch 963/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6060 - accuracy: 0.8242 - val_loss: 1.0218 - val_accuracy: 0.6718\n",
      "Epoch 964/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6242 - accuracy: 0.8184 - val_loss: 1.0401 - val_accuracy: 0.6715\n",
      "Epoch 965/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6211 - accuracy: 0.8076 - val_loss: 0.9456 - val_accuracy: 0.7513\n",
      "Epoch 966/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6391 - accuracy: 0.8019 - val_loss: 0.9217 - val_accuracy: 0.7535\n",
      "Epoch 967/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6284 - accuracy: 0.8202 - val_loss: 1.0322 - val_accuracy: 0.6930\n",
      "Epoch 968/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6232 - accuracy: 0.8217 - val_loss: 1.0030 - val_accuracy: 0.6735\n",
      "Epoch 969/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6154 - accuracy: 0.8137 - val_loss: 0.9401 - val_accuracy: 0.7303\n",
      "Epoch 970/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6020 - accuracy: 0.8126 - val_loss: 0.9183 - val_accuracy: 0.7560\n",
      "Epoch 971/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6042 - accuracy: 0.8277 - val_loss: 1.0267 - val_accuracy: 0.6875\n",
      "Epoch 972/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.6157 - accuracy: 0.8141 - val_loss: 0.9946 - val_accuracy: 0.6950\n",
      "Epoch 973/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6091 - accuracy: 0.8229 - val_loss: 0.9807 - val_accuracy: 0.6985\n",
      "Epoch 974/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6002 - accuracy: 0.8214 - val_loss: 0.9489 - val_accuracy: 0.7262\n",
      "Epoch 975/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5948 - accuracy: 0.8273 - val_loss: 0.9447 - val_accuracy: 0.7558\n",
      "Epoch 976/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6112 - accuracy: 0.8148 - val_loss: 0.8912 - val_accuracy: 0.7722\n",
      "Epoch 977/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6068 - accuracy: 0.8288 - val_loss: 1.0739 - val_accuracy: 0.6562\n",
      "Epoch 978/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6232 - accuracy: 0.8186 - val_loss: 1.0189 - val_accuracy: 0.6902\n",
      "Epoch 979/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6101 - accuracy: 0.8128 - val_loss: 0.9301 - val_accuracy: 0.7505\n",
      "Epoch 980/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6094 - accuracy: 0.8164 - val_loss: 0.9538 - val_accuracy: 0.7525\n",
      "Epoch 981/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6133 - accuracy: 0.8159 - val_loss: 0.9622 - val_accuracy: 0.7380\n",
      "Epoch 982/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6087 - accuracy: 0.8254 - val_loss: 1.0437 - val_accuracy: 0.6630\n",
      "Epoch 983/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6053 - accuracy: 0.8152 - val_loss: 0.9305 - val_accuracy: 0.7548\n",
      "Epoch 984/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6117 - accuracy: 0.8177 - val_loss: 0.9761 - val_accuracy: 0.6895\n",
      "Epoch 985/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6198 - accuracy: 0.8228 - val_loss: 1.0386 - val_accuracy: 0.6490\n",
      "Epoch 986/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6160 - accuracy: 0.8068 - val_loss: 0.8941 - val_accuracy: 0.7772\n",
      "Epoch 987/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6102 - accuracy: 0.8158 - val_loss: 0.9536 - val_accuracy: 0.7535\n",
      "Epoch 988/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6091 - accuracy: 0.8269 - val_loss: 0.9793 - val_accuracy: 0.7240\n",
      "Epoch 989/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6126 - accuracy: 0.8194 - val_loss: 0.9572 - val_accuracy: 0.7400\n",
      "Epoch 990/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6041 - accuracy: 0.8223 - val_loss: 0.9250 - val_accuracy: 0.7558\n",
      "Epoch 991/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5996 - accuracy: 0.8312 - val_loss: 0.9766 - val_accuracy: 0.7212\n",
      "Epoch 992/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6081 - accuracy: 0.8201 - val_loss: 0.9638 - val_accuracy: 0.7175\n",
      "Epoch 993/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6002 - accuracy: 0.8237 - val_loss: 0.9502 - val_accuracy: 0.7395\n",
      "Epoch 994/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5957 - accuracy: 0.8257 - val_loss: 0.9625 - val_accuracy: 0.7347\n",
      "Epoch 995/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6128 - accuracy: 0.8209 - val_loss: 0.9275 - val_accuracy: 0.7412\n",
      "Epoch 996/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6160 - accuracy: 0.8225 - val_loss: 0.9838 - val_accuracy: 0.7085\n",
      "Epoch 997/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6031 - accuracy: 0.8194 - val_loss: 0.9931 - val_accuracy: 0.7165\n",
      "Epoch 998/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6006 - accuracy: 0.8257 - val_loss: 0.9313 - val_accuracy: 0.7418\n",
      "Epoch 999/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6091 - accuracy: 0.8211 - val_loss: 0.9516 - val_accuracy: 0.7442\n",
      "Epoch 1000/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6204 - accuracy: 0.8127 - val_loss: 0.9605 - val_accuracy: 0.7335\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/1000\n",
      "16000/16000 [==============================] - 1s 33us/step - loss: 1.4986 - accuracy: 0.4079 - val_loss: 0.5993 - val_accuracy: 0.7780\n",
      "Epoch 2/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2952 - accuracy: 0.5730 - val_loss: 0.9064 - val_accuracy: 0.2138\n",
      "Epoch 3/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2559 - accuracy: 0.3679 - val_loss: 0.6487 - val_accuracy: 0.6955\n",
      "Epoch 4/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2449 - accuracy: 0.3754 - val_loss: 0.7779 - val_accuracy: 0.2510\n",
      "Epoch 5/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2338 - accuracy: 0.4251 - val_loss: 0.7237 - val_accuracy: 0.3447\n",
      "Epoch 6/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2276 - accuracy: 0.2900 - val_loss: 0.7067 - val_accuracy: 0.4410\n",
      "Epoch 7/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2210 - accuracy: 0.4181 - val_loss: 0.7450 - val_accuracy: 0.3440\n",
      "Epoch 8/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2161 - accuracy: 0.4091 - val_loss: 0.7322 - val_accuracy: 0.3812\n",
      "Epoch 9/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2122 - accuracy: 0.3886 - val_loss: 0.7386 - val_accuracy: 0.3738\n",
      "Epoch 10/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 1.2089 - accuracy: 0.4375 - val_loss: 0.7868 - val_accuracy: 0.3072\n",
      "Epoch 11/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2099 - accuracy: 0.4196 - val_loss: 0.7318 - val_accuracy: 0.3995\n",
      "Epoch 12/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2053 - accuracy: 0.4296 - val_loss: 0.6890 - val_accuracy: 0.5295\n",
      "Epoch 13/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.2012 - accuracy: 0.4331 - val_loss: 0.7144 - val_accuracy: 0.4400\n",
      "Epoch 14/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1966 - accuracy: 0.4243 - val_loss: 0.7225 - val_accuracy: 0.4075\n",
      "Epoch 15/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1944 - accuracy: 0.4358 - val_loss: 0.7398 - val_accuracy: 0.3952\n",
      "Epoch 16/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1922 - accuracy: 0.4273 - val_loss: 0.7030 - val_accuracy: 0.4850\n",
      "Epoch 17/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1934 - accuracy: 0.4598 - val_loss: 0.7245 - val_accuracy: 0.4440\n",
      "Epoch 18/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1882 - accuracy: 0.4661 - val_loss: 0.7411 - val_accuracy: 0.4010\n",
      "Epoch 19/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1892 - accuracy: 0.4512 - val_loss: 0.7676 - val_accuracy: 0.3417\n",
      "Epoch 20/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1905 - accuracy: 0.4764 - val_loss: 0.7878 - val_accuracy: 0.3377\n",
      "Epoch 21/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1878 - accuracy: 0.4672 - val_loss: 0.7697 - val_accuracy: 0.3453\n",
      "Epoch 22/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1810 - accuracy: 0.4786 - val_loss: 0.7745 - val_accuracy: 0.3370\n",
      "Epoch 23/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1759 - accuracy: 0.4710 - val_loss: 0.7277 - val_accuracy: 0.4173\n",
      "Epoch 24/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1708 - accuracy: 0.4440 - val_loss: 0.7288 - val_accuracy: 0.4308\n",
      "Epoch 25/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1690 - accuracy: 0.4830 - val_loss: 0.7242 - val_accuracy: 0.4283\n",
      "Epoch 26/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1656 - accuracy: 0.4545 - val_loss: 0.7450 - val_accuracy: 0.4170\n",
      "Epoch 27/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1618 - accuracy: 0.4941 - val_loss: 0.7128 - val_accuracy: 0.4837\n",
      "Epoch 28/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1573 - accuracy: 0.5303 - val_loss: 0.7018 - val_accuracy: 0.4972\n",
      "Epoch 29/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1548 - accuracy: 0.4815 - val_loss: 0.7131 - val_accuracy: 0.4773\n",
      "Epoch 30/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1496 - accuracy: 0.4836 - val_loss: 0.6785 - val_accuracy: 0.5847\n",
      "Epoch 31/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1527 - accuracy: 0.5254 - val_loss: 0.7410 - val_accuracy: 0.4125\n",
      "Epoch 32/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1486 - accuracy: 0.5059 - val_loss: 0.7410 - val_accuracy: 0.4288\n",
      "Epoch 33/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1503 - accuracy: 0.5206 - val_loss: 0.6924 - val_accuracy: 0.5610\n",
      "Epoch 34/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1432 - accuracy: 0.4941 - val_loss: 0.7112 - val_accuracy: 0.4832\n",
      "Epoch 35/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1405 - accuracy: 0.5317 - val_loss: 0.7019 - val_accuracy: 0.5562\n",
      "Epoch 36/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1369 - accuracy: 0.5261 - val_loss: 0.7677 - val_accuracy: 0.3830\n",
      "Epoch 37/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1374 - accuracy: 0.5371 - val_loss: 0.7392 - val_accuracy: 0.4737\n",
      "Epoch 38/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1314 - accuracy: 0.5447 - val_loss: 0.7060 - val_accuracy: 0.5315\n",
      "Epoch 39/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1303 - accuracy: 0.5433 - val_loss: 0.6937 - val_accuracy: 0.5530\n",
      "Epoch 40/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1256 - accuracy: 0.5725 - val_loss: 0.6939 - val_accuracy: 0.5683\n",
      "Epoch 41/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1217 - accuracy: 0.5526 - val_loss: 0.6827 - val_accuracy: 0.5885\n",
      "Epoch 42/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1183 - accuracy: 0.5445 - val_loss: 0.6704 - val_accuracy: 0.6235\n",
      "Epoch 43/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1142 - accuracy: 0.5654 - val_loss: 0.6974 - val_accuracy: 0.5445\n",
      "Epoch 44/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1111 - accuracy: 0.5848 - val_loss: 0.7236 - val_accuracy: 0.5013\n",
      "Epoch 45/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1148 - accuracy: 0.5521 - val_loss: 0.6849 - val_accuracy: 0.5965\n",
      "Epoch 46/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1119 - accuracy: 0.6056 - val_loss: 0.7147 - val_accuracy: 0.5052\n",
      "Epoch 47/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1068 - accuracy: 0.5636 - val_loss: 0.6951 - val_accuracy: 0.5655\n",
      "Epoch 48/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1040 - accuracy: 0.5884 - val_loss: 0.7254 - val_accuracy: 0.5372\n",
      "Epoch 49/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1049 - accuracy: 0.5483 - val_loss: 0.7207 - val_accuracy: 0.5405\n",
      "Epoch 50/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.1038 - accuracy: 0.5887 - val_loss: 0.7254 - val_accuracy: 0.4642\n",
      "Epoch 51/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0997 - accuracy: 0.5578 - val_loss: 0.6945 - val_accuracy: 0.5720\n",
      "Epoch 52/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0933 - accuracy: 0.5927 - val_loss: 0.7085 - val_accuracy: 0.5282\n",
      "Epoch 53/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0952 - accuracy: 0.5926 - val_loss: 0.6863 - val_accuracy: 0.5853\n",
      "Epoch 54/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0970 - accuracy: 0.5971 - val_loss: 0.7295 - val_accuracy: 0.4782\n",
      "Epoch 55/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0846 - accuracy: 0.5842 - val_loss: 0.7266 - val_accuracy: 0.5110\n",
      "Epoch 56/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0798 - accuracy: 0.6047 - val_loss: 0.6561 - val_accuracy: 0.6385\n",
      "Epoch 57/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0745 - accuracy: 0.6072 - val_loss: 0.6869 - val_accuracy: 0.5727\n",
      "Epoch 58/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0802 - accuracy: 0.5965 - val_loss: 0.6858 - val_accuracy: 0.5750\n",
      "Epoch 59/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0785 - accuracy: 0.6196 - val_loss: 0.6678 - val_accuracy: 0.6097\n",
      "Epoch 60/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0746 - accuracy: 0.6096 - val_loss: 0.6961 - val_accuracy: 0.5642\n",
      "Epoch 61/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0702 - accuracy: 0.6019 - val_loss: 0.6510 - val_accuracy: 0.6392\n",
      "Epoch 62/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0729 - accuracy: 0.6089 - val_loss: 0.7213 - val_accuracy: 0.4983\n",
      "Epoch 63/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0672 - accuracy: 0.5935 - val_loss: 0.6758 - val_accuracy: 0.5940\n",
      "Epoch 64/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0639 - accuracy: 0.6351 - val_loss: 0.7495 - val_accuracy: 0.5015\n",
      "Epoch 65/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0688 - accuracy: 0.6028 - val_loss: 0.6570 - val_accuracy: 0.6532\n",
      "Epoch 66/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0659 - accuracy: 0.6272 - val_loss: 0.6641 - val_accuracy: 0.6342\n",
      "Epoch 67/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0589 - accuracy: 0.6083 - val_loss: 0.6621 - val_accuracy: 0.5910\n",
      "Epoch 68/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0607 - accuracy: 0.6082 - val_loss: 0.6849 - val_accuracy: 0.5558\n",
      "Epoch 69/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0520 - accuracy: 0.6319 - val_loss: 0.6652 - val_accuracy: 0.6108\n",
      "Epoch 70/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0518 - accuracy: 0.6296 - val_loss: 0.6528 - val_accuracy: 0.6340\n",
      "Epoch 71/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0473 - accuracy: 0.6255 - val_loss: 0.6491 - val_accuracy: 0.6507\n",
      "Epoch 72/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0501 - accuracy: 0.6265 - val_loss: 0.7601 - val_accuracy: 0.4770\n",
      "Epoch 73/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0593 - accuracy: 0.5969 - val_loss: 0.6327 - val_accuracy: 0.7048\n",
      "Epoch 74/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0501 - accuracy: 0.6378 - val_loss: 0.6259 - val_accuracy: 0.6895\n",
      "Epoch 75/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0460 - accuracy: 0.6453 - val_loss: 0.6814 - val_accuracy: 0.5805\n",
      "Epoch 76/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0414 - accuracy: 0.6316 - val_loss: 0.6710 - val_accuracy: 0.5947\n",
      "Epoch 77/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0382 - accuracy: 0.6375 - val_loss: 0.6750 - val_accuracy: 0.5900\n",
      "Epoch 78/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0311 - accuracy: 0.6238 - val_loss: 0.6494 - val_accuracy: 0.6653\n",
      "Epoch 79/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0310 - accuracy: 0.6396 - val_loss: 0.6651 - val_accuracy: 0.6273\n",
      "Epoch 80/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0271 - accuracy: 0.6391 - val_loss: 0.6585 - val_accuracy: 0.6363\n",
      "Epoch 81/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0225 - accuracy: 0.6569 - val_loss: 0.6909 - val_accuracy: 0.5567\n",
      "Epoch 82/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0286 - accuracy: 0.6308 - val_loss: 0.6399 - val_accuracy: 0.6587\n",
      "Epoch 83/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0236 - accuracy: 0.6513 - val_loss: 0.6616 - val_accuracy: 0.6320\n",
      "Epoch 84/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0194 - accuracy: 0.6329 - val_loss: 0.6469 - val_accuracy: 0.6438\n",
      "Epoch 85/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0256 - accuracy: 0.6446 - val_loss: 0.6553 - val_accuracy: 0.6582\n",
      "Epoch 86/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0233 - accuracy: 0.6469 - val_loss: 0.6812 - val_accuracy: 0.6622\n",
      "Epoch 87/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0276 - accuracy: 0.6469 - val_loss: 0.6159 - val_accuracy: 0.7060\n",
      "Epoch 88/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0295 - accuracy: 0.6428 - val_loss: 0.7342 - val_accuracy: 0.5598\n",
      "Epoch 89/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0260 - accuracy: 0.6551 - val_loss: 0.6976 - val_accuracy: 0.5562\n",
      "Epoch 90/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0193 - accuracy: 0.6255 - val_loss: 0.6492 - val_accuracy: 0.6332\n",
      "Epoch 91/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0144 - accuracy: 0.6487 - val_loss: 0.5984 - val_accuracy: 0.7185\n",
      "Epoch 92/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0145 - accuracy: 0.6754 - val_loss: 0.6609 - val_accuracy: 0.6263\n",
      "Epoch 93/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0038 - accuracy: 0.6466 - val_loss: 0.6818 - val_accuracy: 0.5755\n",
      "Epoch 94/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0107 - accuracy: 0.6703 - val_loss: 0.7074 - val_accuracy: 0.5312\n",
      "Epoch 95/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0140 - accuracy: 0.6242 - val_loss: 0.6604 - val_accuracy: 0.6177\n",
      "Epoch 96/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0068 - accuracy: 0.6629 - val_loss: 0.6055 - val_accuracy: 0.7103\n",
      "Epoch 97/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0181 - accuracy: 0.6585 - val_loss: 0.7517 - val_accuracy: 0.5038\n",
      "Epoch 98/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0164 - accuracy: 0.6322 - val_loss: 0.6696 - val_accuracy: 0.5947\n",
      "Epoch 99/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0156 - accuracy: 0.6545 - val_loss: 0.6473 - val_accuracy: 0.6415\n",
      "Epoch 100/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9983 - accuracy: 0.6611 - val_loss: 0.6492 - val_accuracy: 0.6520\n",
      "Epoch 101/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0002 - accuracy: 0.6513 - val_loss: 0.6627 - val_accuracy: 0.6367\n",
      "Epoch 102/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 1.0056 - accuracy: 0.6548 - val_loss: 0.6466 - val_accuracy: 0.6628\n",
      "Epoch 103/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9941 - accuracy: 0.6799 - val_loss: 0.6632 - val_accuracy: 0.6317\n",
      "Epoch 104/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9908 - accuracy: 0.6584 - val_loss: 0.6274 - val_accuracy: 0.7028\n",
      "Epoch 105/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9894 - accuracy: 0.6729 - val_loss: 0.6469 - val_accuracy: 0.6423\n",
      "Epoch 106/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9843 - accuracy: 0.6766 - val_loss: 0.6437 - val_accuracy: 0.6532\n",
      "Epoch 107/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9852 - accuracy: 0.6758 - val_loss: 0.6511 - val_accuracy: 0.6485\n",
      "Epoch 108/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9802 - accuracy: 0.6730 - val_loss: 0.7160 - val_accuracy: 0.5922\n",
      "Epoch 109/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9783 - accuracy: 0.6789 - val_loss: 0.5987 - val_accuracy: 0.7315\n",
      "Epoch 110/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9865 - accuracy: 0.6710 - val_loss: 0.7179 - val_accuracy: 0.5605\n",
      "Epoch 111/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9801 - accuracy: 0.6685 - val_loss: 0.6116 - val_accuracy: 0.7075\n",
      "Epoch 112/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9760 - accuracy: 0.6937 - val_loss: 0.7022 - val_accuracy: 0.5905\n",
      "Epoch 113/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9833 - accuracy: 0.6691 - val_loss: 0.6026 - val_accuracy: 0.7262\n",
      "Epoch 114/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9790 - accuracy: 0.6912 - val_loss: 0.7191 - val_accuracy: 0.5552\n",
      "Epoch 115/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9741 - accuracy: 0.6731 - val_loss: 0.6433 - val_accuracy: 0.6930\n",
      "Epoch 116/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9765 - accuracy: 0.6696 - val_loss: 0.6298 - val_accuracy: 0.6923\n",
      "Epoch 117/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9806 - accuracy: 0.6966 - val_loss: 0.6915 - val_accuracy: 0.6162\n",
      "Epoch 118/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9738 - accuracy: 0.6789 - val_loss: 0.6623 - val_accuracy: 0.6708\n",
      "Epoch 119/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9724 - accuracy: 0.6903 - val_loss: 0.6749 - val_accuracy: 0.6290\n",
      "Epoch 120/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9621 - accuracy: 0.6865 - val_loss: 0.6463 - val_accuracy: 0.6705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9604 - accuracy: 0.6898 - val_loss: 0.6431 - val_accuracy: 0.6770\n",
      "Epoch 122/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9530 - accuracy: 0.7100 - val_loss: 0.6612 - val_accuracy: 0.6340\n",
      "Epoch 123/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9621 - accuracy: 0.6823 - val_loss: 0.5925 - val_accuracy: 0.7303\n",
      "Epoch 124/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9623 - accuracy: 0.6963 - val_loss: 0.7062 - val_accuracy: 0.5905\n",
      "Epoch 125/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9596 - accuracy: 0.6780 - val_loss: 0.6468 - val_accuracy: 0.6840\n",
      "Epoch 126/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9624 - accuracy: 0.6899 - val_loss: 0.6872 - val_accuracy: 0.6212\n",
      "Epoch 127/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9513 - accuracy: 0.6926 - val_loss: 0.5790 - val_accuracy: 0.7500\n",
      "Epoch 128/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9671 - accuracy: 0.6999 - val_loss: 0.7893 - val_accuracy: 0.5035\n",
      "Epoch 129/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9707 - accuracy: 0.6737 - val_loss: 0.6748 - val_accuracy: 0.6505\n",
      "Epoch 130/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9615 - accuracy: 0.6955 - val_loss: 0.6387 - val_accuracy: 0.6977\n",
      "Epoch 131/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9627 - accuracy: 0.7007 - val_loss: 0.6558 - val_accuracy: 0.6582\n",
      "Epoch 132/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9564 - accuracy: 0.6842 - val_loss: 0.6185 - val_accuracy: 0.7160\n",
      "Epoch 133/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9575 - accuracy: 0.7068 - val_loss: 0.6563 - val_accuracy: 0.6672\n",
      "Epoch 134/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9530 - accuracy: 0.6875 - val_loss: 0.6325 - val_accuracy: 0.6825\n",
      "Epoch 135/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9472 - accuracy: 0.7147 - val_loss: 0.7107 - val_accuracy: 0.6025\n",
      "Epoch 136/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9412 - accuracy: 0.6892 - val_loss: 0.6551 - val_accuracy: 0.6722\n",
      "Epoch 137/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9486 - accuracy: 0.6961 - val_loss: 0.6538 - val_accuracy: 0.6647\n",
      "Epoch 138/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9454 - accuracy: 0.6988 - val_loss: 0.6488 - val_accuracy: 0.6845\n",
      "Epoch 139/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9355 - accuracy: 0.7130 - val_loss: 0.6854 - val_accuracy: 0.6212\n",
      "Epoch 140/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9357 - accuracy: 0.6882 - val_loss: 0.6527 - val_accuracy: 0.6562\n",
      "Epoch 141/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9358 - accuracy: 0.7214 - val_loss: 0.7208 - val_accuracy: 0.5928\n",
      "Epoch 142/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.9413 - accuracy: 0.6789 - val_loss: 0.6463 - val_accuracy: 0.6850\n",
      "Epoch 143/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9307 - accuracy: 0.7171 - val_loss: 0.6612 - val_accuracy: 0.6760\n",
      "Epoch 144/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9317 - accuracy: 0.7031 - val_loss: 0.6383 - val_accuracy: 0.6855\n",
      "Epoch 145/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9309 - accuracy: 0.7234 - val_loss: 0.7499 - val_accuracy: 0.5580\n",
      "Epoch 146/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9419 - accuracy: 0.6892 - val_loss: 0.6016 - val_accuracy: 0.7207\n",
      "Epoch 147/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9391 - accuracy: 0.6976 - val_loss: 0.7025 - val_accuracy: 0.6177\n",
      "Epoch 148/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9368 - accuracy: 0.6981 - val_loss: 0.6049 - val_accuracy: 0.7237\n",
      "Epoch 149/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9351 - accuracy: 0.7135 - val_loss: 0.7142 - val_accuracy: 0.5960\n",
      "Epoch 150/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9340 - accuracy: 0.7021 - val_loss: 0.6424 - val_accuracy: 0.6837\n",
      "Epoch 151/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9369 - accuracy: 0.7023 - val_loss: 0.7361 - val_accuracy: 0.5635\n",
      "Epoch 152/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9383 - accuracy: 0.6985 - val_loss: 0.6220 - val_accuracy: 0.6995\n",
      "Epoch 153/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9373 - accuracy: 0.7042 - val_loss: 0.6596 - val_accuracy: 0.6708\n",
      "Epoch 154/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9300 - accuracy: 0.7022 - val_loss: 0.6991 - val_accuracy: 0.6248\n",
      "Epoch 155/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.9289 - accuracy: 0.7061 - val_loss: 0.6482 - val_accuracy: 0.6600\n",
      "Epoch 156/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9289 - accuracy: 0.7158 - val_loss: 0.6757 - val_accuracy: 0.6240\n",
      "Epoch 157/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9306 - accuracy: 0.6963 - val_loss: 0.6469 - val_accuracy: 0.6777\n",
      "Epoch 158/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9228 - accuracy: 0.7065 - val_loss: 0.6684 - val_accuracy: 0.6610\n",
      "Epoch 159/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9241 - accuracy: 0.7221 - val_loss: 0.6339 - val_accuracy: 0.6917\n",
      "Epoch 160/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9161 - accuracy: 0.7081 - val_loss: 0.7207 - val_accuracy: 0.5915\n",
      "Epoch 161/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9222 - accuracy: 0.7087 - val_loss: 0.6536 - val_accuracy: 0.6915\n",
      "Epoch 162/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9179 - accuracy: 0.7157 - val_loss: 0.6759 - val_accuracy: 0.6695\n",
      "Epoch 163/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9230 - accuracy: 0.7140 - val_loss: 0.6923 - val_accuracy: 0.6273\n",
      "Epoch 164/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9170 - accuracy: 0.7154 - val_loss: 0.6982 - val_accuracy: 0.6255\n",
      "Epoch 165/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9121 - accuracy: 0.7169 - val_loss: 0.6483 - val_accuracy: 0.6630\n",
      "Epoch 166/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9136 - accuracy: 0.7067 - val_loss: 0.6345 - val_accuracy: 0.6998\n",
      "Epoch 167/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9129 - accuracy: 0.7238 - val_loss: 0.7184 - val_accuracy: 0.5965\n",
      "Epoch 168/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9201 - accuracy: 0.6913 - val_loss: 0.6100 - val_accuracy: 0.7168\n",
      "Epoch 169/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9004 - accuracy: 0.7355 - val_loss: 0.6265 - val_accuracy: 0.6982\n",
      "Epoch 170/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9045 - accuracy: 0.7228 - val_loss: 0.7604 - val_accuracy: 0.5493\n",
      "Epoch 171/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9170 - accuracy: 0.7016 - val_loss: 0.5807 - val_accuracy: 0.7527\n",
      "Epoch 172/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9078 - accuracy: 0.7226 - val_loss: 0.6617 - val_accuracy: 0.6603\n",
      "Epoch 173/1000\n",
      "16000/16000 [==============================] - ETA: 0s - loss: 0.9242 - accuracy: 0.71 - 0s 3us/step - loss: 0.8996 - accuracy: 0.7226 - val_loss: 0.6896 - val_accuracy: 0.6482\n",
      "Epoch 174/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8975 - accuracy: 0.7172 - val_loss: 0.6517 - val_accuracy: 0.6855\n",
      "Epoch 175/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8927 - accuracy: 0.7283 - val_loss: 0.6746 - val_accuracy: 0.6547\n",
      "Epoch 176/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8929 - accuracy: 0.7085 - val_loss: 0.6267 - val_accuracy: 0.7203\n",
      "Epoch 177/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8982 - accuracy: 0.7437 - val_loss: 0.7292 - val_accuracy: 0.5980\n",
      "Epoch 178/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9127 - accuracy: 0.7086 - val_loss: 0.6147 - val_accuracy: 0.7153\n",
      "Epoch 179/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8950 - accuracy: 0.7206 - val_loss: 0.6704 - val_accuracy: 0.6637\n",
      "Epoch 180/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8983 - accuracy: 0.7259 - val_loss: 0.6642 - val_accuracy: 0.6722\n",
      "Epoch 181/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9070 - accuracy: 0.7011 - val_loss: 0.6233 - val_accuracy: 0.7207\n",
      "Epoch 182/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9026 - accuracy: 0.7363 - val_loss: 0.6972 - val_accuracy: 0.6447\n",
      "Epoch 183/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8959 - accuracy: 0.7146 - val_loss: 0.6948 - val_accuracy: 0.6463\n",
      "Epoch 184/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8988 - accuracy: 0.7218 - val_loss: 0.6441 - val_accuracy: 0.6770\n",
      "Epoch 185/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9022 - accuracy: 0.7165 - val_loss: 0.7068 - val_accuracy: 0.6252\n",
      "Epoch 186/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9041 - accuracy: 0.7235 - val_loss: 0.6253 - val_accuracy: 0.7122\n",
      "Epoch 187/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9045 - accuracy: 0.7188 - val_loss: 0.6981 - val_accuracy: 0.6525\n",
      "Epoch 188/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8934 - accuracy: 0.7184 - val_loss: 0.6219 - val_accuracy: 0.7160\n",
      "Epoch 189/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8888 - accuracy: 0.7412 - val_loss: 0.6972 - val_accuracy: 0.6332\n",
      "Epoch 190/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8897 - accuracy: 0.7296 - val_loss: 0.6562 - val_accuracy: 0.6725\n",
      "Epoch 191/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8884 - accuracy: 0.7160 - val_loss: 0.6571 - val_accuracy: 0.6740\n",
      "Epoch 192/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8864 - accuracy: 0.7311 - val_loss: 0.6143 - val_accuracy: 0.7260\n",
      "Epoch 193/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8855 - accuracy: 0.7309 - val_loss: 0.7989 - val_accuracy: 0.5347\n",
      "Epoch 194/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.9044 - accuracy: 0.6887 - val_loss: 0.6086 - val_accuracy: 0.7390\n",
      "Epoch 195/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8933 - accuracy: 0.7497 - val_loss: 0.6878 - val_accuracy: 0.6530\n",
      "Epoch 196/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8819 - accuracy: 0.7239 - val_loss: 0.6831 - val_accuracy: 0.6522\n",
      "Epoch 197/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8838 - accuracy: 0.7218 - val_loss: 0.6119 - val_accuracy: 0.7172\n",
      "Epoch 198/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8814 - accuracy: 0.7384 - val_loss: 0.6416 - val_accuracy: 0.7017\n",
      "Epoch 199/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8826 - accuracy: 0.7274 - val_loss: 0.7154 - val_accuracy: 0.6252\n",
      "Epoch 200/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8818 - accuracy: 0.7200 - val_loss: 0.5906 - val_accuracy: 0.7505\n",
      "Epoch 201/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8907 - accuracy: 0.7270 - val_loss: 0.6731 - val_accuracy: 0.6615\n",
      "Epoch 202/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8888 - accuracy: 0.7176 - val_loss: 0.6595 - val_accuracy: 0.6808\n",
      "Epoch 203/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8735 - accuracy: 0.7381 - val_loss: 0.6763 - val_accuracy: 0.6740\n",
      "Epoch 204/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8706 - accuracy: 0.7338 - val_loss: 0.6356 - val_accuracy: 0.7060\n",
      "Epoch 205/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8699 - accuracy: 0.7377 - val_loss: 0.6831 - val_accuracy: 0.6515\n",
      "Epoch 206/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8726 - accuracy: 0.7387 - val_loss: 0.6585 - val_accuracy: 0.6787\n",
      "Epoch 207/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8755 - accuracy: 0.7337 - val_loss: 0.6788 - val_accuracy: 0.6478\n",
      "Epoch 208/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8772 - accuracy: 0.7343 - val_loss: 0.7071 - val_accuracy: 0.6275\n",
      "Epoch 209/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8709 - accuracy: 0.7288 - val_loss: 0.6718 - val_accuracy: 0.6555\n",
      "Epoch 210/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8724 - accuracy: 0.7378 - val_loss: 0.6760 - val_accuracy: 0.6643\n",
      "Epoch 211/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8763 - accuracy: 0.7229 - val_loss: 0.6794 - val_accuracy: 0.6587\n",
      "Epoch 212/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8800 - accuracy: 0.7329 - val_loss: 0.6575 - val_accuracy: 0.6850\n",
      "Epoch 213/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8785 - accuracy: 0.7357 - val_loss: 0.6668 - val_accuracy: 0.6760\n",
      "Epoch 214/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8779 - accuracy: 0.7310 - val_loss: 0.7213 - val_accuracy: 0.6240\n",
      "Epoch 215/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8870 - accuracy: 0.7249 - val_loss: 0.6142 - val_accuracy: 0.7297\n",
      "Epoch 216/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.8786 - accuracy: 0.7408 - val_loss: 0.7580 - val_accuracy: 0.5815\n",
      "Epoch 217/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8751 - accuracy: 0.7253 - val_loss: 0.6279 - val_accuracy: 0.7115\n",
      "Epoch 218/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8677 - accuracy: 0.7379 - val_loss: 0.7059 - val_accuracy: 0.6440\n",
      "Epoch 219/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8620 - accuracy: 0.7379 - val_loss: 0.7021 - val_accuracy: 0.6378\n",
      "Epoch 220/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8590 - accuracy: 0.7420 - val_loss: 0.7131 - val_accuracy: 0.6405\n",
      "Epoch 221/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8634 - accuracy: 0.7327 - val_loss: 0.6479 - val_accuracy: 0.6898\n",
      "Epoch 222/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8563 - accuracy: 0.7478 - val_loss: 0.6620 - val_accuracy: 0.6825\n",
      "Epoch 223/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8533 - accuracy: 0.7454 - val_loss: 0.6720 - val_accuracy: 0.6680\n",
      "Epoch 224/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8571 - accuracy: 0.7410 - val_loss: 0.7248 - val_accuracy: 0.6255\n",
      "Epoch 225/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8769 - accuracy: 0.7080 - val_loss: 0.5977 - val_accuracy: 0.7513\n",
      "Epoch 226/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8856 - accuracy: 0.7454 - val_loss: 0.7410 - val_accuracy: 0.6070\n",
      "Epoch 227/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8842 - accuracy: 0.7106 - val_loss: 0.6775 - val_accuracy: 0.6750\n",
      "Epoch 228/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8664 - accuracy: 0.7462 - val_loss: 0.6295 - val_accuracy: 0.7180\n",
      "Epoch 229/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8684 - accuracy: 0.7308 - val_loss: 0.6749 - val_accuracy: 0.6590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8638 - accuracy: 0.7376 - val_loss: 0.6601 - val_accuracy: 0.6898\n",
      "Epoch 231/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8492 - accuracy: 0.7420 - val_loss: 0.6332 - val_accuracy: 0.7182\n",
      "Epoch 232/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8504 - accuracy: 0.7452 - val_loss: 0.6686 - val_accuracy: 0.6827\n",
      "Epoch 233/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8544 - accuracy: 0.7456 - val_loss: 0.6740 - val_accuracy: 0.6735\n",
      "Epoch 234/1000\n",
      "16000/16000 [==============================] - ETA: 0s - loss: 0.8290 - accuracy: 0.72 - 0s 3us/step - loss: 0.8470 - accuracy: 0.7523 - val_loss: 0.6599 - val_accuracy: 0.6895\n",
      "Epoch 235/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8483 - accuracy: 0.7389 - val_loss: 0.7443 - val_accuracy: 0.6047\n",
      "Epoch 236/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8529 - accuracy: 0.7383 - val_loss: 0.6062 - val_accuracy: 0.7427\n",
      "Epoch 237/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8500 - accuracy: 0.7476 - val_loss: 0.7220 - val_accuracy: 0.6423\n",
      "Epoch 238/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8569 - accuracy: 0.7342 - val_loss: 0.6791 - val_accuracy: 0.6745\n",
      "Epoch 239/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.8525 - accuracy: 0.7416 - val_loss: 0.6339 - val_accuracy: 0.7135\n",
      "Epoch 240/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8471 - accuracy: 0.7533 - val_loss: 0.7114 - val_accuracy: 0.6370\n",
      "Epoch 241/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8446 - accuracy: 0.7401 - val_loss: 0.6894 - val_accuracy: 0.6595\n",
      "Epoch 242/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8491 - accuracy: 0.7507 - val_loss: 0.7202 - val_accuracy: 0.6403\n",
      "Epoch 243/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8536 - accuracy: 0.7344 - val_loss: 0.6302 - val_accuracy: 0.7295\n",
      "Epoch 244/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8525 - accuracy: 0.7487 - val_loss: 0.7605 - val_accuracy: 0.5975\n",
      "Epoch 245/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8772 - accuracy: 0.7182 - val_loss: 0.6530 - val_accuracy: 0.7055\n",
      "Epoch 246/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8610 - accuracy: 0.7480 - val_loss: 0.7169 - val_accuracy: 0.6407\n",
      "Epoch 247/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8524 - accuracy: 0.7361 - val_loss: 0.6740 - val_accuracy: 0.6935\n",
      "Epoch 248/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8459 - accuracy: 0.7384 - val_loss: 0.6301 - val_accuracy: 0.7212\n",
      "Epoch 249/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.8404 - accuracy: 0.7569 - val_loss: 0.6928 - val_accuracy: 0.6465\n",
      "Epoch 250/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8565 - accuracy: 0.7288 - val_loss: 0.6451 - val_accuracy: 0.6925\n",
      "Epoch 251/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8543 - accuracy: 0.7523 - val_loss: 0.7454 - val_accuracy: 0.6022\n",
      "Epoch 252/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8478 - accuracy: 0.7323 - val_loss: 0.6370 - val_accuracy: 0.7200\n",
      "Epoch 253/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8401 - accuracy: 0.7544 - val_loss: 0.6957 - val_accuracy: 0.6650\n",
      "Epoch 254/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8398 - accuracy: 0.7442 - val_loss: 0.6635 - val_accuracy: 0.6880\n",
      "Epoch 255/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8392 - accuracy: 0.7459 - val_loss: 0.6518 - val_accuracy: 0.6977\n",
      "Epoch 256/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8381 - accuracy: 0.7510 - val_loss: 0.6191 - val_accuracy: 0.7327\n",
      "Epoch 257/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8412 - accuracy: 0.7510 - val_loss: 0.7160 - val_accuracy: 0.6488\n",
      "Epoch 258/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8426 - accuracy: 0.7357 - val_loss: 0.6527 - val_accuracy: 0.7115\n",
      "Epoch 259/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8342 - accuracy: 0.7584 - val_loss: 0.7170 - val_accuracy: 0.6488\n",
      "Epoch 260/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8299 - accuracy: 0.7464 - val_loss: 0.6698 - val_accuracy: 0.6923\n",
      "Epoch 261/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8304 - accuracy: 0.7569 - val_loss: 0.6800 - val_accuracy: 0.6808\n",
      "Epoch 262/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8284 - accuracy: 0.7466 - val_loss: 0.6515 - val_accuracy: 0.7078\n",
      "Epoch 263/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8207 - accuracy: 0.7582 - val_loss: 0.7131 - val_accuracy: 0.6550\n",
      "Epoch 264/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8241 - accuracy: 0.7494 - val_loss: 0.6608 - val_accuracy: 0.6992\n",
      "Epoch 265/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8219 - accuracy: 0.7592 - val_loss: 0.7113 - val_accuracy: 0.6560\n",
      "Epoch 266/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8221 - accuracy: 0.7452 - val_loss: 0.6653 - val_accuracy: 0.7017\n",
      "Epoch 267/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8211 - accuracy: 0.7602 - val_loss: 0.6780 - val_accuracy: 0.6852\n",
      "Epoch 268/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8206 - accuracy: 0.7458 - val_loss: 0.6722 - val_accuracy: 0.7085\n",
      "Epoch 269/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8339 - accuracy: 0.7606 - val_loss: 0.7104 - val_accuracy: 0.6520\n",
      "Epoch 270/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8219 - accuracy: 0.7494 - val_loss: 0.6934 - val_accuracy: 0.6702\n",
      "Epoch 271/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8206 - accuracy: 0.7550 - val_loss: 0.6528 - val_accuracy: 0.7065\n",
      "Epoch 272/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8179 - accuracy: 0.7610 - val_loss: 0.6886 - val_accuracy: 0.6810\n",
      "Epoch 273/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8174 - accuracy: 0.7536 - val_loss: 0.6803 - val_accuracy: 0.6790\n",
      "Epoch 274/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8162 - accuracy: 0.7592 - val_loss: 0.7180 - val_accuracy: 0.6465\n",
      "Epoch 275/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.8166 - accuracy: 0.7536 - val_loss: 0.6524 - val_accuracy: 0.7145\n",
      "Epoch 276/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8189 - accuracy: 0.7569 - val_loss: 0.7343 - val_accuracy: 0.6360\n",
      "Epoch 277/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8258 - accuracy: 0.7465 - val_loss: 0.6611 - val_accuracy: 0.7053\n",
      "Epoch 278/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8223 - accuracy: 0.7567 - val_loss: 0.6852 - val_accuracy: 0.6930\n",
      "Epoch 279/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8212 - accuracy: 0.7537 - val_loss: 0.6413 - val_accuracy: 0.7368\n",
      "Epoch 280/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8213 - accuracy: 0.7590 - val_loss: 0.7530 - val_accuracy: 0.6267\n",
      "Epoch 281/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8213 - accuracy: 0.7461 - val_loss: 0.6554 - val_accuracy: 0.7147\n",
      "Epoch 282/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8171 - accuracy: 0.7671 - val_loss: 0.7042 - val_accuracy: 0.6710\n",
      "Epoch 283/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8214 - accuracy: 0.7449 - val_loss: 0.6471 - val_accuracy: 0.7237\n",
      "Epoch 284/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8208 - accuracy: 0.7556 - val_loss: 0.7002 - val_accuracy: 0.6825\n",
      "Epoch 285/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8170 - accuracy: 0.7564 - val_loss: 0.7126 - val_accuracy: 0.6610\n",
      "Epoch 286/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8180 - accuracy: 0.7541 - val_loss: 0.6772 - val_accuracy: 0.6837\n",
      "Epoch 287/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8094 - accuracy: 0.7539 - val_loss: 0.6864 - val_accuracy: 0.6923\n",
      "Epoch 288/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8142 - accuracy: 0.7541 - val_loss: 0.6854 - val_accuracy: 0.6915\n",
      "Epoch 289/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8146 - accuracy: 0.7613 - val_loss: 0.6770 - val_accuracy: 0.7010\n",
      "Epoch 290/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8203 - accuracy: 0.7534 - val_loss: 0.7218 - val_accuracy: 0.6435\n",
      "Epoch 291/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8084 - accuracy: 0.7613 - val_loss: 0.7102 - val_accuracy: 0.6710\n",
      "Epoch 292/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8110 - accuracy: 0.7613 - val_loss: 0.6775 - val_accuracy: 0.7010\n",
      "Epoch 293/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8049 - accuracy: 0.7559 - val_loss: 0.6661 - val_accuracy: 0.7025\n",
      "Epoch 294/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8014 - accuracy: 0.7633 - val_loss: 0.6994 - val_accuracy: 0.6718\n",
      "Epoch 295/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8140 - accuracy: 0.7560 - val_loss: 0.7378 - val_accuracy: 0.6345\n",
      "Epoch 296/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8062 - accuracy: 0.7534 - val_loss: 0.6519 - val_accuracy: 0.7283\n",
      "Epoch 297/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8066 - accuracy: 0.7569 - val_loss: 0.6784 - val_accuracy: 0.7000\n",
      "Epoch 298/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8026 - accuracy: 0.7559 - val_loss: 0.6702 - val_accuracy: 0.7035\n",
      "Epoch 299/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8079 - accuracy: 0.7599 - val_loss: 0.6704 - val_accuracy: 0.7067\n",
      "Epoch 300/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7965 - accuracy: 0.7581 - val_loss: 0.6723 - val_accuracy: 0.7013\n",
      "Epoch 301/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8078 - accuracy: 0.7663 - val_loss: 0.7478 - val_accuracy: 0.6245\n",
      "Epoch 302/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8086 - accuracy: 0.7526 - val_loss: 0.6768 - val_accuracy: 0.6965\n",
      "Epoch 303/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8056 - accuracy: 0.7632 - val_loss: 0.7045 - val_accuracy: 0.6712\n",
      "Epoch 304/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8064 - accuracy: 0.7544 - val_loss: 0.7253 - val_accuracy: 0.6522\n",
      "Epoch 305/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8105 - accuracy: 0.7556 - val_loss: 0.6915 - val_accuracy: 0.6880\n",
      "Epoch 306/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7994 - accuracy: 0.7538 - val_loss: 0.6374 - val_accuracy: 0.7370\n",
      "Epoch 307/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8091 - accuracy: 0.7501 - val_loss: 0.6810 - val_accuracy: 0.7057\n",
      "Epoch 308/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8045 - accuracy: 0.7701 - val_loss: 0.7401 - val_accuracy: 0.6428\n",
      "Epoch 309/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8002 - accuracy: 0.7632 - val_loss: 0.7565 - val_accuracy: 0.6342\n",
      "Epoch 310/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8010 - accuracy: 0.7460 - val_loss: 0.6356 - val_accuracy: 0.7502\n",
      "Epoch 311/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8017 - accuracy: 0.7571 - val_loss: 0.6996 - val_accuracy: 0.6877\n",
      "Epoch 312/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7917 - accuracy: 0.7561 - val_loss: 0.6718 - val_accuracy: 0.7225\n",
      "Epoch 313/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7942 - accuracy: 0.7632 - val_loss: 0.6496 - val_accuracy: 0.7375\n",
      "Epoch 314/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8037 - accuracy: 0.7655 - val_loss: 0.7856 - val_accuracy: 0.6018\n",
      "Epoch 315/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8156 - accuracy: 0.7474 - val_loss: 0.6967 - val_accuracy: 0.6770\n",
      "Epoch 316/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8000 - accuracy: 0.7560 - val_loss: 0.6609 - val_accuracy: 0.7262\n",
      "Epoch 317/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8178 - accuracy: 0.7606 - val_loss: 0.8119 - val_accuracy: 0.5767\n",
      "Epoch 318/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8119 - accuracy: 0.7385 - val_loss: 0.6310 - val_accuracy: 0.7657\n",
      "Epoch 319/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8027 - accuracy: 0.7667 - val_loss: 0.7615 - val_accuracy: 0.6215\n",
      "Epoch 320/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7928 - accuracy: 0.7617 - val_loss: 0.6869 - val_accuracy: 0.6925\n",
      "Epoch 321/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7895 - accuracy: 0.7716 - val_loss: 0.7179 - val_accuracy: 0.6655\n",
      "Epoch 322/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7902 - accuracy: 0.7554 - val_loss: 0.6471 - val_accuracy: 0.7412\n",
      "Epoch 323/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7900 - accuracy: 0.7673 - val_loss: 0.7506 - val_accuracy: 0.6450\n",
      "Epoch 324/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7861 - accuracy: 0.7602 - val_loss: 0.6633 - val_accuracy: 0.7207\n",
      "Epoch 325/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7803 - accuracy: 0.7753 - val_loss: 0.7149 - val_accuracy: 0.6697\n",
      "Epoch 326/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7871 - accuracy: 0.7607 - val_loss: 0.7147 - val_accuracy: 0.6823\n",
      "Epoch 327/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7941 - accuracy: 0.7640 - val_loss: 0.7535 - val_accuracy: 0.6492\n",
      "Epoch 328/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.8009 - accuracy: 0.7482 - val_loss: 0.6303 - val_accuracy: 0.7560\n",
      "Epoch 329/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7980 - accuracy: 0.7598 - val_loss: 0.7040 - val_accuracy: 0.6848\n",
      "Epoch 330/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7894 - accuracy: 0.7693 - val_loss: 0.7709 - val_accuracy: 0.6395\n",
      "Epoch 331/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7976 - accuracy: 0.7467 - val_loss: 0.6330 - val_accuracy: 0.7515\n",
      "Epoch 332/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7859 - accuracy: 0.7713 - val_loss: 0.6991 - val_accuracy: 0.6933\n",
      "Epoch 333/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7820 - accuracy: 0.7690 - val_loss: 0.7309 - val_accuracy: 0.6675\n",
      "Epoch 334/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7833 - accuracy: 0.7618 - val_loss: 0.6749 - val_accuracy: 0.7247\n",
      "Epoch 335/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7769 - accuracy: 0.7592 - val_loss: 0.7102 - val_accuracy: 0.6768\n",
      "Epoch 336/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7841 - accuracy: 0.7722 - val_loss: 0.6907 - val_accuracy: 0.6988\n",
      "Epoch 337/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7868 - accuracy: 0.7521 - val_loss: 0.6549 - val_accuracy: 0.7445\n",
      "Epoch 338/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7863 - accuracy: 0.7720 - val_loss: 0.7389 - val_accuracy: 0.6535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 339/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7906 - accuracy: 0.7619 - val_loss: 0.7263 - val_accuracy: 0.6755\n",
      "Epoch 340/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7949 - accuracy: 0.7555 - val_loss: 0.6874 - val_accuracy: 0.7168\n",
      "Epoch 341/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7877 - accuracy: 0.7773 - val_loss: 0.7381 - val_accuracy: 0.6553\n",
      "Epoch 342/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7882 - accuracy: 0.7642 - val_loss: 0.7225 - val_accuracy: 0.6702\n",
      "Epoch 343/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7839 - accuracy: 0.7652 - val_loss: 0.7376 - val_accuracy: 0.6615\n",
      "Epoch 344/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7871 - accuracy: 0.7577 - val_loss: 0.6889 - val_accuracy: 0.7160\n",
      "Epoch 345/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7837 - accuracy: 0.7709 - val_loss: 0.7177 - val_accuracy: 0.6665\n",
      "Epoch 346/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7772 - accuracy: 0.7606 - val_loss: 0.6854 - val_accuracy: 0.7092\n",
      "Epoch 347/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7875 - accuracy: 0.7541 - val_loss: 0.6688 - val_accuracy: 0.7295\n",
      "Epoch 348/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7848 - accuracy: 0.7653 - val_loss: 0.6691 - val_accuracy: 0.7255\n",
      "Epoch 349/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7789 - accuracy: 0.7671 - val_loss: 0.7212 - val_accuracy: 0.6837\n",
      "Epoch 350/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7694 - accuracy: 0.7738 - val_loss: 0.7389 - val_accuracy: 0.6650\n",
      "Epoch 351/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7642 - accuracy: 0.7661 - val_loss: 0.6752 - val_accuracy: 0.7160\n",
      "Epoch 352/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7759 - accuracy: 0.7711 - val_loss: 0.7441 - val_accuracy: 0.6605\n",
      "Epoch 353/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7726 - accuracy: 0.7619 - val_loss: 0.6673 - val_accuracy: 0.7370\n",
      "Epoch 354/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7811 - accuracy: 0.7739 - val_loss: 0.7714 - val_accuracy: 0.6380\n",
      "Epoch 355/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7798 - accuracy: 0.7552 - val_loss: 0.6721 - val_accuracy: 0.7410\n",
      "Epoch 356/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7675 - accuracy: 0.7706 - val_loss: 0.7150 - val_accuracy: 0.6992\n",
      "Epoch 357/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7730 - accuracy: 0.7667 - val_loss: 0.7083 - val_accuracy: 0.7065\n",
      "Epoch 358/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7702 - accuracy: 0.7708 - val_loss: 0.7156 - val_accuracy: 0.6750\n",
      "Epoch 359/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7665 - accuracy: 0.7744 - val_loss: 0.7121 - val_accuracy: 0.6877\n",
      "Epoch 360/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7725 - accuracy: 0.7584 - val_loss: 0.6490 - val_accuracy: 0.7412\n",
      "Epoch 361/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7748 - accuracy: 0.7749 - val_loss: 0.7604 - val_accuracy: 0.6453\n",
      "Epoch 362/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.7784 - accuracy: 0.7713 - val_loss: 0.6852 - val_accuracy: 0.7163\n",
      "Epoch 363/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7694 - accuracy: 0.7612 - val_loss: 0.7158 - val_accuracy: 0.6902\n",
      "Epoch 364/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7653 - accuracy: 0.7744 - val_loss: 0.6684 - val_accuracy: 0.7315\n",
      "Epoch 365/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7684 - accuracy: 0.7645 - val_loss: 0.6884 - val_accuracy: 0.7050\n",
      "Epoch 366/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7724 - accuracy: 0.7646 - val_loss: 0.6859 - val_accuracy: 0.7212\n",
      "Epoch 367/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7764 - accuracy: 0.7583 - val_loss: 0.6744 - val_accuracy: 0.7280\n",
      "Epoch 368/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7774 - accuracy: 0.7771 - val_loss: 0.7583 - val_accuracy: 0.6518\n",
      "Epoch 369/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.7714 - accuracy: 0.7644 - val_loss: 0.6533 - val_accuracy: 0.7412\n",
      "Epoch 370/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7734 - accuracy: 0.7694 - val_loss: 0.7441 - val_accuracy: 0.6685\n",
      "Epoch 371/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7670 - accuracy: 0.7712 - val_loss: 0.7310 - val_accuracy: 0.6980\n",
      "Epoch 372/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7598 - accuracy: 0.7694 - val_loss: 0.7367 - val_accuracy: 0.6715\n",
      "Epoch 373/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7609 - accuracy: 0.7741 - val_loss: 0.7160 - val_accuracy: 0.6942\n",
      "Epoch 374/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7658 - accuracy: 0.7621 - val_loss: 0.6504 - val_accuracy: 0.7475\n",
      "Epoch 375/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7571 - accuracy: 0.7731 - val_loss: 0.6894 - val_accuracy: 0.7180\n",
      "Epoch 376/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7675 - accuracy: 0.7611 - val_loss: 0.6451 - val_accuracy: 0.7520\n",
      "Epoch 377/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7751 - accuracy: 0.7737 - val_loss: 0.7866 - val_accuracy: 0.6400\n",
      "Epoch 378/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7734 - accuracy: 0.7612 - val_loss: 0.6743 - val_accuracy: 0.7325\n",
      "Epoch 379/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7700 - accuracy: 0.7742 - val_loss: 0.7496 - val_accuracy: 0.6615\n",
      "Epoch 380/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7583 - accuracy: 0.7759 - val_loss: 0.7230 - val_accuracy: 0.6923\n",
      "Epoch 381/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7556 - accuracy: 0.7735 - val_loss: 0.7578 - val_accuracy: 0.6455\n",
      "Epoch 382/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7561 - accuracy: 0.7663 - val_loss: 0.6677 - val_accuracy: 0.7437\n",
      "Epoch 383/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7687 - accuracy: 0.7819 - val_loss: 0.7611 - val_accuracy: 0.6450\n",
      "Epoch 384/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7589 - accuracy: 0.7607 - val_loss: 0.6901 - val_accuracy: 0.7290\n",
      "Epoch 385/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7531 - accuracy: 0.7702 - val_loss: 0.6983 - val_accuracy: 0.7110\n",
      "Epoch 386/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7479 - accuracy: 0.7807 - val_loss: 0.7128 - val_accuracy: 0.6935\n",
      "Epoch 387/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7574 - accuracy: 0.7774 - val_loss: 0.7645 - val_accuracy: 0.6515\n",
      "Epoch 388/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7697 - accuracy: 0.7639 - val_loss: 0.6934 - val_accuracy: 0.7320\n",
      "Epoch 389/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7756 - accuracy: 0.7650 - val_loss: 0.7015 - val_accuracy: 0.7088\n",
      "Epoch 390/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7766 - accuracy: 0.7731 - val_loss: 0.7387 - val_accuracy: 0.6662\n",
      "Epoch 391/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7840 - accuracy: 0.7499 - val_loss: 0.6345 - val_accuracy: 0.7548\n",
      "Epoch 392/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7723 - accuracy: 0.7709 - val_loss: 0.7289 - val_accuracy: 0.6787\n",
      "Epoch 393/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7620 - accuracy: 0.7725 - val_loss: 0.7172 - val_accuracy: 0.6695\n",
      "Epoch 394/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7484 - accuracy: 0.7722 - val_loss: 0.6934 - val_accuracy: 0.7107\n",
      "Epoch 395/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7467 - accuracy: 0.7810 - val_loss: 0.7249 - val_accuracy: 0.6795\n",
      "Epoch 396/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7488 - accuracy: 0.7744 - val_loss: 0.6994 - val_accuracy: 0.7168\n",
      "Epoch 397/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7393 - accuracy: 0.7849 - val_loss: 0.7253 - val_accuracy: 0.6808\n",
      "Epoch 398/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7449 - accuracy: 0.7731 - val_loss: 0.6905 - val_accuracy: 0.7172\n",
      "Epoch 399/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7584 - accuracy: 0.7718 - val_loss: 0.6937 - val_accuracy: 0.7085\n",
      "Epoch 400/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7504 - accuracy: 0.7770 - val_loss: 0.7650 - val_accuracy: 0.6500\n",
      "Epoch 401/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7524 - accuracy: 0.7794 - val_loss: 0.7280 - val_accuracy: 0.6900\n",
      "Epoch 402/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7589 - accuracy: 0.7613 - val_loss: 0.6621 - val_accuracy: 0.7490\n",
      "Epoch 403/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7667 - accuracy: 0.7734 - val_loss: 0.7811 - val_accuracy: 0.6550\n",
      "Epoch 404/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7583 - accuracy: 0.7778 - val_loss: 0.7938 - val_accuracy: 0.6170\n",
      "Epoch 405/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7662 - accuracy: 0.7515 - val_loss: 0.6571 - val_accuracy: 0.7648\n",
      "Epoch 406/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7594 - accuracy: 0.7800 - val_loss: 0.7580 - val_accuracy: 0.6607\n",
      "Epoch 407/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7483 - accuracy: 0.7716 - val_loss: 0.7018 - val_accuracy: 0.7103\n",
      "Epoch 408/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7456 - accuracy: 0.7827 - val_loss: 0.7699 - val_accuracy: 0.6440\n",
      "Epoch 409/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7430 - accuracy: 0.7721 - val_loss: 0.6509 - val_accuracy: 0.7640\n",
      "Epoch 410/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7479 - accuracy: 0.7825 - val_loss: 0.7674 - val_accuracy: 0.6610\n",
      "Epoch 411/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7486 - accuracy: 0.7772 - val_loss: 0.7113 - val_accuracy: 0.7157\n",
      "Epoch 412/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7481 - accuracy: 0.7717 - val_loss: 0.6767 - val_accuracy: 0.7423\n",
      "Epoch 413/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7487 - accuracy: 0.7663 - val_loss: 0.6781 - val_accuracy: 0.7315\n",
      "Epoch 414/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7474 - accuracy: 0.7814 - val_loss: 0.7382 - val_accuracy: 0.6862\n",
      "Epoch 415/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7463 - accuracy: 0.7862 - val_loss: 0.7712 - val_accuracy: 0.6550\n",
      "Epoch 416/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7409 - accuracy: 0.7746 - val_loss: 0.7120 - val_accuracy: 0.7113\n",
      "Epoch 417/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7370 - accuracy: 0.7776 - val_loss: 0.7643 - val_accuracy: 0.6612\n",
      "Epoch 418/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7339 - accuracy: 0.7836 - val_loss: 0.7081 - val_accuracy: 0.7048\n",
      "Epoch 419/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7315 - accuracy: 0.7826 - val_loss: 0.7278 - val_accuracy: 0.6957\n",
      "Epoch 420/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7296 - accuracy: 0.7826 - val_loss: 0.7142 - val_accuracy: 0.7045\n",
      "Epoch 421/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7329 - accuracy: 0.7787 - val_loss: 0.7570 - val_accuracy: 0.6765\n",
      "Epoch 422/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7320 - accuracy: 0.7824 - val_loss: 0.7159 - val_accuracy: 0.6990\n",
      "Epoch 423/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7265 - accuracy: 0.7897 - val_loss: 0.7567 - val_accuracy: 0.6618\n",
      "Epoch 424/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7274 - accuracy: 0.7836 - val_loss: 0.6904 - val_accuracy: 0.7327\n",
      "Epoch 425/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7315 - accuracy: 0.7722 - val_loss: 0.7378 - val_accuracy: 0.6920\n",
      "Epoch 426/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7341 - accuracy: 0.7946 - val_loss: 0.7771 - val_accuracy: 0.6532\n",
      "Epoch 427/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7256 - accuracy: 0.7736 - val_loss: 0.6936 - val_accuracy: 0.7250\n",
      "Epoch 428/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7341 - accuracy: 0.7740 - val_loss: 0.7677 - val_accuracy: 0.6712\n",
      "Epoch 429/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7376 - accuracy: 0.7864 - val_loss: 0.7428 - val_accuracy: 0.6812\n",
      "Epoch 430/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7344 - accuracy: 0.7742 - val_loss: 0.6890 - val_accuracy: 0.7358\n",
      "Epoch 431/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7352 - accuracy: 0.7748 - val_loss: 0.7032 - val_accuracy: 0.7423\n",
      "Epoch 432/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7281 - accuracy: 0.7893 - val_loss: 0.7763 - val_accuracy: 0.6600\n",
      "Epoch 433/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7269 - accuracy: 0.7778 - val_loss: 0.6758 - val_accuracy: 0.7517\n",
      "Epoch 434/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7472 - accuracy: 0.7707 - val_loss: 0.7180 - val_accuracy: 0.7243\n",
      "Epoch 435/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7339 - accuracy: 0.7837 - val_loss: 0.7109 - val_accuracy: 0.7085\n",
      "Epoch 436/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7271 - accuracy: 0.7809 - val_loss: 0.7296 - val_accuracy: 0.7057\n",
      "Epoch 437/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7285 - accuracy: 0.7832 - val_loss: 0.7458 - val_accuracy: 0.6833\n",
      "Epoch 438/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7157 - accuracy: 0.7871 - val_loss: 0.7301 - val_accuracy: 0.6970\n",
      "Epoch 439/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7163 - accuracy: 0.7811 - val_loss: 0.6687 - val_accuracy: 0.7585\n",
      "Epoch 440/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7163 - accuracy: 0.7935 - val_loss: 0.7415 - val_accuracy: 0.7015\n",
      "Epoch 441/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7210 - accuracy: 0.7894 - val_loss: 0.7385 - val_accuracy: 0.6855\n",
      "Epoch 442/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.7320 - accuracy: 0.7790 - val_loss: 0.7515 - val_accuracy: 0.6837\n",
      "Epoch 443/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7323 - accuracy: 0.7798 - val_loss: 0.7446 - val_accuracy: 0.6920\n",
      "Epoch 444/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7394 - accuracy: 0.7757 - val_loss: 0.7554 - val_accuracy: 0.6963\n",
      "Epoch 445/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7384 - accuracy: 0.7755 - val_loss: 0.7124 - val_accuracy: 0.7258\n",
      "Epoch 446/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7371 - accuracy: 0.7819 - val_loss: 0.7573 - val_accuracy: 0.7000\n",
      "Epoch 447/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7463 - accuracy: 0.7601 - val_loss: 0.6852 - val_accuracy: 0.7678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7560 - accuracy: 0.7809 - val_loss: 0.8241 - val_accuracy: 0.6277\n",
      "Epoch 449/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7415 - accuracy: 0.7711 - val_loss: 0.6715 - val_accuracy: 0.7638\n",
      "Epoch 450/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7370 - accuracy: 0.7771 - val_loss: 0.8326 - val_accuracy: 0.6208\n",
      "Epoch 451/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7311 - accuracy: 0.7785 - val_loss: 0.6808 - val_accuracy: 0.7548\n",
      "Epoch 452/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7303 - accuracy: 0.7730 - val_loss: 0.7232 - val_accuracy: 0.7178\n",
      "Epoch 453/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7272 - accuracy: 0.7828 - val_loss: 0.7279 - val_accuracy: 0.7165\n",
      "Epoch 454/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7287 - accuracy: 0.7780 - val_loss: 0.7681 - val_accuracy: 0.6823\n",
      "Epoch 455/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7241 - accuracy: 0.7913 - val_loss: 0.7442 - val_accuracy: 0.6885\n",
      "Epoch 456/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7090 - accuracy: 0.7833 - val_loss: 0.6999 - val_accuracy: 0.7440\n",
      "Epoch 457/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7152 - accuracy: 0.7999 - val_loss: 0.8273 - val_accuracy: 0.6150\n",
      "Epoch 458/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7326 - accuracy: 0.7582 - val_loss: 0.6759 - val_accuracy: 0.7630\n",
      "Epoch 459/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7307 - accuracy: 0.8016 - val_loss: 0.8048 - val_accuracy: 0.6280\n",
      "Epoch 460/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7156 - accuracy: 0.7770 - val_loss: 0.7466 - val_accuracy: 0.6938\n",
      "Epoch 461/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7108 - accuracy: 0.7878 - val_loss: 0.7241 - val_accuracy: 0.7197\n",
      "Epoch 462/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7154 - accuracy: 0.7921 - val_loss: 0.7409 - val_accuracy: 0.7168\n",
      "Epoch 463/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7080 - accuracy: 0.7921 - val_loss: 0.7534 - val_accuracy: 0.6888\n",
      "Epoch 464/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7162 - accuracy: 0.7762 - val_loss: 0.6873 - val_accuracy: 0.7523\n",
      "Epoch 465/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7205 - accuracy: 0.7946 - val_loss: 0.8033 - val_accuracy: 0.6453\n",
      "Epoch 466/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7156 - accuracy: 0.7810 - val_loss: 0.7273 - val_accuracy: 0.7165\n",
      "Epoch 467/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7073 - accuracy: 0.7856 - val_loss: 0.6953 - val_accuracy: 0.7465\n",
      "Epoch 468/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7156 - accuracy: 0.7938 - val_loss: 0.8154 - val_accuracy: 0.6305\n",
      "Epoch 469/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7249 - accuracy: 0.7721 - val_loss: 0.7013 - val_accuracy: 0.7333\n",
      "Epoch 470/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7226 - accuracy: 0.7856 - val_loss: 0.7346 - val_accuracy: 0.7100\n",
      "Epoch 471/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7193 - accuracy: 0.7940 - val_loss: 0.8204 - val_accuracy: 0.6480\n",
      "Epoch 472/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7311 - accuracy: 0.7750 - val_loss: 0.7312 - val_accuracy: 0.7170\n",
      "Epoch 473/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7294 - accuracy: 0.7856 - val_loss: 0.7380 - val_accuracy: 0.6998\n",
      "Epoch 474/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7177 - accuracy: 0.7807 - val_loss: 0.7121 - val_accuracy: 0.7150\n",
      "Epoch 475/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7234 - accuracy: 0.7821 - val_loss: 0.7803 - val_accuracy: 0.6655\n",
      "Epoch 476/1000\n",
      "16000/16000 [==============================] - ETA: 0s - loss: 0.7423 - accuracy: 0.75 - 0s 3us/step - loss: 0.7248 - accuracy: 0.7839 - val_loss: 0.7332 - val_accuracy: 0.7017\n",
      "Epoch 477/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7183 - accuracy: 0.7881 - val_loss: 0.7635 - val_accuracy: 0.7078\n",
      "Epoch 478/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7113 - accuracy: 0.7928 - val_loss: 0.7344 - val_accuracy: 0.7050\n",
      "Epoch 479/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7035 - accuracy: 0.7877 - val_loss: 0.7225 - val_accuracy: 0.7347\n",
      "Epoch 480/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7058 - accuracy: 0.7934 - val_loss: 0.7756 - val_accuracy: 0.6888\n",
      "Epoch 481/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7033 - accuracy: 0.7968 - val_loss: 0.7468 - val_accuracy: 0.7057\n",
      "Epoch 482/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7048 - accuracy: 0.7819 - val_loss: 0.7742 - val_accuracy: 0.6888\n",
      "Epoch 483/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7113 - accuracy: 0.7933 - val_loss: 0.8107 - val_accuracy: 0.6610\n",
      "Epoch 484/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7115 - accuracy: 0.7855 - val_loss: 0.7749 - val_accuracy: 0.6827\n",
      "Epoch 485/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7020 - accuracy: 0.7922 - val_loss: 0.7409 - val_accuracy: 0.7190\n",
      "Epoch 486/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7013 - accuracy: 0.7865 - val_loss: 0.7571 - val_accuracy: 0.7085\n",
      "Epoch 487/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7111 - accuracy: 0.7963 - val_loss: 0.7764 - val_accuracy: 0.6925\n",
      "Epoch 488/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7062 - accuracy: 0.7841 - val_loss: 0.7534 - val_accuracy: 0.6923\n",
      "Epoch 489/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6968 - accuracy: 0.7902 - val_loss: 0.7345 - val_accuracy: 0.7308\n",
      "Epoch 490/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6997 - accuracy: 0.8042 - val_loss: 0.7975 - val_accuracy: 0.6525\n",
      "Epoch 491/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7089 - accuracy: 0.7856 - val_loss: 0.7176 - val_accuracy: 0.7290\n",
      "Epoch 492/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6981 - accuracy: 0.7871 - val_loss: 0.7422 - val_accuracy: 0.7200\n",
      "Epoch 493/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7059 - accuracy: 0.7937 - val_loss: 0.7615 - val_accuracy: 0.6923\n",
      "Epoch 494/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7052 - accuracy: 0.7867 - val_loss: 0.8014 - val_accuracy: 0.6840\n",
      "Epoch 495/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7092 - accuracy: 0.7922 - val_loss: 0.7258 - val_accuracy: 0.7312\n",
      "Epoch 496/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6993 - accuracy: 0.7872 - val_loss: 0.7552 - val_accuracy: 0.6902\n",
      "Epoch 497/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7221 - accuracy: 0.7811 - val_loss: 0.6675 - val_accuracy: 0.7682\n",
      "Epoch 498/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7322 - accuracy: 0.7697 - val_loss: 0.7674 - val_accuracy: 0.7005\n",
      "Epoch 499/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7147 - accuracy: 0.7958 - val_loss: 0.7707 - val_accuracy: 0.6827\n",
      "Epoch 500/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.7215 - accuracy: 0.7710 - val_loss: 0.7515 - val_accuracy: 0.7188\n",
      "Epoch 501/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7243 - accuracy: 0.7914 - val_loss: 0.8367 - val_accuracy: 0.6317\n",
      "Epoch 502/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7202 - accuracy: 0.7805 - val_loss: 0.7237 - val_accuracy: 0.7287\n",
      "Epoch 503/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7108 - accuracy: 0.7972 - val_loss: 0.8893 - val_accuracy: 0.6018\n",
      "Epoch 504/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7211 - accuracy: 0.7671 - val_loss: 0.7179 - val_accuracy: 0.7437\n",
      "Epoch 505/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7079 - accuracy: 0.7957 - val_loss: 0.7811 - val_accuracy: 0.6908\n",
      "Epoch 506/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6996 - accuracy: 0.7862 - val_loss: 0.6947 - val_accuracy: 0.7650\n",
      "Epoch 507/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6946 - accuracy: 0.7946 - val_loss: 0.7339 - val_accuracy: 0.7293\n",
      "Epoch 508/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6989 - accuracy: 0.8003 - val_loss: 0.7832 - val_accuracy: 0.6860\n",
      "Epoch 509/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6937 - accuracy: 0.7831 - val_loss: 0.7088 - val_accuracy: 0.7565\n",
      "Epoch 510/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6931 - accuracy: 0.7970 - val_loss: 0.7917 - val_accuracy: 0.6817\n",
      "Epoch 511/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.6948 - accuracy: 0.7941 - val_loss: 0.7324 - val_accuracy: 0.7228\n",
      "Epoch 512/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6935 - accuracy: 0.7905 - val_loss: 0.8113 - val_accuracy: 0.6683\n",
      "Epoch 513/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6974 - accuracy: 0.7920 - val_loss: 0.7557 - val_accuracy: 0.7092\n",
      "Epoch 514/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7005 - accuracy: 0.7976 - val_loss: 0.7596 - val_accuracy: 0.7185\n",
      "Epoch 515/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6902 - accuracy: 0.7941 - val_loss: 0.7422 - val_accuracy: 0.7220\n",
      "Epoch 516/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6926 - accuracy: 0.7947 - val_loss: 0.7207 - val_accuracy: 0.7502\n",
      "Epoch 517/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6959 - accuracy: 0.7927 - val_loss: 0.8415 - val_accuracy: 0.6440\n",
      "Epoch 518/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7056 - accuracy: 0.7838 - val_loss: 0.7028 - val_accuracy: 0.7467\n",
      "Epoch 519/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7095 - accuracy: 0.7836 - val_loss: 0.7592 - val_accuracy: 0.7115\n",
      "Epoch 520/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7030 - accuracy: 0.7947 - val_loss: 0.7638 - val_accuracy: 0.6940\n",
      "Epoch 521/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6929 - accuracy: 0.7895 - val_loss: 0.7567 - val_accuracy: 0.7120\n",
      "Epoch 522/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6990 - accuracy: 0.7936 - val_loss: 0.8202 - val_accuracy: 0.6485\n",
      "Epoch 523/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6959 - accuracy: 0.7927 - val_loss: 0.8021 - val_accuracy: 0.6720\n",
      "Epoch 524/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6971 - accuracy: 0.7833 - val_loss: 0.7147 - val_accuracy: 0.7538\n",
      "Epoch 525/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6980 - accuracy: 0.7953 - val_loss: 0.7514 - val_accuracy: 0.7170\n",
      "Epoch 526/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7050 - accuracy: 0.7880 - val_loss: 0.7684 - val_accuracy: 0.7165\n",
      "Epoch 527/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7162 - accuracy: 0.7772 - val_loss: 0.7564 - val_accuracy: 0.7063\n",
      "Epoch 528/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7139 - accuracy: 0.7920 - val_loss: 0.8058 - val_accuracy: 0.6553\n",
      "Epoch 529/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6948 - accuracy: 0.7798 - val_loss: 0.7480 - val_accuracy: 0.7125\n",
      "Epoch 530/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6975 - accuracy: 0.7971 - val_loss: 0.8080 - val_accuracy: 0.6660\n",
      "Epoch 531/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6882 - accuracy: 0.7931 - val_loss: 0.7303 - val_accuracy: 0.7240\n",
      "Epoch 532/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6810 - accuracy: 0.7986 - val_loss: 0.7718 - val_accuracy: 0.6982\n",
      "Epoch 533/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6857 - accuracy: 0.7933 - val_loss: 0.7322 - val_accuracy: 0.7312\n",
      "Epoch 534/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6868 - accuracy: 0.7997 - val_loss: 0.8039 - val_accuracy: 0.6662\n",
      "Epoch 535/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6866 - accuracy: 0.7892 - val_loss: 0.7341 - val_accuracy: 0.7408\n",
      "Epoch 536/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6845 - accuracy: 0.8048 - val_loss: 0.7654 - val_accuracy: 0.7222\n",
      "Epoch 537/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6783 - accuracy: 0.7966 - val_loss: 0.7121 - val_accuracy: 0.7607\n",
      "Epoch 538/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6930 - accuracy: 0.7970 - val_loss: 0.8295 - val_accuracy: 0.6485\n",
      "Epoch 539/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6848 - accuracy: 0.7925 - val_loss: 0.7357 - val_accuracy: 0.7380\n",
      "Epoch 540/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6773 - accuracy: 0.8043 - val_loss: 0.8186 - val_accuracy: 0.6633\n",
      "Epoch 541/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6758 - accuracy: 0.7958 - val_loss: 0.7494 - val_accuracy: 0.7255\n",
      "Epoch 542/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6739 - accuracy: 0.7985 - val_loss: 0.7786 - val_accuracy: 0.6938\n",
      "Epoch 543/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6763 - accuracy: 0.8048 - val_loss: 0.8412 - val_accuracy: 0.6545\n",
      "Epoch 544/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6763 - accuracy: 0.7978 - val_loss: 0.7652 - val_accuracy: 0.7115\n",
      "Epoch 545/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6771 - accuracy: 0.7943 - val_loss: 0.7219 - val_accuracy: 0.7582\n",
      "Epoch 546/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6867 - accuracy: 0.7984 - val_loss: 0.8283 - val_accuracy: 0.6597\n",
      "Epoch 547/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6815 - accuracy: 0.7989 - val_loss: 0.7575 - val_accuracy: 0.7175\n",
      "Epoch 548/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6709 - accuracy: 0.7975 - val_loss: 0.8228 - val_accuracy: 0.6650\n",
      "Epoch 549/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6731 - accuracy: 0.8023 - val_loss: 0.7817 - val_accuracy: 0.6992\n",
      "Epoch 550/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6741 - accuracy: 0.7945 - val_loss: 0.7605 - val_accuracy: 0.7275\n",
      "Epoch 551/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6704 - accuracy: 0.8020 - val_loss: 0.8145 - val_accuracy: 0.6675\n",
      "Epoch 552/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.6726 - accuracy: 0.7989 - val_loss: 0.7355 - val_accuracy: 0.7375\n",
      "Epoch 553/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6840 - accuracy: 0.7891 - val_loss: 0.7746 - val_accuracy: 0.7125\n",
      "Epoch 554/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6903 - accuracy: 0.7995 - val_loss: 0.8105 - val_accuracy: 0.6793\n",
      "Epoch 555/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6996 - accuracy: 0.7834 - val_loss: 0.7442 - val_accuracy: 0.7360\n",
      "Epoch 556/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6918 - accuracy: 0.8023 - val_loss: 0.7793 - val_accuracy: 0.7030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 557/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6921 - accuracy: 0.7849 - val_loss: 0.7589 - val_accuracy: 0.7343\n",
      "Epoch 558/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6879 - accuracy: 0.8086 - val_loss: 0.8600 - val_accuracy: 0.6438\n",
      "Epoch 559/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6964 - accuracy: 0.7791 - val_loss: 0.7334 - val_accuracy: 0.7455\n",
      "Epoch 560/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6796 - accuracy: 0.7978 - val_loss: 0.7673 - val_accuracy: 0.7143\n",
      "Epoch 561/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6746 - accuracy: 0.8086 - val_loss: 0.8040 - val_accuracy: 0.6873\n",
      "Epoch 562/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6793 - accuracy: 0.7891 - val_loss: 0.7265 - val_accuracy: 0.7588\n",
      "Epoch 563/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6729 - accuracy: 0.8095 - val_loss: 0.8365 - val_accuracy: 0.6568\n",
      "Epoch 564/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6665 - accuracy: 0.7986 - val_loss: 0.8177 - val_accuracy: 0.6727\n",
      "Epoch 565/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6804 - accuracy: 0.7979 - val_loss: 0.8057 - val_accuracy: 0.6892\n",
      "Epoch 566/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6830 - accuracy: 0.7918 - val_loss: 0.7711 - val_accuracy: 0.7180\n",
      "Epoch 567/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6681 - accuracy: 0.7964 - val_loss: 0.7391 - val_accuracy: 0.7592\n",
      "Epoch 568/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6740 - accuracy: 0.8004 - val_loss: 0.7492 - val_accuracy: 0.7460\n",
      "Epoch 569/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6716 - accuracy: 0.8084 - val_loss: 0.8368 - val_accuracy: 0.6475\n",
      "Epoch 570/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6744 - accuracy: 0.7939 - val_loss: 0.7263 - val_accuracy: 0.7540\n",
      "Epoch 571/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6793 - accuracy: 0.7995 - val_loss: 0.8145 - val_accuracy: 0.6697\n",
      "Epoch 572/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6790 - accuracy: 0.8018 - val_loss: 0.7363 - val_accuracy: 0.7567\n",
      "Epoch 573/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6827 - accuracy: 0.7937 - val_loss: 0.7704 - val_accuracy: 0.7175\n",
      "Epoch 574/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6765 - accuracy: 0.8021 - val_loss: 0.8062 - val_accuracy: 0.6952\n",
      "Epoch 575/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6719 - accuracy: 0.7909 - val_loss: 0.7531 - val_accuracy: 0.7372\n",
      "Epoch 576/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6676 - accuracy: 0.8001 - val_loss: 0.8059 - val_accuracy: 0.6880\n",
      "Epoch 577/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6665 - accuracy: 0.8096 - val_loss: 0.7775 - val_accuracy: 0.7113\n",
      "Epoch 578/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6600 - accuracy: 0.8032 - val_loss: 0.7937 - val_accuracy: 0.7155\n",
      "Epoch 579/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6622 - accuracy: 0.8091 - val_loss: 0.7984 - val_accuracy: 0.7040\n",
      "Epoch 580/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6642 - accuracy: 0.7997 - val_loss: 0.7724 - val_accuracy: 0.7197\n",
      "Epoch 581/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6656 - accuracy: 0.8048 - val_loss: 0.8122 - val_accuracy: 0.7005\n",
      "Epoch 582/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6640 - accuracy: 0.7990 - val_loss: 0.7717 - val_accuracy: 0.7163\n",
      "Epoch 583/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6534 - accuracy: 0.8124 - val_loss: 0.8462 - val_accuracy: 0.6660\n",
      "Epoch 584/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6667 - accuracy: 0.7954 - val_loss: 0.7478 - val_accuracy: 0.7455\n",
      "Epoch 585/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6609 - accuracy: 0.8099 - val_loss: 0.8049 - val_accuracy: 0.6915\n",
      "Epoch 586/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6691 - accuracy: 0.7941 - val_loss: 0.7660 - val_accuracy: 0.7433\n",
      "Epoch 587/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6641 - accuracy: 0.8091 - val_loss: 0.7704 - val_accuracy: 0.7285\n",
      "Epoch 588/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6660 - accuracy: 0.8023 - val_loss: 0.7973 - val_accuracy: 0.7188\n",
      "Epoch 589/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6648 - accuracy: 0.8063 - val_loss: 0.7590 - val_accuracy: 0.7330\n",
      "Epoch 590/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6681 - accuracy: 0.7952 - val_loss: 0.7645 - val_accuracy: 0.7398\n",
      "Epoch 591/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6667 - accuracy: 0.8025 - val_loss: 0.8264 - val_accuracy: 0.6898\n",
      "Epoch 592/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6660 - accuracy: 0.7978 - val_loss: 0.7634 - val_accuracy: 0.7455\n",
      "Epoch 593/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6673 - accuracy: 0.8023 - val_loss: 0.8086 - val_accuracy: 0.6930\n",
      "Epoch 594/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6749 - accuracy: 0.7927 - val_loss: 0.7566 - val_accuracy: 0.7427\n",
      "Epoch 595/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6747 - accuracy: 0.8027 - val_loss: 0.7763 - val_accuracy: 0.7280\n",
      "Epoch 596/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6763 - accuracy: 0.8032 - val_loss: 0.7881 - val_accuracy: 0.7095\n",
      "Epoch 597/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6773 - accuracy: 0.7966 - val_loss: 0.7931 - val_accuracy: 0.7188\n",
      "Epoch 598/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6758 - accuracy: 0.8038 - val_loss: 0.8670 - val_accuracy: 0.6373\n",
      "Epoch 599/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6670 - accuracy: 0.7984 - val_loss: 0.7788 - val_accuracy: 0.7090\n",
      "Epoch 600/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6521 - accuracy: 0.8071 - val_loss: 0.8219 - val_accuracy: 0.6708\n",
      "Epoch 601/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6664 - accuracy: 0.7986 - val_loss: 0.7580 - val_accuracy: 0.7415\n",
      "Epoch 602/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6728 - accuracy: 0.8018 - val_loss: 0.7666 - val_accuracy: 0.7402\n",
      "Epoch 603/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6849 - accuracy: 0.7966 - val_loss: 0.7579 - val_accuracy: 0.7275\n",
      "Epoch 604/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6683 - accuracy: 0.8014 - val_loss: 0.7754 - val_accuracy: 0.7205\n",
      "Epoch 605/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6739 - accuracy: 0.8007 - val_loss: 0.8023 - val_accuracy: 0.7030\n",
      "Epoch 606/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6661 - accuracy: 0.8038 - val_loss: 0.8073 - val_accuracy: 0.6892\n",
      "Epoch 607/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6728 - accuracy: 0.7953 - val_loss: 0.7581 - val_accuracy: 0.7495\n",
      "Epoch 608/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6761 - accuracy: 0.8112 - val_loss: 0.9388 - val_accuracy: 0.6085\n",
      "Epoch 609/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6902 - accuracy: 0.7931 - val_loss: 0.7861 - val_accuracy: 0.7150\n",
      "Epoch 610/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6621 - accuracy: 0.7948 - val_loss: 0.7859 - val_accuracy: 0.7312\n",
      "Epoch 611/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6652 - accuracy: 0.8046 - val_loss: 0.8428 - val_accuracy: 0.6610\n",
      "Epoch 612/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6548 - accuracy: 0.8055 - val_loss: 0.7957 - val_accuracy: 0.7212\n",
      "Epoch 613/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.6530 - accuracy: 0.8056 - val_loss: 0.7798 - val_accuracy: 0.7300\n",
      "Epoch 614/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.6498 - accuracy: 0.8095 - val_loss: 0.7531 - val_accuracy: 0.7642\n",
      "Epoch 615/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6545 - accuracy: 0.8008 - val_loss: 0.7695 - val_accuracy: 0.7502\n",
      "Epoch 616/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6510 - accuracy: 0.8165 - val_loss: 0.8731 - val_accuracy: 0.6565\n",
      "Epoch 617/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6619 - accuracy: 0.7989 - val_loss: 0.7694 - val_accuracy: 0.7325\n",
      "Epoch 618/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6514 - accuracy: 0.8055 - val_loss: 0.7977 - val_accuracy: 0.7147\n",
      "Epoch 619/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6433 - accuracy: 0.8067 - val_loss: 0.7838 - val_accuracy: 0.7325\n",
      "Epoch 620/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6482 - accuracy: 0.8162 - val_loss: 0.7851 - val_accuracy: 0.7473\n",
      "Epoch 621/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6550 - accuracy: 0.8016 - val_loss: 0.7775 - val_accuracy: 0.7390\n",
      "Epoch 622/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6517 - accuracy: 0.8125 - val_loss: 0.8026 - val_accuracy: 0.7130\n",
      "Epoch 623/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6554 - accuracy: 0.8081 - val_loss: 0.8454 - val_accuracy: 0.6830\n",
      "Epoch 624/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6595 - accuracy: 0.8086 - val_loss: 0.8632 - val_accuracy: 0.6590\n",
      "Epoch 625/1000\n",
      "16000/16000 [==============================] - 0s 6us/step - loss: 0.6520 - accuracy: 0.8018 - val_loss: 0.8212 - val_accuracy: 0.7205\n",
      "Epoch 626/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6681 - accuracy: 0.8035 - val_loss: 0.8532 - val_accuracy: 0.6708\n",
      "Epoch 627/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6836 - accuracy: 0.7920 - val_loss: 0.7673 - val_accuracy: 0.7268\n",
      "Epoch 628/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6907 - accuracy: 0.7954 - val_loss: 0.7754 - val_accuracy: 0.7487\n",
      "Epoch 629/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.7167 - accuracy: 0.7834 - val_loss: 0.8092 - val_accuracy: 0.7030\n",
      "Epoch 630/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6927 - accuracy: 0.7912 - val_loss: 0.8629 - val_accuracy: 0.6495\n",
      "Epoch 631/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6985 - accuracy: 0.7929 - val_loss: 0.7421 - val_accuracy: 0.7515\n",
      "Epoch 632/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6959 - accuracy: 0.7845 - val_loss: 0.8135 - val_accuracy: 0.7055\n",
      "Epoch 633/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6944 - accuracy: 0.8009 - val_loss: 0.8452 - val_accuracy: 0.6775\n",
      "Epoch 634/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6850 - accuracy: 0.7856 - val_loss: 0.7591 - val_accuracy: 0.7442\n",
      "Epoch 635/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6818 - accuracy: 0.8022 - val_loss: 0.8226 - val_accuracy: 0.6898\n",
      "Epoch 636/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6731 - accuracy: 0.7996 - val_loss: 0.7630 - val_accuracy: 0.7585\n",
      "Epoch 637/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6711 - accuracy: 0.7987 - val_loss: 0.8162 - val_accuracy: 0.7163\n",
      "Epoch 638/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6637 - accuracy: 0.8060 - val_loss: 0.7927 - val_accuracy: 0.7258\n",
      "Epoch 639/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6654 - accuracy: 0.7997 - val_loss: 0.7899 - val_accuracy: 0.7460\n",
      "Epoch 640/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6579 - accuracy: 0.8130 - val_loss: 0.8796 - val_accuracy: 0.6488\n",
      "Epoch 641/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6604 - accuracy: 0.8019 - val_loss: 0.8003 - val_accuracy: 0.7300\n",
      "Epoch 642/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6515 - accuracy: 0.8072 - val_loss: 0.8394 - val_accuracy: 0.6780\n",
      "Epoch 643/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6592 - accuracy: 0.8051 - val_loss: 0.7901 - val_accuracy: 0.7215\n",
      "Epoch 644/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6559 - accuracy: 0.8031 - val_loss: 0.8008 - val_accuracy: 0.7170\n",
      "Epoch 645/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6478 - accuracy: 0.8106 - val_loss: 0.7824 - val_accuracy: 0.7355\n",
      "Epoch 646/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6580 - accuracy: 0.8068 - val_loss: 0.7941 - val_accuracy: 0.7275\n",
      "Epoch 647/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6463 - accuracy: 0.8124 - val_loss: 0.7871 - val_accuracy: 0.7393\n",
      "Epoch 648/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6521 - accuracy: 0.8055 - val_loss: 0.8262 - val_accuracy: 0.6998\n",
      "Epoch 649/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6426 - accuracy: 0.8086 - val_loss: 0.8099 - val_accuracy: 0.7212\n",
      "Epoch 650/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6395 - accuracy: 0.8057 - val_loss: 0.7486 - val_accuracy: 0.7732\n",
      "Epoch 651/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6420 - accuracy: 0.8098 - val_loss: 0.7557 - val_accuracy: 0.7620\n",
      "Epoch 652/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6452 - accuracy: 0.8107 - val_loss: 0.7934 - val_accuracy: 0.7305\n",
      "Epoch 653/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6343 - accuracy: 0.8166 - val_loss: 0.8151 - val_accuracy: 0.7003\n",
      "Epoch 654/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6428 - accuracy: 0.8069 - val_loss: 0.8292 - val_accuracy: 0.7045\n",
      "Epoch 655/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6383 - accuracy: 0.8148 - val_loss: 0.8032 - val_accuracy: 0.7218\n",
      "Epoch 656/1000\n",
      "16000/16000 [==============================] - 0s 2us/step - loss: 0.6433 - accuracy: 0.8066 - val_loss: 0.7773 - val_accuracy: 0.7495\n",
      "Epoch 657/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6490 - accuracy: 0.8077 - val_loss: 0.7903 - val_accuracy: 0.7410\n",
      "Epoch 658/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6464 - accuracy: 0.8126 - val_loss: 0.8180 - val_accuracy: 0.7145\n",
      "Epoch 659/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6387 - accuracy: 0.8110 - val_loss: 0.8261 - val_accuracy: 0.7020\n",
      "Epoch 660/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6401 - accuracy: 0.8096 - val_loss: 0.7983 - val_accuracy: 0.7352\n",
      "Epoch 661/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6453 - accuracy: 0.8191 - val_loss: 0.8926 - val_accuracy: 0.6495\n",
      "Epoch 662/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6427 - accuracy: 0.8106 - val_loss: 0.8309 - val_accuracy: 0.7082\n",
      "Epoch 663/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6403 - accuracy: 0.8071 - val_loss: 0.8017 - val_accuracy: 0.7212\n",
      "Epoch 664/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6303 - accuracy: 0.8163 - val_loss: 0.8319 - val_accuracy: 0.6988\n",
      "Epoch 665/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6311 - accuracy: 0.8135 - val_loss: 0.8021 - val_accuracy: 0.7295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 666/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6285 - accuracy: 0.8124 - val_loss: 0.8061 - val_accuracy: 0.7203\n",
      "Epoch 667/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6347 - accuracy: 0.8138 - val_loss: 0.8360 - val_accuracy: 0.7207\n",
      "Epoch 668/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6388 - accuracy: 0.8118 - val_loss: 0.8123 - val_accuracy: 0.7117\n",
      "Epoch 669/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6290 - accuracy: 0.8219 - val_loss: 0.8652 - val_accuracy: 0.6747\n",
      "Epoch 670/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6532 - accuracy: 0.8039 - val_loss: 0.7972 - val_accuracy: 0.7350\n",
      "Epoch 671/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.6634 - accuracy: 0.7951 - val_loss: 0.7863 - val_accuracy: 0.7660\n",
      "Epoch 672/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6686 - accuracy: 0.8052 - val_loss: 0.9222 - val_accuracy: 0.6768\n",
      "Epoch 673/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6734 - accuracy: 0.8034 - val_loss: 0.8216 - val_accuracy: 0.7325\n",
      "Epoch 674/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6661 - accuracy: 0.8021 - val_loss: 0.7957 - val_accuracy: 0.7440\n",
      "Epoch 675/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6543 - accuracy: 0.8075 - val_loss: 0.8207 - val_accuracy: 0.7193\n",
      "Epoch 676/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6541 - accuracy: 0.8023 - val_loss: 0.7966 - val_accuracy: 0.7437\n",
      "Epoch 677/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6414 - accuracy: 0.8134 - val_loss: 0.8346 - val_accuracy: 0.7190\n",
      "Epoch 678/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6392 - accuracy: 0.8120 - val_loss: 0.7895 - val_accuracy: 0.7270\n",
      "Epoch 679/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6485 - accuracy: 0.8110 - val_loss: 0.8552 - val_accuracy: 0.6850\n",
      "Epoch 680/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6459 - accuracy: 0.8117 - val_loss: 0.8277 - val_accuracy: 0.7063\n",
      "Epoch 681/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6315 - accuracy: 0.8132 - val_loss: 0.7860 - val_accuracy: 0.7473\n",
      "Epoch 682/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6328 - accuracy: 0.8114 - val_loss: 0.8116 - val_accuracy: 0.7218\n",
      "Epoch 683/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.6360 - accuracy: 0.8177 - val_loss: 0.8338 - val_accuracy: 0.7128\n",
      "Epoch 684/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6367 - accuracy: 0.8071 - val_loss: 0.7991 - val_accuracy: 0.7335\n",
      "Epoch 685/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6352 - accuracy: 0.8134 - val_loss: 0.7843 - val_accuracy: 0.7450\n",
      "Epoch 686/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6387 - accuracy: 0.8139 - val_loss: 0.8328 - val_accuracy: 0.7053\n",
      "Epoch 687/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6370 - accuracy: 0.8139 - val_loss: 0.9040 - val_accuracy: 0.6568\n",
      "Epoch 688/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6323 - accuracy: 0.8134 - val_loss: 0.8070 - val_accuracy: 0.7350\n",
      "Epoch 689/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6313 - accuracy: 0.8033 - val_loss: 0.7537 - val_accuracy: 0.7732\n",
      "Epoch 690/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6584 - accuracy: 0.8075 - val_loss: 0.8721 - val_accuracy: 0.6873\n",
      "Epoch 691/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6500 - accuracy: 0.8100 - val_loss: 0.8268 - val_accuracy: 0.7088\n",
      "Epoch 692/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6501 - accuracy: 0.8025 - val_loss: 0.7989 - val_accuracy: 0.7375\n",
      "Epoch 693/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6434 - accuracy: 0.8059 - val_loss: 0.7909 - val_accuracy: 0.7395\n",
      "Epoch 694/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6436 - accuracy: 0.8129 - val_loss: 0.8762 - val_accuracy: 0.6802\n",
      "Epoch 695/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6465 - accuracy: 0.8109 - val_loss: 0.8219 - val_accuracy: 0.7215\n",
      "Epoch 696/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.6349 - accuracy: 0.8065 - val_loss: 0.7431 - val_accuracy: 0.7925\n",
      "Epoch 697/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.6412 - accuracy: 0.8124 - val_loss: 0.8516 - val_accuracy: 0.6920\n",
      "Epoch 698/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6442 - accuracy: 0.8165 - val_loss: 0.8564 - val_accuracy: 0.6883\n",
      "Epoch 699/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6493 - accuracy: 0.8058 - val_loss: 0.8101 - val_accuracy: 0.7545\n",
      "Epoch 700/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6442 - accuracy: 0.8081 - val_loss: 0.8294 - val_accuracy: 0.7182\n",
      "Epoch 701/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6434 - accuracy: 0.8131 - val_loss: 0.8218 - val_accuracy: 0.7228\n",
      "Epoch 702/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6386 - accuracy: 0.8152 - val_loss: 0.8084 - val_accuracy: 0.7345\n",
      "Epoch 703/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6366 - accuracy: 0.8094 - val_loss: 0.7939 - val_accuracy: 0.7648\n",
      "Epoch 704/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6351 - accuracy: 0.8176 - val_loss: 0.8530 - val_accuracy: 0.7010\n",
      "Epoch 705/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6250 - accuracy: 0.8136 - val_loss: 0.8060 - val_accuracy: 0.7320\n",
      "Epoch 706/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6263 - accuracy: 0.8146 - val_loss: 0.8169 - val_accuracy: 0.7492\n",
      "Epoch 707/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6315 - accuracy: 0.8208 - val_loss: 0.8847 - val_accuracy: 0.6597\n",
      "Epoch 708/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6332 - accuracy: 0.8047 - val_loss: 0.8089 - val_accuracy: 0.7300\n",
      "Epoch 709/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6231 - accuracy: 0.8179 - val_loss: 0.8352 - val_accuracy: 0.7128\n",
      "Epoch 710/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6285 - accuracy: 0.8130 - val_loss: 0.7833 - val_accuracy: 0.7645\n",
      "Epoch 711/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6161 - accuracy: 0.8206 - val_loss: 0.8151 - val_accuracy: 0.7368\n",
      "Epoch 712/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6215 - accuracy: 0.8220 - val_loss: 0.9245 - val_accuracy: 0.6435\n",
      "Epoch 713/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6416 - accuracy: 0.8068 - val_loss: 0.8123 - val_accuracy: 0.7347\n",
      "Epoch 714/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6347 - accuracy: 0.8054 - val_loss: 0.8092 - val_accuracy: 0.7582\n",
      "Epoch 715/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6240 - accuracy: 0.8248 - val_loss: 0.8601 - val_accuracy: 0.6960\n",
      "Epoch 716/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6275 - accuracy: 0.8119 - val_loss: 0.7760 - val_accuracy: 0.7710\n",
      "Epoch 717/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6307 - accuracy: 0.8170 - val_loss: 0.8233 - val_accuracy: 0.7295\n",
      "Epoch 718/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6278 - accuracy: 0.8267 - val_loss: 0.8467 - val_accuracy: 0.7053\n",
      "Epoch 719/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6206 - accuracy: 0.8129 - val_loss: 0.8300 - val_accuracy: 0.7370\n",
      "Epoch 720/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6200 - accuracy: 0.8196 - val_loss: 0.8539 - val_accuracy: 0.7105\n",
      "Epoch 721/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6324 - accuracy: 0.8186 - val_loss: 0.8667 - val_accuracy: 0.6880\n",
      "Epoch 722/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6240 - accuracy: 0.8064 - val_loss: 0.7972 - val_accuracy: 0.7570\n",
      "Epoch 723/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6272 - accuracy: 0.8115 - val_loss: 0.7826 - val_accuracy: 0.7617\n",
      "Epoch 724/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6249 - accuracy: 0.8177 - val_loss: 0.8243 - val_accuracy: 0.7360\n",
      "Epoch 725/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6123 - accuracy: 0.8261 - val_loss: 0.8398 - val_accuracy: 0.7020\n",
      "Epoch 726/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6076 - accuracy: 0.8213 - val_loss: 0.8070 - val_accuracy: 0.7470\n",
      "Epoch 727/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6051 - accuracy: 0.8241 - val_loss: 0.8416 - val_accuracy: 0.7188\n",
      "Epoch 728/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6090 - accuracy: 0.8196 - val_loss: 0.8570 - val_accuracy: 0.7237\n",
      "Epoch 729/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6225 - accuracy: 0.8149 - val_loss: 0.7860 - val_accuracy: 0.7648\n",
      "Epoch 730/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6183 - accuracy: 0.8164 - val_loss: 0.8240 - val_accuracy: 0.7210\n",
      "Epoch 731/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6218 - accuracy: 0.8209 - val_loss: 0.8979 - val_accuracy: 0.6762\n",
      "Epoch 732/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6084 - accuracy: 0.8229 - val_loss: 0.8129 - val_accuracy: 0.7517\n",
      "Epoch 733/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6250 - accuracy: 0.8111 - val_loss: 0.7984 - val_accuracy: 0.7527\n",
      "Epoch 734/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6225 - accuracy: 0.8173 - val_loss: 0.8343 - val_accuracy: 0.7235\n",
      "Epoch 735/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6132 - accuracy: 0.8208 - val_loss: 0.8356 - val_accuracy: 0.7305\n",
      "Epoch 736/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6128 - accuracy: 0.8216 - val_loss: 0.8170 - val_accuracy: 0.7405\n",
      "Epoch 737/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6098 - accuracy: 0.8202 - val_loss: 0.8505 - val_accuracy: 0.7228\n",
      "Epoch 738/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6164 - accuracy: 0.8203 - val_loss: 0.8046 - val_accuracy: 0.7545\n",
      "Epoch 739/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6161 - accuracy: 0.8222 - val_loss: 0.8864 - val_accuracy: 0.6902\n",
      "Epoch 740/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6178 - accuracy: 0.8194 - val_loss: 0.8277 - val_accuracy: 0.7408\n",
      "Epoch 741/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6191 - accuracy: 0.8179 - val_loss: 0.8108 - val_accuracy: 0.7628\n",
      "Epoch 742/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6219 - accuracy: 0.8159 - val_loss: 0.8149 - val_accuracy: 0.7465\n",
      "Epoch 743/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6195 - accuracy: 0.8189 - val_loss: 0.8375 - val_accuracy: 0.7442\n",
      "Epoch 744/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6188 - accuracy: 0.8238 - val_loss: 0.8515 - val_accuracy: 0.7212\n",
      "Epoch 745/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6206 - accuracy: 0.8165 - val_loss: 0.8151 - val_accuracy: 0.7462\n",
      "Epoch 746/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6309 - accuracy: 0.8126 - val_loss: 0.8363 - val_accuracy: 0.7305\n",
      "Epoch 747/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6095 - accuracy: 0.8240 - val_loss: 0.8731 - val_accuracy: 0.7013\n",
      "Epoch 748/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6121 - accuracy: 0.8211 - val_loss: 0.8638 - val_accuracy: 0.7107\n",
      "Epoch 749/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6093 - accuracy: 0.8213 - val_loss: 0.8326 - val_accuracy: 0.7423\n",
      "Epoch 750/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6070 - accuracy: 0.8261 - val_loss: 0.8608 - val_accuracy: 0.7078\n",
      "Epoch 751/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6166 - accuracy: 0.8191 - val_loss: 0.8591 - val_accuracy: 0.7203\n",
      "Epoch 752/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6229 - accuracy: 0.8151 - val_loss: 0.8798 - val_accuracy: 0.6902\n",
      "Epoch 753/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6155 - accuracy: 0.8181 - val_loss: 0.8416 - val_accuracy: 0.7210\n",
      "Epoch 754/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6069 - accuracy: 0.8146 - val_loss: 0.8382 - val_accuracy: 0.7110\n",
      "Epoch 755/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6113 - accuracy: 0.8258 - val_loss: 0.8797 - val_accuracy: 0.6865\n",
      "Epoch 756/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6207 - accuracy: 0.8179 - val_loss: 0.8642 - val_accuracy: 0.7247\n",
      "Epoch 757/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6154 - accuracy: 0.8181 - val_loss: 0.8253 - val_accuracy: 0.7220\n",
      "Epoch 758/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6146 - accuracy: 0.8240 - val_loss: 0.8357 - val_accuracy: 0.7368\n",
      "Epoch 759/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6230 - accuracy: 0.8112 - val_loss: 0.7918 - val_accuracy: 0.7625\n",
      "Epoch 760/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6107 - accuracy: 0.8229 - val_loss: 0.8170 - val_accuracy: 0.7502\n",
      "Epoch 761/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6129 - accuracy: 0.8191 - val_loss: 0.8617 - val_accuracy: 0.7042\n",
      "Epoch 762/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6106 - accuracy: 0.8270 - val_loss: 0.8879 - val_accuracy: 0.6837\n",
      "Epoch 763/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6109 - accuracy: 0.8166 - val_loss: 0.8344 - val_accuracy: 0.7333\n",
      "Epoch 764/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6025 - accuracy: 0.8239 - val_loss: 0.8464 - val_accuracy: 0.7230\n",
      "Epoch 765/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6078 - accuracy: 0.8193 - val_loss: 0.8517 - val_accuracy: 0.7138\n",
      "Epoch 766/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6064 - accuracy: 0.8244 - val_loss: 0.8492 - val_accuracy: 0.7178\n",
      "Epoch 767/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6050 - accuracy: 0.8192 - val_loss: 0.8088 - val_accuracy: 0.7623\n",
      "Epoch 768/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6145 - accuracy: 0.8172 - val_loss: 0.8583 - val_accuracy: 0.7250\n",
      "Epoch 769/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6238 - accuracy: 0.8200 - val_loss: 0.9008 - val_accuracy: 0.6785\n",
      "Epoch 770/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.6089 - accuracy: 0.8247 - val_loss: 0.8936 - val_accuracy: 0.6980\n",
      "Epoch 771/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6155 - accuracy: 0.8080 - val_loss: 0.7785 - val_accuracy: 0.7930\n",
      "Epoch 772/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6236 - accuracy: 0.8176 - val_loss: 0.8525 - val_accuracy: 0.7230\n",
      "Epoch 773/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6062 - accuracy: 0.8285 - val_loss: 0.9404 - val_accuracy: 0.6575\n",
      "Epoch 774/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6139 - accuracy: 0.8249 - val_loss: 0.8837 - val_accuracy: 0.6992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 775/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6196 - accuracy: 0.8145 - val_loss: 0.8719 - val_accuracy: 0.6990\n",
      "Epoch 776/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6170 - accuracy: 0.8181 - val_loss: 0.8512 - val_accuracy: 0.7218\n",
      "Epoch 777/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6161 - accuracy: 0.8149 - val_loss: 0.8598 - val_accuracy: 0.7163\n",
      "Epoch 778/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6187 - accuracy: 0.8238 - val_loss: 0.8576 - val_accuracy: 0.7125\n",
      "Epoch 779/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6267 - accuracy: 0.8166 - val_loss: 0.8267 - val_accuracy: 0.7440\n",
      "Epoch 780/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6092 - accuracy: 0.8225 - val_loss: 0.8438 - val_accuracy: 0.7387\n",
      "Epoch 781/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6111 - accuracy: 0.8237 - val_loss: 0.8712 - val_accuracy: 0.7220\n",
      "Epoch 782/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6047 - accuracy: 0.8231 - val_loss: 0.8758 - val_accuracy: 0.7215\n",
      "Epoch 783/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6112 - accuracy: 0.8213 - val_loss: 0.8467 - val_accuracy: 0.7283\n",
      "Epoch 784/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6006 - accuracy: 0.8255 - val_loss: 0.8682 - val_accuracy: 0.7197\n",
      "Epoch 785/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6014 - accuracy: 0.8246 - val_loss: 0.8952 - val_accuracy: 0.6845\n",
      "Epoch 786/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6084 - accuracy: 0.8249 - val_loss: 0.9192 - val_accuracy: 0.6750\n",
      "Epoch 787/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6193 - accuracy: 0.8171 - val_loss: 0.9166 - val_accuracy: 0.6770\n",
      "Epoch 788/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6142 - accuracy: 0.8131 - val_loss: 0.8755 - val_accuracy: 0.7197\n",
      "Epoch 789/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6141 - accuracy: 0.8233 - val_loss: 0.9401 - val_accuracy: 0.6945\n",
      "Epoch 790/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6115 - accuracy: 0.8167 - val_loss: 0.8653 - val_accuracy: 0.7320\n",
      "Epoch 791/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6012 - accuracy: 0.8245 - val_loss: 0.8530 - val_accuracy: 0.7393\n",
      "Epoch 792/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6054 - accuracy: 0.8215 - val_loss: 0.8482 - val_accuracy: 0.7290\n",
      "Epoch 793/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6041 - accuracy: 0.8302 - val_loss: 0.9428 - val_accuracy: 0.6702\n",
      "Epoch 794/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6050 - accuracy: 0.8149 - val_loss: 0.8224 - val_accuracy: 0.7632\n",
      "Epoch 795/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6072 - accuracy: 0.8287 - val_loss: 0.9127 - val_accuracy: 0.6890\n",
      "Epoch 796/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6074 - accuracy: 0.8180 - val_loss: 0.8369 - val_accuracy: 0.7523\n",
      "Epoch 797/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6061 - accuracy: 0.8197 - val_loss: 0.8323 - val_accuracy: 0.7545\n",
      "Epoch 798/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6028 - accuracy: 0.8217 - val_loss: 0.8210 - val_accuracy: 0.7588\n",
      "Epoch 799/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6053 - accuracy: 0.8273 - val_loss: 0.9143 - val_accuracy: 0.7055\n",
      "Epoch 800/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6093 - accuracy: 0.8172 - val_loss: 0.8164 - val_accuracy: 0.7598\n",
      "Epoch 801/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6101 - accuracy: 0.8270 - val_loss: 0.9503 - val_accuracy: 0.6923\n",
      "Epoch 802/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6255 - accuracy: 0.8176 - val_loss: 0.9147 - val_accuracy: 0.6785\n",
      "Epoch 803/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6248 - accuracy: 0.8131 - val_loss: 0.8756 - val_accuracy: 0.7410\n",
      "Epoch 804/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6229 - accuracy: 0.8142 - val_loss: 0.8675 - val_accuracy: 0.7253\n",
      "Epoch 805/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6113 - accuracy: 0.8268 - val_loss: 0.9065 - val_accuracy: 0.6888\n",
      "Epoch 806/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6170 - accuracy: 0.8130 - val_loss: 0.8296 - val_accuracy: 0.7617\n",
      "Epoch 807/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6231 - accuracy: 0.8145 - val_loss: 0.8486 - val_accuracy: 0.7620\n",
      "Epoch 808/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6127 - accuracy: 0.8201 - val_loss: 0.8794 - val_accuracy: 0.7055\n",
      "Epoch 809/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6156 - accuracy: 0.8234 - val_loss: 0.8772 - val_accuracy: 0.7218\n",
      "Epoch 810/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6150 - accuracy: 0.8203 - val_loss: 0.8551 - val_accuracy: 0.7487\n",
      "Epoch 811/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6036 - accuracy: 0.8199 - val_loss: 0.8278 - val_accuracy: 0.7753\n",
      "Epoch 812/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6108 - accuracy: 0.8214 - val_loss: 0.8474 - val_accuracy: 0.7595\n",
      "Epoch 813/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6117 - accuracy: 0.8169 - val_loss: 0.8631 - val_accuracy: 0.7595\n",
      "Epoch 814/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6187 - accuracy: 0.8182 - val_loss: 0.8811 - val_accuracy: 0.7327\n",
      "Epoch 815/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6043 - accuracy: 0.8308 - val_loss: 0.9179 - val_accuracy: 0.6950\n",
      "Epoch 816/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6060 - accuracy: 0.8224 - val_loss: 0.8979 - val_accuracy: 0.7253\n",
      "Epoch 817/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5929 - accuracy: 0.8259 - val_loss: 0.8978 - val_accuracy: 0.7228\n",
      "Epoch 818/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5996 - accuracy: 0.8217 - val_loss: 0.8116 - val_accuracy: 0.7740\n",
      "Epoch 819/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6056 - accuracy: 0.8219 - val_loss: 0.9061 - val_accuracy: 0.7097\n",
      "Epoch 820/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6300 - accuracy: 0.8214 - val_loss: 0.9729 - val_accuracy: 0.6518\n",
      "Epoch 821/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6335 - accuracy: 0.8109 - val_loss: 0.8748 - val_accuracy: 0.7425\n",
      "Epoch 822/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6121 - accuracy: 0.8171 - val_loss: 0.8478 - val_accuracy: 0.7580\n",
      "Epoch 823/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6048 - accuracy: 0.8298 - val_loss: 0.9209 - val_accuracy: 0.6883\n",
      "Epoch 824/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6057 - accuracy: 0.8301 - val_loss: 0.8978 - val_accuracy: 0.7065\n",
      "Epoch 825/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5956 - accuracy: 0.8204 - val_loss: 0.8641 - val_accuracy: 0.7567\n",
      "Epoch 826/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5863 - accuracy: 0.8352 - val_loss: 0.9113 - val_accuracy: 0.6852\n",
      "Epoch 827/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6000 - accuracy: 0.8242 - val_loss: 0.9168 - val_accuracy: 0.6842\n",
      "Epoch 828/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5962 - accuracy: 0.8176 - val_loss: 0.8043 - val_accuracy: 0.7822\n",
      "Epoch 829/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5906 - accuracy: 0.8343 - val_loss: 0.8584 - val_accuracy: 0.7350\n",
      "Epoch 830/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6014 - accuracy: 0.8267 - val_loss: 0.9398 - val_accuracy: 0.6745\n",
      "Epoch 831/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6146 - accuracy: 0.8183 - val_loss: 0.8412 - val_accuracy: 0.7692\n",
      "Epoch 832/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6174 - accuracy: 0.8104 - val_loss: 0.8865 - val_accuracy: 0.7222\n",
      "Epoch 833/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5994 - accuracy: 0.8311 - val_loss: 0.8560 - val_accuracy: 0.7293\n",
      "Epoch 834/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6011 - accuracy: 0.8282 - val_loss: 0.8899 - val_accuracy: 0.7193\n",
      "Epoch 835/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5967 - accuracy: 0.8196 - val_loss: 0.8532 - val_accuracy: 0.7602\n",
      "Epoch 836/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5881 - accuracy: 0.8274 - val_loss: 0.8651 - val_accuracy: 0.7390\n",
      "Epoch 837/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5904 - accuracy: 0.8296 - val_loss: 0.9685 - val_accuracy: 0.6720\n",
      "Epoch 838/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6062 - accuracy: 0.8252 - val_loss: 0.9314 - val_accuracy: 0.7032\n",
      "Epoch 839/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5937 - accuracy: 0.8246 - val_loss: 0.8392 - val_accuracy: 0.7670\n",
      "Epoch 840/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5836 - accuracy: 0.8333 - val_loss: 0.8813 - val_accuracy: 0.7275\n",
      "Epoch 841/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5898 - accuracy: 0.8274 - val_loss: 0.9533 - val_accuracy: 0.6802\n",
      "Epoch 842/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5943 - accuracy: 0.8259 - val_loss: 0.8583 - val_accuracy: 0.7502\n",
      "Epoch 843/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5951 - accuracy: 0.8216 - val_loss: 0.8782 - val_accuracy: 0.7218\n",
      "Epoch 844/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5982 - accuracy: 0.8259 - val_loss: 0.8534 - val_accuracy: 0.7458\n",
      "Epoch 845/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6062 - accuracy: 0.8282 - val_loss: 0.9718 - val_accuracy: 0.6582\n",
      "Epoch 846/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6051 - accuracy: 0.8235 - val_loss: 0.9151 - val_accuracy: 0.6888\n",
      "Epoch 847/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6253 - accuracy: 0.8062 - val_loss: 0.8308 - val_accuracy: 0.7780\n",
      "Epoch 848/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6296 - accuracy: 0.8060 - val_loss: 0.8525 - val_accuracy: 0.7563\n",
      "Epoch 849/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6287 - accuracy: 0.8211 - val_loss: 0.9307 - val_accuracy: 0.6888\n",
      "Epoch 850/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6105 - accuracy: 0.8189 - val_loss: 0.8509 - val_accuracy: 0.7490\n",
      "Epoch 851/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6040 - accuracy: 0.8260 - val_loss: 0.9988 - val_accuracy: 0.6578\n",
      "Epoch 852/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6131 - accuracy: 0.8151 - val_loss: 0.8699 - val_accuracy: 0.7585\n",
      "Epoch 853/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6277 - accuracy: 0.8230 - val_loss: 0.8967 - val_accuracy: 0.7180\n",
      "Epoch 854/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6263 - accuracy: 0.8233 - val_loss: 0.9771 - val_accuracy: 0.6685\n",
      "Epoch 855/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6050 - accuracy: 0.8185 - val_loss: 0.8858 - val_accuracy: 0.7228\n",
      "Epoch 856/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6068 - accuracy: 0.8264 - val_loss: 0.9024 - val_accuracy: 0.7193\n",
      "Epoch 857/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5965 - accuracy: 0.8263 - val_loss: 0.9581 - val_accuracy: 0.6948\n",
      "Epoch 858/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5942 - accuracy: 0.8209 - val_loss: 0.8234 - val_accuracy: 0.7565\n",
      "Epoch 859/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5911 - accuracy: 0.8368 - val_loss: 0.9431 - val_accuracy: 0.6775\n",
      "Epoch 860/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6062 - accuracy: 0.8192 - val_loss: 0.8976 - val_accuracy: 0.7082\n",
      "Epoch 861/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6203 - accuracy: 0.8174 - val_loss: 0.9057 - val_accuracy: 0.7180\n",
      "Epoch 862/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6234 - accuracy: 0.8178 - val_loss: 0.8063 - val_accuracy: 0.7595\n",
      "Epoch 863/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6154 - accuracy: 0.8211 - val_loss: 0.8753 - val_accuracy: 0.7268\n",
      "Epoch 864/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5997 - accuracy: 0.8304 - val_loss: 0.9257 - val_accuracy: 0.6827\n",
      "Epoch 865/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5960 - accuracy: 0.8247 - val_loss: 0.8507 - val_accuracy: 0.7423\n",
      "Epoch 866/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5872 - accuracy: 0.8303 - val_loss: 0.8965 - val_accuracy: 0.7268\n",
      "Epoch 867/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6000 - accuracy: 0.8257 - val_loss: 0.9033 - val_accuracy: 0.7157\n",
      "Epoch 868/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5955 - accuracy: 0.8214 - val_loss: 0.8403 - val_accuracy: 0.7655\n",
      "Epoch 869/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5848 - accuracy: 0.8278 - val_loss: 0.8493 - val_accuracy: 0.7450\n",
      "Epoch 870/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5965 - accuracy: 0.8244 - val_loss: 0.8784 - val_accuracy: 0.7343\n",
      "Epoch 871/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5756 - accuracy: 0.8359 - val_loss: 0.8780 - val_accuracy: 0.7370\n",
      "Epoch 872/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5779 - accuracy: 0.8332 - val_loss: 0.8611 - val_accuracy: 0.7368\n",
      "Epoch 873/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5763 - accuracy: 0.8339 - val_loss: 0.8843 - val_accuracy: 0.7297\n",
      "Epoch 874/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5728 - accuracy: 0.8356 - val_loss: 0.9048 - val_accuracy: 0.7103\n",
      "Epoch 875/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5789 - accuracy: 0.8248 - val_loss: 0.8562 - val_accuracy: 0.7605\n",
      "Epoch 876/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5865 - accuracy: 0.8332 - val_loss: 0.9217 - val_accuracy: 0.6933\n",
      "Epoch 877/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5866 - accuracy: 0.8278 - val_loss: 0.8190 - val_accuracy: 0.7780\n",
      "Epoch 878/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5818 - accuracy: 0.8321 - val_loss: 0.8914 - val_accuracy: 0.7330\n",
      "Epoch 879/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5792 - accuracy: 0.8314 - val_loss: 0.8466 - val_accuracy: 0.7520\n",
      "Epoch 880/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5813 - accuracy: 0.8289 - val_loss: 0.8606 - val_accuracy: 0.7498\n",
      "Epoch 881/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5721 - accuracy: 0.8353 - val_loss: 0.8977 - val_accuracy: 0.7220\n",
      "Epoch 882/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5689 - accuracy: 0.8422 - val_loss: 0.8826 - val_accuracy: 0.7253\n",
      "Epoch 883/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5742 - accuracy: 0.8299 - val_loss: 0.8318 - val_accuracy: 0.7653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 884/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5806 - accuracy: 0.8250 - val_loss: 0.8270 - val_accuracy: 0.7747\n",
      "Epoch 885/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5822 - accuracy: 0.8346 - val_loss: 0.9228 - val_accuracy: 0.7015\n",
      "Epoch 886/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5754 - accuracy: 0.8391 - val_loss: 0.9361 - val_accuracy: 0.6827\n",
      "Epoch 887/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5926 - accuracy: 0.8221 - val_loss: 0.8493 - val_accuracy: 0.7640\n",
      "Epoch 888/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5799 - accuracy: 0.8270 - val_loss: 0.8456 - val_accuracy: 0.7630\n",
      "Epoch 889/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5795 - accuracy: 0.8296 - val_loss: 0.8765 - val_accuracy: 0.7370\n",
      "Epoch 890/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5797 - accuracy: 0.8332 - val_loss: 0.9017 - val_accuracy: 0.7250\n",
      "Epoch 891/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5742 - accuracy: 0.8356 - val_loss: 0.9419 - val_accuracy: 0.6758\n",
      "Epoch 892/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5745 - accuracy: 0.8276 - val_loss: 0.8493 - val_accuracy: 0.7628\n",
      "Epoch 893/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5682 - accuracy: 0.8366 - val_loss: 0.8758 - val_accuracy: 0.7465\n",
      "Epoch 894/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5744 - accuracy: 0.8378 - val_loss: 0.8896 - val_accuracy: 0.7315\n",
      "Epoch 895/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5669 - accuracy: 0.8371 - val_loss: 0.9012 - val_accuracy: 0.7265\n",
      "Epoch 896/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5671 - accuracy: 0.8305 - val_loss: 0.8828 - val_accuracy: 0.7452\n",
      "Epoch 897/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5710 - accuracy: 0.8324 - val_loss: 0.8702 - val_accuracy: 0.7405\n",
      "Epoch 898/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5675 - accuracy: 0.8331 - val_loss: 0.8504 - val_accuracy: 0.7555\n",
      "Epoch 899/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5666 - accuracy: 0.8338 - val_loss: 0.8572 - val_accuracy: 0.7602\n",
      "Epoch 900/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5730 - accuracy: 0.8369 - val_loss: 0.8921 - val_accuracy: 0.7565\n",
      "Epoch 901/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5746 - accuracy: 0.8374 - val_loss: 0.9005 - val_accuracy: 0.7262\n",
      "Epoch 902/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5741 - accuracy: 0.8372 - val_loss: 0.8950 - val_accuracy: 0.7278\n",
      "Epoch 903/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5768 - accuracy: 0.8313 - val_loss: 0.9240 - val_accuracy: 0.7003\n",
      "Epoch 904/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5723 - accuracy: 0.8334 - val_loss: 0.8625 - val_accuracy: 0.7695\n",
      "Epoch 905/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5772 - accuracy: 0.8260 - val_loss: 0.8352 - val_accuracy: 0.7785\n",
      "Epoch 906/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.5865 - accuracy: 0.8231 - val_loss: 0.8852 - val_accuracy: 0.7465\n",
      "Epoch 907/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5831 - accuracy: 0.8421 - val_loss: 1.0254 - val_accuracy: 0.6647\n",
      "Epoch 908/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5893 - accuracy: 0.8238 - val_loss: 0.9313 - val_accuracy: 0.7245\n",
      "Epoch 909/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5813 - accuracy: 0.8292 - val_loss: 0.8834 - val_accuracy: 0.7423\n",
      "Epoch 910/1000\n",
      "16000/16000 [==============================] - 0s 6us/step - loss: 0.5761 - accuracy: 0.8361 - val_loss: 0.9266 - val_accuracy: 0.7193\n",
      "Epoch 911/1000\n",
      "16000/16000 [==============================] - 0s 6us/step - loss: 0.5736 - accuracy: 0.8282 - val_loss: 0.8813 - val_accuracy: 0.7527\n",
      "Epoch 912/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.5699 - accuracy: 0.8416 - val_loss: 0.9666 - val_accuracy: 0.6930\n",
      "Epoch 913/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5729 - accuracy: 0.8329 - val_loss: 0.8645 - val_accuracy: 0.7615\n",
      "Epoch 914/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5955 - accuracy: 0.8236 - val_loss: 0.8947 - val_accuracy: 0.7440\n",
      "Epoch 915/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5879 - accuracy: 0.8256 - val_loss: 0.9005 - val_accuracy: 0.7393\n",
      "Epoch 916/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5826 - accuracy: 0.8356 - val_loss: 0.9967 - val_accuracy: 0.6718\n",
      "Epoch 917/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5963 - accuracy: 0.8296 - val_loss: 0.9705 - val_accuracy: 0.6945\n",
      "Epoch 918/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5958 - accuracy: 0.8142 - val_loss: 0.8560 - val_accuracy: 0.7660\n",
      "Epoch 919/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5880 - accuracy: 0.8260 - val_loss: 0.9333 - val_accuracy: 0.7308\n",
      "Epoch 920/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5797 - accuracy: 0.8377 - val_loss: 0.9613 - val_accuracy: 0.6870\n",
      "Epoch 921/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5754 - accuracy: 0.8330 - val_loss: 0.9207 - val_accuracy: 0.7355\n",
      "Epoch 922/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5793 - accuracy: 0.8275 - val_loss: 0.8569 - val_accuracy: 0.7853\n",
      "Epoch 923/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5991 - accuracy: 0.8200 - val_loss: 0.9248 - val_accuracy: 0.7180\n",
      "Epoch 924/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6028 - accuracy: 0.8351 - val_loss: 0.9863 - val_accuracy: 0.6942\n",
      "Epoch 925/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5879 - accuracy: 0.8198 - val_loss: 0.9132 - val_accuracy: 0.7548\n",
      "Epoch 926/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5682 - accuracy: 0.8394 - val_loss: 0.9355 - val_accuracy: 0.7300\n",
      "Epoch 927/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5794 - accuracy: 0.8336 - val_loss: 0.9507 - val_accuracy: 0.7182\n",
      "Epoch 928/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5823 - accuracy: 0.8334 - val_loss: 0.9737 - val_accuracy: 0.6885\n",
      "Epoch 929/1000\n",
      "16000/16000 [==============================] - 0s 4us/step - loss: 0.5746 - accuracy: 0.8285 - val_loss: 0.8820 - val_accuracy: 0.7750\n",
      "Epoch 930/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5906 - accuracy: 0.8271 - val_loss: 0.9436 - val_accuracy: 0.7185\n",
      "Epoch 931/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5834 - accuracy: 0.8419 - val_loss: 0.9902 - val_accuracy: 0.6880\n",
      "Epoch 932/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5942 - accuracy: 0.8149 - val_loss: 0.8973 - val_accuracy: 0.7533\n",
      "Epoch 933/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6037 - accuracy: 0.8257 - val_loss: 0.9496 - val_accuracy: 0.7207\n",
      "Epoch 934/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6114 - accuracy: 0.8294 - val_loss: 0.9863 - val_accuracy: 0.7000\n",
      "Epoch 935/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6031 - accuracy: 0.8150 - val_loss: 0.9042 - val_accuracy: 0.7467\n",
      "Epoch 936/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.6023 - accuracy: 0.8182 - val_loss: 0.8769 - val_accuracy: 0.7538\n",
      "Epoch 937/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5926 - accuracy: 0.8355 - val_loss: 1.0004 - val_accuracy: 0.6808\n",
      "Epoch 938/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5818 - accuracy: 0.8270 - val_loss: 0.8870 - val_accuracy: 0.7620\n",
      "Epoch 939/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5731 - accuracy: 0.8396 - val_loss: 0.9272 - val_accuracy: 0.7135\n",
      "Epoch 940/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5792 - accuracy: 0.8358 - val_loss: 0.9268 - val_accuracy: 0.7335\n",
      "Epoch 941/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5760 - accuracy: 0.8276 - val_loss: 0.8758 - val_accuracy: 0.7588\n",
      "Epoch 942/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5634 - accuracy: 0.8411 - val_loss: 0.9120 - val_accuracy: 0.7335\n",
      "Epoch 943/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5583 - accuracy: 0.8331 - val_loss: 0.8685 - val_accuracy: 0.7812\n",
      "Epoch 944/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5658 - accuracy: 0.8389 - val_loss: 0.9218 - val_accuracy: 0.7245\n",
      "Epoch 945/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5647 - accuracy: 0.8427 - val_loss: 0.9920 - val_accuracy: 0.6908\n",
      "Epoch 946/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5758 - accuracy: 0.8249 - val_loss: 0.9020 - val_accuracy: 0.7615\n",
      "Epoch 947/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5755 - accuracy: 0.8326 - val_loss: 0.9231 - val_accuracy: 0.7567\n",
      "Epoch 948/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5758 - accuracy: 0.8352 - val_loss: 0.9180 - val_accuracy: 0.7272\n",
      "Epoch 949/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5824 - accuracy: 0.8369 - val_loss: 0.9485 - val_accuracy: 0.7080\n",
      "Epoch 950/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5738 - accuracy: 0.8298 - val_loss: 0.8876 - val_accuracy: 0.7678\n",
      "Epoch 951/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5763 - accuracy: 0.8326 - val_loss: 0.9369 - val_accuracy: 0.7423\n",
      "Epoch 952/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5758 - accuracy: 0.8382 - val_loss: 0.9227 - val_accuracy: 0.7433\n",
      "Epoch 953/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5742 - accuracy: 0.8261 - val_loss: 0.8800 - val_accuracy: 0.7780\n",
      "Epoch 954/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5705 - accuracy: 0.8410 - val_loss: 0.9726 - val_accuracy: 0.7060\n",
      "Epoch 955/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5634 - accuracy: 0.8399 - val_loss: 0.9724 - val_accuracy: 0.7042\n",
      "Epoch 956/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5690 - accuracy: 0.8298 - val_loss: 0.9308 - val_accuracy: 0.7385\n",
      "Epoch 957/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5657 - accuracy: 0.8365 - val_loss: 0.9715 - val_accuracy: 0.7230\n",
      "Epoch 958/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5609 - accuracy: 0.8417 - val_loss: 0.9518 - val_accuracy: 0.7240\n",
      "Epoch 959/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5645 - accuracy: 0.8304 - val_loss: 0.9144 - val_accuracy: 0.7395\n",
      "Epoch 960/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5556 - accuracy: 0.8413 - val_loss: 0.9348 - val_accuracy: 0.7262\n",
      "Epoch 961/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5601 - accuracy: 0.8389 - val_loss: 0.9674 - val_accuracy: 0.7220\n",
      "Epoch 962/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5608 - accuracy: 0.8390 - val_loss: 0.9317 - val_accuracy: 0.7450\n",
      "Epoch 963/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5631 - accuracy: 0.8378 - val_loss: 0.9183 - val_accuracy: 0.7605\n",
      "Epoch 964/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5597 - accuracy: 0.8345 - val_loss: 0.9032 - val_accuracy: 0.7675\n",
      "Epoch 965/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5616 - accuracy: 0.8402 - val_loss: 0.9936 - val_accuracy: 0.6942\n",
      "Epoch 966/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5657 - accuracy: 0.8319 - val_loss: 0.9327 - val_accuracy: 0.7515\n",
      "Epoch 967/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5570 - accuracy: 0.8351 - val_loss: 0.9226 - val_accuracy: 0.7615\n",
      "Epoch 968/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5764 - accuracy: 0.8328 - val_loss: 0.9364 - val_accuracy: 0.7375\n",
      "Epoch 969/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5602 - accuracy: 0.8396 - val_loss: 0.9625 - val_accuracy: 0.7253\n",
      "Epoch 970/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5529 - accuracy: 0.8441 - val_loss: 1.0213 - val_accuracy: 0.6910\n",
      "Epoch 971/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5727 - accuracy: 0.8328 - val_loss: 0.9011 - val_accuracy: 0.7713\n",
      "Epoch 972/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5613 - accuracy: 0.8348 - val_loss: 0.9359 - val_accuracy: 0.7423\n",
      "Epoch 973/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5612 - accuracy: 0.8422 - val_loss: 0.9565 - val_accuracy: 0.7075\n",
      "Epoch 974/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5580 - accuracy: 0.8354 - val_loss: 0.9529 - val_accuracy: 0.7310\n",
      "Epoch 975/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5623 - accuracy: 0.8374 - val_loss: 0.9227 - val_accuracy: 0.7322\n",
      "Epoch 976/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5618 - accuracy: 0.8372 - val_loss: 0.9964 - val_accuracy: 0.6995\n",
      "Epoch 977/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5806 - accuracy: 0.8401 - val_loss: 0.9766 - val_accuracy: 0.6873\n",
      "Epoch 978/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5903 - accuracy: 0.8184 - val_loss: 0.9179 - val_accuracy: 0.7645\n",
      "Epoch 979/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5677 - accuracy: 0.8346 - val_loss: 0.9098 - val_accuracy: 0.7425\n",
      "Epoch 980/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5598 - accuracy: 0.8384 - val_loss: 0.8996 - val_accuracy: 0.7688\n",
      "Epoch 981/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5661 - accuracy: 0.8401 - val_loss: 0.9933 - val_accuracy: 0.7057\n",
      "Epoch 982/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5711 - accuracy: 0.8401 - val_loss: 0.9963 - val_accuracy: 0.6780\n",
      "Epoch 983/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5827 - accuracy: 0.8209 - val_loss: 0.9013 - val_accuracy: 0.7788\n",
      "Epoch 984/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5750 - accuracy: 0.8364 - val_loss: 0.9725 - val_accuracy: 0.7048\n",
      "Epoch 985/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5630 - accuracy: 0.8356 - val_loss: 0.9327 - val_accuracy: 0.7527\n",
      "Epoch 986/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5693 - accuracy: 0.8344 - val_loss: 0.9034 - val_accuracy: 0.7760\n",
      "Epoch 987/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5701 - accuracy: 0.8368 - val_loss: 1.0029 - val_accuracy: 0.7035\n",
      "Epoch 988/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5618 - accuracy: 0.8358 - val_loss: 0.8951 - val_accuracy: 0.7753\n",
      "Epoch 989/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5772 - accuracy: 0.8334 - val_loss: 0.9578 - val_accuracy: 0.7395\n",
      "Epoch 990/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5821 - accuracy: 0.8297 - val_loss: 0.9876 - val_accuracy: 0.7140\n",
      "Epoch 991/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5748 - accuracy: 0.8363 - val_loss: 1.0199 - val_accuracy: 0.6985\n",
      "Epoch 992/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5691 - accuracy: 0.8357 - val_loss: 1.0027 - val_accuracy: 0.7107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 993/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5524 - accuracy: 0.8386 - val_loss: 0.9507 - val_accuracy: 0.7385\n",
      "Epoch 994/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5584 - accuracy: 0.8434 - val_loss: 1.0041 - val_accuracy: 0.6982\n",
      "Epoch 995/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5640 - accuracy: 0.8382 - val_loss: 0.9779 - val_accuracy: 0.7207\n",
      "Epoch 996/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5617 - accuracy: 0.8311 - val_loss: 0.9559 - val_accuracy: 0.7423\n",
      "Epoch 997/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5568 - accuracy: 0.8401 - val_loss: 0.9652 - val_accuracy: 0.7255\n",
      "Epoch 998/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5575 - accuracy: 0.8411 - val_loss: 0.9477 - val_accuracy: 0.7250\n",
      "Epoch 999/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5519 - accuracy: 0.8404 - val_loss: 0.9456 - val_accuracy: 0.7285\n",
      "Epoch 1000/1000\n",
      "16000/16000 [==============================] - 0s 3us/step - loss: 0.5518 - accuracy: 0.8446 - val_loss: 0.9778 - val_accuracy: 0.7285\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1152 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "    \n",
    "direct_classifier = {}\n",
    "\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "plt.figure(figsize=(10, 16))\n",
    "epochs = [1000,1000,1000,1000,1000,1000]\n",
    "for ind,var in enumerate(variables):\n",
    "    ax = plt.subplot(3, 2, ind+1)\n",
    "    plt.subplots_adjust(hspace=0.45,wspace=0.3)\n",
    "    num_inputs = xtrain.shape[1]\n",
    "    num_outputs = ytrain.shape[1]\n",
    "    direct_classifier[var] = Sequential()\n",
    "    direct_classifier[var].add(layers.Dense(100, input_dim=num_inputs, kernel_initializer='normal', activation='relu'))\n",
    "    direct_classifier[var].add(layers.Dense(50, kernel_initializer='normal', activation='relu'))\n",
    "    direct_classifier[var].add(layers.Dense(1, kernel_initializer='normal',activation='sigmoid'))\n",
    "    \n",
    "    opt = 'adam'\n",
    "    \n",
    "    direct_classifier[var].compile(loss='binary_crossentropy', \n",
    "                     metrics = ['accuracy'],optimizer=opt)\n",
    "    \n",
    "    class_weight = {0:1,\n",
    "            1:weight_fraction[ind]} \n",
    "    \n",
    "    history = direct_classifier[var].fit(xtrain,label_train[:,ind],epochs=epochs[ind],\n",
    "               class_weight = class_weight,batch_size=2000,\n",
    "                     validation_data=(xval, label_val[:,ind]))\n",
    "    \n",
    "        \n",
    "    plt.plot(history.history['accuracy'], label='train_accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('{} (best accuracy: {:0.3f}'.format(var,history.history['val_accuracy'][-1]))\n",
    "    plt.ylim([0, 1])\n",
    "    textstr = 'Best Validation Accuracy: {:0.3f}'.format(history.history['val_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data from the validation station and scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = 'Station008_samples_to_check.xlsx'\n",
    "test_samples = pd.read_excel(filename)\n",
    "\n",
    "X_scale = x_scaler.transform(test_samples[variable_headers])\n",
    "labels = test_samples[label_headers].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the prediction for each class and then print the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for: solar:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     16944\n",
      "           1       0.00      0.00      0.00        43\n",
      "\n",
      "    accuracy                           0.99     16987\n",
      "   macro avg       0.50      0.49      0.50     16987\n",
      "weighted avg       0.99      0.99      0.99     16987\n",
      "\n",
      "Classification Report for: temp:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jmatt\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     16899\n",
      "           1       0.00      0.00      0.00        88\n",
      "\n",
      "    accuracy                           0.99     16987\n",
      "   macro avg       0.50      0.50      0.50     16987\n",
      "weighted avg       0.99      0.99      0.99     16987\n",
      "\n",
      "Classification Report for: speed:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     16899\n",
      "           1       0.00      0.00      0.00        88\n",
      "\n",
      "    accuracy                           0.99     16987\n",
      "   macro avg       0.50      0.50      0.50     16987\n",
      "weighted avg       0.99      0.99      0.99     16987\n",
      "\n",
      "Classification Report for: dir:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97     16653\n",
      "           1       0.02      0.05      0.03       334\n",
      "\n",
      "    accuracy                           0.93     16987\n",
      "   macro avg       0.50      0.50      0.50     16987\n",
      "weighted avg       0.96      0.93      0.95     16987\n",
      "\n",
      "Classification Report for: u\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.92     16653\n",
      "           1       0.01      0.08      0.02       334\n",
      "\n",
      "    accuracy                           0.86     16987\n",
      "   macro avg       0.50      0.48      0.47     16987\n",
      "weighted avg       0.96      0.86      0.91     16987\n",
      "\n",
      "Classification Report for: v\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95     16653\n",
      "           1       0.10      0.42      0.16       334\n",
      "\n",
      "    accuracy                           0.91     16987\n",
      "   macro avg       0.54      0.67      0.56     16987\n",
      "weighted avg       0.97      0.91      0.94     16987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classification_val = {}\n",
    "for ind,var in enumerate(variables):\n",
    "    print('Classification Report for: {}'.format(var))\n",
    "\n",
    "    classification_val[var] = direct_classifier[var].predict(X_scale)\n",
    "    classification_val[var] = classification_val[var]>0.5\n",
    "    print(classification_report(labels[:,ind],classification_val[var]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oddly, I did train a set of classifiers that work well, but the result was not repeatable.  This network was trained first on data that had been scaled by min/max to be between 0 and 1 but works to classify un-scaled data.  I have no explaination for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     16944\n",
      "           1       0.62      0.93      0.74        43\n",
      "\n",
      "    accuracy                           1.00     16987\n",
      "   macro avg       0.81      0.96      0.87     16987\n",
      "weighted avg       1.00      1.00      1.00     16987\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     16899\n",
      "           1       0.30      0.74      0.43        88\n",
      "\n",
      "    accuracy                           0.99     16987\n",
      "   macro avg       0.65      0.86      0.71     16987\n",
      "weighted avg       1.00      0.99      0.99     16987\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     16899\n",
      "           1       0.33      0.74      0.45        88\n",
      "\n",
      "    accuracy                           0.99     16987\n",
      "   macro avg       0.66      0.87      0.72     16987\n",
      "weighted avg       1.00      0.99      0.99     16987\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     16653\n",
      "           1       0.65      0.88      0.75       334\n",
      "\n",
      "    accuracy                           0.99     16987\n",
      "   macro avg       0.82      0.94      0.87     16987\n",
      "weighted avg       0.99      0.99      0.99     16987\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     16653\n",
      "           1       0.67      0.83      0.74       334\n",
      "\n",
      "    accuracy                           0.99     16987\n",
      "   macro avg       0.83      0.91      0.87     16987\n",
      "weighted avg       0.99      0.99      0.99     16987\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     16653\n",
      "           1       0.63      0.76      0.69       334\n",
      "\n",
      "    accuracy                           0.99     16987\n",
      "   macro avg       0.81      0.88      0.84     16987\n",
      "weighted avg       0.99      0.99      0.99     16987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import load_model\n",
    "for ind,var in enumerate(variables):\n",
    "    filename = 'dir_class_model_{}.h5'.format(var)\n",
    "    model = load_model(filename)\n",
    "    cl = model.predict(X_scale)\n",
    "    cl = cl>0.5\n",
    "    print(classification_report(labels[:,ind],cl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
